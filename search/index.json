[{"content":"坚果3，发布于2018年4月，骁龙625处理器，4G内存，安卓7.1系统。\n我手里这台，已经退役两个多月了，屏幕摔得到处是裂缝，老罗破产了，系统最后一次更新是2020年2月了，而且安卓7.1也老了一点。锤子手机其实不是太喜欢，它的特色功能我一个都不喜欢，什么one step，大爆炸，胶囊，我都用不上，当时买它只是因为便宜，性价比不错。另外，锤子的手机也不够开放，我也卸载或冻结了很多它自带的系统APP，导致系统APP卸载了，菜单还保留着，但不能点击，额，不能忍受，所以越用越不顺眼，正好换了新手机，就刷机了。\n准备工具  高通 EDL 线 （也称为 9008 线、救砖线、工程线），自行上淘宝购买（10几块的就够了，反正就用一次。淘宝上有些卖家会写着「小米工程线」，其实是同一个东西，通用的）。 QPST 线刷工具、TWRP 线刷包、底包、魔趣 ROM 等相关资源，详见：坚果手机 3 (oscar) 底包、TWRP 及相关工具  不建议自己 DIY 刷机线，type-c接口的线DIY比较复杂，用micro b的线自制还得配个转接头。所以能买就买吧。\n一、刷入 TWRP  安装 QPST 工具包中的线刷工具和驱动，打开 Qfil 软件； 进 Configuration，确保 Device Type 选了 eMMC； 拔掉数据线， 关机。等待手机彻底关机、屏幕不亮为止； 把 EDL 线插到电脑上，按住 EDL 线上的小开关把另一头插入手机。等待大概 3 秒**（注意：不长不短，掐好3秒，否则可能不能成功识别）**松手，此时电脑上的 Qfil 应该会识别到 Qualcomm HS-USB QDLoader 设备； 在 Qfil 里选择 Flat Build； 点击 Programmer 的那个 Browse，选择线刷包中的 prog_ 开头的文件； 点击 Load XML，选择工具包里的 rawprogram_unsparse.xml； 它会再次弹出选择框，点取消； 深呼吸； 点击 Download 按钮，稍等片刻，TWRP 刷入完成； 长按音量增和电源键。直到你看到白色锤子的时候松开电源键（继续按住音量减键）；直到你看到 TWRP 的时候才松开所有按键，进入 TWRP，继续进行下面的步骤。  二、刷入魔趣   进 Wipe（清除），把下面那个条条拖住向右划一下。此时电脑上已经出现手机所在的存储盘，拷贝底包和魔趣的包到手机上。\n  返回上一层，进 Install（安装），刷入底包（RADIO- 开头的那个）\n  返回上一层（不要重启），再次进安装，刷入魔趣（MK 开头的那个）\n  刷完重启，完成\n  第一次需要花费2分钟重启。\n  刷Magisk 因为Magisk V19的作者用了错的密钥生成boot.img签名，这个在大多数手机上均没问题，但是在锤子这种没有解锁Bootloader的手机来说，会导致无法解开锁屏。但是导演适配了错误密钥。所以坚果3可以刷Magisk V19；但是，Magisk V20作者密钥又重新改对了，所以目前坚果3不支持V20. 提供一个V19.3的安装包：链接:https://pan.baidu.com/s/1UgLGnM5AdpUgv4wQwBp5Wg 密码:prmf\n注意事项  由于坚果的 Bootloader 仍然会校验 boot.img 的签名，所以请勿自己刷入 Magisk 等需要改动 boot 的模块。否则会导致卡在白锤子。也不是不可以，但是要注意版本 刷机后原手机已经安装的APP还在，但由于魔趣最新包是安卓9版本，会导致软件不兼容，频繁弹出app停止运行的错误窗口。此时，需要恢复出厂设置，手机自动重启进入TWRP ,清空data分区，重启即可。 如果需要root，需要去官方下载一个apk，安装即可。 即使没有root魔趣，建设银行这类APP仍然无法运行。它会认为系统不安全，拒绝运行。所以你如果很依赖银行APP，慎重考虑下。当然，也有解决办法。  如何刷回原厂 Smartisan OS 系统  2021年了，不建议刷回去了。原厂系统已经死了。  魔趣体验 才700多M的安装包，基本没有捆绑软件，原生接近AOSP，那个丝滑流畅啊，太舒服了。原生万岁，国产流氓可耻。我都想把手里的onePlus 8刷了\n参考 https://www.mintimate.cn/2019/11/30/%E5%9D%9A%E6%9E%9C3%E5%88%B7%E9%AD%94%E8%B6%A3/\n","date":"2021-05-21","permalink":"https://iminto.github.io/post/%E5%9D%9A%E6%9E%9C3%E6%89%8B%E6%9C%BA%E5%88%B7%E9%AD%94%E8%B6%A3%E4%BD%93%E9%AA%8C/","tags":["闲扯淡"],"title":"坚果3手机刷魔趣体验"},{"content":"起因是某客户的服务器上，只要一启动server，过不了几秒就被kill，然后错误日志也看不出啥。 server是基于jvm的，怎么看一个进程被哪个进程杀死，这个可以写一篇文章了。\n自信一点，这肯定不是我们代码的问题导致JVM崩溃啊，毫无疑问是那些做安全的脚本小子搞的。\n找啊找，套路无非是crontab，mount伪装这些玩意。至于篡改ps,top隐藏进程这类，我相信大部分脚本小子也没这能力，当然了，干这一行很多都是有传承的，扛不住其所在的家族雄厚，有祖传神器也难说。 好吧，最后找到是一个放到.log目录起名为x86-64的可执行程序。是我以小人之心度君子之腹了，人家也没搞隐藏ps的操作，就是每秒钟起来杀一次占用CPU最多的程序以免影响它干活。。这心机婊，还起个这么有迷惑性的名字，我就信了你是系统文件不去碰？\ncp一份，保留备份，killall，然后分析下。vim一看，不是脚本，那就是elf喽。\nLinux下用来快速分析elf文件有几个工具，一个是readelf，一个是objdump，另外一个是ldd。 通常用ldd来分析动态加载的库，objdump用来反编译。但是这几个工具面对一些恶意文件并不总是有效。 比如对于静态编译的程序，或者变种脚本，ldd就无效了。 对于没有section table的程序，objdump也就可能无法得出结果了。\n#objdump -d ./wi ./wi: file format elf64-x86-64  因为objdump需要依赖code sections或section table，可以用readelf看看\n[root@localhost ~]# readelf -a ./wi ELF Header: Magic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 Class: ELF64 Data: 2's complement, little endian Version: 1 (current) OS/ABI: UNIX - System V ABI Version: 0 Type: EXEC (Executable file) Machine: Advanced Micro Devices X86-64 Version: 0x1 Entry point address: 0x5c9e70 Start of program headers: 64 (bytes into file) Start of section headers: 0 (bytes into file) Flags: 0x0 Size of this header: 64 (bytes) Size of program headers: 56 (bytes) Number of program headers: 3 Size of section headers: 64 (bytes) Number of section headers: 0 Section header string table index: 0 There are no sections in this file. There are no sections to group in this file. Program Headers: Type Offset VirtAddr PhysAddr FileSiz MemSiz Flags Align LOAD 0x0000000000000000 0x0000000000400000 0x0000000000400000 0x00000000001ca78b 0x00000000001ca78b R E 200000 LOAD 0x0000000000000000 0x00000000005cb000 0x00000000005cb000 0x0000000000000000 0x0000000000597d58 RW 1000 GNU_STACK 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 RW 10 There is no dynamic section in this file. There are no relocations in this file. The decoding of unwind sections for machine type Advanced Micro Devices X86-64 is not currently supported. Dynamic symbol information is not available for displaying symbols. No version information found in this file.  所以这种情况下，可以这么来，-D表示对全部文件进行反汇编，-b表示二进制，-m表示指令集架构\n[root@localhost ~]# objdump -b binary -D -m i386 ./wi ./wi: file format binary Disassembly of section .data: 00000000 \u0026lt;.data\u0026gt;: 0: 7f 45 jg 0x47 2: 4c dec %esp 3: 46 inc %esi 4: 02 01 add (%ecx),%al 6: 01 00 add %eax,(%eax) ... 10: 02 00 add (%eax),%al 12: 3e 00 01 add %al,%ds:(%ecx) 15: 00 00 add %al,(%eax)  另外，strace，gdb等工具也有一定的帮助。当然，上IDA这种大型武器就更有效了。 这只是浅尝辄止，就算dump出了这么一堆汇编代码，又有什么用，没那么容易看懂。\n我又凭啥让别人相信这东西不是个正常的二进制文件？仅仅凭它各种龌龊的隐藏行为还不够。\n所以，好端端的一个ELF可执行文件，怎么就没了section table呢？很简单，脚本小子就是喜欢玩些小把戏，很容易就想到是加壳了，Linux下最容易想到的壳就是UPX。\n[root@localhost ~]# strings ./wi |grep UPX nUPX!( $Info: This file is packed with the UPX executable packer http://upx.sf.net $ $Id: UPX 3.95 Copyright (C) 1996-2018 the UPX Team. All Rights Reserved. $ UPX!u UPX! UPX!  脚本小子做事还是毛糙，也不晓得隐藏一下壳。把它的王八壳子扒了\n[root@localhost ~]# ./upx -d wi Ultimate Packer for eXecutables Copyright (C) 1996 - 2020 UPX 3.96 Markus Oberhumer, Laszlo Molnar \u0026amp; John Reiser Jan 23rd 2020 File size Ratio Format Name -------------------- ------ ----------- ----------- 5011080 \u0026lt;- 1878380 37.48% linux/amd64 wi Unpacked 1 file.  要是脚本小子把UPX壳的信息给隐藏了，那么UPX自带的-d命令就没法脱壳了，这个时候就得用IDA了。加壳的本质就是把原来的程序的数据全部压缩加密了，在静态文件中无法分析，随着程序的执行，运行时会将代码释放到内存中。我们可以用ida远程调试test程序，找到upx自解壳后的 OEP，再把内存给dump出来，就可以实现手动脱壳了。怎样找OEP，这就得看经验了。\n脱壳之后呢，继续用strings，strace，netstat等命令做定性分析。\n其实到了这一步,strings命令已经足够分析出其行为了。\n[1;37monnection * COMMANDS 'h' hashrate, 'p' pause, 'r' resume, 's' results, 'c' connection \u0026gt;wz *ctz\u0026gt;3\u0026gt;c) :w 3 [32m|| [31m ERROR [32m|| [37m Invalid Port Use In This Range [36m'1-65535' [37me.g [31m ( ./xmrig -p 3333 ) [32m|| [31m ERROR [32m|| [37m Invalid Class You Can Use Only These Classes [36m'192.168' [32m, [36m'172' [32m, [36m'100' [32m, [36m'10' [37m e.g [31m ( ./xmrig -lan 192.168.0.1 ) [32m|| [31m ERROR [32m|| [37m Empty Or Invalid Pool Address  还能分析出是C++写的木马。想要反汇编出C++源文件，你吃屁呢。objdump得依赖debug信息才行，脚本小子再菜鸡也不会这么做啊。要C++源文件，那只能用IDA dump了，这也得出近似的源文件。\n当然了，最简单的就是直接上传到virustotal，最后得出的结果果然是一个Linux.Risk.Bitcoinminer.Tbix。\n呵呵，脚本小子。\n","date":"2021-05-17","permalink":"https://iminto.github.io/post/linux%E6%81%B6%E6%84%8Felf%E6%96%87%E4%BB%B6%E5%88%86%E6%9E%90/","tags":["Linux"],"title":"Linux恶意ELF文件分析"},{"content":"简介 keycloak是一个非常强大的权限认证系统，我们使用keycloak可以方便的实现SSO的功能。虽然keycloak底层使用的wildfly，但是提供了非常方便的Client Adapters和各种服务器进行对接，比如wildfly，tomcat，Jetty等。\n对于最流行的SpringBoot来说，keycloak有官方Adapter，只需要修改配置即可。如果非SpringBoot应用呢，那就只能使用Java Servlet Filter Adapter了。\nSpringBoot接入keycloak的例子比较多，我就不赘述了。这里只简单说明下。\n接入前的前置准备 在接入各种应用之前，需要在keycloak中做好相应的配置。一般来说需要使用下面的步骤：\n  创建新的realm\n一般来说，为了隔离不同类型的系统，我们建议为不同的client创建不同的realm。当然，如果这些client是相关联的，则可以创建在同一个realm中。\n  创建新的用户和角色。\n用户是用来登录keycloak用的，如果是不同的realm，则需要分别创建用户。用户密码也是在这一步创建的\n  添加和配置client\n这一步是非常重要的，我们需要根据应用程序的不同，配置不同的root URL，redirect URI等。\n还可以配置mapper和scope信息。\n最后，如果是服务器端的配置的话，还需要installation的一些信息。\n有了这些基本的配置之后，我们就可以准备接入应用程序了。\n  Springboot接入keycloak 引入依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.keycloak\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;keycloak-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;11.0.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;  然后配置application.yml keycloak: auth-server-url: http://localhost:8080/auth realm: wildfly public-client: true resource: product-app securityConstraints: - authRoles: # 以下路径需要user角色才能访问 - user securityCollections: # name可以随便写 - name: user-role-mappings patterns: - /users/*  至此就接入完成了，不需要编写任何代码。\n获取KeycloakSecurityContext 但是实际使用中，光能控制登陆权限还不够，业务代码中还需要能获取到当前角色，用户名等信息，这就需要用到KeycloakSecurityContext了。KeycloakSecurityContext是keycloak的上下文，我们可以从其中获取到AccessToken，IDToken，AuthorizationContext和realm信息。\nIdentity.java\nimport java.util.List; import org.keycloak.AuthorizationContext; import org.keycloak.KeycloakSecurityContext; import org.keycloak.representations.idm.authorization.Permission; /** * \u0026lt;p\u0026gt;This is a simple facade to obtain information from authenticated users. You should see usages of instances of this class when * rendering the home page (@code home.ftl). * * \u0026lt;p\u0026gt;Instances of this class are are added to models as attributes in order to make them available to templates. * * @author \u0026lt;a href=\u0026quot;mailto:psilva@redhat.com\u0026quot;\u0026gt;Pedro Igor\u0026lt;/a\u0026gt; * @see com.github.your.demo.controller.HomeController */ public class Identity { private final KeycloakSecurityContext securityContext; public Identity(KeycloakSecurityContext securityContext) { this.securityContext = securityContext; } /** * An example on how you can use the {@link org.keycloak.AuthorizationContext} to check for permissions granted by Keycloak for a particular user. * * @param name the name of the resource * @return true if user has was granted with a permission for the given resource. Otherwise, false. */ public boolean hasResourcePermission(String name) { return getAuthorizationContext().hasResourcePermission(name); } /** * An example on how you can use {@link KeycloakSecurityContext} to obtain information about user's identity. * * @return the user name */ public String getName() { return securityContext.getIdToken().getPreferredUsername(); } /** * An example on how you can use the {@link org.keycloak.AuthorizationContext} to obtain all permissions granted for a particular user. * * @return */ public List\u0026lt;Permission\u0026gt; getPermissions() { return getAuthorizationContext().getPermissions(); } /** * Returns a {@link AuthorizationContext} instance holding all permissions granted for an user. The instance is build based on * the permissions returned by Keycloak. For this particular application, we use the Entitlement API to obtain permissions for every single * resource on the server. * * @return */ private AuthorizationContext getAuthorizationContext() { return securityContext.getAuthorizationContext(); } }  使用\n@RestController public class HomeController { private Logger logger = LoggerFactory.getLogger(HomeController.class); @Autowired private JdbcTemplate jdbcTemplate; @Autowired private HttpServletRequest request; @RequestMapping(\u0026quot;/users\u0026quot;) @ResponseBody public List\u0026lt;Users\u0026gt; users() { logIdentity(); logger.info(\u0026quot;使用JdbcTemplate查询数据库\u0026quot;); String sql = \u0026quot;SELECT * FROM users \u0026quot;; List\u0026lt;Users\u0026gt; queryAllList = jdbcTemplate.query(sql, new Object[]{}, new BeanPropertyRowMapper\u0026lt;\u0026gt;(Users.class)); logger.info(\u0026quot;查询用户列表\u0026quot; + queryAllList); return queryAllList; } @RequestMapping(\u0026quot;/\u0026quot;) public String home() { return \u0026quot;Hello Docker World\u0026quot;; } private void logIdentity() { KeycloakSecurityContext context=getKeycloakSecurityContext(); if(context!=null){ Identity identity=new Identity(context); logger.info(\u0026quot;KeycloakSecurityContext identity={}\u0026quot;,identity); }else{ logger.info(\u0026quot;KeycloakSecurityContext is null\u0026quot;); } } private KeycloakSecurityContext getKeycloakSecurityContext() { return (KeycloakSecurityContext) request.getAttribute(KeycloakSecurityContext.class.getName()); } }  Identity类来自Keycloak的官方example。上面介绍的Spring Boot中的其实是隐藏的做法，adaptor自动为我们做了和Keycloak认证服务连接的事情，如果我们需要手动去处理，则需要用到Authorization Client Java API。\n添加maven依赖：\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.keycloak\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;keycloak-authz-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${KEYCLOAK_VERSION}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt;  具体使用AuthzClient可查看官方文档。\nRest接口 有了这些配置，我们基本上就可以创建一个基于spring boot和keycloak的一个rest服务了。\n假如我们为keycloak的client创建了新的用户：alice。\n第一步我们需要拿到alice的access token，则可以这样操作：\nexport access_token=$(\\ curl -X POST http://localhost:8180/auth/realms/spring-boot-quickstart/protocol/openid-connect/token \\ -H 'Authorization: Basic YXBwLWF1dGh6LXJlc3Qtc3ByaW5nYm9vdDpzZWNyZXQ=' \\ -H 'content-type: application/x-www-form-urlencoded' \\ -d 'username=alice\u0026amp;password=alice\u0026amp;grant_type=password' | jq --raw-output '.access_token' \\ )  这个命令是直接通过用户名密码的方式去keycloak服务器中拿取access_token,除了access_token，这个命令还会返回refresh_token和session state的信息。\n因为是直接和keycloak进行交换，所以keycloak的directAccessGrantsEnabled一定要设置为true。\n上面命令中的Authorization是什么值呢？\n这个值是为了防止未授权的client对keycloak服务器的非法访问，所以需要请求客户端提供client-id和对应的client-secret并且以下面的方式进行编码得到的：\nAuthorization: basic BASE64(client-id + ':' + client-secret)  access_token是JWT格式的，我们可以简单解密一下上面命令得出的token:\n{ alg: \u0026quot;RS256\u0026quot;, typ: \u0026quot;JWT\u0026quot;, kid: \u0026quot;FJ86GcF3jTbNLOco4NvZkUCIUmfYCqoqtOQeMfbhNlE\u0026quot; }. { exp: 1603614445, iat: 1603614145, jti: \u0026quot;b69c784d-5b2d-46ad-9f8d-46214add7afb\u0026quot;, iss: \u0026quot;http://localhost:8180/auth/realms/spring-boot-quickstart\u0026quot;, sub: \u0026quot;e6606d93-99f6-4829-ba99-1329be604159\u0026quot;, typ: \u0026quot;Bearer\u0026quot;, azp: \u0026quot;app-authz-springboot\u0026quot;, session_state: \u0026quot;bdc33764-fd1a-400e-9fe0-90a82f4873c1\u0026quot;, acr: \u0026quot;1\u0026quot;, allowed-origins: [ \u0026quot;http://localhost:8080\u0026quot; ], realm_access: { roles: [ \u0026quot;user\u0026quot; ] }, scope: \u0026quot;email profile\u0026quot;, email_verified: false, preferred_username: \u0026quot;alice\u0026quot; }. [signature]  有了access_token,我们就可以根据access_token去做很多事情了。\n比如：访问受限的资源：\ncurl http://localhost:8080/api/resourcea \\ -H \u0026quot;Authorization: Bearer \u0026quot;$access_token  这里的api/resourcea只是我们本地spring boot应用中一个非常简单的请求资源链接，一切的权限校验工作都会被keycloak拦截，我们看下这个api的实现：\n@RequestMapping(value = \u0026quot;/api/resourcea\u0026quot;, method = RequestMethod.GET) public String handleResourceA() { return createResponse(); } private String createResponse() { return \u0026quot;Access Granted\u0026quot;; }  可以看到这个只是一个简单的txt返回，但是因为有keycloak的加持，就变成了一个带权限的资源调用。\n上面的access_token解析过后，我们可以看到里面是没有包含权限信息的，我们可以使用access_token来交换一个特殊的RPT的token，这个token里面包含用户的权限信息：\ncurl -X POST \\ http://localhost:8180/auth/realms/spring-boot-quickstart/protocol/openid-connect/token \\ -H \u0026quot;Authorization: Bearer \u0026quot;$access_token \\ --data \u0026quot;grant_type=urn:ietf:params:oauth:grant-type:uma-ticket\u0026quot; \\ --data \u0026quot;audience=app-authz-rest-springboot\u0026quot; \\ --data \u0026quot;permission=Default Resource\u0026quot; | jq --raw-output '.access_token'  将得出的结果解密之后，看下里面的内容：\n{ alg: \u0026quot;RS256\u0026quot;, typ: \u0026quot;JWT\u0026quot;, kid: \u0026quot;FJ86GcF3jTbNLOco4NvZkUCIUmfYCqoqtOQeMfbhNlE\u0026quot; }. { exp: 1603614507, iat: 1603614207, jti: \u0026quot;93e42d9b-4bc6-486a-a650-b912185c35db\u0026quot;, iss: \u0026quot;http://localhost:8180/auth/realms/spring-boot-quickstart\u0026quot;, aud: \u0026quot;app-authz-springboot\u0026quot;, sub: \u0026quot;e6606d93-99f6-4829-ba99-1329be604159\u0026quot;, typ: \u0026quot;Bearer\u0026quot;, azp: \u0026quot;app-authz-springboot\u0026quot;, session_state: \u0026quot;bdc33764-fd1a-400e-9fe0-90a82f4873c1\u0026quot;, acr: \u0026quot;1\u0026quot;, allowed-origins: [ \u0026quot;http://localhost:8080\u0026quot; ], realm_access: { roles: [ \u0026quot;user\u0026quot; ] }, authorization: { permissions: [ { rsid: \u0026quot;e26d5d63-5976-4959-8683-94b7d85318e7\u0026quot;, rsname: \u0026quot;Default Resource\u0026quot; } ] }, scope: \u0026quot;email profile\u0026quot;, email_verified: false, preferred_username: \u0026quot;alice\u0026quot; }. [signature]  可以看到，这个RPT和之前的access_token的区别是这个里面包含了authorization信息。\n我们可以将这个RPT的token和之前的access_token一样使用。\nJetty+Jersey框架接入Keycloak 我们有一个老系统，用的embeded Jetty+Jersey，虽然官方提供了Jetty 9.x Adapters，但这是针对standalone而言的，现在几乎没人这么用了，所以还是得自己来。官方有Java Servlet Filter Adapter的教程，但是用的是web.xml的例子，而且语焉不详，所以这里就我自己的摸索提供一点参考。\nJetty整合Jersey框架 先来看一下Jetty+Jersey的原生例子，涉及两个文件 App.java\npackage xyz.chen; import org.eclipse.jetty.server.Server; import org.eclipse.jetty.servlet.ServletContextHandler; import org.eclipse.jetty.servlet.ServletHolder; import org.glassfish.jersey.servlet.ServletContainer; public class App { public static void main(String[] args) { Server server = new Server(9999); ServletContextHandler context = new ServletContextHandler(ServletContextHandler.NO_SESSIONS); context.setContextPath(\u0026quot;/\u0026quot;); server.setHandler(context); // 配置Servlet ServletHolder holder = context.addServlet(ServletContainer.class.getCanonicalName(), \u0026quot;/rest/*\u0026quot;); holder.setInitOrder(1); holder.setInitParameter(\u0026quot;jersey.config.server.provider.packages\u0026quot;, \u0026quot;xyz.chen\u0026quot;); holder.setInitParameter(\u0026quot;jersey.config.server.provider.classnames\u0026quot;, \u0026quot;org.glassfish.jersey.server.filter.CsrfProtectionFilter\u0026quot;); try { server.start(); server.join(); } catch (Exception e) { e.printStackTrace(); } finally { server.destroy(); } } }  然后是业务类： HelloResource.java\npackage xyz.chen; import javax.ws.rs.*; import javax.ws.rs.core.MediaType; import javax.ws.rs.core.MultivaluedMap; import javax.ws.rs.core.PathSegment; import javax.ws.rs.core.Response; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Map.Entry; @Path(\u0026quot;hello\u0026quot;) public class HelloResource { @Path(\u0026quot;index\u0026quot;) @GET @Consumes(MediaType.TEXT_PLAIN) @Produces(MediaType.TEXT_PLAIN) public Response helloworld() { return Response.ok(\u0026quot;hello jersey\u0026quot;).build(); } @GET @Path(\u0026quot;/user/{userName}\u0026quot;) public Response getThemeCss(@PathParam(\u0026quot;userName\u0026quot;) String userName) { StringBuilder sb = new StringBuilder(userName); return Response.ok(sb.toString()).build(); } }  pom.xml文件\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;project xmlns=\u0026quot;http://maven.apache.org/POM/4.0.0\u0026quot; xmlns:xsi=\u0026quot;http://www.w3.org/2001/XMLSchema-instance\u0026quot; xsi:schemaLocation=\u0026quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026quot;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;org.example\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jersey-demo\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;Maven\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://maven.apache.org/\u0026lt;/url\u0026gt; \u0026lt;inceptionYear\u0026gt;2001\u0026lt;/inceptionYear\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.glassfish.jersey.core\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jersey-server\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.27\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.glassfish.jersey.inject\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jersey-hk2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.27\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.glassfish.jersey.containers\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jersey-container-servlet-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.27\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.glassfish.jersey.containers\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jersey-container-jetty-http\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.27\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.eclipse.jetty\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jetty-server\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;9.4.12.v20180830\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.eclipse.jetty\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jetty-servlet\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;9.4.12.v20180830\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.eclipse.jetty\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jetty-util\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;9.4.12.v20180830\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-shade-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.4.3\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;createDependencyReducedPom\u0026gt;true\u0026lt;/createDependencyReducedPom\u0026gt; \u0026lt;filters\u0026gt; \u0026lt;filter\u0026gt; \u0026lt;artifact\u0026gt;*:*\u0026lt;/artifact\u0026gt; \u0026lt;excludes\u0026gt; \u0026lt;exclude\u0026gt;META-INF/*.SF\u0026lt;/exclude\u0026gt; \u0026lt;exclude\u0026gt;META-INF/*.DSA\u0026lt;/exclude\u0026gt; \u0026lt;exclude\u0026gt;META-INF/*.RSA\u0026lt;/exclude\u0026gt; \u0026lt;/excludes\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;/filters\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;shade\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;transformers\u0026gt; \u0026lt;transformer implementation=\u0026quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer\u0026quot; /\u0026gt; \u0026lt;transformer implementation=\u0026quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\u0026quot;\u0026gt; \u0026lt;manifestEntries\u0026gt; \u0026lt;Main-Class\u0026gt;xyz.chen.App\u0026lt;/Main-Class\u0026gt; \u0026lt;/manifestEntries\u0026gt; \u0026lt;/transformer\u0026gt; \u0026lt;/transformers\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt;  运行就不再举例了。\n整合keycloak 引入依赖\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.keycloak\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;keycloak-servlet-filter-adapter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;11.0.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;  修改App类，加入Filter\nServletHandler handler = new ServletHandler(); FilterHolder fh=handler.addFilterWithMapping(org.keycloak.adapters.servlet.KeycloakOIDCFilter.class,\u0026quot;/*\u0026quot;, EnumSet.of(DispatcherType.REQUEST)); fh.setInitParameter(\u0026quot;keycloak.config.file\u0026quot;, \u0026quot;keycloak.json\u0026quot;); context.addFilter(fh, \u0026quot;/*\u0026quot;, EnumSet.of(DispatcherType.REQUEST)); server.setHandler(context);  其中，keycloak.json文件来自keycloak-clients-installtion，形如\n{ \u0026quot;realm\u0026quot;: \u0026quot;wildfly\u0026quot;, \u0026quot;auth-server-url\u0026quot;: \u0026quot;http://localhost:8080/auth/\u0026quot;, \u0026quot;ssl-required\u0026quot;: \u0026quot;external\u0026quot;, \u0026quot;resource\u0026quot;: \u0026quot;product-app\u0026quot;, \u0026quot;public-client\u0026quot;: true, \u0026quot;confidential-port\u0026quot;: 0 }  keycloak的配置不再赘述。\n获取用户权限信息 这块不再举例，自己写个Filter去KeycloakSecurityContext里拿就可以了。\n其它问题 1.如何用代码完成在KeyCloak注册和配置过程，实现自动化配置？ KeyCloark有restApi，也有命令行工具。下面是简单暴力的做法，使用命令行\n#添加管理员用户 .../bin/add-user-keycloak.sh -r master -u \u0026lt;username\u0026gt; -p \u0026lt;password\u0026gt; $ kcadm.sh config credentials --server http://localhost:8080/auth --realm master --user admin $ kcadm.sh create realms -s realm=demorealm -s enabled=true -o $ CID=$(kcadm.sh create clients -r demorealm -s clientId=my_client -s 'redirectUris=[\u0026quot;http://localhost:8980/myapp/*\u0026quot;]' -i) $ kcadm.sh get clients/$CID/installation/providers/keycloak-oidc-keycloak-json  如下所示，使用windows举例\nPS G:\\keycloak11\\bin\u0026gt; .\\kcadm config credentials --server http://localhost:8080/auth --realm master --user admin Logging into http://localhost:8080/auth as user admin of realm master Enter password: admin PS G:\\keycloak11\\bin\u0026gt; .\\kcadm create realms -s realm=demorealm -s enabled=true -o PS G:\\keycloak11\\bin\u0026gt; .\\kcadm create clients -r demorealm -s clientId=my_client -s 'redirectUris=[\\\u0026quot;http://localhost:8980/myapp/*\\\u0026quot;]' -i \u0026gt; clientid.txt PS G:\\keycloak11\\bin\u0026gt; set /p CID=\u0026lt;clientid.txt PS G:\\keycloak11\\bin\u0026gt; .\\kcadm get http://localhost:8080/auth/admin/realms/demorealm/clients/8aba2b1f-4587-43ba-8f51-d2e75db5f65d/installation/providers/keycloak-oidc-keycloak-json { \u0026quot;realm\u0026quot; : \u0026quot;demorealm\u0026quot;, \u0026quot;auth-server-url\u0026quot; : \u0026quot;http://localhost:8080/auth/\u0026quot;, \u0026quot;ssl-required\u0026quot; : \u0026quot;external\u0026quot;, \u0026quot;resource\u0026quot; : \u0026quot;my_client\u0026quot;, \u0026quot;credentials\u0026quot; : { \u0026quot;secret\u0026quot; : \u0026quot;54b8027b-6d7f-4e2b-9b6a-5c1e85b685fa\u0026quot; }, \u0026quot;confidential-port\u0026quot; : 0 } PS G:\\keycloak11\\bin\u0026gt;  基本操作：\n$ kcadm.sh create ENDPOINT [ARGUMENTS] $ kcadm.sh get ENDPOINT [ARGUMENTS] $ kcadm.sh update ENDPOINT [ARGUMENTS] $ kcadm.sh delete ENDPOINT [ARGUMENTS]  ENDPOINT is a target resource URI and can either be absolute (starting with http: or https:) or relative, used to compose an absolute URL of the following format:\nSERVER_URI/admin/realms/REALM/ENDPOINT  For example, if you authenticate against the server http://localhost:8080/auth and realm is master, then using users as ENDPOINT results in the resource URL http://localhost:8080/auth/admin/realms/master/users.\nIf you set ENDPOINT to clients, the effective resource URI would be http://localhost:8080/auth/admin/realms/master/clients.\n角色和用户的管理等也能用kcadm命令来完成。\n2.如何退出 HttpServletRequest.logout()  3.更暴力的接入方式KeyCloak Proxy（已停止维护） 把KeyCloak作为一个proxy来使用，免去修改现有代码。\nhttps://hub.docker.com/r/jboss/keycloak-proxy/ 这里有简单的使用方式说明。这种方式只能代理一个client。\n This image is deprecated as the Java based Proxy will be replaced by a new Go based implementation soon.\n keycloak-proxy在2018年已停止维护，用Golang实现的继任者louketo-proxy也已在2020年停止更新维护。\n官方文档已不推荐使用这种方式，相关文档已移除。\nouketo-proxy停止更新和维护，官网说明：https://www.keycloak.org/2020/08/sunsetting-louketo-project.adoc\n官网提供的一种类似替代方案：https://github.com/oauth2-proxy/oauth2-proxy （Golang实现，未验证）\n参考 https://www.keycloak.org/docs/latest/securing_apps/#_jetty9_adapter\nhttps://stackoverflow.com/questions/22188285/does-embedded-jetty-have-the-ability-to-set-the-init-params-of-a-filter\n","date":"2021-04-07","permalink":"https://iminto.github.io/post/keycloak%E6%8E%A5%E5%85%A5%E8%87%AA%E7%A0%94%E7%B3%BB%E7%BB%9F/","tags":["Java"],"title":"Keycloak接入自研系统"},{"content":"Centos8安装Superset。Superset 是 Airbnb （知名在线房屋短租公司）开源的数据探查与可视化平台（曾用名 Panoramix、Caravel ），也就是BI，该工具在可视化、易用性和交互性上非常有特色。\n不建议使用python3.8以下版本。低版本建议使用docker-composer或者helm安装。当然，想要低版本Python安装也不是不可以，其实也就一个conda create 的操作而已。我在Centos7+Python 2.7.5 环境下也安装成功。 我是新环境，直接升级就好。\n初始化，升级到python 3.8（非必须） wget https://www.python.org/ftp/python/3.8.1/Python-3.8.1.tgz yum install gcc gcc-c++ libffi-devel tar -xvf Python-3.8.1.tgz cd Python-3.8.1 ./configure --prefix=/usr/local/python3 make \u0026amp;\u0026amp; make install rm -f /usr/bin/python rm -f /usr/bin/pip ln -s /usr/local/python3/bin/python3 /usr/bin/python ln -s /usr/local/python3/bin/python3 /usr/bin/python python -V  安装miniconda wget -c https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh chmod 777 Miniconda3-latest-Linux-x86_64.sh bash Miniconda3-latest-Linux-x86_64.sh  一步一步来，最后把conda的路径加入环境变量。\nconda list #验证安装是否成功 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ conda config --add channels conda create -n superset python=3.8 conda config --get channels  使用conda安装SuperSet 最后进入安装superset环节。创建虚拟环境，这也是低版本python安装高版本python软件的关键。为什么不直接用pip，还是考虑到python版本比较混乱的问题。为什么不用virtualenv，主要是conda能安装一些依赖，减少手动操作。最新版的superset应该是不需要这么麻烦，pip一路到底就可以，不过我还是参考了老的安装教程。有闲的可以直接看官方教程，更简单。\nconda create -n superset python=3.8 activate superset pip install apache-superset  要退出conda创建的虚拟环节可以用conda deactivate指令。\n查看和切换虚拟环境\nconda info --envs conda env list conda activate base  如果pip太慢，可以加入国内源\n#新建配置文件 touch ~/.pip/pip.conf #加入如下配置 [global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple [install] trusted-host = https://pypi.tuna.tsinghua.edu.cn  如果出现了类似的报错\ngcc: error trying to exec 'cc1plus': execvp: No such file or directory error: command 'gcc' failed with exit status 1 ---------------------------------------- ERROR: Failed building wheel for python-geohash  是因为缺少了 gcc-c++，安装即可。这就是第一步里面的初始化所做的。\n配置和启动 如果顺利的话，superset应该是安装成功了。接下来就是官方文档里的初始化操作了。\nsuperset db upgrade # Create an admin user (you will be prompted to set a username, first and last name before setting a password) $ export FLASK_APP=superset superset fab create-admin # Load some data to play with superset load_examples # Create default roles and permissions superset init # To start a development web server on port 8088, use -p to bind to another port superset run -p 8088 --with-threads --reload --debugger  在superset load_examples这一步，可能会卡很久然后失败，原因是example数据是存放在github的，然而某些人没有妈，所以就不能访问了。可以直接中止就好了。或者从github上手动下载回来（压缩包大约28M），然后手动导入（需要起一个HTTP服务，修改Superset源码superset/examples/helpers.py替换BASE_URL，比较麻烦）。\n另外superset默认只绑定localhost，想要外网可访问，可以绑定一个主机。\n#hosts文件里添加一条映射 0.0.0.0 ten #绑定ten superset run -h ten -p 8080 --with-threads --reload #这样直接绑定IP地址是会报错的 superset run -h 110.6.7.8 -p 8080 --with-threads --reload  这操作也有点诡异了些。。\n 2021-04-13更新\n 导入样例 前面说过，在superset load_examples这一步会失败，原因是example数据是存放在github的，这个网站被司马佬吃了。这个路径配置在examples/helpers.py里的BASE_URL项。\n#github上下载examples压缩包 wget https://github.com/apache-superset/examples-data/archive/refs/heads/master.zip #解压，启动本地server unzip master.zip python -m SimpleHTTPServer 18089 #PYTHONPATH处理 cp /root/miniconda2/envs/superset/lib/python3.8/site-packages/superset/examples/ /root/py/examples #修改helpers.py BASE_URL = \u0026quot;http://10.180.210.146:18089/\u0026quot; #导入 superset load_examples  成功的话，输出应该如下：\nLoaded your LOCAL configuration at [/root/py/superset_config.py] Loaded your LOCAL configuration at [/root/py/superset_config.py] logging was configured successfully INFO:superset.utils.logging_configurator:logging was configured successfully /root/miniconda2/envs/superset/lib/python3.8/site-packages/flask_caching/__init__.py:201: UserWarning: Flask-Caching: CACHE_TYPE is set to null, caching is effectively disabled. warnings.warn( No PIL installation found INFO:superset.utils.screenshots:No PIL installation found Loading examples metadata and related data into examples Creating default CSS templates Loading energy related dataset Creating table [wb_health_population] reference Loading [World Bank's Health Nutrition and Population Stats] Creating table [wb_health_population] reference Creating a World's Health Bank dashboard Loading [Birth names] Done loading table! -------------------------------------------------------------------------------- Creating table [birth_names] reference Creating some slices Creating a dashboard Loading [Random time series data] Done loading table! -------------------------------------------------------------------------------- Creating table [random_time_series] reference Creating a slice Loading [Random long/lat data] Done loading table! -------------------------------------------------------------------------------- Creating table reference Creating a slice Loading [Country Map data] Done loading table! -------------------------------------------------------------------------------- Creating table reference Creating a slice Loading [Multiformat time series] Done loading table! -------------------------------------------------------------------------------- Creating table [multiformat_time_series] reference Creating Heatmap charts Loading [Paris GeoJson] Creating table paris_iris_mapping reference ...  自定义配置及汉化 编辑配置文件后重启即可\nvim /root/miniconda2/envs/superset/lib/python3.8/site-packages/superset/config.py # Setup default language BABEL_DEFAULT_LOCALE = \u0026quot;zh\u0026quot;  这样直接修改配置文件很麻烦（路径太深），可以把自定义配置文件放到指定位置：\nTo configure your application, you need to create a file superset_config.py and add it to your PYTHONPATH.\nAll the parameters and default values defined in https://github.com/apache/superset/blob/master/superset/config.py can be altered in your local superset_config.py.\nAPI文档 API 文档地址：http://10.180.210.146:18088/swagger/v1\n虽然SuperSet支持Oauth，但由于SuperSet用的是FlaskAB框架（不是Flask框架），支持比较弱，需要自己写python代码。如果是外部系统对接Superset，只能用cookie登陆的方式调用。\n","date":"2021-04-02","permalink":"https://iminto.github.io/post/superset%E5%AE%89%E8%A3%85/","tags":["大数据"],"title":"SuperSet安装配置"},{"content":"安装依赖 yum list | grep google-authenticator yum install google-authenticator yum install qrencode  配置Google Authenticator 安装完直接跑下面的命令进行配置，注意只在当前用户生效\n\u0026gt; google-authenticator  之后会需要确认几点信息\nDo you want authentication tokens to be time-based (y/n) y  是否配置基于时间的动态密钥，选择y，之后会出现超级大一个二维码，下面还会有一些小字,这里的key就是用于配置手机端app的，我们先保存下来，不用慌，因为这个key随时都可以查得到.\nDo you want me to update your \u0026quot;/root/.google_authenticator\u0026quot; file? (y/n) y  是否将配置信息更新到自己家目录，选择y进行更新，这个文件里面就保存着上面的key信息，以防后续还有新的手机设备需要用到key\nDo you want to disallow multiple uses of the same authentication token? This restricts you to one login about every 30s, but it increases your chances to notice or even prevent man-in-the-middle attacks (y/n) y  是否禁止同一密钥在30秒内被多次使用，如果想要更安全就选择y，如果想要更方便就选择n\nBy default, a new token is generated every 30 seconds by the mobile app. In order to compensate for possible time-skew between the client and the server, we allow an extra token before and after the current time. This allows for a time skew of up to 30 seconds between authentication server and client. If you experience problems with poor time synchronization, you can increase the window from its default size of 3 permitted codes (one previous code, the current code, the next code) to 17 permitted codes (the 8 previous codes, the current code, and the 8 next codes). This will permit for a time skew of up to 4 minutes between client and server. Do you want to do so? (y/n) n  是否允许前8次和后8次的动态密钥也有效，如果客户端和手机端都是基于网络的时间同步，选择n提高安全性\nIf the computer that you are logging into isn't hardened against brute-force login attempts, you can enable rate-limiting for the authentication module. By default, this limits attackers to no more than 3 login attempts every 30s. Do you want to enable rate-limiting? (y/n) y  是否限制30秒内最多3次尝试，为了防止恶意试错，选择y 这样服务端的Google Authenticator就配置完毕。下面做一些系统设置，使上面的配置用作ssh。\n配置pam vim /etc/pam.d/sshd auth required pam_google_authenticator.so nullok vim /etc/ssh/sshd_config UsePAM yes PasswordAuthentication no ChallengeResponseAuthentication yes sshd -t systemctl restart sshd  需要注意的是必须设置PasswordAuthentication no（禁用密码登陆，但是并非必须使用公钥），否则二次验证无法使用，会报如下错误：\nsshd[2690384]: fatal: PAM: pam_setcred(): Permission denied  手机设置 推荐使用 andotp 这个APP，扫码添加即可。\n如果换了手机也很容易，登录到服务器，找到~/.google_authenticator文件，里面会有之前保存的key，重新在新手机进行添加即可。\nXshell登录验证 下面还是正常ssh登陆服务器，不过输入完用户名以后只能选择交互键盘，依次输入密码和OTP验证码即可。关于登录的一些报错都在/var/log/secure这个日志文件中，不管是什么场景登陆失败都可以先查看下失败日志，对症下药。\n注意保持时间同步。 直接使用ntpdate即可，国内可以使用国家授时中心的地址\nntpdate -u 210.72.145.44  基本上服务器和手机都是用的网络时间就不太会有时间同步的问题。\nrefer:https://blog.csdn.net/Victor2code/\u0026hellip;\n","date":"2020-12-29","permalink":"https://iminto.github.io/post/centos%E9%85%8D%E7%BD%AEgoogleauthenticator%E5%8A%A8%E6%80%81%E5%AF%86%E9%92%A5%E8%BF%9B%E8%A1%8Cssh%E4%BA%8C%E6%AC%A1%E9%AA%8C%E8%AF%81/","tags":["Linux"],"title":"Centos配置GoogleAuthenticator动态密钥进行ssh二次验证"},{"content":"TUI ConsoleLauncher basically transforms your Android into a terminal window, requiring you to type out commands to start apps and explore your phone\u0026rsquo;s system as opposed to the familiar process of tapping on icons. It\u0026rsquo;s a great way to practice or learn about Linux commands, and it has the added benefit of securing your phone against unwanted access.\n常用命令：\n-- 不允许别人用exit命令退出 alias add exit=echo \u0026quot;No\u0026quot; -- 定制化界面，取消不必要元素 config -set show_session_info false config -set show_storage_info false config -set show_device_name false config -set show_ram false config -set show_network_info false -- 优化 config -set time_size 20 --调大时间字体 config -set system_wallpaper true --显示系统壁纸 config -set fullscreen true config -set enable_music true -- 记日志/备忘录 note -add 明早九点加班  修改配置后需要restart才能生效。\n结合shellcommand等，还可以自定义出各种小工具。\n","date":"2020-12-25","permalink":"https://iminto.github.io/post/tui-consolelauncher-%E5%8F%AF%E5%AE%9A%E5%88%B6%E5%8C%96geek%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%A1%8C%E9%9D%A2%E5%90%AF%E5%8A%A8%E5%99%A8/","tags":["闲扯淡"],"title":"TUI ConsoleLauncher 可定制化geek命令行桌面启动器"},{"content":"Ambari里主机，集群，用户等等都视为一种资源，对它们的增删改查就是对资源的增删改查。\n了解实现Ambari里增加一个资源的流程，就更方便修改Ambari的实现。\n1.新建控制器层 ambari的控制器层在service包里\npackage org.apache.ambari.server.api.services.dataspace; import io.swagger.annotations.Api; import org.apache.ambari.server.api.resources.ResourceInstance; import org.apache.ambari.server.api.services.BaseService; import org.apache.ambari.server.api.services.Request; import org.apache.ambari.server.controller.spi.Resource; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.Context; import javax.ws.rs.core.HttpHeaders; import javax.ws.rs.core.Response; import javax.ws.rs.core.UriInfo; import java.util.Collections; @Path(\u0026quot;/hdfs/\u0026quot;) @Api(value = \u0026quot;Hdfss\u0026quot;, description = \u0026quot;Endpoint for user specific operations\u0026quot;) public class HdfsService extends BaseService { @GET//查询全部 @Produces(\u0026quot;text/plain\u0026quot;) public Response getHdfses(String body, @Context HttpHeaders headers, @Context UriInfo ui) { return handleRequest(headers, body, ui, Request.Type.GET, createHdfsResource(null)); } @GET @Path(\u0026quot;{path}\u0026quot;)//查询单个 @Produces(\u0026quot;text/plain\u0026quot;) public Response getHdfs(String body, @Context HttpHeaders headers, @Context UriInfo ui) { return handleRequest(headers, body, ui, Request.Type.GET, createHdfsResource(path)); } private ResourceInstance createHdfsResource(String path) { return createResource(Resource.Type.Hdfs, Collections.singletonMap(Resource.Type.Hdfs, path)); } }  继承BaseService。这里定义访问路径和参数。serivice的方法参数上是看不出VO的类型的。复杂的控制器，可以在一个service里调用另外一个service.\n访问参数可以封装成对象，需要新建一个XXXRequest对象，比如\npackage org.apache.ambari.server.controller; public class HdfsRequest { private Integer id; private String path; private Integer size; //getter,setter略 }  这里的xxxRequest是不会像springboot一样自动封装成对象的。\n2.继承ResourceProvide，实现具体的handleRequest方法 package org.apache.ambari.server.controller.internal; import com.google.common.collect.ImmutableMap; import com.google.common.collect.Sets; import org.apache.ambari.server.controller.AmbariManagementController; import org.apache.ambari.server.controller.HdfsRequest; import org.apache.ambari.server.controller.spi.Predicate; import org.apache.ambari.server.controller.spi.Request; import org.apache.ambari.server.controller.spi.Resource; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import java.util.HashSet; import java.util.Map; import java.util.Set; public class HdfsResourceProvider extends AbstractControllerResourceProvider{ private static final Logger LOG = LoggerFactory.getLogger(HdfsResourceProvider.class); public static final String HDFS_RESOURCE_CATEGORY=\u0026quot;Hdfses\u0026quot;; public static final String HDFS_ID_PROPERTY_ID =\u0026quot;hdfs_id\u0026quot;; public static final String HDFS_PATH_PROPERTY_ID =\u0026quot;hdfs_path\u0026quot;; public static final String HDFS_SIZE_PROPERTY_ID =\u0026quot;hdfs_size\u0026quot;; public static final String HDFS_RESOURCE_HDFS_ID_PROPERTY_ID =HDFS_RESOURCE_CATEGORY+\u0026quot;/\u0026quot;+HDFS_ID_PROPERTY_ID; public static final String HDFS_RESOURCE_HDFS_PATH_PROPERTY_ID =HDFS_RESOURCE_CATEGORY+\u0026quot;/\u0026quot;+HDFS_PATH_PROPERTY_ID; public static final String HDFS_RESOURCE_HDFS_SIZE_PROPERTY_ID =HDFS_RESOURCE_CATEGORY+\u0026quot;/\u0026quot;+HDFS_SIZE_PROPERTY_ID; private static Map\u0026lt;Resource.Type, String\u0026gt; keyPropertyIds = ImmutableMap.\u0026lt;Resource.Type, String\u0026gt;builder() .put(Resource.Type.Hdfs, HDFS_RESOURCE_HDFS_ID_PROPERTY_ID) .build(); private static Set\u0026lt;String\u0026gt; propertyIds = Sets.newHashSet( HDFS_RESOURCE_HDFS_ID_PROPERTY_ID, HDFS_RESOURCE_HDFS_PATH_PROPERTY_ID, HDFS_RESOURCE_HDFS_SIZE_PROPERTY_ID ); public static void init(){ //注入操作在此 } HdfsResourceProvider(AmbariManagementController managementController) { super(Resource.Type.Hdfs, propertyIds, keyPropertyIds, managementController); } @Override protected Set\u0026lt;Resource\u0026gt; getResourcesAuthorized(Request request, Predicate predicate){ Set\u0026lt;String\u0026gt; hdfsIds=getRequestPropertyIds(request,predicate); Set\u0026lt;Resource\u0026gt; resources=new HashSet\u0026lt;\u0026gt;(); //查询数据库略 for(int i=0;i\u0026lt;3;i++){ ResourceImpl resource=new ResourceImpl(Resource.Type.Hdfs); setResourceProperty(resource,HDFS_RESOURCE_HDFS_ID_PROPERTY_ID,i,hdfsIds); setResourceProperty(resource,HDFS_RESOURCE_HDFS_PATH_PROPERTY_ID,\u0026quot;path\u0026quot;+i,hdfsIds); setResourceProperty(resource,HDFS_RESOURCE_HDFS_SIZE_PROPERTY_ID,i*100,hdfsIds); resources.add(resource); } return resources; } private HdfsRequest getRequest(Map\u0026lt;String,Object\u0026gt; properties){ if(properties==null){ return new HdfsRequest(); } HdfsRequest hdfsRequest=new HdfsRequest(); if(properties.get(\u0026quot;HDFS_RESOURCE_HDFS_ID_PROPERTY_ID\u0026quot;)!=null){ hdfsRequest.setId(Integer.parseInt(properties.get(\u0026quot;HDFS_RESOURCE_HDFS_ID_PROPERTY_ID\u0026quot;).toString())); } if(properties.get(\u0026quot;HDFS_RESOURCE_HDFS_SIZE_PROPERTY_ID\u0026quot;)!=null){ hdfsRequest.setSize(Integer.parseInt(properties.get(\u0026quot;HDFS_RESOURCE_HDFS_SIZE_PROPERTY_ID\u0026quot;).toString())); } hdfsRequest.setPath(properties.get(\u0026quot;HDFS_RESOURCE_HDFS_ID_PROPERTY_ID\u0026quot;).toString()); return hdfsRequest; } @Override public RequestStatus updateResources(Request request, Predicate predicate){ //更新操作略 return getRequestStatus(null); } @Override protected Set\u0026lt;String\u0026gt; getPKPropertyIds() { return new HashSet\u0026lt;\u0026gt;(keyPropertyIds.values()); } }  这里面定义了各种参数字段和参数完整性校验，对应前端传值，实现CRUD逻辑，调用dao等。ResourceProvider和Request类的作用有交叉。\ngetRequest()用于从request Map里获取字符串参数组装成对象。\n同时需要在AbstractControllerResourceProvider里增加一条记录\ncase AlertTarget: return resourceProviderFactory.getAlertTargetResourceProvider(); case ViewInstance: return resourceProviderFactory.getViewInstanceResourceProvider(); case Hdfs: return new HdfsResourceProvider(managementController); default: throw new IllegalArgumentException(\u0026quot;Unknown type \u0026quot; + type);  3.实现ResourceDefinition package org.apache.ambari.server.api.resources; import org.apache.ambari.server.controller.spi.Resource; import java.util.HashSet; import java.util.Set; public class HdfsResourceDefinition extends BaseResourceDefinition { { } /** * Constructor. * * @param resourceType resource type */ public HdfsResourceDefinition() { super(Resource.Type.Hdfs); } /** * Obtain the plural name of the resource. * * @return the plural name of the resource */ @Override public String getPluralName() { return \u0026quot;hdfses\u0026quot;; } /** * Obtain the singular name of the resource. * * @return the singular name of the resource */ @Override public String getSingularName() { return \u0026quot;hdfs\u0026quot;; } @Override public Set\u0026lt;SubResourceDefinition\u0026gt; getSubResourceDefinitions() { final Set\u0026lt;SubResourceDefinition\u0026gt; subResourceDefinitions = new HashSet\u0026lt;\u0026gt;(); subResourceDefinitions.add(new SubResourceDefinition(Resource.Type.Hdfs)); return subResourceDefinitions; } }  这里跟权限应该就有了关系。\n修改ResourceInstanceFactoryImpl，加入自己定义的新类型\ncase RemoteCluster: resourceDefinition = new RemoteClusterResourceDefinition(); break; case Hdfs: resourceDefinition = new HdfsResourceDefinition(); break; default: throw new IllegalArgumentException(\u0026quot;Unsupported resource type: \u0026quot; + type); }  spi包下Resource接口新增一个枚举\npackage org.apache.ambari.server.controller.spi; public interface Resource { enum InternalType { Cluster, Service, Setting,  4.数据库相关 orm包下添加对应的实体类和Dao实现，resource/META-INF下需要手动添加实体类对象全名，比如\n\u0026lt;persistence-unit name=\u0026quot;ambari-server\u0026quot; transaction-type=\u0026quot;RESOURCE_LOCAL\u0026quot;\u0026gt; \u0026lt;provider\u0026gt;org.eclipse.persistence.jpa.PersistenceProvider\u0026lt;/provider\u0026gt; \u0026lt;class\u0026gt;org.apache.ambari.server.orm.entities.AlertCurrentEntity\u0026lt;/class\u0026gt; \u0026lt;class\u0026gt;org.apache.ambari.server.orm.entities.AlertDefinitionEntity\u0026lt;/class\u0026gt; \u0026lt;/persistence-unit\u0026gt;  entity举例：\npackage org.apache.ambari.server.orm.entities; import javax.persistence.*; @Entity @Table(name = \u0026quot;admin_cluster_host\u0026quot;) public class AdminClusterHostEntity { @Id @GeneratedValue(strategy = GenerationType.AUTO) @Column(name = \u0026quot;id\u0026quot;, nullable = false, updatable = false) private Integer id; @Column(name = \u0026quot;host\u0026quot;, length = 255) private String host; @Column(name = \u0026quot;cluster\u0026quot;, length = 255) private String cluster; public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public String getHost() { return host; } public void setHost(String host) { this.host = host; } public String getCluster() { return cluster; } public void setCluster(String cluster) { this.cluster = cluster; } }  dao举例\npackage org.apache.ambari.server.orm.dao; import com.google.inject.Inject; import com.google.inject.Provider; import com.google.inject.Singleton; import org.apache.ambari.server.orm.RequiresSession; import org.apache.ambari.server.orm.entities.AdminClusterHostEntity; import org.apache.ambari.server.orm.entities.AlertHistoryEntity; import javax.persistence.EntityManager; import javax.persistence.NoResultException; import javax.persistence.TypedQuery; import java.util.Collections; import java.util.List; @Singleton public class AdminClusterDAO { @Inject private Provider\u0026lt;EntityManager\u0026gt; m_entityManagerProvider; @RequiresSession public List\u0026lt;AdminClusterHostEntity\u0026gt; findAll() { TypedQuery\u0026lt;AdminClusterHostEntity\u0026gt; query = m_entityManagerProvider.get().createQuery( \u0026quot;SELECT ac FROM AdminClusterHostEntity ac\u0026quot;, AdminClusterHostEntity.class); try { return query.getResultList(); } catch (NoResultException e) { return Collections.emptyList(); } } }  5.注入相关 AmbariServer类里也需要相应注入类依赖的对象，一种方式是手动注入，例如：\nermissionResourceProvider.init(injector.getInstance(PermissionDAO.class)); ViewPermissionResourceProvider.init(injector.getInstance(PermissionDAO.class)); PrivilegeResourceProvider.init(injector.getInstance(PrivilegeDAO.class), injector.getInstance(UserDAO.class), injector.getInstance(GroupDAO.class), injector.getInstance(PrincipalDAO.class), injector.getInstance(PermissionDAO.class), injector.getInstance(ResourceDAO.class));  还有一种方式是注解注入，参考org.apache.ambari.server.controller.ControllerModule\nAmbari注入这块比较迷，比如dao里用到的m_entityManagerProvider对象就不需要手动注入，在它原有的类里使用新加的dao也不需要手动注入。但是有些自己写的ResourceProvider里就需要注入。\n6.postman模拟验证 请求\ncurl --location --request GET 'http://10.180.210.146:8080/api/v1/hdfs?fields=Hdfses/*' \\ --header 'Content-Typ: application/x-www-form-urlencoded; charset=UTF-8' \\ --header 'Cookie: AMBARISESSIONID=node0qm8s4v2muk61199wsf0jqgmg1.node0' \\ --header 'X-Requested-By: X-Requested-By' \\ --data-raw ''  返回\n{ \u0026quot;href\u0026quot; : \u0026quot;http://10.180.210.146:8080/api/v1/hdfs?fields=Hdfses/*\u0026quot;, \u0026quot;items\u0026quot; : [ { \u0026quot;href\u0026quot; : \u0026quot;http://10.180.210.146:8080/api/v1/hdfs/0\u0026quot;, \u0026quot;Hdfses\u0026quot; : { \u0026quot;hdfs_id\u0026quot; : 0, \u0026quot;hdfs_path\u0026quot; : \u0026quot;path0\u0026quot;, \u0026quot;hdfs_size\u0026quot; : 0 } }, { \u0026quot;href\u0026quot; : \u0026quot;http://10.180.210.146:8080/api/v1/hdfs/1\u0026quot;, \u0026quot;Hdfses\u0026quot; : { \u0026quot;hdfs_id\u0026quot; : 1, \u0026quot;hdfs_path\u0026quot; : \u0026quot;path1\u0026quot;, \u0026quot;hdfs_size\u0026quot; : 100 } }, { \u0026quot;href\u0026quot; : \u0026quot;http://10.180.210.146:8080/api/v1/hdfs/2\u0026quot;, \u0026quot;Hdfses\u0026quot; : { \u0026quot;hdfs_id\u0026quot; : 2, \u0026quot;hdfs_path\u0026quot; : \u0026quot;path2\u0026quot;, \u0026quot;hdfs_size\u0026quot; : 200 } } ] }  请求必须带上?fields=Hdfses/*,表示展示所有字段，否则查询结果是显示不完整的。\n7.自由风格Controller 也可以抛开ambari的规则，自由使用javax.ws风格。\n但这样就没法使用Ambari内置的权限和谓词风格URL查询了\n8.异常和参数校验 参数校验在ResourceProvider里，抛出SystemException即可返回给页面\n权限异常\nif (!AuthorizationHelper.isAuthorized(resourceType, resourceId, RoleAuthorization.SERVICE_RUN_SERVICE_CHECK)) { throw new AuthorizationException(\u0026quot;The authenticated user is not authorized to execute service checks.\u0026quot;); }  ","date":"2020-10-13","permalink":"https://iminto.github.io/post/ambari%E9%87%8C%E8%87%AA%E5%AE%9A%E4%B9%89%E8%B5%84%E6%BA%90%E6%A8%A1%E5%9D%97%E7%9A%84%E5%AE%9E%E7%8E%B0/","tags":["Java","大数据"],"title":"Ambari里自定义资源模块的实现"},{"content":"按惯例上Prosody 自己的文档: https://prosody.im/doc/\n安装 使用centos8安装\nyum install prosody dnf --enablerepo=PowerTools install lua-filesystem  其它版本linux则无需单独安装lua-filesystem依赖。\n配置 主配置文件 prosody.cfg.lua 一般不需要修改。\n下面写些咱做的修改😂\n 在 modules_enabled 中取消启用 version 和 uptime 模块，顺便启动些其他的模块，比如offline。 如果需要允许在客户端上注册的话，把 allow_registration 设置成 true 。  其它配置保持默认即可。\n另外一个配置文件就是具体和域名对应的配置文件了，位于/etc/prosody/conf.d目录下 我的配置是： baidecai.xyz.cfg.lua\nVirtualHost \u0026quot;baidecai.xyz\u0026quot; http_host = \u0026quot;www.baidecai.xyz\u0026quot; -- enabled = false -- Remove this line to enable this host -- Prosody will automatically search for a certificate and key -- in /etc/prosody/certs/ unless a path is manually specified -- in the config file, see https://prosody.im/doc/certificates ssl = { key = \u0026quot;/etc/prosody/cer/baidecai.xyz.key\u0026quot;; certificate = \u0026quot;/etc/prosody/cer/baidecai.xyz.crt\u0026quot;; protocol = \u0026quot;tlsv1_1+\u0026quot;; --- 为客户端到服务器（c2s）和服务器到服务器（s2s）打开认证 verify = { \u0026quot;peer\u0026quot;, \u0026quot;peer\u0026quot; }; ciphers = \u0026quot;EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH\u0026quot;; dhparam = \u0026quot;/etc/prosody/certs/dh-1024.pem\u0026quot; } disco_items = { { \u0026quot;upload.baidecai.xyz\u0026quot; }, } Component \u0026quot;upload.baidecai.xyz\u0026quot; \u0026quot;http_upload\u0026quot; http_upload_file_size_limit = 1024000 http_upload_expire_after = 60 * 60 * 24 * 7 http_upload_path = \u0026quot;/uploaded/files\u0026quot; http_files_dir = \u0026quot;/uploaded/files\u0026quot;  为了支持聊天中发送文件，我加入了http_upload模块。需要注意的是，这个模块来自社区，并不是prosody自带的，所以需要自己去下载放入prosody的插件目录（在这个问题上，我折腾了好几天才搞定，官方文档没有说清楚），要不然你的xmpp就没法发文件了，及时客户端支持发送操作也会报错。\nprosody的插件目录位置可以通过这个命令查看：\nprosodyctl about  社区插件下载地址： https://hg.prosody.im/prosody-modules/file/tip 记得给http_upload_path赋予可写权限 重启即可。\n注意  现在的xmpp client基本都不再支持非SSL登陆了，所以你必须要有一个证书。也就是前文配置中的certificate和key文件，这个很好申请，推荐网址： https://freessl.cn/ 。 dhparam文件生成指令  openssl dhparam -out dh.pem 1024  如果没开启允许客户端注册的话，用 prosodyctl 注册账户  prosodyctl adduser \u0026lt;JID\u0026gt;  到此为止，你已经拥有了一个可以加密聊天，可以发文件的xmpp server了。\n","date":"2020-08-26","permalink":"https://iminto.github.io/post/prosody%E6%90%AD%E5%BB%BAxmpp%E6%9C%8D%E5%8A%A1%E5%99%A8/","tags":["Linux","闲扯淡"],"title":"Prosody搭建xmpp服务器"},{"content":"k8s rest api对rc、svc、ingress、pod、deployment等都提供的watch接口，可以实时的监听应用部署状态。\n在此之前简单先说一下http长连接\n分块传输编码（Chunked transfer encoding） 超文本传输协议（HTTP）中的一种数据传输机制，允许HTTP由应用服务器发送给客户端应用（ 通常是网页浏览器）的数据可以分成多个部分。分块传输编码只在HTTP协议1.1版本（HTTP/1.1）中提供。 通常，HTTP应答消息中发送的数据是整个发送的，Content-Length消息头字段表示数据的长度。数据的长度很重要，因为客户端需要知道哪里是应答消息的结束，以及后续应答消息的开始。然而，使用分块传输编码，数据分解成一系列数据块，并以一个或多个块发送，这样服务器可以发送数据而不需要预先知道发送内容的总大小。通常数据块的大小是一致的，但也不总是这种情况。\nTransfer-Encoding 消息首部指明了将 entity 安全传递给用户所采用的编码形式。\nTransfer-Encoding 是一个逐跳传输消息首部，即仅应用于两个节点之间的消息传递，而不是所请求的资源本身。一个多节点连接中的每一段都可以应用不同的Transfer-Encoding 值。如果你想要将压缩后的数据应用于整个连接，那么请使用端到端传输消息首部 Content-Encoding 。\n当这个消息首部出现在 HEAD 请求的响应中，而这样的响应没有消息体，那么它其实指的是应用在相应的 GET 请求的应答的值。\n指令 chunked 数据以一系列分块的形式进行发送。 Content-Length 首部在这种情况下不被发送。。在每一个分块的开头需要添加当前分块的长度，以十六进制的形式表示，后面紧跟着 \u0026lsquo;\\r\\n\u0026rsquo; ，之后是分块本身，后面也是'\\r\\n' 。终止块是一个常规的分块，不同之处在于其长度为0。终止块后面是一个挂载（trailer），由一系列（或者为空）的实体消息首部构成。\n分块编码 分块编码主要应用于如下场景，即要传输大量的数据，但是在请求在没有被处理完之前响应的长度是无法获得的。例如，当需要用从数据库中查询获得的数据生成一个大的HTML表格的时候，或者需要传输大量的图片的时候。一个分块响应形式如下：\nHTTP/1.1 200 OK Content-Type: text/plain Transfer-Encoding: chunked 7\\r\\n Mozilla\\r\\n 9\\r\\n Developer\\r\\n 7\\r\\n Network\\r\\n 0\\r\\n \\r\\n  HTTP 1.1引入分块传输编码提供了以下几点好处：\n HTTP分块传输编码允许服务器为动态生成的内容维持HTTP持久连接。通常，持久链接需要服务器在开始发送消息体前发送Content-Length消息头字段，但是对于动态生成的内容来说，在内容创建完之前是不可知的。[动态内容，content-length无法预知] 分块传输编码允许服务器在最后发送消息头字段。对于那些头字段值在内容被生成之前无法知道的情形非常重要，例如消息的内容要使用散列进行签名，散列的结果通过HTTP消息头字段进行传输。没有分块传输编码时，服务器必须缓冲内容直到完成后计算头字段的值并在发送内容前发送这些头字段的值。[散列签名，需缓冲完成才能计算] HTTP服务器有时使用压缩 （gzip或deflate）以缩短传输花费的时间。分块传输编码可以用来分隔压缩对象的多个部分。在这种情况下，块不是分别压缩的，而是整个负载进行压缩，压缩的输出使用本文描述的方案进行分块传输。在压缩的情形中，分块编码有利于一边进行压缩一边发送数据，而不是先完成压缩过程以得知压缩后数据的大小。[gzip压缩，压缩与传输同时进行]  一般情况HTTP的Header包含Content-Length域来指明报文体的长度。有时候服务生成HTTP回应是无法确定消息大小的，比如大文件的下载，或者后台需要复杂的逻辑才能全部处理页面的请求，这时用需要实时生成消息长度，服务器一般使用chunked编码\n原理 k8s提供的watch功能是建立在对etcd的watch之上的，当etcd的key-value出现变化时，会通知kube-apiserver，这里的Key-vlaue其实就是k8s资源的持久化。\n早期的k8s架构中，kube-apiserver、kube-controller-manager、kube-scheduler、kubelet、kube-proxy，都是直接去watch etcd的，这样就造成etcd的连接数太大（节点成千上万时），对etcd压力太大，浪费资源，因此到了后面，只有kube-apiserver去watch etcd，而kube-apiserver对外提供watch api，也就是kube-controller-manager、kube-scheduler、kubelet、kube-proxy去watch kube-apiserver，这样大大减小了etcd的压力\nWatch API 通过k8s 官网 rest api的描述，可以看到，Watch API实际上一个标准的HTTP GET请求，我们以Pod的Watch API为例\nHTTP Request GET /api/v1/watch/namespaces/{namespace}/pods Path Parameters Parameter Description namespace object name and auth scope, such as for teams and projects Query Parameters Parameter Description fieldSelector A selector to restrict the list of returned objects by their fields. Defaults to everything. labelSelector A selector to restrict the list of returned objects by their labels. Defaults to everything. pretty If ‘true’, then the output is pretty printed. resourceVersion When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it’s 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv. timeoutSeconds Timeout for the list/watch call. watch Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion. Response Code Description 200 WatchEvent OK  从上面可以看出Watch其实就是一个GET请求，和一般请求不同的是，它有一个watch的query parameter，也就是kube-apiserver接到这个请求，当发现query parameter里面包含watch，就知道这是一个Watch API，watch参数默认为true。\n==返回值是200和WatchEvent。apiserver首先会返回一个200的状态码，建立长连接，然后不断的返回watch event==\n源码 原理都讲完了，现在到源码了，很简单。\nOkHttpClient client = makeSSLClient(); Request request = new Request.Builder() .url(\u0026quot;https://10.1.1.11:6443/api/v1/watch/namespaces/default/pods\u0026quot;) .addHeader(\u0026quot;Authorization\u0026quot;,\u0026quot;Bearer \u0026quot;+\u0026quot;eyJhbGciOiBnlQ\u0026quot;) .get() .build(); client.newCall(request).enqueue(new Callback() { @Override public void onFailure(Call call, IOException e) { log.info(\u0026quot;Watch connection failed. reason: {}\u0026quot;, e.getMessage()); } @Override public void onResponse(Call call, Response response) throws IOException { if (!response.isSuccessful()) { log.info(\u0026quot;!response.isSuccessful() {}\u0026quot;, response.code()); } try { BufferedSource source = response.body().source(); while (!source.exhausted()) { String message = source.readUtf8LineStrict(); log.info(message); } } catch (Exception e) { log.info(\u0026quot;Watch terminated unexpectedly. reason: {}\u0026quot;, e.getMessage()); } } });  剩下的就待自己完善了。\n需要注意的是：\n k8s提供的restful API在此处并不是网上常说的HTTP2协议，它就是HTTP 1.1 长连接 要注意http connection的超时，这里是长连接，超时应该是-1  如果是Java k8s client，可以使用fabric8的watch机制，使用如下：\nKubernetesClient client = new DefaultKubernetesClient(config);//使用默认的就足够了 //由于4.10.2版本有个影响events使用的回归bug，暂时回退到4.9.2版本。详情见官网issue#2328 //4.10.3已修复 client.v1().events().inAnyNamespace().watch(new Watcher\u0026lt;Event\u0026gt;() { @Override public void eventReceived(Action action, Event resource) { log.info(\u0026quot;event {} resource:{}\u0026quot; , action.name(),resource.toString()); redisService.lSet(\u0026quot;k8sevent\u0026quot;,resource,3600*24*5); } @Override public void onClose(KubernetesClientException cause) { log.info(\u0026quot;Watcher close due to {}\u0026quot; , cause); } });  其本质也是调用的restful API。\n","date":"2020-08-11","permalink":"https://iminto.github.io/post/%E5%9F%BA%E4%BA%8Erestfulapi%E5%AE%9E%E7%8E%B0k8s%E7%9A%84%E7%9B%91%E5%90%AC%E6%9C%BA%E5%88%B6/","tags":["k8s","Java"],"title":"基于restfulAPI实现k8s的监听机制"},{"content":"helm3集成minio搭建私有仓库 我们一般是从本地的目录结构中的chart去进行部署，如果要集中管理chart,就需要涉及到repository的问题可以通过minio建立一个私有的存放仓库。\nminio安装 安装过程略去，直接下载执行文件即可\n.\\minio.exe server g:/tmp/  配置mc\nmc config host add minio http://192.168.1.51 BKIKJAA5BMMU2RHO6IBB V7f1CwQqAcwo80UEIJEjc5gVQUSSx5ohQ9GSrr12  仓库创建 helm create helm-chart helm package ./helm-chart --debug #构建索引 helm repo index ./  接下来是复制生成的index.yaml到minio中\n.\\mc.exe policy set download minio/data .\\mc.exe cp G:\\data\\project\\helm\\index.yaml minio/data/  到这一步基本就快好了，然后\nhelm repo add mi http://10.180.204.129:9000/data/ helm repo list  最终可以看到如下结果，说明添加仓库成功：\nPS G:\\data\\project\\helm\u0026gt; helm repo list NAME URL stable https://kubernetes-charts.storage.googleapis.com/ mi http://10.180.204.129:9000/data/ PS G:\\data\\project\\helm\u0026gt;  搜索下\nPS G:\\tmp\\data\u0026gt; helm search repo mi/helm-chart NAME CHART VERSION APP VERSION DESCRIPTION mi/helm-chart 0.2.0 1.16.4 A Helm chart for Kubernetes  也能搜到新加的Chart，完工。\n注意 1.minio虽然是一个文件对象服务器，但是也支持直接在OS文件系统下的操作。也就是说，直接在文件夹上的操作会同步到minio的数据库中。此前一直顾虑minio这种文件系统是否适合用来做repo，其实是多虑的。\n2.官网 https://helm.sh/docs/topics/chart_repository/ 的helm仓库格式如下，典型的tgz+index.yaml格式\ncharts/ | |- index.yaml | |- alpine-0.1.2.tgz | |- alpine-0.1.2.tgz.prov  然而，helm安装是支持文件夹格式的包路径，所以有些应用商店如rancher内置了一些仓库是git+文件夹格式的组织结构，这不是标准的helm仓库，但是也是可以使用的，只是不能被helm repo add而已。这样的仓库需要下载一个文件夹到临时目录再调用helm安装。\n3.如果你发布了两个版本的chart包，也update了，但是仓库默认只能搜到高版本的。需要这么做\nPS G:\\tmp\\data\u0026gt; helm search repo mi/helm-chart --versions NAME CHART VERSION APP VERSION DESCRIPTION mi/helm-chart 0.2.0 1.16.4 A Helm chart for Kubernetes mi/helm-chart 0.1.0 1.16.0 A Helm chart for Kubernetes  安装\nhelm install mi/helm-chart --version 0.1.0  ","date":"2020-07-03","permalink":"https://iminto.github.io/post/helm%E9%9B%86%E6%88%90minio%E6%90%AD%E5%BB%BA%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/","tags":["k8s"],"title":"Helm集成minio搭建私有仓库"},{"content":"在后端项目中，难免遇到需要写接口文档方便第三方调用的场景，一般业界最常用的方案是使用swagger。Java项目中，一般采用springfox项目，它集成了swagger和swagger-ui，不需要单独部署项目，可让文档随着项目一起发布。\n但是开源项目往往是开源一时热，事后拂衣去，缺少维护。这个项目已经两年多没有维护了，很多人在issue反馈过bug，作者一年前表示自己比较忙，没空维护。\nspringfox最新的版本是2.9.2，不支持spring5（虽然有个快照版支持spring5，但一直没发布，整合也有点麻烦）。spring5比较大的一个改变就是增加了webflux，因此旧版springfox无法兼容spring5的。\n其实用快照版，稍作修改也能让springfox支持webflux，但是我不是很喜欢这种做法。一个是增加了打包体积和运行内存占用，另一个则是swagger的使用污染了Java源码，很是不美观，强迫症不能忍。\n@RestController @RequestMapping(\u0026quot;/dataspace/api/v1/hive\u0026quot;) @Api(value = \u0026quot;hive\u0026quot;, description = \u0026quot;hive资源管理\u0026quot;) public class HiveManagerController { @Autowired HiveManagerService hiveManagerService; @RequestMapping(value = \u0026quot;/list\u0026quot;, method = {RequestMethod.POST}) @ApiOperation(value = \u0026quot;资源列表\u0026quot;, notes = \u0026quot;\u0026quot;) public PageResult\u0026lt;HiveVO\u0026gt; showPublic(@ApiParam(value = \u0026quot;hive查询对象\u0026quot;) @RequestBody PageReqParam\u0026lt;HiveReq\u0026gt; hiveReq) { PageResult\u0026lt;HiveVO\u0026gt; result = new PageResult\u0026lt;\u0026gt;(); if (hiveReq.getReqParam() == null) { result.setCode(-1); result.setMsg(\u0026quot;参数不完整\u0026quot;); return result; } if (hiveReq.getPageSize() \u0026gt; 50 || hiveReq.getPageSize() \u0026lt; 0) { result.setCode(-1); result.setMsg(\u0026quot;页码非法\u0026quot;); return result; } result = hiveManagerService.getList(hiveReq); return result; }  源码中混入了各种ApiParam、Api、ApiOperation注解。\n再加上我现在使用的springcloud套件，需要在gateway的feign接口上加注释，这样的话，无论是springfox，还是很多第三方的api doc工具都很难胜任。\n于是，我想到了另外一种方法，就是javadoc。然而javadoc自带的注解很有限，不能满足第三方对文档的需求，比如\n/** * 根据节点名删除主机 * @method DELETE * @path host/delHostByNodeName * @param nodeName 节点名 * @param cluster 集群名 * @return JSON */ @DeleteMapping(\u0026quot;/delHostByNodeName\u0026quot;) public String delHostByNodeName(@RequestParam(\u0026quot;nodeName\u0026quot;) String nodeName,@RequestParam(\u0026quot;cluster\u0026quot;) String cluster);  javadoc并不认识method和path这两个标签，生成的文档还是缺少一些必须要的信息。\n这个不难，扩展下taglet即可。\n先引入maven依赖\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;jdk.tools\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jdk.tools\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.8\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;system\u0026lt;/scope\u0026gt; \u0026lt;systemPath\u0026gt;${JAVA_HOME}/lib/tools.jar\u0026lt;/systemPath\u0026gt; \u0026lt;/dependency\u0026gt;  扩展taglet代码\npackage com.github.cloud.ali.common.tool; import com.sun.javadoc.Tag; import com.sun.tools.doclets.Taglet; import java.util.Map; public class MethodTaglet implements Taglet { private String NAME = \u0026quot;HTTP请求类型\u0026quot;; private String HEADER = \u0026quot;HTTP请求类型:\u0026quot;; @Override public boolean inField() { return false; } @Override public boolean inConstructor() { return false; } @Override public boolean inMethod() { return true; } @Override public boolean inOverview() { return true; } @Override public boolean inPackage() { return true; } @Override public boolean inType() { return true; } @Override public boolean isInlineTag() { return false; } public static void register(Map tagletMap) { MethodTaglet tag = new MethodTaglet(); Taglet t = (Taglet) tagletMap.get(tag.getName()); if (t != null) { tagletMap.remove(tag.getName()); } tagletMap.put(tag.getName(), tag); } @Override public String getName() { return NAME; } @Override public String toString(Tag tag) { return \u0026quot;\u0026lt;DT\u0026gt;\u0026lt;B\u0026gt;\u0026quot; + HEADER + \u0026quot;\u0026lt;/B\u0026gt;\u0026lt;DD\u0026gt;\u0026quot; + \u0026quot;\u0026lt;table cellpadding=2 cellspacing=0\u0026gt;\u0026lt;tr\u0026gt;\u0026lt;td bgcolor=\\\u0026quot;yellow\\\u0026quot;\u0026gt;\u0026quot; + tag.text() + \u0026quot;\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;/table\u0026gt;\u0026lt;/DD\u0026gt;\\n\u0026quot;; } @Override public String toString(Tag[] tags) { if (tags.length == 0) { return null; } String result = \u0026quot;\\n\u0026lt;DT\u0026gt;\u0026lt;B\u0026gt;\u0026quot; + HEADER + \u0026quot;\u0026lt;/B\u0026gt;\u0026lt;DD\u0026gt;\u0026quot;; result += \u0026quot;\u0026lt;table cellpadding=2 cellspacing=0\u0026gt;\u0026lt;tr\u0026gt;\u0026lt;td bgcolor=\\\u0026quot;yellow\\\u0026quot;\u0026gt;\u0026quot;; for (int i = 0; i \u0026lt; tags.length; i++) { if (i \u0026gt; 0) { result += \u0026quot;, \u0026quot;; } result += tags[i].text(); } return result + \u0026quot;\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;/table\u0026gt;\u0026lt;/DD\u0026gt;\\n\u0026quot;; } }  同理，path注解也是类似的实现。编译命令如下：\njavadoc -protected -splitindex -use -author -version -encoding utf-8 -charset utf-8 -d /usr/jackma/doc -windowtitle \u0026quot;ali 文档\u0026quot; $(ls /usr/jackma/ali/ali-common/src/main/java/com/github/cloud/ali/common/model/*.java |tr \u0026quot;\\n\u0026quot; \u0026quot; \u0026quot;) $(ls /usr/jackma/ali/ali-gateway/src/main/java/com/github/cloud/ali/feign/*.java |tr \u0026quot;\\n\u0026quot; \u0026quot; \u0026quot;) -tag method🅰️\u0026quot;HTTP请求方法:\u0026quot; -tag path🅰️\u0026quot;请求路径:\u0026quot; -tagletpath /usr/jackma/ali/ali-common/src/main/java/com/github/cloud/ali/common/tool/MethodTaglet.java -tagletpath /usr/jackma/ali/ali-common/src/main/java/com/github/cloud/ali/common/tool/PathTaglet.java -taglet com.github.cloud.ali.common.tool.MethodTaglet -taglet com.github.cloud.ali.common.tool.PathTaglet  最终效果如下：\n还可以进一步，加上数据类型的注解，这样就更完善了。\n虽然离swagger-ui还有点差距，但是还是比原版javadoc好多了。最大的优点是没有任何限制和对源码的污染。\n不得不说，Java的扩展性不是盖的。\n","date":"2020-05-12","permalink":"https://iminto.github.io/post/%E4%B8%80%E7%A7%8Dswagger-ui%E7%9A%84%E6%9B%BF%E4%BB%A3%E6%96%B9%E6%A1%88%E4%B8%8D%E5%BC%95%E5%85%A5%E4%BB%BB%E4%BD%95%E6%BA%90%E7%A0%81%E6%B1%A1%E6%9F%93/","tags":["Java"],"title":"一种swagger Ui的替代方案不引入任何源码污染"},{"content":"​ 这个问题纠结我快一年了。某次manjaro升级后，我的manjaro在系统自带应用上如konsole,kate,Yakuake上都不能切换输入法（目测系统自带的软件都不能），鼠标放键盘图标上提示“无输入窗口”。但是浏览器和其他软件是可以的。这个问题不是太影响使用，就忍了很久，大不了其他地方写好了再复制到kate里，但是就好像衣服上落沾了一坨黄泥，始终感觉不爽，每隔一两个月就要尝试解决一次，始终无果。\n尝试过的解决方案有下面几种：\n 修改/etc/profile 修改.xprofile 修改/etc/environment 更换其他中文输入法 用fcitx-diagnose诊断配置  配置文件肯定是正确的，按照网上说的 Linux下输入中文的配置也检查了很多，作为一个有六七年经验的 Linux老司机，怎么可能翻车呢。搜了很多文章，死马当作活马医，一直无解。\nfcitx-diagnose诊断结果如下，然而确认配置了，可为什么就是不认识一直没理解。\n\u0026quot; 而不是 \u0026quot;fcitx\u0026quot;. 请检查您是否在某个初始化文件中错误的设置了它的值.** **您可能会在 qt4 程序中使用 fcitx 时遇到问题.** **请使用您发行版提供的工具将环境变量 QT_IM_MODULE 设为 \u0026quot;fcitx\u0026quot; 或者将 `export QT_IM_MODULE=fcitx` 添加到您的 `~/.xprofile` 中. 参见 [输入法相关的环境变量: QT_IM_MODULE](http://fcitx-im.org/wiki/Input_method_related_environment_variables/zh-cn#QT_IM_MODULE).** gtk - `${GTK_IM_MODULE}`: \u0026quot; 而不是 \u0026quot;fcitx\u0026quot;. 请检查您是否在某个初始化文件中错误的设置了它的值.** **您可能会在 gtk 程序中使用 fcitx 时遇到问题.** **请使用您发行版提供的工具将环境变量 GTK_IM_MODULE 设为 \u0026quot;fcitx\u0026quot; 或者将 `export GTK_IM_MODULE=fcitx` 添加到您的 `~/.xprofile` 中. 参见 [输入法相关的环境变量: GTK_IM_MODULE](http://fcitx-im.org/wiki/Input_method_related_environment_variables/zh-cn#GTK_IM_MODULE).**  直到今天，偶尔搜到了这篇文章，出现的问题和我遇到的一模一样。原来是我的.xprofile里环境变量 XMODIFIERS、QT_IM_MODULE、GTK_IM_MODULE 值的末尾有一个回车符。也就是说，设置这些环境变量的那个文件错误地使用了 DOS / Windows 的换行符。\n解决方案就很简单了，在 Vim 中打开并执行 :set ff=unix，然后保存并退出 :wq。\n重新注销，解决了。\n然后想起来，快一年前更新系统，结果挂了。这是唯一一次更新 manjaro滚挂了（这是manjaro软件源的一次bug 导致），修复系统后用了百度复制来的代码，竟然疏忽了。\n要是没那篇文章，真不知何年何月能解决。放狗一搜，还有许许多多受害者遇到这种情况至今没有解决，甚至在manjaro官网提问也无解。所以记录下，希望更多人能看到。\n","date":"2020-03-07","permalink":"https://iminto.github.io/post/kde%E6%A1%8C%E9%9D%A2%E4%B8%8B%E9%83%A8%E5%88%86%E5%BA%94%E7%94%A8%E6%97%A0%E6%B3%95%E8%BE%93%E5%85%A5%E4%B8%AD%E6%96%87/","tags":["linux"],"title":"Kde桌面下自带应用无法输入中文"},{"content":"1.安装k8s 安装K8S的步骤略去，使用k3s安装会更快捷方便，方便测试环境。\n如果使用k3s会有个坑，k3s默认使用container而不是docker作为容器，会导致运行时出现一些问题，后面会详细分析。\n安装k3s后，需要按照如下修改 /etc/systemd/system/k3s.service\nExecStartPre=-/sbin/modprobe overlay ExecStart=/usr/local/bin/k3s \\ server --docker \\ #添加 --docker 参数  2.springboot镜像准备 pom.xml\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;project xmlns=\u0026quot;http://maven.apache.org/POM/4.0.0\u0026quot; xmlns:xsi=\u0026quot;http://www.w3.org/2001/XMLSchema-instance\u0026quot; xsi:schemaLocation=\u0026quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026quot;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.5.RELEASE\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;com.github.iminto\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;bcdemo\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;bcdemo\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;Demo project for Spring Boot\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt;  BcdemoApplication.java 启动器代码略。\nsrc\\main\\java\\com\\github\\iminto\\bcdemo\\controller\\HomeController.java\npackage com.github.iminto.bcdemo.controller; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class HomeController { @RequestMapping(\u0026quot;/\u0026quot;) public String home() { return \u0026quot;Hello Docker World\u0026quot;; } }  src\\main\\resources\\application.yaml\nserver: port: 9010  mvn打包。\nDockerfile文件如下：\nFROM openjdk:8-jdk-alpine ENV TZ=Asia/Shanghai RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime \u0026amp;\u0026amp; echo $TZ \u0026gt; /etc/timezone COPY bcdemo.jar /opt/app.jar COPY run.sh /opt/run.sh EXPOSE 9010 ENTRYPOINT [\u0026quot;/bin/sh\u0026quot;, \u0026quot;/opt/run.sh\u0026quot;]  run.sh\n#!/bin/bash # do other things here java -jar /opt/app.jar 2\u0026gt;\u0026amp;1  需要注意，docker必须要有一个前台进程，不然运行后会马上退出，所以不能使用下面的命令\n#这么写是错的 java -jar /opt/app.jar 2\u0026gt;\u0026amp;1 \u0026amp;  docker镜像构建\ndocker build . -t bcdemo:1.0  测试docker镜像是否正确时，需要用ctrl+p+q终止控制台日志打印，不要用ctrl+c。\n3.k8s部署 编写yaml文件\napiVersion: v1 kind: Deployment metadata: name: k8s-springboot-demo labels: app: k8s-springboot-demo spec: replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: app: k8s-springboot-demo template: metadata: labels: app: k8s-springboot-demo spec: containers: - name: k8s-springboot-demo image: bcdemo:1.0 ports: - containerPort: 9010 protocol: TCP livenessProbe: httpGet: path: / port: 9010 initialDelaySeconds: 30 timeoutSeconds: 30 imagePullPolicy: IfNotPresent tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule --- apiVersion: v1 kind: Service metadata: name: k8s-springboot-demo namespace: default labels: app: k8s-springboot-demo spec: ports: - port: 9010 targetPort: 9010 selector: app: k8s-springboot-demo type: NodePort  部署\n#部署 kubectl apply -f sp.yaml #查看运行状态 kubectl get po,svc,deploy -o wide #删除Deployment kubectl delete -f sp.yaml #删除节点 kubectl delete pod k8s-springboot-demo-fc778b44-f4p49 #查看节点详细运行状态，可用于排错 kubectl describe pod k8s-springboot-demo-fc778b44-f4p49  最终部署结果如下：\n[root@chenwork2 project]# kubectl get po,svc,deploy -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES pod/k8s-springboot-demo-fc778b44-zfjnx 1/1 Running 0 16h 10.42.0.11 chenwork2 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR service/k8s-springboot-demo NodePort 10.43.35.126 \u0026lt;none\u0026gt; 9010:31622/TCP 16h app=k8s-springboot-demo service/kubernetes ClusterIP 10.43.0.1 \u0026lt;none\u0026gt; 443/TCP 51d \u0026lt;none\u0026gt; NAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR deployment.extensions/k8s-springboot-demo 1/1 1 1 16h k8s-springboot-demo bcdemo:1.0 app=k8s-springboot-demo  验证：\n[root@chenwork2 project]# curl -i -X GET chenwork2:31622/ HTTP/1.1 200 Content-Type: text/plain;charset=UTF-8 Content-Length: 18 Date: Fri, 06 Mar 2020 01:55:40 GMT Hello Docker World  这样的端口，只能在集群内访问，集群外是无法访问的。\n4.k3s的问题 如果pod一直是 ContainerCreating 状态，那就是pod没有创建成功，用describe命令看一下，最后几行一般会看到如下报错\nWarning FailedCreatePodSandBox 91s (x29 over 21m) kubelet, host123 Failed create pod sandbox: rpc error: code = Unknown desc = failed to get sandbox image \u0026quot;k8s.gcr.io/pause:3.1\u0026quot;: failed to pull image \u0026quot;k8s.gcr.io/pause:3.1\u0026quot;: failed to pull and unpack image \u0026quot;k8s.gcr.io/pause:3.1\u0026quot;: failed to resolve reference \u0026quot;k8s.gcr.io/pause:3.1\u0026quot;: failed to do request: Head https://k8s.gcr.io/v2/pause/manifests/3.1: dial tcp 108.177.97.82:443: i/o timeout  原因已经非常清楚了，failed to pull image \u0026ldquo;k8s.gcr.io/pause:3.1\u0026rdquo;，镜像拉不到。\n解决方法：\ndocker pull mirrorgooglecontainers/pause:3.1 #其实直接把rancher/pause镜像命名成k8s.gcr.io/pause即可 docker tag mirrorgooglecontainers/pause:3.1 k8s.gcr.io/pause:3.1  重启k3s，你会发现pod还是启动不起来，这就是前面说的原因：k3s默认使用container而不是docker作为容器\n你有了pause镜像，但是k3s不认docker镜像，而是认container容器，所以需要把k3s改成docker运行时。\n或者如下操作：\nctr --version #需要预先导出pause镜像 ctr images import pause-amd64-3.1.tar #看看有没有加载进来 ctr images list #如果加载了，但是名字不匹配，需要打标签 ctr images tag gcr.io/google_containers/pause-amd64:3.1 k8s.gcr.io/pause:3.1  5.LoadBalancer服务暴露给外部访问 K8S Service 暴露服务类型有三种：ClusterIP、NodePort、LoadBalancer，三种类型分别有不同的应用场景。\n  对内服务发现，可以使用 ClusterIP 方式对内暴露服务，因为存在 Service 重新创建 IP 会更改的情况，所以不建议直接使用分配的 ClusterIP 方式来内部访问，可以使用 K8S DNS 方式解析，DNS 命名规则为：\u0026lt;svc_name\u0026gt;.\u0026lt;namespace_name\u0026gt;.svc.cluster.local，按照该方式可以直接在集群内部访问对应服务。\n  对外服务暴露，可以采用 NodePort、LoadBalancer 方式对外暴露服务，NodePort 方式使用集群固定 IP，但是端口号是指定范围内随机选择的，每次更新 Service 该 Port 就会更改，不太方便，当然也可以指定固定的 NodePort，但是需要自己维护 Port 列表，也不方便。LoadBalancer 方式使用集群固定 IP 和 NodePort，会额外申请申请一个负载均衡器来转发到对应服务，但是需要底层平台支撑。如果使用 Aliyun、GCE 等云平台商，可以使用该种方式，他们底层会提供 LoadBalancer 支持，直接使用非常方便。\n  以上方式或多或少都会存在一定的局限性，所以建议如果在公有云上运行，可以使用 LoadBalancer、 Ingress 方式对外提供服务，私有云的话，可以使用 Ingress 通过域名解析来对外提供服务。\n下面使用LoadBalancer方式。\nyaml文件修改 修改k8s-springboot-demo.yaml\napiVersion: v1 kind: Service metadata: name: k8s-springboot-demo namespace: default labels: app: k8s-springboot-demo spec: ports: - port: 8080 targetPort: 8080 selector: app: k8s-springboot-demo type: LoadBalancer  service的type修改为LoadBalancer，然后\nkubectl apply -f k8s-springboot-demo.yaml  命令修改 用命令修改的方式更方便。\n[root@chenwork2 project]# kubectl delete svc k8s-springboot-demo service \u0026quot;k8s-springboot-demo\u0026quot; deleted [root@chenwork2 project]# kubectl get po,svc,deploy NAME READY STATUS RESTARTS AGE pod/k8s-springboot-demo-fc778b44-zfjnx 1/1 Running 0 16h NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 10.43.0.1 \u0026lt;none\u0026gt; 443/TCP 51d NAME READY UP-TO-DATE AVAILABLE AGE deployment.extensions/k8s-springboot-demo 1/1 1 1 16h [root@chenwork2 project]# kubectl expose deploy k8s-springboot-demo --type=LoadBalancer service/k8s-springboot-demo exposed [root@chenwork2 project]# kubectl get po,svc,deploy NAME READY STATUS RESTARTS AGE pod/k8s-springboot-demo-fc778b44-zfjnx 1/1 Running 0 16h pod/svclb-k8s-springboot-demo-crfvw 1/1 Running 0 4s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/k8s-springboot-demo LoadBalancer 10.43.112.54 10.180.249.73 9010:32219/TCP 4s service/kubernetes ClusterIP 10.43.0.1 \u0026lt;none\u0026gt; 443/TCP 51d NAME READY UP-TO-DATE AVAILABLE AGE deployment.extensions/k8s-springboot-demo 1/1 1 1 16h  这样就能在集群外，直接用浏览器访问了。\n也可以使用 ClusterIP+kubectl proxy 方式，但不推荐。\n6.容器部署yaml中传递参数 可以向容器传递参数到脚本执行一些特殊操作，而且这里变成脚本来启动，这样后续构建镜像基本不需要改 Dockerfile 了\n#!/bin/bash # do other things here java -jar $JAVA_OPTS /opt/project/app.jar $1 2\u0026gt;\u0026amp;1  上边示例中，我们就注入 $JAVA_OPTS 环境变量，来优化 JVM 参数，还可以传递一个变量，这个变量大家应该就猜到了，就是服务启动加载哪个配置文件参数，例如：\u0026ndash;spring.profiles.active=prod 那么，在 Deployment 中就可以通过如下方式配置了：\nspec: containers: - name: project-name image: registry.docker.com/project/app:v1.0.0 args: [\u0026quot;--spring.profiles.active=prod\u0026quot;] env: - name: JAVA_OPTS value: \u0026quot;-XX:PermSize=512M -XX:MaxPermSize=512M -Xms1024M -Xmx1024M...\u0026quot;  7.参考 Spring Boot 项目转容器化 K8S 部署实用经验分享\nK8s 集群使用 ConfigMap 优雅加载 Spring Boot 配置文件\n[Spring Boot应用容器化及Kubernetes部署](http://fly-luck.github.io/2018/11/10/Spring Boot App on Kubernetes/)\n基于Kubernetes和Springboot构建微服务\nDocker / Kubernetes部署Java / SpringBoot项目\n在Kubernetes中部署spring boot应用\n","date":"2020-03-06","permalink":"https://iminto.github.io/post/k8s%E9%83%A8%E7%BD%B2springboot/","tags":["k8s","Java"],"title":"K8s部署springboot"},{"content":"rancher 是一个为DevOps团队提供的完整的Kubernetes与容器管理解决方案。rancher最大的优点就是安装部署方便，极大地简化了K8S的安装配置。在官网上，推荐的是使用docker方式安装rancher，这种方式隐藏了大量的细节。在网上搜了下现有的资料，几乎都是照抄官方文档，更没有在windows上安装rancher的先例。\nrancher是用golang写的，跨平台问题不大，但也需要一些修改。正好最近要对rancher做二次开发，于是记录下了在windows上编译安装rancher的步骤。\n1.修改源码 rancher要在windows上编译通过并运行，需要修改以下源码\nmain.go\nfunc run(cfg app.Config) error { logrus.Infof(\u0026quot;Rancher version %s is starting\u0026quot;, VERSION) logrus.Infof(\u0026quot;Rancher arguments %+v\u0026quot;, cfg) dump.GoroutineDumpOn(syscall.SIGUSR1, syscall.SIGILL) ctx := signals.SetupSignalHandler(context.Background())  改为如下，此处修改基本不会有副作用\nfunc run(cfg app.Config) error { logrus.Infof(\u0026quot;Rancher version %s is starting\u0026quot;, VERSION) logrus.Infof(\u0026quot;Rancher arguments %+v\u0026quot;, cfg) dump.GoroutineDumpOn(syscall.SIGILL, syscall.SIGILL) ctx := signals.SetupSignalHandler(context.Background())  然后屏蔽以下几个文件中相关syscall的处理：（这几处修改可能会导致K8S相关的功能带来影响，但影响未知.建议使用条件编译方式）\npkg/controllers/user/helm/common/common.go\nfunc JailCommand(cmd *exec.Cmd, jailPath string) (*exec.Cmd, error) { if os.Getenv(\u0026quot;CATTLE_DEV_MODE\u0026quot;) != \u0026quot;\u0026quot; { return cmd, nil } else { //cred, err := jailer.GetUserCred() //if err != nil { // return nil, errors.WithMessage(err, \u0026quot;get user cred error\u0026quot;) //} // //cmd.SysProcAttr = \u0026amp;syscall.SysProcAttr{} //cmd.SysProcAttr.Credential = cred //cmd.SysProcAttr.Chroot = jailPath //cmd.Env = jailer.WhitelistEnvvars(cmd.Env) return cmd, nil } }  pkg/controllers/management/node/utils.go 修改同理\nfunc buildCommand(nodeDir string, node *v3.Node, cmdArgs []string) (*exec.Cmd, error) { // In dev_mode, don't need jail or reference to jail in command if os.Getenv(\u0026quot;CATTLE_DEV_MODE\u0026quot;) != \u0026quot;\u0026quot; { env := initEnviron(nodeDir) command := exec.Command(nodeCmd, cmdArgs...) command.Env = env return command, nil } //cred, err := jailer.GetUserCred() //if err != nil { // return nil, errors.WithMessage(err, \u0026quot;get user cred error\u0026quot;) //} command := exec.Command(nodeCmd, cmdArgs...) //command.SysProcAttr = \u0026amp;syscall.SysProcAttr{} //command.SysProcAttr.Credential = cred //command.SysProcAttr.Chroot = path.Join(jailer.BaseJailPath, node.Namespace) envvars := []string{ nodeDirEnvKey + nodeDir, \u0026quot;PATH=/usr/bin:/var/lib/rancher/management-state/bin\u0026quot;, } command.Env = jailer.WhitelistEnvvars(envvars) return command, nil }  屏蔽jailer的处理\npkg/jailer/jailer.go 注释掉这个方法\n// GetUserCred looks up the user and provides it in syscall.Credential //func GetUserCred() (*syscall.Credential, error) { // //}  修改一个依赖库里的文件 （比较正规的方式是在go mod中使用replace语法，而不是直接修改第三方package）\nvendor/github.com/rancher/kontainer-engine/service/service.go\n#446行开始注释这段代码 //if os.Getenv(\u0026quot;CATTLE_DEV_MODE\u0026quot;) == \u0026quot;\u0026quot; { // cred, err := getUserCred() // if err != nil { // return \u0026quot;\u0026quot;, errors.WithMessage(err, \u0026quot;get user cred error\u0026quot;) // } // // cmd.SysProcAttr = \u0026amp;syscall.SysProcAttr{} // cmd.SysProcAttr.Credential = cred // cmd.SysProcAttr.Chroot = \u0026quot;/opt/jail/driver-jail\u0026quot; // cmd.Env = whitelistEnvvars([]string{\u0026quot;PATH=/usr/bin\u0026quot;}) //}  628行注释掉这个方法\n// getUserCred looks up the user and provides it in syscall.Credential //func getUserCred() (*syscall.Credential, error) {  然后编译即可生成exe文件。\n2.运行 如果笔记本内存在8G以上，可以安装windows版本k8s或者minikube\n由于我本机配置太低，所以使用了linux服务器上的配置。\n#每次运行一定要执行这个命令，或者在环境变量里配置加下也可一劳永逸 set CATTLE_DEV_MODE=true go build -mod=vendor #生成可执行文件 rancher.exe 运行文件需要k8s 在服务器上安装k8s 然后将配置文件k3s.yaml下载到本地windows上，修改配置文件的ip为k8s所在服务器上的ip #修改完成后执行下面指令 其中：g:\\data\\k3s.yaml为配置文件所在本地路径 rancher.exe --k8s-mode=external --kubeconfig g:\\data\\k3s.yaml --no-cacerts=true  k3s.yaml是Linux服务器上的K8S配置文件。不要使用服务器上已经被rancher使用过的k8s，而是用一个崭新的K8S环境。\n服务器上安装k8s可以参考这里：https://k3s.io/\n#这一步可能需要翻墙 curl -sfL https://get.k3s.io | sh - #Check for Ready node, takes maybe 30 seconds k3s kubectl get node  新增一个用户试一下，可以新增成功\n3.条件编译 条件编译不需要在原有文件内容上做修改，编译出的文件可以保证在linux上是完整的。\n以修改pkg/controllers/user/helm/common/common.go 为例，将原文件重命名未common_linux.go，然后新建一个common_windows_amd64.go，里面是windows版本的源码。\n然后编译即可。\n看起来条件编译对源文件做了重命名操作，但是保证了linux上代码的完整，不会让windows上的修改导致linux上产生隐患。\ngolang条件编译的源里可以参考此处：https://www.jianshu.com/p/4bb03e67e7ae\n4.问题 1.未测试更多高级功能，还未知。\n","date":"2020-02-28","permalink":"https://iminto.github.io/post/windows%E4%B8%8A%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%E8%BF%90%E8%A1%8Crancher/","tags":["k8s"],"title":"Windows上编译安装运行rancher"},{"content":"今天群里有位360的安全大佬，发了个链接http://93.175.29.89:8008/，说爬这个网址的时候，IO会一直卡在那，一直没有返回响应。 那个网址是他构造的一个特殊请求，输出一个视频流，但是服务器端不返回Content-Length，也不输出真实数据，就是输出不到1024字节的流后就一直停在那也不close，浏览器打开的效果就是看到了视频的前几帧，然后一直卡在哪转圈。\n这么说来，感觉不是个大问题，设置下ReadTimeout不就好了么，大佬说他也设置了，但是无效，他使用的python代码实现，刚开始我觉得是他代码的问题，或者那个API库实现的问题，就用Java也实现了一把\npackage sms.bai.util; import com.squareup.okhttp.Headers; import com.squareup.okhttp.OkHttpClient; import com.squareup.okhttp.Request; import com.squareup.okhttp.Response; import java.io.IOException; import java.util.concurrent.*; public class Req { public static void reqUrl() throws IOException { OkHttpClient client = new OkHttpClient(); client.setConnectTimeout(5,TimeUnit.SECONDS); client.setReadTimeout(5,TimeUnit.SECONDS); Request request = new Request.Builder() .url(\u0026quot;http://93.175.29.89:8008/\u0026quot;) .build(); Response response = client.newCall(request).execute(); if (!response.isSuccessful()) { throw new IOException(\u0026quot;服务器端错误: \u0026quot; + response); } Headers responseHeaders = response.headers(); for (int i = 0; i \u0026lt; responseHeaders.size(); i++) { System.out.println(responseHeaders.name(i) + \u0026quot;: \u0026quot; + responseHeaders.value(i)); } System.out.println(response.body().string()); } public static void main(String[] args) throws IOException { reqUrl(); } }  果然如其所言，无论设置ConnectTimeout还是ReadTimeout都是无效的，代码一直停留在输出那里，不输出任何body（浏览器里还能勉强看到画面），程序也不stop\nContent-Type: multipart/x-mixed-replace;boundary=---nessy2jpegboundary OkHttp-Sent-Millis: 1582028133591 OkHttp-Received-Millis: 1582028133875  这里用的是OkHttp库 ,换其它库或者用Java自带的HttpUrlConnection理论上效果也是一样的。\n用ffmpeg来看看这个请求\n[kk@kk ~]$ ffmpeg -i http://93.175.29.89:8008/ -f mp4 out.mp4 ffmpeg version n4.2.2 Copyright (c) 2000-2019 the FFmpeg developers built with gcc 9.2.0 (GCC) libavutil 56. 31.100 / 56. 31.100 libavcodec 58. 54.100 / 58. 54.100 libavformat 58. 29.100 / 58. 29.100 libavdevice 58. 8.100 / 58. 8.100 libavfilter 7. 57.100 / 7. 57.100 libswscale 5. 5.100 / 5. 5.100 libswresample 3. 5.100 / 3. 5.100 libpostproc 55. 5.100 / 55. 5.100 Input #0, mpjpeg, from 'http://93.175.29.89:8008/': Duration: N/A, bitrate: N/A Stream #0:0: Video: mjpeg (Baseline), yuvj420p(pc, bt470bg/unknown/unknown), 640x480 [SAR 1:1 DAR 4:3], 25 tbr, 25 tbn, 25 tbc Stream mapping: Stream #0:0 -\u0026gt; #0:0 (mjpeg (native) -\u0026gt; h264 (libx264)) Press [q] to stop, [?] for help [libx264 @ 0x562ad6812cc0] using SAR=1/1 [libx264 @ 0x562ad6812cc0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 [libx264 @ 0x562ad6812cc0] profile High, level 3.0, 4:2:0, 8-bit [libx264 @ 0x562ad6812cc0] 264 - core 159 r2991 1771b55 - H.264/MPEG-4 AVC codec - Copyleft 2003-2019 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00 Output #0, mp4, to 'out.mp4': Metadata: encoder : Lavf58.29.100 Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuvj420p(pc), 640x480 [SAR 1:1 DAR 4:3], q=-1--1, 25 fps, 12800 tbn, 25 tbc Metadata: encoder : Lavc58.54.100 libx264 Side data: cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1 frame= 83 fps=1.1 q=-1.0 Lsize= 336kB time=00:00:03.20 bitrate= 859.8kbits/s speed=0.0436x  ffmpeg 能识别出是一个视频流，但是会一直卡在frame=xx这里，一直读取帧而不停止。强行终止后能输出一个时长有几秒的视频\n看来依靠HttpUrlConnection中的SocketTimeoutException是无解了，只能在外面套一层了。main方法改成如下\n public static void main(String[] args) throws Exception { final ExecutorService exec = Executors.newFixedThreadPool(1); Callable\u0026lt;String\u0026gt; call = new Callable\u0026lt;String\u0026gt;() { public String call() throws Exception { //开始执行耗时操作 reqUrl(); return \u0026quot;线程执行完成.\u0026quot;; } }; Future\u0026lt;String\u0026gt; future = null; try { future = exec.submit(call); String obj = future.get(1000 * 10, TimeUnit.MILLISECONDS); //任务处理超时时间设为 10 秒 System.out.println(\u0026quot;任务成功返回:\u0026quot; + obj); } catch (TimeoutException ex) { System.out.println(\u0026quot;处理超时啦....\u0026quot;); ex.printStackTrace(); future.cancel(true); } catch (Exception e) { System.out.println(\u0026quot;处理失败.\u0026quot;); e.printStackTrace(); }finally { // 关闭线程池 System.out.println(\u0026quot;关闭线程池\u0026quot;); exec.shutdown(); } }  这下能得到期望的结果了\nContent-Type: multipart/x-mixed-replace;boundary=---nessy2jpegboundary OkHttp-Sent-Millis: 1582028854911 OkHttp-Received-Millis: 1582028855178 处理超时啦.... java.util.concurrent.TimeoutException at java.util.concurrent.FutureTask.get(FutureTask.java:205) at sms.bai.util.Req.main(Req.java:47) 关闭线程池 Process finished with exit code 0  那这个HttpUrlConnection里的超时到底是啥意思呢？为什么无效呢？看一下文档。 ConnectTimeout , java 是这样解释的：\n Sets a specified timeout value, in milliseconds, to be used when opening a communications link to the resource referenced by this URLConnection. If the timeout expires before the connection can be established, a java.net.SocketTimeoutException is raised. A timeout of zero is interpreted as an infinite timeout.\nSome non-standard implmentation of this method may ignore the specified timeout. To see the connect timeout set, please call getConnectTimeout().\n 意思是用来建立连接的时间。如果到了指定的时间，还没建立连接，则报异常。 这个比较好理解。\nReadTimeout , Java 是这样解释的：\n Sets the read timeout to a specified timeout, in milliseconds. A non-zero value specifies the timeout when reading from Input stream when a connection is established to a resource. If the timeout expires before there is data available for read, a java.net.SocketTimeoutException is raised. A timeout of zero is interpreted as an infinite timeout.\nSome non-standard implementation of this method ignores the specified timeout. To see the read timeout set, please call getReadTimeout().\n 意思是已经建立连接，并开始读取服务端资源。如果到了指定的时间，没有可能的数据被客户端读取，则报异常。\n也就是说setReadTimeout not mean read complete, it mean when wait for 10s, when there\u0026rsquo;re no more data read in, will throw a timeoutexception。\n所以针对这种特殊的服务器构造的异常流，是没法用SocketTimeoutException来解决超时的，只能在外面再设置一层，通过线程的超时来控制。\n另外提一句，python是通过设置gevent超时来解决的，原理是一样的。\ntips：360大佬认为，这种特殊URL，不失为一种给爬虫挖坑的做法。\n","date":"2020-02-18","permalink":"https://iminto.github.io/post/httpurlconnection%E9%87%8Csetreadtimeout%E8%B6%85%E6%97%B6%E6%97%A0%E6%95%88/","tags":["Java"],"title":"HttpURLConnection里setReadTimeout超时无效"},{"content":"k8s每个版本看起来兼容性不是太好，很多网上的例子跑起来往往都有问题。\n目前用的版本\nroot@de001:/develop# kubectl version Client Version: version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;17\u0026quot;, GitVersion:\u0026quot;v1.17.2+k3s1\u0026quot;, GitCommit:\u0026quot;cdab19b09a84389ffbf57bebd33871c60b1d6b28\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2020-01-27T18:09:26Z\u0026quot;, GoVersion:\u0026quot;go1.13.6\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;} Server Version: version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;17\u0026quot;, GitVersion:\u0026quot;v1.17.2+k3s1\u0026quot;, GitCommit:\u0026quot;cdab19b09a84389ffbf57bebd33871c60b1d6b28\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2020-01-27T18:09:26Z\u0026quot;, GoVersion:\u0026quot;go1.13.6\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;}  1.编写Spec文档 apiVersion: apiextensions.k8s.io/v1beta1 kind: CustomResourceDefinition metadata: # name must match the spec fields below, and be in the form: \u0026lt;plural\u0026gt;.\u0026lt;group\u0026gt; name: crontabs.chenwen.com spec: # group name to use for REST API: /apis/\u0026lt;group\u0026gt;/\u0026lt;version\u0026gt; group: chenwen.com # list of versions supported by this CustomResourceDefinition versions: - name: v2 # Each version can be enabled/disabled by Served flag. served: true # One and only one version must be marked as the storage version. storage: true # A schema is required # The conversion section is introduced in Kubernetes 1.13+ with a default value of # None conversion (strategy sub-field set to None). conversion: # None conversion assumes the same schema for all versions and only sets the apiVersion # field of custom resources to the proper value strategy: None # either Namespaced or Cluster scope: Namespaced names: # plural name to be used in the URL: /apis/\u0026lt;group\u0026gt;/\u0026lt;version\u0026gt;/\u0026lt;plural\u0026gt; plural: crontabs # singular name to be used as an alias on the CLI and for display singular: crontab # kind is normally the CamelCased singular type. Your resource manifests use this. kind: Crontab listKind: CrontabList # shortNames allow shorter string to match your resource on the CLI shortNames: - ct  2.导入K8S ln -s /etc/rancher/k3s/k3s.yaml ~/.kube/config kubectl apply -f crontab_crd.yml kubectl get crd  可以看到自己创建的crd了。\n查看这个CRD\nroot@de001:/develop# kubectl describe crontabs.chenwen.com Name: my-test-crontab Namespace: default Labels: \u0026lt;none\u0026gt; Annotations: kubectl.kubernetes.io/last-applied-configuration: {\u0026quot;apiVersion\u0026quot;:\u0026quot;chenwen.com/v2\u0026quot;,\u0026quot;kind\u0026quot;:\u0026quot;Crontab\u0026quot;,\u0026quot;metadata\u0026quot;:{\u0026quot;annotations\u0026quot;:{},\u0026quot;name\u0026quot;:\u0026quot;my-test-crontab\u0026quot;,\u0026quot;namespace\u0026quot;:\u0026quot;default\u0026quot;},\u0026quot;spec\u0026quot;:{\u0026quot;cron... API Version: chenwen.com/v2 Kind: Crontab Metadata: Creation Timestamp: 2020-02-05T06:09:10Z Generation: 1 Resource Version: 19965 Self Link: /apis/chenwen.com/v2/namespaces/default/crontabs/my-test-crontab UID: 27beca8a-0ddb-4861-8643-90bb2f850b0d Spec: Cron Spec: * * * * */10 Image: my-test-image Replicas: 2 Events: \u0026lt;none\u0026gt; root@de001:/develop#  rancher启动的时候也会给K8S注册一些CRD\n不太清楚这样创建的CRD里用rancher的API是否能看到（rancher环境未搭建好测试 ）\n添加一个自定义对象\napiVersion: chenwen.com/v2 kind: Crontab metadata: name: my-test-crontab spec: cronSpec: \u0026quot;* * * * */10\u0026quot; image: my-test-image replicas: 2  导入\nkubectl apply -f test_crd.yml kubectl get ct #删除自定义对象 kubectl delete ct my-test-crontab #删除CRD kubectl delete crd crontabs.chenwen.com  运行结果：\nroot@de001:/develop# kubectl get crd|grep cron crontabs.chenwen.com 2020-02-05T06:08:53Z root@de001:/develop# kubectl get ct NAME AGE my-test-crontab 75s root@de001:/develop#  3.代码生成 先在gopath下建立如下目录\ngo └── src └── github.com └── examplechen └── go.mod └── hack └── pkg └── apis └── chenwen.com └── v1 ├── doc.go └── types.go └── pkg └── bin  然后安装https://github.com/kubernetes/code-generator 项目的代码到gopath下。\ndoc.go文件内容\n// FileName: doc.go // Distributed under terms of the GPL license. // +k8s:deepcopy-gen=package // Package v1 is the v1 version of the API. // +groupName=chenwen.com package v1  上述代码中的两行注释，都是代码生成工具会用到的，一个是声明为整个v1包下的类型定义生成DeepCopy方法，另一个声明了这个包对应的API的组名，和CRD中的组名一致\n“// +k8s:deepcopy-gen=package”：为这个package中的所有type生成deepcopy代码。\n“// +groupName=crd.lijiaocn.com”：设置这个package对应的api group。\ntypes.go文件内容\npackage v1 import ( metav1 \u0026quot;k8s.io/apimachinery/pkg/apis/meta/v1\u0026quot; ) // +genclient // +genclient:noStatus // +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object // CronTab is a top-level type. A client is created for it. // +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object type Crontab struct { metav1.TypeMeta `json:\u0026quot;,inline\u0026quot;` // +optional metav1.ObjectMeta `json:\u0026quot;metadata,omitempty\u0026quot;` // Username unique username of the consumer. Username string `json:\u0026quot;username,omitempty\u0026quot;` // CustomID existing unique ID for the consumer - useful for mapping // Kong with users in your existing database CustomID string `json:\u0026quot;custom_id,omitempty\u0026quot;` // Spec is the custom resource spec Spec CrontabSpec `json:\u0026quot;spec\u0026quot;` } // the spec for a MyResource resource type CrontabSpec struct { Min int `json:\u0026quot;min\u0026quot;` } // +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object type CrontabList struct { metav1.TypeMeta `json:\u0026quot;,inline\u0026quot;` metav1.ListMeta `json:\u0026quot;metadata\u0026quot;` Items []Crontab `json:\u0026quot;items\u0026quot;` } // Configuration contains a plugin configuration // +k8s:deepcopy-gen=false type Configuration map[string]interface{}  “// +genclient”：为该type生成client代码。\n“// +genclient:noStatus”：为该type生成的client代码，不包含UpdateStatus方法。\n“// +genclient:nonNamespaced”：如果是集群资源，设置为不带namespace。\n还支持在注释中使用以下tag：\n// +genclient:noVerbs // +genclient:onlyVerbs=create,delete // +genclient:skipVerbs=get,list,create,update,patch,delete,deleteCollection,watch // +genclient:method=Create,verb=create,result=k8s.io/apimachinery/pkg/apis/meta/v1.Status  ==CrontabSpec结构体的字段不需要和yaml文件里的Spec 部分一一对应==。\n同级目录编写register.go (这个文件非必须，此文件的作用是通过addKnownTypes方法使得client可以知道Crontab类型的API对象)\npackage v1 import ( metav1 \u0026quot;k8s.io/apimachinery/pkg/apis/meta/v1\u0026quot; \u0026quot;k8s.io/apimachinery/pkg/runtime\u0026quot; \u0026quot;k8s.io/apimachinery/pkg/runtime/schema\u0026quot; examplecom \u0026quot;github.com/examplechen/pkg/apis/chenwen.com\u0026quot; ) // SchemeGroupVersion is group version used to register these objects var SchemeGroupVersion = schema.GroupVersion{Group: examplecom.GroupName, Version: \u0026quot;v1\u0026quot;} // Resource takes an unqualified resource and returns a Group qualified GroupResource func Resource(resource string) schema.GroupResource { return SchemeGroupVersion.WithResource(resource).GroupResource() } var ( // localSchemeBuilder and AddToScheme will stay in k8s.io/kubernetes. SchemeBuilder runtime.SchemeBuilder localSchemeBuilder = \u0026amp;SchemeBuilder AddToScheme = localSchemeBuilder.AddToScheme ) func init() { // We only register manually written functions here. The registration of the // generated functions takes place in the generated files. The separation // makes the code compile even when the generated files are missing. localSchemeBuilder.Register(addKnownTypes) } // Adds the list of known types to api.Scheme. func addKnownTypes(scheme *runtime.Scheme) error { scheme.AddKnownTypes(SchemeGroupVersion, \u0026amp;Crontab{}, \u0026amp;CrontabList{}, ) metav1.AddToGroupVersion(scheme, SchemeGroupVersion) return nil }  go.mod文件内容\nmodule github.com/examplechen go 1.13  生成代码只需要以上三个文件和其对应的目录结构\n生成代码\n[koudai@koudai-pc v1]$ /develop/go/src/k8s.io/code-generator/generate-groups.sh all github.com/examplechen/pkg/client/crontab github.com/examplechen/pkg/apis chenwen.com:v1 Generating deepcopy funcs Generating clientset for chenwen.com:v1 at github.com/examplechen/pkg/client/crontab/clientset Generating listers for chenwen.com:v1 at github.com/examplechen/pkg/client/crontab/listers Generating informers for chenwen.com:v1 at github.com/examplechen/pkg/client/crontab/informers  尤其需要注意的是generate-groups.sh必须是==绝对路径==，不能是进入到code-generator目录下执行相对路径，不然会报找不到包的报错。\n另外，需要进入到examplechen目录执行，不然会报莫名其妙如下的错误\nGenerating deepcopy funcs F0210 17:31:46.418659 16605 deepcopy.go:885] Hit an unsupported type invalid type for invalid type, from github.com/examplechen/pkg/apis/chenwen.com/v1.Crontab  生成后的目录树如下：\n[koudai@koudai-pc examplechen]$ tree . ├── go.mod ├── go.sum ├── hack │ └── boilerplate.go.txt └── pkg ├── apis │ └── chenwen.com │ ├── register.go │ └── v1 │ ├── doc.go │ ├── types.go │ └── zz_generated.deepcopy.go └── client └── crontab ├── clientset │ └── versioned │ ├── clientset.go │ ├── doc.go │ ├── fake │ │ ├── clientset_generated.go │ │ ├── doc.go │ │ └── register.go │ ├── scheme │ │ ├── doc.go │ │ └── register.go │ └── typed │ └── chenwen.com │ └── v1 │ ├── chenwen.com_client.go │ ├── crontab.go │ ├── doc.go │ ├── fake │ │ ├── doc.go │ │ ├── fake_chenwen.com_client.go │ │ └── fake_crontab.go │ └── generated_expansion.go ├── informers │ └── externalversions │ ├── chenwen.com │ │ ├── interface.go │ │ └── v1 │ │ ├── crontab.go │ │ └── interface.go │ ├── factory.go │ ├── generic.go │ └── internalinterfaces │ └── factory_interfaces.go └── listers └── chenwen.com └── v1 ├── crontab.go └── expansion_generated.go 23 directories, 29 files  4.使用自动生成的代码 examplechen 下新建main.go用来测试\npackage main import ( \u0026quot;flag\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;github.com/golang/glog\u0026quot; metav1 \u0026quot;k8s.io/apimachinery/pkg/apis/meta/v1\u0026quot; \u0026quot;k8s.io/client-go/tools/clientcmd\u0026quot; \u0026quot;k8s.io/client-go/rest\u0026quot; examplecomclientset \u0026quot;github.com/examplechen/pkg/client/crontab/clientset/versioned\u0026quot; ) var ( kuberconfig = flag.String(\u0026quot;kubeconfig\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;Path to a kubeconfig. Only required if out-of-cluster.\u0026quot;) master = flag.String(\u0026quot;master\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;The address of the Kubernetes API server. Overrides any value in kubeconfig. Only required if out-of-cluster.\u0026quot;) ) func main() { flag.Parse() cfg, err := buildConfig(\u0026quot;https://127.0.0.1:6443\u0026quot;, \u0026quot;/root/.kube/config\u0026quot;) if err != nil { fmt.Printf(\u0026quot;%v\\n\u0026quot;, err) return } exampleClient, err := examplecomclientset.NewForConfig(cfg) if err != nil { glog.Fatalf(\u0026quot;Error building example clientset: %v\u0026quot;, err) } list, err := exampleClient.ChenwenV1().Crontabs(\u0026quot;default\u0026quot;).List(metav1.ListOptions{}) if err != nil { glog.Fatalf(\u0026quot;Error listing all databases: %v\u0026quot;, err) } for _, db := range list.Items { fmt.Printf(\u0026quot;database %s with user %q\\n\u0026quot;, db.Name, db.Spec.Min) } } func buildConfig(master, kubeconfig string) (*rest.Config, error) { if master != \u0026quot;\u0026quot; || kubeconfig != \u0026quot;\u0026quot; { return clientcmd.BuildConfigFromFlags(master, kubeconfig) } return rest.InClusterConfig() }  编译通过，但运行报错。\nF0210 14:19:32.477583 1845 main.go:39] Error listing all databases: the server could not find the requested resource (get crontabs.chenwen.com)  经检查，是版本号不一致造成，将yml文件里的版本号v2换成v1，另一个yml文件同理\nspec: # group name to use for REST API: /apis/\u0026lt;group\u0026gt;/\u0026lt;version\u0026gt; group: chenwen.com # list of versions supported by this CustomResourceDefinition versions: - name: v1 # 把v2换成v1，需要和API对应  重新编译，运行结果如下，符合预期\n#go build #./examplechenold -kubeconfig=$HOME/.kube/config database my-test-crontab with user '\\x00' database my-test-crontab2 with user '\\x00'  5.进一步了解API 再写个稍微复杂点的例子\n在 项目根目录下新建controller.go文件\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;time\u0026quot; \u0026quot;github.com/golang/glog\u0026quot; corev1 \u0026quot;k8s.io/api/core/v1\u0026quot; \u0026quot;k8s.io/apimachinery/pkg/api/errors\u0026quot; \u0026quot;k8s.io/apimachinery/pkg/util/runtime\u0026quot; utilruntime \u0026quot;k8s.io/apimachinery/pkg/util/runtime\u0026quot; \u0026quot;k8s.io/apimachinery/pkg/util/wait\u0026quot; \u0026quot;k8s.io/client-go/kubernetes\u0026quot; \u0026quot;k8s.io/client-go/kubernetes/scheme\u0026quot; typedcorev1 \u0026quot;k8s.io/client-go/kubernetes/typed/core/v1\u0026quot; \u0026quot;k8s.io/client-go/tools/cache\u0026quot; \u0026quot;k8s.io/client-go/tools/record\u0026quot; \u0026quot;k8s.io/client-go/util/workqueue\u0026quot; bolingcavalryv1 \u0026quot;github.com/examplechen/pkg/apis/chenwen.com/v1\u0026quot; clientset \u0026quot;github.com/examplechen/pkg/client/crontab/clientset/versioned\u0026quot; cronscheme \u0026quot;github.com/examplechen/pkg/client/crontab/clientset/versioned/scheme\u0026quot; informers \u0026quot;github.com/examplechen/pkg/client/crontab/informers/externalversions/chenwen.com/v1\u0026quot; listers \u0026quot;github.com/examplechen/pkg/client/crontab/listers/chenwen.com/v1\u0026quot; ) const controllerAgentName = \u0026quot;student-controller\u0026quot; const ( SuccessSynced = \u0026quot;Synced\u0026quot; MessageResourceSynced = \u0026quot;Student synced successfully\u0026quot; ) // Controller is the controller implementation for Student resources type Controller struct { // kubeclientset is a standard kubernetes clientset kubeclientset kubernetes.Interface // cronclientset is a clientset for our own API group cronclientset clientset.Interface cronsLister listers.CrontabLister cronsSynced cache.InformerSynced workqueue workqueue.RateLimitingInterface recorder record.EventRecorder } // NewController returns a new student controller func NewController( kubeclientset kubernetes.Interface, cronclientset clientset.Interface, cronInformer informers.CrontabInformer) *Controller { utilruntime.Must(cronscheme.AddToScheme(scheme.Scheme)) glog.V(4).Info(\u0026quot;Creating event broadcaster\u0026quot;) eventBroadcaster := record.NewBroadcaster() eventBroadcaster.StartLogging(glog.Infof) eventBroadcaster.StartRecordingToSink(\u0026amp;typedcorev1.EventSinkImpl{Interface: kubeclientset.CoreV1().Events(\u0026quot;\u0026quot;)}) recorder := eventBroadcaster.NewRecorder(scheme.Scheme, corev1.EventSource{Component: controllerAgentName}) controller := \u0026amp;Controller{ kubeclientset: kubeclientset, cronclientset: cronclientset, cronsLister: cronInformer.Lister(), cronsSynced: cronInformer.Informer().HasSynced, workqueue: workqueue.NewNamedRateLimitingQueue(workqueue.DefaultControllerRateLimiter(), \u0026quot;Students\u0026quot;), recorder: recorder, } glog.Info(\u0026quot;Setting up event handlers\u0026quot;) // Set up an event handler for when Student resources change cronInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{ AddFunc: controller.enqueueStudent, UpdateFunc: func(old, new interface{}) { oldStudent := old.(*bolingcavalryv1.Crontab) newStudent := new.(*bolingcavalryv1.Crontab) if oldStudent.ResourceVersion == newStudent.ResourceVersion { //版本一致，就表示没有实际更新的操作，立即返回 return } controller.enqueueStudent(new) }, DeleteFunc: controller.enqueueStudentForDelete, }) return controller } //在此处开始controller的业务 func (c *Controller) Run(threadiness int, stopCh \u0026lt;-chan struct{}) error { defer runtime.HandleCrash() defer c.workqueue.ShutDown() glog.Info(\u0026quot;开始controller业务，开始一次缓存数据同步\u0026quot;) if ok := cache.WaitForCacheSync(stopCh, c.cronsSynced); !ok { return fmt.Errorf(\u0026quot;failed to wait for caches to sync\u0026quot;) } glog.Info(\u0026quot;worker启动\u0026quot;) for i := 0; i \u0026lt; threadiness; i++ { go wait.Until(c.runWorker, time.Second, stopCh) } glog.Info(\u0026quot;worker已经启动\u0026quot;) \u0026lt;-stopCh glog.Info(\u0026quot;worker已经结束\u0026quot;) return nil } func (c *Controller) runWorker() { for c.processNextWorkItem() { } } // 取数据处理 func (c *Controller) processNextWorkItem() bool { obj, shutdown := c.workqueue.Get() if shutdown { return false } // We wrap this block in a func so we can defer c.workqueue.Done. err := func(obj interface{}) error { defer c.workqueue.Done(obj) var key string var ok bool if key, ok = obj.(string); !ok { c.workqueue.Forget(obj) runtime.HandleError(fmt.Errorf(\u0026quot;expected string in workqueue but got %#v\u0026quot;, obj)) return nil } // 在syncHandler中处理业务 if err := c.syncHandler(key); err != nil { return fmt.Errorf(\u0026quot;error syncing '%s': %s\u0026quot;, key, err.Error()) } c.workqueue.Forget(obj) glog.Infof(\u0026quot;Successfully synced '%s'\u0026quot;, key) return nil }(obj) if err != nil { runtime.HandleError(err) return true } return true } // 处理 func (c *Controller) syncHandler(key string) error { // Convert the namespace/name string into a distinct namespace and name namespace, name, err := cache.SplitMetaNamespaceKey(key) if err != nil { runtime.HandleError(fmt.Errorf(\u0026quot;invalid resource key: %s\u0026quot;, key)) return nil } // 从缓存中取对象 student, err := c.cronsLister.Crontabs(namespace).Get(name) if err != nil { // 如果Cron对象被删除了，就会走到这里，所以应该在这里加入执行 if errors.IsNotFound(err) { glog.Infof(\u0026quot;Student对象被删除，请在这里执行实际的删除业务: %s/%s ...\u0026quot;, namespace, name) return nil } runtime.HandleError(fmt.Errorf(\u0026quot;failed to list student by: %s/%s\u0026quot;, namespace, name)) return err } glog.Infof(\u0026quot;这里是cron对象的期望状态: %#v ...\u0026quot;, student) glog.Infof(\u0026quot;实际状态是从业务层面得到的，此处应该去的实际状态，与期望状态做对比，并根据差异做出响应(新增或者删除)\u0026quot;) c.recorder.Event(student, corev1.EventTypeNormal, SuccessSynced, MessageResourceSynced) return nil } // 数据先放入缓存，再入队列 func (c *Controller) enqueueStudent(obj interface{}) { var key string var err error // 将对象放入缓存 if key, err = cache.MetaNamespaceKeyFunc(obj); err != nil { runtime.HandleError(err) return } // 将key放入队列 c.workqueue.AddRateLimited(key) } // 删除操作 func (c *Controller) enqueueStudentForDelete(obj interface{}) { var key string var err error // 从缓存中删除指定对象 key, err = cache.DeletionHandlingMetaNamespaceKeyFunc(obj) if err != nil { runtime.HandleError(err) return } //再将key放入队列 c.workqueue.AddRateLimited(key) }  然后是 main.go\npackage main import ( \u0026quot;flag\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;time\u0026quot; \u0026quot;github.com/golang/glog\u0026quot; \u0026quot;k8s.io/client-go/tools/clientcmd\u0026quot; \u0026quot;k8s.io/client-go/kubernetes\u0026quot; informers \u0026quot;github.com/examplechen/pkg/client/crontab/informers/externalversions\u0026quot; \u0026quot;github.com/examplechen/pkg/signals\u0026quot; examplecomclientset \u0026quot;github.com/examplechen/pkg/client/crontab/clientset/versioned\u0026quot; ) var ( kubeconfig string master string ) func main() { flag.Parse() // 处理信号量 stopCh := signals.SetupSignalHandler() cfg, err := clientcmd.BuildConfigFromFlags(master, kubeconfig) if err != nil { fmt.Printf(\u0026quot;%v\\n\u0026quot;, err) return } kubeClient, err := kubernetes.NewForConfig(cfg) if err != nil { glog.Fatalf(\u0026quot;Error building kubernetes clientset: %s\u0026quot;, err.Error()) } exampleClient, err := examplecomclientset.NewForConfig(cfg) if err != nil { glog.Fatalf(\u0026quot;Error building example clientset: %v\u0026quot;, err) } studentInformerFactory := informers.NewSharedInformerFactory(exampleClient, time.Second*30) //得到controller controller := NewController(kubeClient, exampleClient, studentInformerFactory.Chenwen().V1().Crontabs()) //启动informer go studentInformerFactory.Start(stopCh) //controller开始处理消息 if err = controller.Run(2, stopCh); err != nil { glog.Fatalf(\u0026quot;Error running controller: %s\u0026quot;, err.Error()) } } func init() { flag.StringVar(\u0026amp;kubeconfig, \u0026quot;kubeconfig\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;Path to a kubeconfig. Only required if out-of-cluster.\u0026quot;) flag.StringVar(\u0026amp;master, \u0026quot;master\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;The address of the Kubernetes API server. Overrides any value in kubeconfig. Only required if out-of-cluster.\u0026quot;) }  编译运行\nroot@de001:/develop# ./examplechen -kubeconfig=$HOME/.kube/config I0210 17:40:22.161175 18552 controller.go:72] Setting up event handlers I0210 17:40:22.161769 18552 controller.go:96] 开始controller业务，开始一次缓存数据同步 I0210 17:40:22.262540 18552 controller.go:101] worker启动 I0210 17:40:22.262616 18552 controller.go:106] worker已经启动 I0210 17:40:22.262693 18552 controller.go:181] 这里是student对象的期望状态: \u0026amp;v1.Crontab{TypeMeta:v1.TypeMeta{Kind:\u0026quot;Crontab\u0026quot;, APIVersion:\u0026quot;chenwen.com/v1\u0026quot;}, ObjectMeta:v1.ObjectMeta{Name:\u0026quot;my-test-crontab2\u0026quot;, GenerateName:\u0026quot;\u0026quot;, Namespace:\u0026quot;default\u0026quot;, SelfLink:\u0026quot;/apis/chenwen.com/v1/namespaces/default/crontabs/my-test-crontab2\u0026quot;, UID:\u0026quot;ab5e00e6-88e4-4b7e-b587-f5797baec3eb\u0026quot;, ResourceVersion:\u0026quot;29576\u0026quot;, Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63716923534, loc:(*time.Location)(0x1e56c60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string{\u0026quot;kubectl.kubernetes.io/last-applied-configuration\u0026quot;:\u0026quot;{\\\u0026quot;apiVersion\\\u0026quot;:\\\u0026quot;chenwen.com/v1\\\u0026quot;,\\\u0026quot;kind\\\u0026quot;:\\\u0026quot;Crontab\\\u0026quot;,\\\u0026quot;metadata\\\u0026quot;:{\\\u0026quot;annotations\\\u0026quot;:{},\\\u0026quot;name\\\u0026quot;:\\\u0026quot;my-test-crontab2\\\u0026quot;,\\\u0026quot;namespace\\\u0026quot;:\\\u0026quot;default\\\u0026quot;},\\\u0026quot;spec\\\u0026quot;:{\\\u0026quot;cronSpec\\\u0026quot;:\\\u0026quot;* * * * */10\\\u0026quot;,\\\u0026quot;image\\\u0026quot;:\\\u0026quot;my-test-image\\\u0026quot;,\\\u0026quot;replicas\\\u0026quot;:2}}\\n\u0026quot;}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:\u0026quot;\u0026quot;, ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Username:\u0026quot;\u0026quot;, CustomID:\u0026quot;\u0026quot;, Spec:v1.CrontabSpec{Min:0}} ... I0210 17:40:22.262988 18552 controller.go:182] 实际状态是从业务层面得到的，此处应该去的实际状态，与期望状态做对比，并根据差异做出响应(新增或者删除) I0210 17:40:22.263039 18552 controller.go:145] Successfully synced 'default/my-test-crontab2' I0210 17:40:22.263063 18552 controller.go:181] 这里是student对象的期望状态: \u0026amp;v1.Crontab{TypeMeta:v1.TypeMeta{Kind:\u0026quot;Crontab\u0026quot;, APIVersion:\u0026quot;chenwen.com/v1\u0026quot;}, ObjectMeta:v1.ObjectMeta{Name:\u0026quot;my-test-crontab\u0026quot;, GenerateName:\u0026quot;\u0026quot;, Namespace:\u0026quot;default\u0026quot;, SelfLink:\u0026quot;/apis/chenwen.com/v1/namespaces/default/crontabs/my-test-crontab\u0026quot;, UID:\u0026quot;72036436-451a-4ec5-9851-bc27342faa5f\u0026quot;, ResourceVersion:\u0026quot;29532\u0026quot;, Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63716923360, loc:(*time.Location)(0x1e56c60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string{\u0026quot;kubectl.kubernetes.io/last-applied-configuration\u0026quot;:\u0026quot;{\\\u0026quot;apiVersion\\\u0026quot;:\\\u0026quot;chenwen.com/v1\\\u0026quot;,\\\u0026quot;kind\\\u0026quot;:\\\u0026quot;Crontab\\\u0026quot;,\\\u0026quot;metadata\\\u0026quot;:{\\\u0026quot;annotations\\\u0026quot;:{},\\\u0026quot;name\\\u0026quot;:\\\u0026quot;my-test-crontab\\\u0026quot;,\\\u0026quot;namespace\\\u0026quot;:\\\u0026quot;default\\\u0026quot;},\\\u0026quot;spec\\\u0026quot;:{\\\u0026quot;cronSpec\\\u0026quot;:\\\u0026quot;* * * * */10\\\u0026quot;,\\\u0026quot;image\\\u0026quot;:\\\u0026quot;my-test-image\\\u0026quot;,\\\u0026quot;replicas\\\u0026quot;:2}}\\n\u0026quot;}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:\u0026quot;\u0026quot;, ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Username:\u0026quot;\u0026quot;, CustomID:\u0026quot;\u0026quot;, Spec:v1.CrontabSpec{Min:0}} ... I0210 17:40:22.263157 18552 controller.go:182] 实际状态是从业务层面得到的，此处应该去的实际状态，与期望状态做对比，并根据差异做出响应(新增或者删除) I0210 17:40:22.263185 18552 controller.go:145] Successfully synced 'default/my-test-crontab' I0210 17:40:22.265730 18552 event.go:278] Event(v1.ObjectReference{Kind:\u0026quot;Crontab\u0026quot;, Namespace:\u0026quot;default\u0026quot;, Name:\u0026quot;my-test-crontab\u0026quot;, UID:\u0026quot;72036436-451a-4ec5-9851-bc27342faa5f\u0026quot;, APIVersion:\u0026quot;chenwen.com/v1\u0026quot;, ResourceVersion:\u0026quot;29532\u0026quot;, FieldPath:\u0026quot;\u0026quot;}): type: 'Normal' reason: 'Synced' Student synced successfully I0210 17:40:22.265885 18552 event.go:278] Event(v1.ObjectReference{Kind:\u0026quot;Crontab\u0026quot;, Namespace:\u0026quot;default\u0026quot;, Name:\u0026quot;my-test-crontab2\u0026quot;, UID:\u0026quot;ab5e00e6-88e4-4b7e-b587-f5797baec3eb\u0026quot;, APIVersion:\u0026quot;chenwen.com/v1\u0026quot;, ResourceVersion:\u0026quot;29576\u0026quot;, FieldPath:\u0026quot;\u0026quot;}): type: 'Normal' reason: 'Synced' Student synced successfully I0210 17:41:00.324824 18552 controller.go:181] 这里是student对象的期望状态: \u0026amp;v1.Crontab{TypeMeta:v1.TypeMeta{Kind:\u0026quot;\u0026quot;, APIVersion:\u0026quot;\u0026quot;}, ObjectMeta:v1.ObjectMeta{Name:\u0026quot;my-test-crontab2\u0026quot;, GenerateName:\u0026quot;\u0026quot;, Namespace:\u0026quot;default\u0026quot;, SelfLink:\u0026quot;/apis/chenwen.com/v1/namespaces/default/crontabs/my-test-crontab2\u0026quot;, UID:\u0026quot;ab5e00e6-88e4-4b7e-b587-f5797baec3eb\u0026quot;, ResourceVersion:\u0026quot;29811\u0026quot;, Generation:2, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63716923534, loc:(*time.Location)(0x1e56c60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string{\u0026quot;kubectl.kubernetes.io/last-applied-configuration\u0026quot;:\u0026quot;{\\\u0026quot;apiVersion\\\u0026quot;:\\\u0026quot;chenwen.com/v1\\\u0026quot;,\\\u0026quot;kind\\\u0026quot;:\\\u0026quot;Crontab\\\u0026quot;,\\\u0026quot;metadata\\\u0026quot;:{\\\u0026quot;annotations\\\u0026quot;:{},\\\u0026quot;name\\\u0026quot;:\\\u0026quot;my-test-crontab2\\\u0026quot;,\\\u0026quot;namespace\\\u0026quot;:\\\u0026quot;default\\\u0026quot;},\\\u0026quot;spec\\\u0026quot;:{\\\u0026quot;cronSpec\\\u0026quot;:\\\u0026quot;* 5 * * */10\\\u0026quot;,\\\u0026quot;image\\\u0026quot;:\\\u0026quot;my-test-image\\\u0026quot;,\\\u0026quot;replicas\\\u0026quot;:2}}\\n\u0026quot;}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:\u0026quot;\u0026quot;, ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Username:\u0026quot;\u0026quot;, CustomID:\u0026quot;\u0026quot;, Spec:v1.CrontabSpec{Min:0}} ...  6.验证controller 新开一个窗口连接到k8s环境，新建一个名为test2_crd.yml的文件，内容如下\napiVersion: chenwen.com/v1 kind: Crontab metadata: name: my-test-crontab2 spec: cronSpec: \u0026quot;* 5 * * */10\u0026quot; image: my-test-image replicas: 2  执行命令\nkubectl apply -f test2_crd.yml  返回controller所在的控制台窗口，发现新输出了如下内容，可见新增Crontab对象的事件已经被controller监听并处理：\nI0210 17:41:00.324974 18552 controller.go:182] 实际状态是从业务层面得到的，此处应该去的实际状态，与期望状态做对比，并根据差异做出响应(新增或者删除) I0210 17:41:00.325006 18552 controller.go:145] Successfully synced 'default/my-test-crontab2' I0210 17:41:00.332401 18552 event.go:278] Event(v1.ObjectReference{Kind:\u0026quot;Crontab\u0026quot;, Namespace:\u0026quot;default\u0026quot;, Name:\u0026quot;my-test-crontab2\u0026quot;, UID:\u0026quot;ab5e00e6-88e4-4b7e-b587-f5797baec3eb\u0026quot;, APIVersion:\u0026quot;chenwen.com/v1\u0026quot;, ResourceVersion:\u0026quot;29811\u0026quot;, FieldPath:\u0026quot;\u0026quot;}): type: 'Normal' reason: 'Synced' Student synced successfully  接下来您也可以尝试修改和删除已有的Crontab对象，观察controller控制台的输出，确定是否已经监听到所有Crontab变化的事件.\n7.总结 三步走：\n 创建CRD（Custom Resource Definition），令k8s明白我们自定义的API对象； 编写代码，将CRD的情况写入对应的代码中，然后通过自动代码生成工具，将controller之外的informer，client等内容较为固定的代码通过工具生成； 编写controller，在里面判断实际情况是否达到了API对象的声明情况，如果未达到，就要进行实际业务处理，而这也是controller的通用做法；  实际要自己动手写的文件不多，就3-4个，但是理解起来比较难。\n8.refer https://blog.csdn.net/weixin_41806245/article/details/94451734\nhttps://blog.csdn.net/aixiaoyang168/article/details/81875907\nhttps://github.com/kubernetes/sample-controller/blob/master/README.md\nhttps://blog.openshift.com/kubernetes-deep-dive-code-generation-customresources/\nhttps://www.jianshu.com/p/4910da4c8285\nhttps://blog.csdn.net/boling_cavalry/article/details/88924194\n","date":"2020-02-11","permalink":"https://iminto.github.io/post/k8s%E7%AE%A1%E7%90%86crd%E5%92%8Ck8sapi%E7%BC%96%E7%A8%8B/","tags":["k8s"],"title":"K8s管理crd和K8SAPI编程"},{"content":"hadoop 3.1.2 单机模式安装配置 现在搞大数据记录一下，方便查阅。\n1.安装配置jdk和下载hadoop略。 hadoop 下载地址：http://mirror.bit.edu.cn/apache/hadoop/common/ 使用了较新且保守的3.1.2版本\n2.配置修改 环境变量修改\nexport HADOOP_HOME=/soft/hadoop export PATH=$PATH:$HADOOP_HOME/bin  配置etc/hadoop/hadoop-env.sh\nexport JAVA_HOME=/soft/java export HADOOP_HOME=/soft/hadoop  配置etc/hadoop/core-site.xml\n\u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hadoop.tmp.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:///develop/data/hadoop\u0026lt;/value\u0026gt; \u0026lt;description\u0026gt;Abase for other temporary directories.\u0026lt;/description\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;fs.defaultFS\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdfs://192.168.0.104:8888\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt;  配置etc/hadoop/hdfs-site.xml\n\u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.replication\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;1\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.name.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:///develop/data/hadoop/dfs/name\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.datanode.data.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:///develop/data/hadoop/dfs/data\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.datanode.du.reserved\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;1073741824\u0026lt;/value\u0026gt; \u0026lt;description\u0026gt;Reserved space in bytes per volume..\u0026lt;/description\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt;  3.配置免密码SSH登录 ssh-keygen -t rsa cat ~/ssh/id_rsa.pub\u0026gt;\u0026gt;~/ssh/authorized_keys #ssh localhost 测试是否成功  4.启动测试 #格式化 hdfs namenode -format #启动hdfs ./sbin/start-dfs.sh #停止hdfs ./sbin/stop-dfs.sh #验证是否成功 http://localhost:9870/  至此，hadoop的单机模式基本安装结束。\n简单的验证hadoop命令：\nhadoop fs -mkdir /test  在浏览器中应该可以看到新建的目录了。\n注意： 1.网上的教程很多是2.x老版本，3.1.0版本后，hdfs的web 50070端口 -\u0026gt; 9870端口了 。\n2.如果webHDFS出错，提示\u0026quot;Failed to retrieve data from /webhdfs/v1/?op=LISTSTATUS:Server Error“，也无法透过Web界面上传文件，一般是JDK版本过高引起的，目前hadoop还只支持JDK8版本。如果是JDK9以上版本，可以编辑hadoop-env.sh\nexport HADOOP_OPTS=\u0026quot;--add-modules java.activation\u0026quot;  3.上传文件/创建目录报错 Permission Denied，修改hdfs-site.xml，设定dfs.permissions=false。按照本文的最新配置就不会遇到这个问题。\n","date":"2019-08-25","permalink":"https://iminto.github.io/post/hadoop3.1.2%E5%8D%95%E6%9C%BA%E6%A8%A1%E5%BC%8F%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","tags":["Java","大数据"],"title":"hadoop 3.1.2 单机模式安装配置"},{"content":"互联网低潮，老是会看到别人发面试经验，看到很多人谈乐观锁，谈CAS，但是都没有说清楚。忍不住叨叨几句。\n那什么是乐观锁呢，比较书面的定义是 “它假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据。在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，正在提交的事务会进行回滚。”，在多线程中则指对于数据冲突保持一种乐观态度，操作数据时不会对操作的数据进行加锁（这使得多个任务可以并行的对数据进行操作），只有到数据提交的时候才通过一种机制来验证数据是否存在冲突。在Java中，是通过CAS来实现乐观锁的。\nCAS是英文单词Compare And Swap的缩写，翻译过来就是比较并替换。CAS机制当中使用了3个基本操作数：内存地址V，旧的预期值A，要修改的新值B。\n更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B。\nCAS比较难于理解的地方就在于V、A、B这三个变量到底代表什么含义，很容易混淆，也不容易讲清楚。单纯看书上的文章会觉得晦涩，我们可以来看个例子。\n举个例子：\n1.在内存地址V当中，存储着值为10的变量\n2.此时线程1想要把变量的值增加1。对线程1来说，旧的预期值A=10，要修改的新值B=11。\n3.在线程1要提交更新之前，另一个线程2抢先一步，把内存地址V中的变量值率先更新成了11。\n4.线程1开始提交更新，首先进行A和地址V的实际值比较（Compare），发现A不等于V的实际值，提交失败。\n5.线程1重新获取内存地址V的当前值，并重新计算想要修改的新值。此时对线程1来说，A=11，B=12。这个重新尝试的过程被称为自旋。\n6.这一次比较幸运，没有其他线程改变地址V的值。线程1进行Compare，发现A和地址V的实际值是相等的，线程1进行Swap，把地址V的值替换为B，也就是12。在这一步，Compare和Swap这个过程是原子的(由操作系统和硬件保证)，比较并更新的过程是不会被其他线程打断的。\n到这里，其实基本说请了CAS的过程，但是CAS的API，还是不够清晰，很多人能够进行到这里，但如果让他实际使用CAS的API时则又没辙了，这里我们通过一个例子来演示CAS的API实际用例。\n/** * 使用CAS来获取单例 */ public class CasSingleton { private static final AtomicReference\u0026lt;CasSingleton\u0026gt; INSTANCE=new AtomicReference\u0026lt;\u0026gt;(); private CasSingleton(){} public static CasSingleton getInstance(){ for(;;){ CasSingleton singleton=INSTANCE.get(); if(null!=singleton){ return singleton; } singleton=new CasSingleton(); if(INSTANCE.compareAndSet(null,singleton)){ return singleton; } } } public static void main(String[] args) { CasSingleton singleton=getInstance(); CasSingleton singleton1=getInstance(); System.out.println(singleton); System.out.println(singleton1); } }  这里使用CAS来实现单例，我们对照着compareAndSet的API来看看\n/** * Atomically sets the value to {@code newValue} * if the current value {@code == expectedValue}, * with memory effects as specified by {@link VarHandle#compareAndSet}. * * @param expectedValue the expected value * @param newValue the new value * @return {@code true} if successful. False return indicates that * the actual value was not equal to the expected value. */ public final boolean compareAndSet(V expectedValue, V newValue) { return VALUE.compareAndSet(this, expectedValue, newValue); }  上面CAS实现单例的代码中，第一个参数null就是A，第二个参数singleton就是B，调用者INSTANCE就是V。在调用compareAndSet的同时，已经完成了更新的过程，并且返回了更新与否的结果。这样就比较好理解了（虽然CAS能实现单例，但在这个场景下并不是最佳方案，为什么，大家可以思考下）。\n现在再来看看AtomicInteger的源码，能理解++i这块的实现了吗？\npublic final int incrementAndGet() { for (;;) { int current = get(); int next = current + 1; if (compareAndSet(current, next)) return next; } }  至于什么ABA问题和CPU底层实现，则不是本文重点。\n","date":"2019-07-16","permalink":"https://iminto.github.io/post/%E8%AE%B2%E6%B8%85%E6%A5%9Acas%E7%9A%84%E9%82%A3%E7%82%B9%E4%BA%8B/","tags":["Java"],"title":"讲清楚CAS的那点事"},{"content":"netty实现http服务器keep-alive无效的问题排查 今天在用netty实现一个http服务器的时候，发现keep-alive并没有生效，具体表现是在request和response的header里都能看到keep-alive的标志：\nrequest: Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3 Accept-Encoding: gzip, deflate, br Accept-Language: zh-CN,zh;q=0.9,en;q=0.8 Cache-Control: max-age=0 Connection: keep-alive response: HTTP/1.1 200 OK content-type: text/html;charset=UTF-8 content-length: 0 connection: keep-alive  可以看出，无论是请求还是响应，都是keep-alive的，但是请求两次，服务器端日志如下：\n七月 06, 2019 9:51:27 下午 io.netty.handler.logging.LoggingHandler channelRead 信息: [id: 0xade39344, L:/0:0:0:0:0:0:0:0:8080] READ: [id: 0x26d40041, L:/0:0:0:0:0:0:0:1:8080 - R:/0:0:0:0:0:0:0:1:33130] 七月 06, 2019 9:51:27 下午 io.netty.handler.logging.LoggingHandler channelReadComplete 信息: [id: 0xade39344, L:/0:0:0:0:0:0:0:0:8080] READ COMPLETE keepAlive=true channel id=26d40041 http uri: /a.txt?name=chen\u0026amp;f=123;key=456 name=chen f=123 key=456 七月 06, 2019 9:51:29 下午 io.netty.handler.logging.LoggingHandler channelRead 信息: [id: 0xade39344, L:/0:0:0:0:0:0:0:0:8080] READ: [id: 0x600995e6, L:/0:0:0:0:0:0:0:1:8080 - R:/0:0:0:0:0:0:0:1:33156] 七月 06, 2019 9:51:29 下午 io.netty.handler.logging.LoggingHandler channelReadComplete 信息: [id: 0xade39344, L:/0:0:0:0:0:0:0:0:8080] READ COMPLETE keepAlive=true channel id=600995e6 http uri: /a.txt?name=chen\u0026amp;f=123;key=456 name=chen f=123 key=456  客户端两次连接的socket端口一次是33130,第二次是33156，channel id也不一样，证明确实是两个连接，keep-alive并没有生效。\n其中，channel id来自这里\n@Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { // System.out.println(\u0026quot;channel id=\u0026quot;+ctx.channel().id()); }  为什么呢，看下代码中Server和ServerHandle也没什么问题，关键代码如下：\nserverBootstrap.channel(NioServerSocketChannel.class) .group(boss, work) .handler(new LoggingHandler(LogLevel.INFO)) // handler在初始化时就会执行，可以设置打印日志级别 .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(\u0026quot;http-coder\u0026quot;,new HttpServerCodec()); ch.pipeline().addLast(\u0026quot;aggregator\u0026quot;,new HttpObjectAggregator(1024*1024)); //在处理 POST消息体时需要加上 ch.pipeline().addLast(new HttpServerHandler()); } }) .option(ChannelOption.SO_BACKLOG, 1024) .childOption(ChannelOption.SO_KEEPALIVE, true) .childOption(ChannelOption.TCP_NODELAY, true); //handle代码 httpResponse.headers().set(HttpHeaderNames.CONTENT_TYPE, \u0026quot;text/html;charset=UTF-8\u0026quot;); httpResponse.headers().setInt(HttpHeaderNames.CONTENT_LENGTH, httpResponse.content().readableBytes()); if (keepAlive) { httpResponse.headers().set(HttpHeaderNames.CONNECTION, HttpHeaderValues.KEEP_ALIVE); ctx.writeAndFlush(httpResponse); } else { ctx.writeAndFlush(httpResponse).addListener(ChannelFutureListener.CLOSE); }  代码很明显，如果请求是 keep-alive的，那么响应头也加上keep-alive标志，从而实现了长连接。看了半天代码没看出端倪来，突然注意到了在浏览器中，F12看到了/favicon.ico的请求一直是pending的，也就是阻塞在了这里，代码里是这么写的\n//去除浏览器\u0026quot;/favicon.ico\u0026quot;的干扰 if (uri.equals(FAVICON_ICO)) { return ; }  这段代码来自我参考的别人的代码，本意是要忽略 /favicon.ico这种无效的请求，但是由于直接return了，导致当前连接被阻塞了，如果这时刷新，就会导致新开一个连接来处理请求。要解决这个问题很简单，只需要注释掉这段代码，对于/favicon.ico请求，直接返回空的200状态码就好了。\n现在再来看下请求日志：\n信息: [id: 0xee8bc5e1, L:/0:0:0:0:0:0:0:0:8080] READ: [id: 0x734e2ebb, L:/0:0:0:0:0:0:0:1:8080 - R:/0:0:0:0:0:0:0:1:37386] 七月 06, 2019 10:03:48 下午 io.netty.handler.logging.LoggingHandler channelReadComplete 信息: [id: 0xee8bc5e1, L:/0:0:0:0:0:0:0:0:8080] READ COMPLETE keepAlive=true channel id=734e2ebb http uri: /a.txt?name=chen\u0026amp;f=123;key=456 name=chen f=123 key=456 keepAlive=true channel id=734e2ebb http uri: /favicon.ico keepAlive=true channel id=734e2ebb http uri: /a.txt?name=chen\u0026amp;f=123;key=456 name=chen f=123 key=456 keepAlive=true channel id=734e2ebb http uri: /favicon.ico  无论刷新多少次，服务器端日志里也只记录了一次socket连接日志，并且每次的channel id都是一样的。\n顺便再测试下，如果把server中的ChannelOption.SO_KEEPALIVE设置为false，是不会影响http的keep-alive的。\n","date":"2019-07-06","permalink":"https://iminto.github.io/post/netty%E5%AE%9E%E7%8E%B0http%E6%9C%8D%E5%8A%A1%E5%99%A8keep-alive%E6%97%A0%E6%95%88%E7%9A%84%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/","tags":["Java"],"title":"Netty实现http服务器keep Alive无效的问题排查"},{"content":"我用的filebeat7来收集日志发给Elastic search，版本是7.1.1，对应的elasticsearch版本和其相同。\n默认的，filebeat生成的索引名字是filebeat-7.1.1-2019.06.24这种，不利于区分不同的业务，需要自定义索引，看了下官方文档， 是这么写的\nindexedit The index name to write events to. The default is \u0026quot;filebeat-%{[agent.version]}-%{+yyyy.MM.dd}\u0026quot; (for example, \u0026quot;filebeat-7.2.0-2019-06-26\u0026quot;). If you change this setting, you also need to configure the setup.template.name and setup.template.pattern options (see Load the Elasticsearch index template). If you are using the pre-built Kibana dashboards, you also need to set the setup.dashboards.index option (see Load the Kibana dashboards). You can set the index dynamically by using a format string to access any event field. For example, this configuration uses a custom field, fields.log_type, to set the index: output.elasticsearch: hosts: [\u0026quot;http://localhost:9200\u0026quot;] index: \u0026quot;%{[fields.log_type]}-%{[agent.version]}-%{+yyyy.MM.dd}\u0026quot;  重点提到了还需要修改setup.template.name和setup.template.pattern，于是我配置如下：\noutput.elasticsearch: hosts: [\u0026quot;127.0.0.1:9200\u0026quot;] index: \u0026quot;ngerr-%{[agent.version]}-%{+yyyy.MM.dd}\u0026quot; setup.template.name: \u0026quot;ngerr\u0026quot; setup.template.pattern: \u0026quot;ngerr-*\u0026quot;  结果发现无论如何都不生效，找了很多文章都说配置这几个地方就行，包括google也搜不到结果。我试了不同的配置，甚至把setup.template配置调了位置，还是徒劳，控制台永远都是输出如下\n2019-06-26T13:11:20.287+0800 INFO pipeline/output.go:95 Connecting to backoff(elasticsearch(http://127.0.0.1:9200)) 2019-06-26T13:11:20.294+0800 INFO elasticsearch/client.go:734 Attempting to connect to Elasticsearch version 7.1.1 2019-06-26T13:11:20.379+0800 INFO [index-management] idxmgmt/std.go:223 Auto ILM enable success. 2019-06-26T13:11:20.380+0800 INFO [index-management.ilm] ilm/std.go:134 do not generate ilm policy: exists=true, overwrite=false 2019-06-26T13:11:20.380+0800 INFO [index-management] idxmgmt/std.go:238 ILM policy successfully loaded. 2019-06-26T13:11:20.380+0800 INFO [index-management] idxmgmt/std.go:361 Set setup.template.name to '{filebeat-7.1.1 {now/d}-000001}' as ILM is enabled. 2019-06-26T13:11:20.380+0800 INFO [index-management] idxmgmt/std.go:366 Set setup.template.pattern to 'filebeat-7.1.1-*' as ILM is enabled. 2019-06-26T13:11:20.380+0800 INFO [index-management] idxmgmt/std.go:400 Set settings.index.lifecycle.rollover_alias in template to {filebeat-7.1.1 {now/d}-000001} as ILM is enabled. 2019-06-26T13:11:20.380+0800 INFO [index-management] idxmgmt/std.go:404 Set settings.index.lifecycle.name in template to {filebeat-7.1.1 map[policy:{\u0026quot;phases\u0026quot;:{\u0026quot;hot\u0026quot;:{\u0026quot;actions\u0026quot;:{\u0026quot;rollover\u0026quot;:{\u0026quot;max_age\u0026quot;:\u0026quot;30d\u0026quot;,\u0026quot;max_size\u0026quot;:\u0026quot;50gb\u0026quot;}}}}}]} as ILM is enabled. 2019-06-26T13:11:20.383+0800 INFO template/load.go:129 Template already exists and will not be overwritten. 2019-06-26T13:11:20.383+0800 INFO [index-management] idxmgmt/std.go:272 Loaded index template. 2019-06-26T13:11:20.524+0800 INFO [index-management] idxmgmt/std.go:283 Write alias successfully generated.  {filebeat-7.1.1 {now/d}-000001} 这个名字总是会覆盖我自己的配置。反复尝试，觉得是 ILM 这个东西在作梗，于是试着搜索了下“filebeat ILM is enabled”，发现了这个issue ，有不少人踩坑了。提出issue的人也指出了文档没有说清楚。\n指向了这个官方文档：https://www.elastic.co/guide/en/beats/filebeat/current/ilm.html\n原来\n Starting with version 7.0, Filebeat uses index lifecycle management by default when it connects to a cluster that supports lifecycle management. Filebeat loads the default policy automatically and applies it to any indices created by Filebeat.\n 可惜的是filebeat的配置项那里一直没有说清楚。网上由于大多数人用的都是很保守的配置和较老的版本，所以很难搜索到类似的问题，我基本上是头几个踩坑的了。\n加上这个配置就好了：\nsetup.ilm.enabled: false  希望能帮到踩坑的人，我已经在这个问题上浪费了三四个小时了。\n","date":"2019-06-26","permalink":"https://iminto.github.io/post/filebeat%E4%BF%AE%E6%94%B9index%E7%9A%84%E4%B8%80%E4%B8%AA%E5%9D%91/","tags":["Java"],"title":"Filebeat7自定义index的一个坑"},{"content":"本来我一个软件工程师，是很不屑提产品的，但时不时总见到一些产品人吹牛皮，也忍不住凑个热闹。\n钉钉(DingTalk)是一款由阿里巴巴集团开发的用于商务沟通和工作协同的IM，其和企业版微信占据了中国的大部分企业IM市场。阿里并不是一个擅长做社交的公司，钉钉也是一款命途多舛的产品。2014年左右阿里在内部强行推广来往，一款承载了阿里社交梦的产品，花了巨额的研发和营销费用后，依然是折戟沉沙。后来，来往的团队保留了部分下来，做起了钉钉，针对办公社交，居然做成功了。\n在办公社交上，钉钉的崛起甚至早于以社交闻名的腾讯，在社交上扳回了一局，甚至可以说是唯一的一局。微信和QQ在钉钉后也快速推出了办公社交QQ和企业微信等功能，但是在它们推出后，钉钉在很多城市使用的频率已经很高了。\n我用的是linux操作系统，钉钉并没有官方linux版本，所以有时候我会使用手机钉钉和网页版钉钉凑合。但是某一次打开钉钉设置的时候，发现了一个问题。\n\n不知大家注意到没有，网页版钉钉的设置使用了流行的switch开关，但是用了红色和绿色的搭配。可能钉钉的设计和开发者觉得“红灯停，绿灯行”的概念已经深入人心，但是他们是否想到了一个事实：中国存在近亿的色盲和色弱用户，这其中又以红绿色盲色弱最多！\n红色和绿色，是两个对比度比较接近的颜色，也是最难辨识的两个颜色，别说对色盲和色弱用户来说，即使是对于普通人来说，在某些光线条件下，红绿色也是很难于辨识的。实际上在打开这个页面的时候，我也愣了一会，才辨清了这两个颜色状态。\n正因为红绿色是很难于辨识的两种颜色，现在城市的红绿灯，大部分都是掺了蓝色的，所以大家看到的绿灯，都是泛蓝的，而不是单纯的绿色。还有的城市，绿灯不仅掺了蓝色，还会使用动画或声音提示行人车辆，目的就是为了减少了特殊用户甚至是正常用户的困扰。\n阿里一直宣传产品的人文关怀，比如雇佣残疾人客服，支付宝支持语音支付等，但是可曾想到，他们另外一款最流行的企业IM软件，却忽略了上亿人！\n产品的设计开发中，有许多细节，只有真正用心的人才会注意到，并设计出用户友好的软件，减少用户的困扰。\n作者使用了钉钉很久了，最早的APP版设置页面就是使用红色和绿色来作为swith开关的，作者曾经在微博等多个渠道向阿里反馈，可惜一直没有收到阿里的回复，直到一年后的某天，钉钉悄悄地改了这个细节，也不知道是无意中修改还是真的收到了用户的反馈。遗憾的是，网页版钉钉至今没有修改这个细节。\n","date":"2019-05-06","permalink":"https://iminto.github.io/post/oh-dingtalk/","tags":["闲扯淡"],"title":"从钉钉一个忽略了近亿人的产品细节谈谈产品思维"},{"content":"公司的生产服务器买了QiZhi Technologie的堡垒机，每次登录都得输入密码+空格+OTOP验证码，都得打开手机APP操作一把，烦不胜烦。\n不可忍，想了想，还是借助Java在每次调用时自动生成验证码，然后搞个ssh自动登录（别问我问啥不用公钥，哪有权限啊）得了。\n结合之前写的博客 TOTP算法Java版本，很容易就写出计算验证码的代码：\npublic long getCode(String secret, long timeMsec) throws Exception { Base32 codec = new Base32(); byte[] decodedKey = codec.decode(secret); long t = (timeMsec / 1000L) / 30L; for (int i = -window_size; i \u0026lt;= window_size; ++i) { long hash; try { hash = verify_code(decodedKey, t + i); return hash; } catch (Exception e) { e.printStackTrace(); } } return 0L; }  写一个类，专门调用这个方法生成验证码，获取程序执行结果\njava -Dfile.encoding=UTF-8 -classpath /soft/tool/authcode/ GoogleAuthTest  ，接下来，要实现自动登录就简单多了，先写一个shell\n#!/bin/bash passwd=$(java -Dfile.encoding=UTF-8 -classpath /soft/tool/authcode/ GoogleAuthTest) ./prod.exp $passwd  shell调用java生成验证码，然后传给expect脚本\n#!/bin/expect set timeout 10 set fullpasswd [lindex $argv 0] spawn ssh -l chenwen 172.10.3.110 expect \u0026quot;*ssword*\u0026quot; send \u0026quot;dev744988 $fullpasswd\\r\u0026quot; interact  不到100行新代码，搞定收工，全程不到半小时。最耗时的还是传递变量给expact花了不少时间。\n","date":"2018-11-16","permalink":"https://iminto.github.io/post/auto-login-bastion-with-otop-by-java/","tags":["Java","Linux"],"title":"使用Java自动登录需要动态密码的堡垒机"},{"content":"在Linux里，用户层面并没有文件创建时间的概念，无论是用ls还是stat 指令，都无法获取到文件的创建时间\n[tudou@tudou-pc statx]$ stat test-statx.c 文件：test-statx.c 大小：6656 块：16 IO 块：4096 普通文件 设备：805h/2053d Inode：6684737 硬链接：1 权限：(0644/-rw-r--r--) Uid：( 1000/ tudou) Gid：( 1001/ tudou) 最近访问：2018-10-07 13:16:29.000000000 +0800 最近更改：2018-10-07 13:21:09.855461986 +0800 最近改动：2018-10-07 13:21:09.855461986 +0800 创建时间：-  可以看到「创建时间」一行总是「-」。\n如果我们使用百度的话，会看到很多文章说，最近改动时间就是创建时间。的确，我们拿很多文件试验了下，这个最近改动时间（Change Time）确实和创建时间很相近，然而Change time并不是Create time，它实际是文件属性修改时间。 试一下即知：\n[tudou@tudou-pc 下载]$ ./statx ~/.face statx(/home/tudou/.face) = 0 results=fff Size: 7589 Blocks: 16 IO Block: 4096 regular file Device: 08:05 Inode: 5505043 Links: 1 Access: (0644/-rw-r--r--) Uid: 1000 Gid: 1001 Access: 2018-09-16 01:15:52.320014139+0800 Modify: 2018-09-16 01:15:52.320014139+0800 Change: 2018-09-16 01:15:52.320014139+0800 Birth: 2018-09-16 01:15:52.320014139+0800 Attributes: 0000000000000000 (........ ........ ........ ........ ........ ........ ....-... .---.-..) [tudou@tudou-pc 下载]$ chattr +u ~/.face [tudou@tudou-pc 下载]$ ./statx ~/.face statx(/home/tudou/.face) = 0 results=fff Size: 7589 Blocks: 16 IO Block: 4096 regular file Device: 08:05 Inode: 5505043 Links: 1 Access: (0644/-rw-r--r--) Uid: 1000 Gid: 1001 Access: 2018-09-16 01:15:52.320014139+0800 Modify: 2018-09-16 01:15:52.320014139+0800 Change: 2018-10-07 16:17:10.929769171+0800 Birth: 2018-09-16 01:15:52.320014139+0800 Attributes: 0000000000000000 (........ ........ ........ ........ ........ ........ ....-... .---.-..)  不过，linux也不是完全不支持文件创建时间，文件系统如ext4其实是支持的，只是没有API可以获取到这个数据。比如Java提供的文件API，也就因此无法获取文件创建时间。\n不过，自内核 4.11 版本引入的 statx 系统调用支持获取创建时间了，字段名里用的是 btime（Birth time）。\n如果用户想要实现在代码里获取这个创建时间，那么只需要调用glibc提供的API即可。但是目前glibc还没有支持，所以只能自己用syscall函数调用。如果仅仅只是想自己实现一个小工具来获取这个时间，那么内核源码树里 samples/statx/test-statx.c 这个文件就是现成的实现。 下载源码：https://cdn.kernel.org/pub/linux/kernel/v4.x/linux-4.18.12.tar.xz，选择一个和自己操作系统版本最近的源码分支 . 你要是不想下载几十M的linux源码的话，也可以从这里获取到各个linux版本的源码 编译文件：\n[tudou@tudou-pc statx]$ gcc -O2 -o statx test-statx.c In file included from /usr/include/sys/stat.h:446, from test-statx.c:28: /usr/include/bits/statx.h:25:8: 错误：‘struct statx_timestamp’重定义 struct statx_timestamp ^~~~~~~~~~~~~~~ In file included from test-statx.c:26: /usr/include/linux/stat.h:56:8: 附注：原先在这里定义 struct statx_timestamp { ^~~~~~~~~~~~~~~ In file included from /usr/include/sys/stat.h:446, from test-statx.c:28: /usr/include/bits/statx.h:36:8: 错误：‘struct statx’重定义  注释如下两行代码：\n#define _GNU_SOURCE #define _ATFILE_SOURCE  再次编译即可。\n[tudou@tudou-pc statx]$ gcc -O2 -o statx test-statx.c [tudou@tudou-pc statx]$ ./statx test-statx.c statx(test-statx.c) = 0 results=fff Size: 6656 Blocks: 16 IO Block: 4096 regular file Device: 08:05 Inode: 6684737 Links: 1 Access: (0644/-rw-r--r--) Uid: 1000 Gid: 1001 Access: 2018-10-07 13:16:29.000000000+0800 Modify: 2018-10-07 13:21:09.855461986+0800 Change: 2018-10-07 13:21:09.855461986+0800 Birth: 2018-10-07 13:16:47.771175840+0800 Attributes: 0000000000000000 (........ ........ ........ ........ ........ ........ ....-... .---.-..)  另外一个思路， 使用debugfs来搞。\n附：glibc即将支持statx调用Glibc Support For Statx Is Finally Under Review\n参考： https://blog.lilydjwg.me/2018/7/11/get-file-birth-time-in-linux.213101.html\n","date":"2018-10-07","permalink":"https://iminto.github.io/post/get-createtime-in-linux/","tags":["Linux"],"title":"Linux 下获取文件创建时间"},{"content":"现在的一些Linux软件很流行使用bin这种安装包格式，只需要下载个安装包就能自动安装解压，比tar.gz省事，比.deb，.rpm的安装包兼容性强，适应范围广。但也有一个问题，bin安装包让人无法知道里面的细节，还是有所顾虑的。比如我前几天需要下载一个JRE6，但Oracle官方在JDK7之前都没有tar.gz包，只有bin包。我肯定不能直接安装bin文件啊，这会破坏我本机已有的JDK8开发环境。\n怎么从bin文件里提取出原始安装包呢？其实很简单。用vi打开一个bin文件就知道了，bin文件其实就是一个sh文件和二进制文件的合并文件，前面一段是sh命令，负责实际的安装，它会提取后半部分的二进制数据，后半部分一般是个压缩文件包或者自解压文件的二进制流。\nvi jre-for-linux.bin  可以看到，第一行是\n#!/bin/bash  接下来就是一堆安装和设置环境变量，提取解压部分了，最关键的部分在这几行\noutname=install.sfx.$$ tail ${tail_args} +162 \u0026quot;$0\u0026quot;\u0026gt;$outname chmod +x $outname  继续往下看，267行是exit 0，从第268行开始，就是一堆看似乱码的二进制了，到这里那就清晰多了\n# 从268行起提取二进制文件 tail -n +268 jre-for-linux.bin \u0026gt;install.sfx # 因为是sfx格式，就用7z解压 7z x install.sfx  到此解压成功。手动安装，使用export设置临时变量，就用上了JRE6了。\n","date":"2018-06-02","permalink":"https://iminto.github.io/post/linux%E4%B8%8B%E8%A7%A3%E5%8E%8Bbin%E6%96%87%E4%BB%B6/","tags":["Linux"],"title":"linux下解压bin文件"},{"content":"今天在修一个老项目，使用的是jfinal框架，这个框架算是一个比较传统的框架，只支持打包成war运行放入容器中运行，但是在开发过程中可以使用jetty快速启动和调试。个人不是很喜欢jetty，遂换成了undertow。 引入如下依赖\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.undertow\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;undertow-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.1.Final\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.undertow\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;undertow-servlet\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.1.Final\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt;  再写一个启动类就好了\npublic class Main { public static void main(String[] args) throws Exception { DeploymentInfo servletBuilder = Servlets.deployment() .setContextPath(\u0026quot;/\u0026quot;) .setClassLoader(Main.class.getClassLoader()) .setDeploymentName(\u0026quot;zooadmin.war\u0026quot;) ; FilterInfo jfinalFilter=new FilterInfo(\u0026quot;jfinal\u0026quot;,JFinalFilter.class); jfinalFilter.addInitParam(\u0026quot;configClass\u0026quot;,\u0026quot;com.baicai.core.Config\u0026quot;); servletBuilder.addFilter(jfinalFilter); servletBuilder.addFilterUrlMapping(\u0026quot;jfinal\u0026quot;,\u0026quot;/*\u0026quot;, DispatcherType.REQUEST); servletBuilder.addFilterUrlMapping(\u0026quot;jfinal\u0026quot;,\u0026quot;/*\u0026quot;, DispatcherType.FORWARD); servletBuilder.setResourceManager(new FileResourceManager(new File(\u0026quot;src/main/webapp\u0026quot;), 1024)); DeploymentManager manager = Servlets.defaultContainer().addDeployment(servletBuilder); manager.deploy(); PathHandler path = Handlers.path(Handlers.redirect(\u0026quot;/\u0026quot;)) .addPrefixPath(\u0026quot;/\u0026quot;, manager.start()); Undertow server = Undertow.builder() .addHttpListener(1080, \u0026quot;localhost\u0026quot;) .setHandler(path) .build(); // start server server.start(); } }  直接在这个类上运行main方法即可。关键的地方就是把传统的web项目的web.xml翻译成Java代码而已。 本来想继续实现springboot那种fatjar的打包方式，最后发现现有的maven插件都无法满足需求，spring是自己扩展了jar的一套协议实现的，实现起来颇有难度。留待以后折腾吧\n","date":"2018-05-19","permalink":"https://iminto.github.io/post/%E4%BD%BF%E7%94%A8%E5%86%85%E5%B5%8Cundertow%E5%BC%80%E5%8F%91%E8%B0%83%E8%AF%95jfinal%E9%A1%B9%E7%9B%AE/","tags":["Java"],"title":"使用内嵌undertow开发调试jfinal项目"},{"content":"之前公司的一个网站使用了OTP来做二次验证，然后我就在手机上安装了freeotp这款软件来管理OTP密码，等到换手机了，才发现没法导出原手机的配置，这就尴尬了。FreeOTP is sponsored and officially published by Red Hat，也算是大家闺秀出品的软件，居然不支持这么重要的功能。\n试了很多方法，在手机的文件管理器中到处搜索，都没有找到这个配置，基本可以确定freeotp把密钥存放在了系统目录，没有root的话，是没法查看和处理系统目录下的文件，即使用备份工具也备份不出来。\n当初网站的OTP二维码也找不到了，网站也没找到重新设置OTP的入口，本着万事不求人的想法，暂时还不想最后求助运维。看来唯一的办法就是root手机了，试了很多工具，没想到kingroot居然支持root魅蓝手机了。\nroot成功后，马上去freeotp的配置存储目录找到配置文件，找到 /data/data/org.fedorahosted.freeotp/shared_prefs/tokens.xml 文件，得到如下的配置,配置中的引号被转义了\n\u0026lt;?xml version='1.0' encoding='utf-8' standalone='yes' ?\u0026gt; \u0026lt;map\u0026gt; \u0026lt;string name=\u0026quot;bbcx@qq.com:chen\u0026quot;\u0026gt;{\u0026quot;algo\u0026quot;:\u0026quot;SHA256\u0026quot;,\u0026quot;counter\u0026quot;:0,\u0026quot;digits\u0026quot;:6,\u0026quot;issuerExt\u0026quot;:\u0026quot;bbcx@qq.com\u0026quot;,\u0026quot;label\u0026quot;:\u0026quot;chen\u0026quot;,\u0026quot;period\u0026quot;:30,\u0026quot;secret\u0026quot;:[17,-56,-42,-70,-48,-79,53],\u0026quot;type\u0026quot;:\u0026quot;TOTP\u0026quot;}\u0026lt;/string\u0026gt; \u0026lt;string name=\u0026quot;bbc\u0026quot;\u0026gt;{\u0026quot;algo\u0026quot;:\u0026quot;SHA1\u0026quot;,\u0026quot;counter\u0026quot;:0,\u0026quot;digits\u0026quot;:6,\u0026quot;issuerExt\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;label\u0026quot;:\u0026quot;bbc\u0026quot;,\u0026quot;period\u0026quot;:30,\u0026quot;secret\u0026quot;:[0,1,2,3],\u0026quot;type\u0026quot;:\u0026quot;TOTP\u0026quot;}\u0026lt;/string\u0026gt; \u0026lt;string name=\u0026quot;tokenOrder\u0026quot;\u0026gt;[\u0026quot;bbcx@qq.com:bbcx\u0026quot;,\u0026quot;bbc\u0026quot;]\u0026lt;/string\u0026gt; \u0026lt;/map\u0026gt;  可以看出，这里面是就是关于otp的全部配置了，最关键的就是secret字段，这里做了加密，反复试验了半天，没找到解决方案，最终想到Google，找到了这个解决方案： https://github.com/viljoviitanen/freeotp-export/blob/master/README.md ，只需要把tokens.xml贴到这里，https://rawgit.com/viljoviitanen/freeotp-export/master/export-xml.html，就能还原出二维码来，用新手机扫描就好了。\n事情还没完，最后想去freeotp的官方那里反应下，没想到官方的态度让我大跌眼镜，https://github.com/freeotp/freeotp-android/issues/20，“出门右转买收费软件去，老子就是不增加备份功能，你能咋地”。\n\u0026quot;'''Can I create backupcodes'''? ''No, but if you're using an Android smartphone you can replace the Google Authenticator app with Authenticator Plus. It's a really nice app that can import your existing settings, sync between devices and backup/restore using your sd-card. It's not a free app, but it's well worth the money.''\u0026quot; This proprietary app, Authenticator Plus, does look very nice and has some nice features, but the most beneficial I think is its ability to backup and restore codes. This could be a huge addition to FreeOTP and I would like to request that someone considers this feature and looks at a way of implementing it. I am not able to code myself.  最终，在用户义愤填膺的评论下，发现这个软件 andOTP，真是兴奋，满足了我对OTP软件的所有需求，也支持备份和导入，极力推荐。\n立马卸载了拽拽的freeOTP，装上andOTP，感觉整个世界都阳光明媚。开源的傲慢真是领悟了，惹不起惹不起。\n","date":"2018-05-14","permalink":"https://iminto.github.io/post/export-freeopt-config/","tags":null,"title":"导出freeOTP中的配置"},{"content":"很久没更新博客了，想到几个小坑，虽然没啥技术含量，但或许有人不知道呢。\n1.删除sublist的元素导致原对象元素被删除 看下面这段代码\nList\u0026lt;Integer\u0026gt; students=new ArrayList\u0026lt;Integer\u0026gt;(); for (int i = 0; i \u0026lt;5 ; i++) { students.add(i); } List\u0026lt;Integer\u0026gt; subList=new ArrayList\u0026lt;Integer\u0026gt;(); subList=students.subList(0,5); subList.remove(0); subList.remove(1); for (int i = 0; i \u0026lt;5 ; i++) { System.out.println(i+\u0026quot;=\u0026quot;+students.get(i)); }  students是个list，然后我们新建立了一个subList对象，这个对象截取了students的一部分，我们删除了subList对象里的一些元素，看下运行结果。\n0=1 1=3 2=4 Exception in thread \u0026quot;main\u0026quot; java.lang.IndexOutOfBoundsException: Index: 3, Size: 3 at java.util.ArrayList.rangeCheck(ArrayList.java:657) at java.util.ArrayList.get(ArrayList.java:433) at bai.ListDo.main(ListDo.java:17)  难道说，删除subList对象里的元素也会导致students里的元素被删除？我明明是新建了一个对象啊。然而，事实确实是这样的。 我们要理解一个事情，使用new新建一个对象，只是开辟了一块空间，用来存放这个对象的地址指针，但是这个新建的对象地址，指向的却是原有对象，也就是说，使用subList这个方法的时候，并没有从students里把内容拷贝了一份，仅仅是纪录了一个指针的移动，这样从某种角度来说，是提高了性能节省内存的做法。 看一下subList这个方法的JavaDoc我们就更清楚了。\nReturns a view of the portion of this list between the specified * \u0026lt;tt\u0026gt;fromIndex\u0026lt;/tt\u0026gt;, inclusive, and \u0026lt;tt\u0026gt;toIndex\u0026lt;/tt\u0026gt;, exclusive. (If * \u0026lt;tt\u0026gt;fromIndex\u0026lt;/tt\u0026gt; and \u0026lt;tt\u0026gt;toIndex\u0026lt;/tt\u0026gt; are equal, the returned list is * empty.) The returned list is backed by this list, so non-structural * changes in the returned list are reflected in this list, and vice-versa. * The returned list supports all of the optional list operations supported * by this list.\u0026lt;p\u0026gt;  什么时候会用到subList方法呢，通常是接收到了一个大的list，需要切割成一个个小的子list再加工处理，以减少内存占用和提高性能，如果不注意的话，就很容易触发这种隐形的bug。所以，使用subList时不要轻易做增删操作，要么不使用subList方法，而是手动add.\n2.SimpleDateFormat的线程安全问题 很多博客和文章都会告诉我们，一定要注意SimpleDateFormat的线程安全问题，那究竟是怎么回事呢？ 看下面的代码\npublic class DateFormatTest extends Thread { @Override public void run() { while(true) { try { this.join(2000); } catch (InterruptedException e1) { e1.printStackTrace(); } try { System.out.println(this.getName()+\u0026quot;:\u0026quot;+DateUtil.parse(\u0026quot;2018-05-05 12:12:12\u0026quot;)); } catch (ParseException e) { e.printStackTrace(); } } } public static void main(String[] args) { for(int i = 0; i \u0026lt; 3; i++){ new DateFormatTest().start(); } } } class DateUtil { private static final SimpleDateFormat sdf = new SimpleDateFormat(\u0026quot;yyyy-MM-dd HH:mm:ss\u0026quot;); public static String formatDate(Date date)throws ParseException{ return sdf.format(date); } public static Date parse(String strDate) throws ParseException{ return sdf.parse(strDate); } }  运行这段代码后，会发现Thread-1会报出Exception in thread \u0026ldquo;Thread-0\u0026rdquo; Exception in thread \u0026ldquo;Thread-1\u0026rdquo; java.lang.NumberFormatException: multiple points 的异常，并且导致Thread-2有一些错误的日期输出。为什么呢，原因在于SimpleDataFormat不是线程安全的，因为SimpleDataFormat里面用了Calendar 这个成员变量来实现SimpleDataFormat,并且在Parse 和Format的时候对Calendar 进行了修改，calendar.clear()，calendar.setTime(date); 为了线程安全和效率的双重兼顾，建议使用ThreadLocal，代码如下：\npublic class DateUtil1 { private static final ThreadLocal\u0026lt;DateFormat\u0026gt; messageFormat = new ThreadLocal\u0026lt;DateFormat\u0026gt;(); private static final String MESSAGE_FORMAT = \u0026quot;MM-dd HH:mm:ss.ms\u0026quot;; private static final DateFormat getDateFormat() { DateFormat format = messageFormat.get(); if (format == null) { format = new SimpleDateFormat(MESSAGE_FORMAT, Locale.getDefault()); messageFormat.set(format); } return format; } }  如果自己没有把握的话，还是建议每次new一个SimpleDataFormat对象。 Java里面还有许多线程不安全的类，使用这些类的时候，务必注意使用同步原语，或者使用new新建一个对象省事，或者使用对应的线程安全的类。比如hashMap对应的ConcurrentHashMap.\n3.split的坑 看下面的代码，\nString[] re=\u0026quot;2|33|4\u0026quot;.split(\u0026quot;|\u0026quot;); for (int i = 0; i \u0026lt;re.length ; i++) { System.out.println(re[i]); }  你以为输出的结果会是2,33,4，实际上却是 2,|，3,3，|，4。为什么呢，稍微看一下split的方法注释就知道了，原来split的分隔符参数实际上是一个正则表达式，而不是普通的字符串。 所以，正确的写法应该是String.split(\u0026quot;\\|\u0026quot;) 当然，这种坑纯粹是由于对Java基本方法的使用不熟悉造成的，是完全可以避免的。\n","date":"2018-05-05","permalink":"https://iminto.github.io/post/java_trap/","tags":["Java"],"title":"Java里常见的几个语法小坑"},{"content":" 这两天想给博客做个插件,利用阿里云的OSS来存储文件.但阿里的文档和代码都烂的超乎想象,要么代码老旧不堪,要么跟小脚老太一样引入一坨依赖,想必这块是外包团队做的吧,或者阿里非核心业务员的技术水平也就这样吧.\n 所以想绕开阿里云官方提供的代码自己整一套OSS的API,先跑一个上传文件的demo,能在客户端跑通后再用代码去实现.最简单的方法就是用REST client来模拟.折腾了一下,还挺费劲,记录下折腾过程\n 先来试试上传文件,选择PUT方法,要请求的URL为http://baicaidoc.oss-cn-shenzhen.aliyuncs.com/image/small/mm1.jpg ,添加以下header,header头需要包含哪些内容可以看这里\nAuthorization:OSS LTAIxkX6Qj2OuMZ6:tLZ7nYYP/hkCJbG/6gkOJ7Mi4E= Date:Thu, 25 Jan 2018 15:20:39 GMT Content-Disposition:attachment;filename=ivy.jpg Host:baicaidoc.oss-cn-shenzhen.aliyuncs.com Content-Encoding:utf-8  然后在body里添加file body. 至于header头怎么写和Authorization字段计算的方法,文档里说的比较清晰了https://help.aliyun.com/document_detail/31951.html. 尤其需要注意的是Date必须是GMT格式,这个对Java来说也好办,不过要注意时区的问题,GMT时间比东八区慢了8个小时.还有Host需要带上bucket,这在早期是不需要的(早期带上反而会报错SignatureDoesNotMatch) 另外就是这个Authorization字段的签名需要注意,base64需要处理byte[]数组,而不是字符串.所以用网上的在线验证工具是验证不了的. Java版的签名代码如下:\nimport bai.tool.Base64; import javax.crypto.Mac; import javax.crypto.spec.SecretKeySpec; import java.security.InvalidKeyException; import java.security.NoSuchAlgorithmException; /** * Hello world! * */ public class App { public static byte[] hamcsha1(byte[] data, byte[] key) { try { SecretKeySpec signingKey = new SecretKeySpec(key, \u0026quot;HmacSHA1\u0026quot;); Mac mac = Mac.getInstance(\u0026quot;HmacSHA1\u0026quot;); mac.init(signingKey); return mac.doFinal(data); } catch (NoSuchAlgorithmException e) { e.printStackTrace(); } catch (InvalidKeyException e) { e.printStackTrace(); } return null; } public static void main( String[] args ) { String toSign=\u0026quot;PUT\\n\u0026quot; + \u0026quot;\\n\u0026quot; + \u0026quot;image/jpeg; charset=UTF-8\\n\u0026quot; + \u0026quot;Thu, 25 Jan 2018 15:20:39 GMT\\n\u0026quot; + \u0026quot;/baicaidoc/image/small/mm1.jpg\u0026quot;; String accessKey=\u0026quot;OrzrzxIsfpFjA7S7yk0Lwy8Bw21TLhquhboiip56\u0026quot;; byte[] hm=hamcsha1(toSign.getBytes(),accessKey.getBytes()); System.out.println(\u0026quot;OSS LTAIxkX6Qj2OuMZ6:\u0026quot;+Base64.encodeToString(hm)); } }   客户端能跑通就好办了，最后是代码，使用HttpURLConnection来实现PUT上传代码。阿里云的OSS SDK太重了，而一般常用的就上传和删除功能\nimport java.io.*; import java.net.HttpURLConnection; import java.net.MalformedURLException; import java.net.URL; import java.text.SimpleDateFormat; import java.util.Date; import java.util.Locale; import java.util.TimeZone; public class OSSUpload { public String httpUrlConnectionPut(String fileName) { String result = \u0026quot;\u0026quot;; URL url = null; String httpUrl = \u0026quot;http://baicaidoc.oss-cn-shenzhen.aliyuncs.com/image/small/test.jpg\u0026quot;; try { url = new URL(httpUrl); } catch (MalformedURLException e) { e.printStackTrace(); } if (url != null) { HttpURLConnection urlConn; try { urlConn = (HttpURLConnection) url.openConnection(); File file = new File(fileName); urlConn.setRequestProperty(\u0026quot;content-type\u0026quot;, \u0026quot;image/jpeg; charset=UTF-8\u0026quot;); urlConn.setDoOutput(true);// http正文内，因此需要设为true, 默认情况下是false; urlConn.setDoInput(true);// 设置是否从httpUrlConnection读入，默认情况下是true; urlConn.setConnectTimeout(15 * 1000); urlConn.setRequestProperty(\u0026quot;User-Agent\u0026quot;, \u0026quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.84 Safari/537.36\u0026quot;); //设置请求方式为 PUT urlConn.setRequestMethod(\u0026quot;PUT\u0026quot;); urlConn.setRequestProperty(\u0026quot;Connection\u0026quot;, \u0026quot;Keep-Alive\u0026quot;); SimpleDateFormat sdf = new SimpleDateFormat(\u0026quot;EEE, dd MMM yyyy HH:mm:ss 'GMT'\u0026quot;, Locale.US); sdf.setTimeZone(TimeZone.getTimeZone(\u0026quot;GMT\u0026quot;)); urlConn.setRequestProperty(\u0026quot;Host\u0026quot;, \u0026quot;baicaidoc.oss-cn-shenzhen.aliyuncs.com\u0026quot;); urlConn.setRequestProperty(\u0026quot;Content-Encoding\u0026quot;, \u0026quot;UTF-8\u0026quot;); urlConn.setRequestProperty(\u0026quot;Date\u0026quot;, sdf.format(new Date())); urlConn.setRequestProperty(\u0026quot;Content-Length\u0026quot;, String.valueOf(file.length())); urlConn.setRequestProperty(\u0026quot;Authorization\u0026quot;, \u0026quot;OSS LTAIxk223j2OuMZ6:tLZ74YYP/hkCJbG/6gkOJ7Mi4E=\u0026quot;); DataOutputStream dos = new DataOutputStream(urlConn.getOutputStream()); //写入请求参数 try { InputStream in = new FileInputStream(file); int bytes = 0; byte[] bufferOut = new byte[4096]; while ((bytes = in.read(bufferOut)) != -1) { dos.write(bufferOut, 0, bytes); } dos.flush(); dos.close(); InputStream is = urlConn.getInputStream(); int ch; StringBuffer b = new StringBuffer(); while ((ch = is.read()) != -1) { b.append((char) ch); } System.out.println(\u0026quot;result:\u0026quot; + b.toString()); }catch (IOException e){ e.printStackTrace(); InputStream is=urlConn.getErrorStream(); int ch; StringBuffer b = new StringBuffer(); while ((ch = is.read()) != -1) { b.append((char) ch); } System.out.println(\u0026quot;error result:\u0026quot;+b.toString()); } urlConn.disconnect(); } catch (Exception e) { e.printStackTrace(); }finally { } } return result; } public static void main(String[] args) { OSSUpload oss = new OSSUpload(); oss.httpUrlConnectionPut(\u0026quot;/home/chen/Desktop/tmp/sd.png\u0026quot;); } }  ","date":"2018-01-25","permalink":"https://iminto.github.io/post/aliyun_oss_custom/","tags":["Java"],"title":"折腾阿里云OSS的API"},{"content":" 前不久,有人问到我一个问题，就是使用mb_check_encoding来侦测一段字符的编码，预期是GBK编码，但是PHP给出来UTF-8编码的错误判断。那么，mb_check_encoding的正确姿势是什么呢？ 我们来看一段代码，\n\u0026lt;?php $utf8Str = '别abc扯淡'; var_dump(mb_check_encoding($utf8Str, 'UTF-8')); //输出true var_dump(mb_check_encoding($utf8Str, 'gbk')); //输出true   这段代码的输出是啥呢？按理，我们的PHP文件保存为什么编码，那它输出的就应该是啥编码，然而以上输出的都是true。再换个例子，这样呢？\n\u0026lt;?php $utf8Str = '别abc扯淡啊'; var_dump(mb_check_encoding($utf8Str, 'UTF-8')); var_dump(mb_check_encoding($utf8Str, 'gbk'));   后面多加了一个汉字，这次PHP做出了正确的判断，给出了是UTF-8的判断。那么mb_check_encoding到底有没有用？是这个函数有bug还是我自己不懂姿势？\n 难道是，只要汉字是3的整数倍就会判断失灵？试验后确实是的，当然这只是表面现象，但无疑说明这个函数是不可靠的。为什么呢？其实原理说起来也不难理解，计算机并不懂什么叫乱码。一段文字，解释成UTF8或GBK其实都是可以的，我们用肉眼看到有了乱码，根据我们的经验，觉得解释成这种编码是错误的，而解释成另外一种编码才算正确。可是计算机不懂啊，你觉得有个字符很奇怪，你不认识所以认定是乱码，可计算机认识啊，它不觉得奇怪。除非字节数解释成另外一种编码，会多出一个字节，并且ASCII码也不是常见范围，计算机才能大胆判定解释成这种编码不对。所以这样去检测编码是无法完全可靠地.\n 那既然mb_check_encoding这个函数不可靠，那么用正则可靠么？或许吧。 但是我们更应该关注的是PHP为什么会有这么一个功能？为什么其他语言没有这个方法，或者根本不会遇到这个问题？\n 问题还是出在PHP本身。因为客户端可能会有多种编码输入，PHP为了解决这个问题就引入这么一个贴心的函数给使用者。可是PHP不应该是遇到问题就去动歪脑筋解决问题啊，而且规范问题。为什么其他语言不需要在SDK里引入这个方法呢？或者说是PHP程序员的使用姿势不正确?\n 最后，其实PHP给出这个函数也不算错，但是一定要参照其他语言里的惯行做法，在文档里说清楚，这个函数的判断的是一种“可信度”，而不是给出一个非此即彼的“权威”结果。但是遗憾的是，这个函数的文档里没说很好的说清楚，而是这么写的，\n “Checks if the specified byte stream is valid for the specified encoding. It is useful to prevent so-called \u0026ldquo;Invalid Encoding Attack Returns TRUE on success or FALSE on failure.”\n  其实加上这样一句话“This function only give the confidence level of the result”就好了，也就不会平白引起那么多的疑虑。\n 比如，Python的做法就比较专业，chardet模块给出的是一个置信检测，而不是非true即false的判断。java里面的第三方工具包cpdetector也指出了其规则，按照“谁最先返回非空的探测结果，就以该结果为准”的原则返回探测到的字符集编码。其是基于统计学原理的，不保证完全正确。\n","date":"2018-01-12","permalink":"https://iminto.github.io/post/php%E7%9A%84mb_check_encoding%E5%87%BD%E6%95%B0%E7%9A%84%E5%AD%98%E5%9C%A8%E6%98%AF%E9%B8%A1%E8%82%8B%E5%90%97/","tags":["PHP"],"title":"PHP的mb_check_encoding函数的存在是鸡肋吗"},{"content":" 针对最新火狐浏览器50+以上版本的firebug协议，类似FirePHP，但是FirePHP已经很久不更新，并且对最新的浏览器也已失效。\n 这个在Firebug之上运行的扩展，结合一个服务器端的库，就可以让你的PHP代码向浏览器发送调试信息，该信息以HTTP响应头（HTTP headers）的方式编码。经过设置，你可以像在Firebug控制台调试JavaScript代码一样得到PHP脚本的警告和错误提示。下面我们来看看具体步骤。\n 直接上代码\nimport com.alibaba.fastjson.JSON; import java.util.ArrayList; import java.util.HashMap; import java.util.Map; import java.util.Objects; /** * @version V1.0 * @Description:直接输出服务器端调试日志到控制台，简易版本。 * @date 2017/6/13 16:51 */ public class DebugTool { public final String VERSION = \u0026quot;2.0.j1\u0026quot;; public final String HEADER_NAME = \u0026quot;X-ChromeLogger-Data\u0026quot;; protected Map\u0026lt;String, Object\u0026gt; console = new HashMap\u0026lt;\u0026gt;(); private String response=\u0026quot;\u0026quot;; public DebugTool() { console.put(\u0026quot;version\u0026quot;, VERSION); console.put(\u0026quot;columns\u0026quot;, new String[]{\u0026quot;log\u0026quot;, \u0026quot;backtrace\u0026quot;, \u0026quot;type\u0026quot;}); console.put(\u0026quot;rows\u0026quot;, new ArrayList\u0026lt;Objects\u0026gt;()); console.put(\u0026quot;request_uri\u0026quot;, this.getClass().getName()); } public DebugTool(Class cls) { this(); console.put(\u0026quot;request_uri\u0026quot;, cls.getName()); } public void log(Object o) { log(o,\u0026quot;\u0026quot;); } public void info(Object o) { log(o,\u0026quot;info\u0026quot;); } public void warn(Object o) { log(o,\u0026quot;warn\u0026quot;); } public void error(Object o) { log(o,\u0026quot;error\u0026quot;); } public void log(Object o,String type) { Object[] info; if(o instanceof Map){ info = new Object[]{o}; }else { info = new Object[]{o.toString()}; } Object[] obj = new Object[]{info, console.get(\u0026quot;request_uri\u0026quot;), type}; ArrayList\u0026lt;Object\u0026gt; rows = (ArrayList\u0026lt;Object\u0026gt;) console.get(\u0026quot;rows\u0026quot;); rows.add(obj); console.put(\u0026quot;rows\u0026quot;, rows); } public String getResponse(){ String json = JSON.toJSONString(console); json = Base64.encodeToString(json); return json; } }  使用方法：\nDebugTool debug=new DebugTool(this.getClass()); tool.log(\u0026quot;hello 八阿哥\u0026quot;); Map hash=new HashMap(); hash.put(\u0026quot;25\u0026quot;,\u0026quot;张三\u0026quot;); hash.put(\u0026quot;19\u0026quot;,\u0026quot;李四\u0026quot;); tool.warn(hash); response.add(DebugTool.HEADER_NAME,tool.response);  仅对最新版Firefox有效。新版chrome有自己的debug协议（使用websocket）。有趣的是，这本来是一个chrome浏览器支持的协议，后来chrome放弃了，而Firefox拿过来了。 参考：https://craig.is/writing/chrome-logger\n","date":"2018-01-10","permalink":"https://iminto.github.io/post/firejava%E8%BE%93%E5%87%BAjava%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E8%B0%83%E8%AF%95%E6%97%A5%E5%BF%97%E5%88%B0%E6%8E%A7%E5%88%B6%E5%8F%B0/","tags":["Java"],"title":"FireJava输出Java服务器端调试日志到控制台"},{"content":"TOTP 概念 TOTP - Time-based One-time Password Algorithm is an extension of the HMAC-based One Time Password algorithm HOTP to support a time based moving factor.\nTOTP（基于时间的一次性密码算法）是支持时间作为动态因素基于HMAC一次性密码算法的扩展。它是OTP算法的一种\n算法如下: TOTP = Truncate(HMAC-SHA-1(K, (T - T0) / X))\nK 共享密钥 T 时间 T0 开始计数的时间步长 X 时间步长\n代码实现 最简实现需要如下两个类 1.Base32.java\npublic class Base32 { private static final char[] ALPHABET = { 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '2', '3', '4', '5', '6', '7' }; private static final byte[] DECODE_TABLE; static { DECODE_TABLE = new byte[128]; for (int i = 0; i \u0026lt; DECODE_TABLE.length; i++) { DECODE_TABLE[i] = (byte) 0xFF; } for (int i = 0; i \u0026lt; ALPHABET.length; i++) { DECODE_TABLE[(int) ALPHABET[i]] = (byte) i; if (i \u0026lt; 24) { DECODE_TABLE[(int) Character.toLowerCase(ALPHABET[i])] = (byte) i; } } } public static String encode(byte[] data) { char[] chars = new char[((data.length * 8) / 5) + ((data.length % 5) != 0 ? 1 : 0)]; for (int i = 0, j = 0, index = 0; i \u0026lt; chars.length; i++) { if (index \u0026gt; 3) { int b = data[j] \u0026amp; (0xFF \u0026gt;\u0026gt; index); index = (index + 5) % 8; b \u0026lt;\u0026lt;= index; if (j \u0026lt; data.length - 1) { b |= (data[j + 1] \u0026amp; 0xFF) \u0026gt;\u0026gt; (8 - index); } chars[i] = ALPHABET[b]; j++; } else { chars[i] = ALPHABET[((data[j] \u0026gt;\u0026gt; (8 - (index + 5))) \u0026amp; 0x1F)]; index = (index + 5) % 8; if (index == 0) { j++; } } } return new String(chars); } public static byte[] decode(String s) throws Exception { char[] stringData = s.toCharArray(); byte[] data = new byte[(stringData.length * 5) / 8]; for (int i = 0, j = 0, index = 0; i \u0026lt; stringData.length; i++) { int val; try { val = DECODE_TABLE[stringData[i]]; } catch (ArrayIndexOutOfBoundsException e) { throw new Exception(\u0026quot;Illegal character\u0026quot;); } if (val == 0xFF) { throw new Exception(\u0026quot;Illegal character\u0026quot;); } if (index \u0026lt;= 3) { index = (index + 5) % 8; if (index == 0) { data[j++] |= val; } else { data[j] |= val \u0026lt;\u0026lt; (8 - index); } } else { index = (index + 5) % 8; data[j++] |= (val \u0026gt;\u0026gt; index); if (j \u0026lt; data.length) { data[j] |= val \u0026lt;\u0026lt; (8 - index); } } } return data; } }  2.GoogleAuthenticator.java\nimport javax.crypto.spec.SecretKeySpec; import java.security.InvalidKeyException; import java.security.NoSuchAlgorithmException; import java.security.SecureRandom; import java.util.Base64; import javax.crypto.Mac; public class GoogleAuthenticator { // taken from Google pam docs - we probably don't need to mess with these public static final int SECRET_SIZE = 10; public static final String SEED = \u0026quot;g8GjEvTbW5oVSV7avLBdwIHqGlUYNzKFI7izOF8GwLDVKs2m0QN7vxRs2im5MDaNCWGmcD2rvcZx\u0026quot;; public static final String RANDOM_NUMBER_ALGORITHM = \u0026quot;SHA1PRNG\u0026quot;; int window_size = 3; // default 3 - max 17 (from google docs)最多可偏移的时间 /** * set the windows size. This is an integer value representing the number of 30 second windows * we allow * The bigger the window, the more tolerant of clock skew we are. * @param s window size - must be \u0026gt;=1 and \u0026lt;=17. Other values are ignored */ public void setWindowSize(int s) { if (s \u0026gt;= 1 \u0026amp;\u0026amp; s \u0026lt;= 17) window_size = s; } /** * Generate a random secret key. This must be saved by the server and associated with the * users account to verify the code displayed by Google Authenticator. * The user must register this secret on their device. * @return secret key */ public static String generateSecretKey() { SecureRandom sr = null; try { sr = SecureRandom.getInstance(RANDOM_NUMBER_ALGORITHM); sr.setSeed(Base64.getDecoder().decode(SEED)); byte[] buffer = sr.generateSeed(SECRET_SIZE); Base32 codec = new Base32(); byte[] bEncodedKey = codec.encode(buffer).getBytes(); String encodedKey = new String(bEncodedKey); return encodedKey; }catch (NoSuchAlgorithmException e) { // should never occur... configuration error } return null; } /** * Return a URL that generates and displays a QR barcode. The user scans this bar code with the * Google Authenticator application on their smartphone to register the auth code. They can also * manually enter the * secret if desired * @param user user id (e.g. fflinstone) * @param host host or system that the code is for (e.g. myapp.com) * @param secret the secret that was previously generated for this user * @return the URL for the QR code to scan */ public static String getQRBarcodeURL(String user, String host, String secret) { String format = \u0026quot;https://www.google.com/chart?chs=200x200\u0026amp;chld=M%%7C0\u0026amp;cht=qr\u0026amp;chl=otpauth://totp/%s@%s%%3Fsecret%%3D%s\u0026quot;; return String.format(format, user, host, secret); } /** * Check the code entered by the user to see if it is valid * @param secret The users secret. * @param code The code displayed on the users device * @param t The time in msec (System.currentTimeMillis() for example) * @return * @throws Exception */ public boolean check_code(String secret, long code, long timeMsec) throws Exception { Base32 codec = new Base32(); byte[] decodedKey = codec.decode(secret); // convert unix msec time into a 30 second \u0026quot;window\u0026quot; // this is per the TOTP spec (see the RFC for details) long t = (timeMsec / 1000L) / 30L; // Window is used to check codes generated in the near past. // You can use this value to tune how far you're willing to go. for (int i = -window_size; i \u0026lt;= window_size; ++i) { long hash; try { hash = verify_code(decodedKey, t + i); }catch (Exception e) { // Yes, this is bad form - but // the exceptions thrown would be rare and a static configuration problem e.printStackTrace(); throw new RuntimeException(e.getMessage()); //return false; } if (hash == code) { return true; } } // The validation code is invalid. return false; } private static int verify_code(byte[] key, long t) throws NoSuchAlgorithmException, InvalidKeyException { byte[] data = new byte[8]; long value = t; for (int i = 8; i-- \u0026gt; 0; value \u0026gt;\u0026gt;\u0026gt;= 8) { data[i] = (byte) value; } SecretKeySpec signKey = new SecretKeySpec(key, \u0026quot;HmacSHA1\u0026quot;); Mac mac = Mac.getInstance(\u0026quot;HmacSHA1\u0026quot;); mac.init(signKey); byte[] hash = mac.doFinal(data); int offset = hash[20 - 1] \u0026amp; 0xF; // We're using a long because Java hasn't got unsigned int. long truncatedHash = 0; for (int i = 0; i \u0026lt; 4; ++i) { truncatedHash \u0026lt;\u0026lt;= 8; // We are dealing with signed bytes: // we just keep the first byte. truncatedHash |= (hash[offset + i] \u0026amp; 0xFF); } truncatedHash \u0026amp;= 0x7FFFFFFF; truncatedHash %= 1000000; return (int) truncatedHash; } }  测试类如下:\nimport org.junit.Test; public class GoogleAuthTest { @Test public void genSecretTest() { String secret = GoogleAuthenticator.generateSecretKey(); System.out.println(\u0026quot;secret=\u0026quot;+secret); String url = GoogleAuthenticator.getQRBarcodeURL(\u0026quot;testuser\u0026quot;, \u0026quot;testhost\u0026quot;, secret); System.out.println(\u0026quot;Please register \u0026quot; + url); System.out.println(\u0026quot;Secret key is \u0026quot; + secret); } // Change this to the saved secret from the running the above test. static String savedSecret = \u0026quot;VGH25A7M54QPME5F\u0026quot;; @Test public void authTest() throws Exception { // enter the code shown on device. Edit this and run it fast before the code expires! long code = 146841; long t = System.currentTimeMillis(); GoogleAuthenticator ga = new GoogleAuthenticator(); ga.setWindowSize(5); //should give 5 * 30 seconds of grace... boolean r = ga.check_code(savedSecret, code, t); System.out.println(\u0026quot;Check code = \u0026quot; + r); } }  OTP Auth协议 在实际使用中,通常把secret嵌入一段URL中并以二维码的形式发布,这个URL一般称为otpauth协议.其URL如下所示: otpauth://totp/testuser@testhost?secret=VGH25A7M54QPME5F\u0026amp;algorithm=SHA1\u0026amp;digits=6\u0026amp;period=30\n","date":"2018-01-08","permalink":"https://iminto.github.io/post/totp%E7%AE%97%E6%B3%95java%E7%89%88%E6%9C%AC/","tags":["Java"],"title":"TOTP算法Java版本"},{"content":" 前段时间用vala开发了一个很小的程序,体验了一把vala的使用,网上关于vala的文章比较少,所以写一篇博客,如果你有相同的使用经验可以交流下.\n 根据百度百科的解释，vala是一种新的、为GNOME开发者提供的具有现代化编程语言功能的一种编程语言。Vala是一种和C#极度类似的语言。\n 众所周知,C是一门古老而落后的语言,虽然由于历史原因,大量的操作系统底层仍然在使用C(毕竟最早写底层的那批人早就退休甚至不在人世了,谁又愿意没事找事去重构呢.不过,还别说,Google就在干这种事,开发全新的操作系统),但并不适用于大型项目和协作开发.尽管Linux的作者Linus极度憎恨C++这样的面向对象的语言,并拒绝C++在Linux内核的使用.但是,Linux的其它开发者也心知肚明,C并不是一切,并且在Linux的各个方面大量使用C++和面向对象的开发模式.知名的KDE桌面就是基于QT来构建的,而QT是对C++的一个扩展,Linux上的大部分可用的应用都是基于QT来构建的,而另一个桌面环境Gnome则使用了GTK绑定,同时也大量使用了面向对象的特性和组件,比如Gobject,Vala.Vala的一个重要使用场景就是Gnome环境的GUI开发.\n Vala语言的主要特点：支持lambda表达式；支持对象反射与内省；使用引用计数进行内存管理，计数嵌入在对象内；使用Glib和Gobject的主循环、事件回调系统。\n安装  在Ubuntu/Debian下安装很简单，使用命令sudo apt-get install valac，测试valac编译器的版本号，可以输入valac \u0026ndash;version命令。 我现在使用的是0.36版本,最新版本应该是0.40 Beta.\nHelloWorld程序 class Demo.HelloWorld : GLib.Object { public static int main(string[] args) { stdout.printf(\u0026quot;Hello, World\\n\u0026quot;); return 0; } }  其实在Vala里,类并不是必须的.类名和文件名并不需要一致,并且一个类里允许多个类.\n编译运行 编译这个程序使用命令valac hello.vala，编译成功之后生成hello这个可执行程序，运行这个程序，输入结果为： Hello, World\nVala一个比较有趣的地方就是可以直接从Vala源码编译成C源码,比如上面的代码可以使用如下的命令编译成C源码\nvalac -C ./hello.vala  生成的C源码如下:\n/* hello.c generated by valac 0.36.5, the Vala compiler * generated from hello.vala, do not modify */ #include \u0026lt;glib.h\u0026gt; #include \u0026lt;glib-object.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #define DEMO_TYPE_HELLO_WORLD (demo_hello_world_get_type ()) #define DEMO_HELLO_WORLD(obj) (G_TYPE_CHECK_INSTANCE_CAST ((obj), DEMO_TYPE_HELLO_WORLD, DemoHelloWorld)) #define DEMO_HELLO_WORLD_CLASS(klass) (G_TYPE_CHECK_CLASS_CAST ((klass), DEMO_TYPE_HELLO_WORLD, DemoHelloWorldClass)) #define DEMO_IS_HELLO_WORLD(obj) (G_TYPE_CHECK_INSTANCE_TYPE ((obj), DEMO_TYPE_HELLO_WORLD)) #define DEMO_IS_HELLO_WORLD_CLASS(klass) (G_TYPE_CHECK_CLASS_TYPE ((klass), DEMO_TYPE_HELLO_WORLD)) #define DEMO_HELLO_WORLD_GET_CLASS(obj) (G_TYPE_INSTANCE_GET_CLASS ((obj), DEMO_TYPE_HELLO_WORLD, DemoHelloWorldClass)) typedef struct _DemoHelloWorld DemoHelloWorld; typedef struct _DemoHelloWorldClass DemoHelloWorldClass; typedef struct _DemoHelloWorldPrivate DemoHelloWorldPrivate; struct _DemoHelloWorld { GObject parent_instance; DemoHelloWorldPrivate * priv; }; struct _DemoHelloWorldClass { GObjectClass parent_class; }; static gpointer demo_hello_world_parent_class = NULL; GType demo_hello_world_get_type (void) G_GNUC_CONST; enum { DEMO_HELLO_WORLD_DUMMY_PROPERTY }; gint demo_hello_world_main (gchar** args, int args_length1); DemoHelloWorld* demo_hello_world_new (void); DemoHelloWorld* demo_hello_world_construct (GType object_type); gint demo_hello_world_main (gchar** args, int args_length1) { gint result = 0; FILE* _tmp0_; _tmp0_ = stdout; fprintf (_tmp0_, \u0026quot;Hello, World\\n\u0026quot;); result = 0; return result; } int main (int argc, char ** argv) { #if !GLIB_CHECK_VERSION (2,35,0) g_type_init (); #endif return demo_hello_world_main (argv, argc); } DemoHelloWorld* demo_hello_world_construct (GType object_type) { DemoHelloWorld * self = NULL; self = (DemoHelloWorld*) g_object_new (object_type, NULL); return self; } DemoHelloWorld* demo_hello_world_new (void) { return demo_hello_world_construct (DEMO_TYPE_HELLO_WORLD); } static void demo_hello_world_class_init (DemoHelloWorldClass * klass) { demo_hello_world_parent_class = g_type_class_peek_parent (klass); } static void demo_hello_world_instance_init (DemoHelloWorld * self) { } GType demo_hello_world_get_type (void) { static volatile gsize demo_hello_world_type_id__volatile = 0; if (g_once_init_enter (\u0026amp;demo_hello_world_type_id__volatile)) { static const GTypeInfo g_define_type_info = { sizeof (DemoHelloWorldClass), (GBaseInitFunc) NULL, (GBaseFinalizeFunc) NULL, (GClassInitFunc) demo_hello_world_class_init, (GClassFinalizeFunc) NULL, NULL, sizeof (DemoHelloWorld), 0, (GInstanceInitFunc) demo_hello_world_instance_init, NULL }; GType demo_hello_world_type_id; demo_hello_world_type_id = g_type_register_static (G_TYPE_OBJECT, \u0026quot;DemoHelloWorld\u0026quot;, \u0026amp;g_define_type_info, 0); g_once_init_leave (\u0026amp;demo_hello_world_type_id__volatile, demo_hello_world_type_id); } return demo_hello_world_type_id__volatile; }   可以看出 vala实际是把vala源码编译成GObject的语法,并且加入了很多语法糖.由于vala的这个特性,从而也决定了vala是一种性能比较高的语言.既能获得面向对象的便利,又能获得接近于C语言的性能.\n vala可以大量使用glib的库,具有比较强的表现力和较高的开发效率.然而由于其定位的问题,不能在服务端市场分得一杯羹,导致发展极为有限,可惜了这门在我看来,在Linux上开发体验仅次于C++和Java的语言.如果你接触过C++ 17 以上标准的C++,你就会感觉到C++的表现能力和开发效率,已经是一门比较现代化的语言了,并不会比脚本语言低多少.\n","date":"2018-01-08","permalink":"https://iminto.github.io/post/vala%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C/","tags":["Vala"],"title":"Vala使用体验"}]