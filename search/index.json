[{"content":"服务端\nimport socket\rimport struct\r# 多播地址和端口\rMULTICAST_GROUP = '239.0.0.110'\rSERVER_PORT = 12345\r# 创建 UDP 套接字\rserver_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)\r# 允许地址重用\rserver_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\r# 绑定到指定端口\rserver_socket.bind(('', SERVER_PORT))\r# 将套接字加入多播组\rgroup = socket.inet_aton(MULTICAST_GROUP)\rmreq = struct.pack('4sL', group, socket.INADDR_ANY)\rserver_socket.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)\rprint(f\u0026quot;Listening on multicast address {MULTICAST_GROUP}:{SERVER_PORT}...\u0026quot;)\rtry:\rwhile True:\r# 接收数据\rdata, client_address = server_socket.recvfrom(1024)\rmessage = data.decode('utf-8')\rprint(f\u0026quot;Received message from {client_address}: {message}\u0026quot;)\r# 向客户端发送响应\rresponse = \u0026quot;Message received successfully!\u0026quot;\rserver_socket.sendto(response.encode('utf-8'), client_address)\rexcept KeyboardInterrupt:\rprint(\u0026quot;Shutting down...\u0026quot;)\rfinally:\rserver_socket.close()\r客户端\nimport socket\rMULTICAST_GROUP = '239.0.0.110'\rSERVER_PORT = 12345\rclient_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\rclient_socket.settimeout(3)\rmessage = \u0026quot;Hello, I'm a client!\u0026quot;\rtry:\rclient_socket.sendto(message.encode('utf-8'), (MULTICAST_GROUP, SERVER_PORT))\rprint(f\u0026quot;Sent message to {MULTICAST_GROUP}:{SERVER_PORT}\u0026quot;)\rtry:\rdata, server_address = client_socket.recvfrom(1024)\rprint(f\u0026quot;Received response from {server_address}: {data.decode('utf-8')}\u0026quot;)\rexcept socket.timeout:\rprint(\u0026quot;No response from server. Server may be unavailable.\u0026quot;)\rexcept socket.error as e:\rprint(f\u0026quot;Error: {e}\u0026quot;)\rfinally:\rclient_socket.close()\r","date":"2025-04-02","permalink":"http://localhost:1313/post/python%E5%A4%9A%E6%92%AD/","tags":["python"],"title":"Python多播"},{"content":"将图片/文件转为二维码动画\nyum install qrencode test=\u0026quot;$(cat dianlong.jpg| base64|tr '\\n' ' '|sed 's/[[:space:]]//g')\u0026quot;\recho $test \u0026gt;\u0026gt; base64.txt #文件转base64\rsplit -b 1k base64.txt 1_ #按1K分割\rfor x in $(find -type f -name \u0026quot;1_*\u0026quot;); do cat $x|qrencode -o $x.png -s 4 ;done\rffmpeg -framerate 6 -pattern_type glob -i '1_*.png' -loop 0 out1.gif #转GIF\rffmpeg -framerate 10 -pattern_type glob -i '1_*.png' -c:v libx264 -pix_fmt yuv420p out.mp4\r#计算帧数，验证\rffprobe -i out.mp4\rffmpeg -i out.mp4 -map 0:v:0 -c copy -f null -\rffprobe -v error -select_streams v:0 -show_entries stream=nb_frames -of default=nokey=1:noprint_wrappers=1 out.mp4\r还原：\nffmpeg -i out1.gif re/img_%2d.jpg\rbase64 -d base64.txt \u0026gt;b.jpg\r","date":"2023-06-16","permalink":"http://localhost:1313/post/%E6%96%87%E4%BB%B6%E7%94%9F%E6%88%90%E5%8A%A8%E6%80%81%E4%BA%8C%E7%BB%B4%E7%A0%81/","tags":["Linux"],"title":"文件生成动态二维码"},{"content":"最近测试反馈了一个问题，每次重启服务器，我们某个版本的业务系统中的机器码都会改变，导致根据机器码算出来的许可证失效，从而使软件无法使用。 这个问题反馈了有一段时间了，但是本地一直没复现。然后前几天测试说又复现了，马上去看了下测试环境，服务器是一台国产化FT S2500服务器,验证了下，果然如此，马上去看了下关键代码。\npublic static String executeLinuxCmd(int type) {\rtry {\rString cmd = \u0026quot;dmidecode |grep 'Serial Number'\u0026quot;;\rif (type == 1) {\rcmd = \u0026quot;fdisk -l\u0026quot;;\r}\r//...\r} catch (IOException e) {//\r}\rreturn null;\r}\rpublic static String getSerialNumber(int type, String record, String symbol) {\rString execResult = executeLinuxCmd(type);\rString[] infos = execResult.split(\u0026quot;\\n\u0026quot;);\rfor (String info : infos) {\rinfo = info.trim();\rif (info.indexOf(record) != -1) {\rString[] sn = info.replace(\u0026quot; \u0026quot;, \u0026quot;\u0026quot;).split(symbol);\rreturn sn[1];\r}\r}\r//...\r}\r/**\r* 获取CPUID、硬盘序列号、MAC地址、主板序列号\r*\r* @return\r*/\rpublic static Map\u0026lt;String, String\u0026gt; getAllSn() {\rString os = System.getProperty(\u0026quot;os.name\u0026quot;);\rMap\u0026lt;String, String\u0026gt; snVo = new HashMap();\rif (\u0026quot;LINUX\u0026quot;.equalsIgnoreCase(os)) {\rString mainboardNumber = getSerialNumber(0, \u0026quot;Serial Number\u0026quot;, \u0026quot;:\u0026quot;);\rString diskNumber = getSerialNumber(1, \u0026quot;Disk identifier\u0026quot;, \u0026quot;:\u0026quot;);\rsnVo.put(\u0026quot;diskid\u0026quot;, diskNumber == null ? \u0026quot;tmpDiskId\u0026quot; : diskNumber.toUpperCase().replace(\u0026quot; \u0026quot;, \u0026quot;\u0026quot;));\rsnVo.put(\u0026quot;mainboard\u0026quot;, mainboardNumber == null ? \u0026quot;tmpMainboard\u0026quot; : mainboardNumber.toUpperCase().replace(\u0026quot; \u0026quot;, \u0026quot;\u0026quot;));\r} else {\r这下明白了，它是取的CPU序列号作为机器码。dmidecode的输出中有多个Serial Number，它只取了第一个，恰恰就是Processor Information，也就是我们常说的CPU序列号。\nHandle 0x0001, DMI type 4, 48 bytes\rProcessor Information\rSocket Designation: CPU0\rType: Central Processor\rFamily: ARMv8\rManufacturer: Phytium\rID: 33 66 1F 70 00 00 00 00\rSignature: Implementor 0x70, Variant 0x1, Architecture 15, Part 0x663, Revision 3\rVersion: S2500\rVoltage: 0.8 V\rExternal Clock: 100 MHz\rMax Speed: 2100 MHz\rCurrent Speed: 2100 MHz\rStatus: Populated, Enabled\rUpgrade: Unknown\rL1 Cache Handle: 0x1001\rL2 Cache Handle: 0x1002\rL3 Cache Handle: 0x1003\rSerial Number: A5F9B0AD-E023-7E89-CF01-47772188AD003\rAsset Tag: 9EEC0F35-D6DB-EE11-4788-C0EE56755439\rPart Number: ABD15C29-35D3-1659-BFAF-AD57F39874C3\rCore Count: 64\rCore Enabled: 64\rThread Count: 64\rCharacteristics:\r64-bit capable\rMulti-Core\rExecute Protection\rEnhanced Virtualization\rPower/Performance Control\rCPU支持过序列号功能，但是被人指责侵犯隐私，所以现在的规范中，CPU完全没有所谓的序列号。\n关于CPU序列号，其实还有一段历史。在奔腾3中短暂的引入过这个功能，但是后来很快就移除了。\nEAX=3: Processor Serial Number\nSee also: Pentium III § Controversy about privacy issues（https://en.wikipedia.org/wiki/Pentium_III#Controversy_about_privacy_issues）\nThis returns the processor\u0026rsquo;s serial number. The processor serial number was introduced on Intel Pentium III, but due to privacy concerns, this feature is no longer implemented on later models (PSN feature bit is always cleared). Transmeta\u0026rsquo;s Efficeon and Crusoe processors also provide this feature. AMD CPUs however, do not implement this feature in any CPU models.\nFor Intel Pentium III CPUs, the serial number is returned in EDX:ECX registers. For Transmeta Efficeon CPUs, it is returned in EBX:EAX registers. And for Transmeta Crusoe CPUs, it is returned in EBX register only.\nNote that the processor serial number feature must be enabled in the BIOS setting in order to function.\n所以，我们不应该使用CPU Serial Number来作为设备唯一性判断，而应该使用CPU ID来判断。\n1.Windows下获取CPU ID 如果是windows系统，根据MSDN文档：http://msdn.microsoft.com/en-us/library/aa394373(v=vs.85).aspx ProcessorId\nData type: string\nAccess type: Read-only\nProcessor information that describes the processor features. For an x86 class CPU, the field format depends on the processor support of the CPUID instruction. If the instruction is supported, the property contains 2 (two) DWORD formatted values. The first is an offset of 08h-0Bh, which is the EAX value that a CPUID instruction returns with input EAX set to 1. The second is an offset of 0Ch-0Fh, which is the EDX value that the instruction returns. Only the first two bytes of the property are significant and contain the contents of the DX register at CPU reset—all others are set to 0 (zero), and the contents are in DWORD format.\u0026quot;\n可以用如下代码获取CPU ID\n#include \u0026quot;stdafx.h\u0026quot;\r#include\u0026lt;iostream\u0026gt;\rint main()\r{\rint32_t deBuf[4];\r__cpuidex(deBuf, 01, 0);\rprintf(\u0026quot;%.8x%.8x\u0026quot;, deBuf[3], deBuf[0]);\rgetchar();\rreturn 0;\r}\r本地没有msvc编译环境，就不做测试了。\n2.linux x86/amd64获取CPU ID 在Linux上呢，我们也可以用C内联汇编来实现\n#include \u0026lt;stdio.h\u0026gt;\rstatic inline void native_cpuid(unsigned int *eax, unsigned int *ebx,\runsigned int *ecx, unsigned int *edx)\r{\r/* ecx is often an input as well as an output. */\rasm volatile(\u0026quot;cpuid\u0026quot;\r: \u0026quot;=a\u0026quot; (*eax),\r\u0026quot;=b\u0026quot; (*ebx),\r\u0026quot;=c\u0026quot; (*ecx),\r\u0026quot;=d\u0026quot; (*edx)\r: \u0026quot;0\u0026quot; (*eax), \u0026quot;2\u0026quot; (*ecx));\r}\rint main(int argc, char **argv)\r{\runsigned eax, ebx, ecx, edx;\reax = 1; /* processor info and feature bits */\rnative_cpuid(\u0026amp;eax, \u0026amp;ebx, \u0026amp;ecx, \u0026amp;edx);\rprintf(\u0026quot;stepping %d\\n\u0026quot;, eax \u0026amp; 0xF);\rprintf(\u0026quot;model %d\\n\u0026quot;, (eax \u0026gt;\u0026gt; 4) \u0026amp; 0xF);\rprintf(\u0026quot;family %d\\n\u0026quot;, (eax \u0026gt;\u0026gt; 8) \u0026amp; 0xF);\rprintf(\u0026quot;processor type %d\\n\u0026quot;, (eax \u0026gt;\u0026gt; 12) \u0026amp; 0x3);\rprintf(\u0026quot;extended model %d\\n\u0026quot;, (eax \u0026gt;\u0026gt; 16) \u0026amp; 0xF);\rprintf(\u0026quot;extended family %d\\n\u0026quot;, (eax \u0026gt;\u0026gt; 20) \u0026amp; 0xFF);\r/* EDIT */\reax = 3; /* processor serial number */\rnative_cpuid(\u0026amp;eax, \u0026amp;ebx, \u0026amp;ecx, \u0026amp;edx);\r/** see the CPUID Wikipedia article on which models return the serial number in which registers. The example here is for Pentium III */\rprintf(\u0026quot;cpu serial number 0x%08x%08x\\n\u0026quot;, edx, ecx);\rnative_cpuid这段代码来自linux kernel里的源码，其实gcc里有cpuid.h这个文件，它封装了ASM代码，直接引入即可。\n看下运行结果：\n[root@localhost xx]# gcc cpu_x86.c -o cpu_x86\r[root@localhost xx]# ./cpu_x86\rstepping 4\rmodel 5\rfamily 6\rprocessor type 0\rextended model 5\rextended family 0\rserial number 0x0000000000000000\r如上所示，eax, ebx, ecx, edx这四个寄存器对应的内容就是cpu id。跟dmidecode的结果比较下，可以对应上。\n[root@localhost xx]# dmidecode -t 4\r# dmidecode 3.0\rGetting SMBIOS data from sysfs.\rSMBIOS 2.7 present.\rHandle 0x0004, DMI type 4, 42 bytes\rProcessor Information\rSocket Designation: CPU #000\rType: Central Processor\rFamily: Unknown\rManufacturer: GenuineIntel\rID: 54 06 05 00 FF FB AB 0F\rVersion: Intel(R) Xeon(R) Gold 6152 CPU @ 2.10GHz\rVoltage: 3.3 V\rExternal Clock: Unknown\rMax Speed: 30000 MHz\rCurrent Speed: 2100 MHz\rStatus: Populated, Enabled\rUpgrade: ZIF Socket\rL1 Cache Handle: 0x0016\rL2 Cache Handle: 0x0018\rL3 Cache Handle: Not Provided\rSerial Number: Not Specified\rAsset Tag: Not Specified\rPart Number: Not Specified\rCore Count: 1\rCore Enabled: 1\rCharacteristics:\r64-bit capable\rExecute Protection\r3.aarch64下获取CPU ID 如果是aarch64架构，CPU架构不一样，就不能用同样的ASM汇编了，找了下ARM官方文档，https://developer.arm.com/documentation/ddi0500/d/system-control/aarch64-register-descriptions/main-id-register\u0026ndash;el1?lang=en，参考CPU架构，可以从MIDR_EL1寄存器获取\n#include \u0026lt;stdio.h\u0026gt;\rint main(int argc, char **argv)\r{\runsigned long arm_cpuid;\r__asm__(\u0026quot;mrs %0, MIDR_EL1\u0026quot; : \u0026quot;=r\u0026quot;(arm_cpuid));\rprintf(\u0026quot;%-20s: 0x%016lx\\n\u0026quot;, \u0026quot;MIDR_EL1=\u0026quot;, arm_cpuid);\r}\r输出如下\n[root@master98 xx]# gcc cpu.c -o cpu\r[root@master98 xx]# ./cpu\rMIDR_EL1= : 0x00000000701f6633\r正好与dmidecode中的ID对应。经过测试，重启后cpuid是不会改变的。\n4.CPU ID or Serial Number？ Java代码里匹配的是Serial Number，这里一直说的是CPU ID，这俩东西到底是不是同一个事呢？\n结论是： 1.CPU Serial Number是一个Embedded 96-bit code during chip fabrication，但废弃标准，不应该使用，而应该使用CPU ID来判断。\n2.因为涉及隐私问题（Serial Number is Readable by networks \u0026amp; applications），现在的服务器架构已经不支持CPU Serial Number的获取了，用dmidecode获取到的Serial Number不保证有值的。\n3.CPU ID包含的是CPU架构的一些信息，更接近条形码的概念，并不是唯一身份标识，不保证唯一性。\n4.dmidecode在国产服务器架构下获取到的CPU Serial Number，其实又叫PSN（Processor Serial Number）。之所以国产化服务器能拿到PSN，是因为国产服务器是aarch64架构，并且是自主化研发，并没有遵循Intel的规范。另外同为国产化服务器，不同的厂家实现也不一样，有的重启即变，有的并不会变化。关于PSN的开启，应该是可以在BIOS里配置。其实，PSN should NOT exist at all。为什么国产服务器还保留PSN，就不做过多展开了。有兴趣的可以自行阅读PSN相关文档\n最后，修改很简单，如果使用场景不严格，可以使用CPU ID，或者System Information中的UUID即可，两者都能保证重启不变，但System Information中的UUID能保证唯一性，而CPU ID不能 。\n","date":"2022-02-09","permalink":"http://localhost:1313/post/cpuid%E5%92%8C%E5%BA%8F%E5%88%97%E5%8F%B7%E8%83%8C%E5%90%8E%E7%9A%84%E9%82%A3%E4%BA%9B%E6%95%85%E4%BA%8B/","tags":["Linux"],"title":"Cpuid和序列号背后的那些故事"},{"content":"前几天看到有人发的一个面试题，问的是MySQL连接的进程描述符的问题。\n在Linux里，一切皆文件，那进程描述符，实际就是文件描述符了。\n我们还知道Linux 内核提供了一种通过 proc文件系统，/proc 文件系统是一个虚拟文件系统，通过它可以使用一种新的方法在 Linux内核空间和用户间之间进行通信。在 /proc文件系统中，我们可以将对虚拟文件的读写作为与内核中实体进行通信的一种手段，但是与普通文件不同的是，这些虚拟文件的内容都是动态创建的。用户和应用程序可以通过proc得到系统的信息，并可以改变内核的某些参数。\n/proc目录通常对用户来说是只读的，如果你直接在bash下想要修改一个文件是权限不足的。但是对系统来说是可写的，因此也就可以通过编程来实现增删改查。\n查看socket描述符 那么，这个文件描述符就一定是在/proc 目录了。想必那就是在相应进程的/proc/$pid/fd 目录下存放了此进程所有打开的fd。\n[root@localhost fd]# pwd\r/proc/1723/fd\r[root@manager 1723]# ll fd|grep socket\rlrwx------ 1 root root 64 Jul 7 13:49 103 -\u0026gt; socket:[5722374]\rlrwx------ 1 root root 64 Jul 7 13:49 104 -\u0026gt; socket:[5057632]\rlrwx------ 1 root root 64 Jul 7 13:49 105 -\u0026gt; socket:[5722375]\rlrwx------ 1 root root 64 Jul 7 13:49 106 -\u0026gt; socket:[5057636]\rlrwx------ 1 root root 64 Jul 7 13:49 107 -\u0026gt; socket:[5983188]\rlrwx------ 1 root root 64 Jul 7 13:49 124 -\u0026gt; socket:[5983189]\rlrwx------ 1 root root 64 Jul 7 13:49 130 -\u0026gt; socket:[27456]\rlrwx------ 1 root root 64 Jul 7 13:49 131 -\u0026gt; socket:[27458]\rlrwx------ 1 root root 64 Jul 7 13:49 132 -\u0026gt; socket:[27460]\rlrwx------ 1 root root 64 Jul 7 13:49 51 -\u0026gt; socket:[23447]\rlrwx------ 1 root root 64 Jul 7 13:49 52 -\u0026gt; socket:[23448]\rlrwx------ 1 root root 64 Jul 7 13:49 78 -\u0026gt; socket:[5057630]\rlrwx------ 1 root root 64 Jul 7 13:49 79 -\u0026gt; socket:[5721339]\rlrwx------ 1 root root 64 Jul 7 13:49 80 -\u0026gt; socket:[3639663]\rlrwx------ 1 root root 64 Jul 7 13:49 81 -\u0026gt; socket:[5057631]\rlrwx------ 1 root root 64 Jul 7 13:49 82 -\u0026gt; socket:[5721340]\rlrwx------ 1 root root 64 Jul 7 13:49 95 -\u0026gt; socket:[5722372]\r这个结果，和netant看到的相差无几\n[root@manager ~]# netstat -antp | grep 1723 | wc -l\r16\r当然，这和用lsof统计到的结果应该也是差不多的。之所以说差不多，而不是一样，是因为虽然netstat和lsof虽然也是读取的/proc文件系统，但是有自己的过滤和判断条件，比如这两个工具除了读取/proc/pid/fd目录，还会读取/proc/net/tcp(udp)文件。因此，如果socket创建了，没有被使用，那么就只会在/proc/pid/fd下面有，而不会在/proc/net/tcp(udp)，那么netstat就统计不到了。\n那么这个socket:后面的一串数字是什么呢？看起来像是端口号，有些又明显不是，其实是该socket的inode号。 那么，知道了某个进程打开的socket的inode号后，我们可以做什么呢？这就涉及到/proc/net/tcp(udp对应/proc/net/udp)文件了，其中也列出了相应socket的inode号通过比对此字段，我们能在/proc/net/tcp下获得此套接口的其他信息，如对应的\u0026lt;本地地址：端口号，远端地址：端口号\u0026gt;四元组，窗口大小，状态等信息。具体字段含义详见net/ipv4/tcp_ipv4.c 中的 tcp4_seq_show 函数。\n[root@manager net]# cat /proc/net/tcp\rsl local_address rem_address st tx_queue rx_queue tr tm-\u0026gt;when retrnsmt uid timeout inode\r0: 00000000:006F 00000000:0000 0A 00000000:00000000 00:00000000 00000000 0 0 15528 1 ffff880426f60000 100 0 0 10 0\r1: 00000000:0016 00000000:0000 0A 00000000:00000000 00:00000000 00000000 0 0 19300 1 ffff880426f607c0 100 0 0 10 0\r2: 0100007F:0019 00000000:0000 0A 00000000:00000000 00:00000000 00000000 0 0 20170 1 ffff88042dfc8000 100 0 0 10 0\r3: 00000000:21DE 00000000:0000 0A 00000000:00000000 00:00000000 00000000 0 0 21513 1 ffff88042dfc87c0 100 0 0 10 0\r4: 55F9B40A:0016 59CDB40A:2779 01 00000000:00000000 02:000936FD 00000000 0 0 6004930 2 ffff88042dfca6c0 22 6 1 10 -1\r5: 55F9B40A:0016 59CDB40A:2733 01 00000030:00000000 01:00000018 00000000 0 0 5984362 4 ffff880426f645c0 25 4 31 10 -1\r6: 55F9B40A:0016 59CDB40A:2778 01 00000000:00000000 02:000936FD 00000000 0 0 6004866 2 ffff88042dfcae80 24 7 1 10 -1\r7: 55F9B40A:8F2E 55F9B40A:20F9 01 00000000:00000000 00:00000000 00000000 0 0 22051 1 ffff88042dfc9f00 20 4 30 10 -1\r8: 55F9B40A:0016 59CDB40A:2738 01 00000000:00000000 02:000843C9 00000000 0 0 5983909 2 ffff880426f664c0 22 4 21 7 6\r[root@manager net]#\r这个文件怎么解读呢，我们暂时只看第一部分\n8: 55F9B40A:0016 59CDB40A:2738 01 | | | | | |--\u0026gt; connection state（套接字状态）\r| | | | |------\u0026gt; remote TCP port number（远端端口，主机字节序）\r| | | |-------------\u0026gt; remote IPv4 address（远端IP，网络字节序）\r| | |--------------------\u0026gt; local TCP port number（本地端口，主机字节序）\r| |---------------------------\u0026gt; local IPv4 address（本地IP，网络字节序）\r|----------------------------------\u0026gt; number of entry\r比如我们看到59CDB40A:2738这个rem_address，很自然它就是TCP的四元组，十六进制转为二进制后就是 89.205.180.10:10040，注意此处IP地址应该是10.180.205.89。用lsof验证下\n[root@manager net]# lsof -i|grep 10040\rsshd 17757 root 3u IPv4 5983909 0t0 TCP manager.bigdata:ssh-\u0026gt;10.180.205.89:10040 (ESTABLISHED)\rconnection state(套接字状态)，不同的数值代表不同的状态，参照如下：\nTCP_ESTABLISHED:1 TCP_SYN_SENT:2\rTCP_SYN_RECV:3 TCP_FIN_WAIT1:4\rTCP_FIN_WAIT2:5 TCP_TIME_WAIT:6\rTCP_CLOSE:7 TCP_CLOSE_WAIT:8\rTCP_LAST_ACL:9 TCP_LISTEN:10\rTCP_CLOSING:11\r我们看的这条数据并不是MySQL的连接。问题来了，为什么MySQL里看到那么多fd，netstat也看到了很多，但是 /proc/net/tcp 下并没有那么多socket描述符呢。前面说过了，/proc/net/tcp(udp)可以认为是proc/pid/fd的子集，但是这也差的太离谱了。其实原因很简单，如果你在 /proc/net/tcp下找不到，试试去/proc/net/tcp6 下找找呢。\n关闭指定socket连接 如果我们再进一步，我们现在可以找到每个pid下的socket描述符，如果我想断掉这个描述符也就是断开这个连接，怎么做呢？用防火墙显然不是好主意，防火墙通常是针对某个IP和固定端口的。这个时候，socket fd号就派上用场了。注意，fd和inode是两码事。\n查看当前fd\n(base) [root@manager ~]# ll /proc/1723/fd|grep socket\rlrwx------ 1 root root 64 Jul 7 13:49 103 -\u0026gt; socket:[10232948]\rlrwx------ 1 root root 64 Jul 7 13:49 105 -\u0026gt; socket:[9490029]\rlrwx------ 1 root root 64 Jul 7 13:49 107 -\u0026gt; socket:[10232952]\rlrwx------ 1 root root 64 Jul 7 13:49 124 -\u0026gt; socket:[10232954]\rlrwx------ 1 root root 64 Jul 7 13:49 130 -\u0026gt; socket:[27456]\rlrwx------ 1 root root 64 Jul 7 13:49 131 -\u0026gt; socket:[27458]\rlrwx------ 1 root root 64 Jul 7 13:49 132 -\u0026gt; socket:[27460]\rlrwx------ 1 root root 64 Jul 7 13:49 51 -\u0026gt; socket:[23447]\rlrwx------ 1 root root 64 Jul 7 13:49 52 -\u0026gt; socket:[23448]\rlrwx------ 1 root root 64 Jul 7 13:49 79 -\u0026gt; socket:[10882498]\r现在在另外一台服务器，直接用命令行mysql -h连接本机的mysql服务，然后再查看下fd列表\n(base) [root@manager ~]# ll /proc/1723/fd|grep socket\rlrwx------ 1 root root 64 Jul 7 13:49 103 -\u0026gt; socket:[10232948]\rlrwx------ 1 root root 64 Jul 7 13:49 105 -\u0026gt; socket:[9490029]\rlrwx------ 1 root root 64 Jul 7 13:49 107 -\u0026gt; socket:[10232952]\rlrwx------ 1 root root 64 Jul 7 13:49 124 -\u0026gt; socket:[10232954]\rlrwx------ 1 root root 64 Jul 7 13:49 130 -\u0026gt; socket:[27456]\rlrwx------ 1 root root 64 Jul 7 13:49 131 -\u0026gt; socket:[27458]\rlrwx------ 1 root root 64 Jul 7 13:49 132 -\u0026gt; socket:[27460]\rlrwx------ 1 root root 64 Jul 7 13:49 51 -\u0026gt; socket:[23447]\rlrwx------ 1 root root 64 Jul 7 13:49 52 -\u0026gt; socket:[23448]\rlrwx------ 1 root root 64 Jul 7 13:49 79 -\u0026gt; socket:[10882498]\rlrwx------ 1 root root 64 Jul 7 13:49 80 -\u0026gt; socket:[11222776]\r对比下，最下面多出来的一行就是新增的那个连接，fd=80,socket inode=11222776。\n我们使用gdb调用syscall，关闭这个fd\ngdb -p 1723\rcall close(80)\rquit\r然后看一下，远程mysql连接已经断了。\n","date":"2021-07-09","permalink":"http://localhost:1313/post/socket%E6%8F%8F%E8%BF%B0%E7%AC%A6%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/","tags":["Linux"],"title":"进程Socket描述符的那些事"},{"content":"之前一篇文章提到了System.exit和SecurityManager,引入了下面的代码\npublic class SelfSecurityManager extends SecurityManager{\r..//\r@Override\rpublic void checkExit(int status) {\rsuper.checkExit(status);\rthrow new ExitException(status);\r}\r}\r通过自定义SecurityManager来禁止System.exit的执行，这里我们来分析下其实现原理，看下super.checkExit方法\n/*\r* @param status the exit status.\r* @exception SecurityException if the calling thread does not have\r* permission to halt the Java Virtual Machine with\r* the specified status.\r* @see java.lang.Runtime#exit(int) exit\r* @see #checkPermission(java.security.Permission) checkPermission\r*/\rpublic void checkExit(int status) {\rcheckPermission(new RuntimePermission(\u0026quot;exitVM.\u0026quot;+status));\r}\r可以看到checkPermission方法检查了RuntimePermission类型中的exitVM操作。RuntimePermission是JVM对运行时权限的一个集合，提供了对Java运行时的权限定义，那RuntimePermission有哪些权限呢，我们可以看下RuntimePermission类上的注释，或者直接看官方文档\nPermission 可以看到仅仅是RuntimePermission类型就非常之多 ，包括之前我们提到的setSecurityManager和exitVM。\nPermission Target Name What the Permission Allows Risks of Allowing this Permission createClassLoader Creation of a class loader This is an extremely dangerous permission to grant. Malicious applications that can instantiate their own class loaders could then load their own rogue classes into the system. These newly loaded classes could be placed into any protection domain by the class loader, thereby automatically granting the classes the permissions for that domain. getClassLoader Retrieval of a class loader (e.g., the class loader for the calling class) This would grant an attacker permission to get the class loader for a particular class. This is dangerous because having access to a class\u0026rsquo;s class loader allows the attacker to load other classes available to that class loader. The attacker would typically otherwise not have access to those classes. setContextClassLoader Setting of the context class loader used by a thread The context class loader is used by system code and extensions when they need to lookup resources that might not exist in the system class loader. Granting setContextClassLoader permission would allow code to change which context class loader is used for a particular thread, including system threads. enableContextClassLoaderOverride Subclass implementation of the thread context class loader methods The context class loader is used by system code and extensions when they need to lookup resources that might not exist in the system class loader. Granting enableContextClassLoaderOverride permission would allow a subclass of Thread to override the methods that are used to get or set the context class loader for a particular thread. closeClassLoader Closing of a ClassLoader Granting this permission allows code to close any URLClassLoader that it has a reference to. setSecurityManager Setting of the security manager (possibly replacing an existing one) The security manager is a class that allows applications to implement a security policy. Granting the setSecurityManager permission would allow code to change which security manager is used by installing a different, possibly less restrictive security manager, thereby bypassing checks that would have been enforced by the original security manager. createSecurityManager Creation of a new security manager This gives code access to protected, sensitive methods that may disclose information about other classes or the execution stack. getenv.{variable name} Reading of the value of the specified environment variable This would allow code to read the value, or determine the existence, of a particular environment variable. This is dangerous if the variable contains confidential data. exitVM.{exit status} Halting of the Java Virtual Machine with the specified exit status This allows an attacker to mount a denial-of-service attack by automatically forcing the virtual machine to halt. Note: The \u0026ldquo;exitVM.\u0026rdquo; permission is automatically granted to all code loaded from the application class path, thus enabling applications to terminate themselves. Also, the \u0026ldquo;exitVM\u0026rdquo; permission is equivalent to \u0026ldquo;exitVM.\u0026rdquo;. shutdownHooks Registration and cancellation of virtual-machine shutdown hooks This allows an attacker to register a malicious shutdown hook that interferes with the clean shutdown of the virtual machine. .. .. .. 也就是说，Java代码里，禁止执行哪些方法，允许执行哪些方法，都是有开关可以控制的。除了RuntimePermission，还有 AudioPermission, AuthPermission, AWTPermission, DelegationPermission, JAXBPermission, LinkPermission, LoggingPermission, ManagementPermission, MBeanServerPermission, MBeanTrustPermission, NetPermission, PropertyPermission, ReflectPermission, RuntimePermission, SecurityPermission, SerializablePermission, SQLPermission, SSLPermission, SubjectDelegationPermission, WebServicePermission等类型，比如设置Java代码对操作系统和JVM常量读取的PropertyPermission，设置读写文件位置和操作的FilePermission等。\n需要说明的是，RuntimePermission是java.security.BasicPermission的子类，BasicPermission又是java.security.Permission的子类，因此FilePermission和RuntimePermission不在一个同级别的包下。\n要让这些Permission生效，我们需要在JVM启动时就指定对应的策略文件，比如 java -jar aa.jar -Djava.security.manager -Djava.security.policy==d:/other/security.policy\npolicy策略文件 我们接着讲下policy策略文件是啥。\npolicy文件的作用是指定哪些类有哪些权限。policy文件根据类的url和类的签名来确定类，指定权限，例如：\ngrant codeBase \u0026quot;file:${{java.ext.dirs}}/*\u0026quot; {\rpermission java.security.AllPermission;\r};\rgrant {\rpermission java.io.FilePermission \u0026quot;\u0026lt;\u0026lt;ALL FILES\u0026gt;\u0026gt;\u0026quot;, \u0026quot;execute\u0026quot;;\r};\rpolicy文件的具体语法可以看oracle的文档，DSL如下：\ngrant signedBy \u0026quot;signer_names\u0026quot;, codeBase \u0026quot;URL\u0026quot;,\rprincipal principal_class_name \u0026quot;principal_name\u0026quot;,\rprincipal principal_class_name \u0026quot;principal_name\u0026quot;,\r... {\rpermission permission_class_name \u0026quot;target_name\u0026quot;, \u0026quot;action\u0026quot;, signedBy \u0026quot;signer_names\u0026quot;;\rpermission permission_class_name \u0026quot;target_name\u0026quot;, \u0026quot;action\u0026quot;, signedBy \u0026quot;signer_names\u0026quot;;\r...\r};\rtarget有限支持 \u0026ldquo;*\u0026rdquo; 和\u0026quot;-\u0026ldquo;这种通配符，但使用场景有限。\n一旦开启了policy策略，JVM的权限检查就变成了白名单模式。默认情况下，JVM的policy是AllPermission的（默认的policy文件位于java.home/lib/security/java.policy），如果你定义了自己的policy文件覆盖JVM的默认策略，那么就严格按照你的定义来走了，不在你policy策略里的代码一律无法执行。\nimport java.io.FileWriter;\rimport java.io.IOException;\rpublic class Poc {\rpublic static void main(String[] args) throws IOException {\rexec(\u0026quot;calc\u0026quot;);\rSystem.setSecurityManager(null);\rwrite();\r}\rpublic static void write() {\rfinal String str = \u0026quot;Hi \u0026quot;;\rtry {\rFileWriter writer = new FileWriter(\u0026quot;d:\\\\a.txt\u0026quot;);\rwriter.write(str);\rwriter.close();\r} catch (IOException e) {\re.printStackTrace();\r}\r}\rpublic static void exec(String command) {\rtry {\rRuntime.getRuntime().exec(command);\r} catch (Exception e) {\re.printStackTrace();\r}\r}\r}\r脚本小子要想再执行exec弹个计算器就不行了，异常如下\nLauncher failed - \u0026quot;Dump Threads\u0026quot; and \u0026quot;Exit\u0026quot; actions are unavailable (access denied (\u0026quot;java.lang.RuntimePermission\u0026quot; \u0026quot;loadLibrary.G:\\idea\\bin\\breakgen64.dll\u0026quot;))\rjava.security.AccessControlException: access denied (\u0026quot;java.io.FilePermission\u0026quot; \u0026quot;\u0026lt;\u0026lt;ALL FILES\u0026gt;\u0026gt;\u0026quot; \u0026quot;execute\u0026quot;)\rat java.security.AccessControlContext.checkPermission(AccessControlContext.java:472)\r可以看到execute被阻止了，甚至连idea的javaagent挂载都被禁止了。因为前面说过，policy策略是白名单模式。\n实用性 想要把policy策略用起来，看来是很困难的，因为默认的白名单模式也会导致很多常规操作受阻，包括文件读写，一些反射API。要想白名单起作用，需要严格的测试和复杂的policy策略，当然为了安全，这些都是值得的。\n在java中，反射是一个常见的操作，如果由于业务需要，无法禁用反射，尤其是Spring，对反射强依赖，这种情况可以设置禁止反射的方法和变量的黑名单，方法就是sun.reflect.Reflection类的registerFieldsToFilter和registerMethodsToFilter方法。\n那么policy策略有黑名单模式吗？没有。如果你非要有，也可以自定义java.security.manager类，但是黑名单策略明显是比白名单安全隐患要大的。\n要实现安全和易用之间的平衡，还是很难的。另外，Java体系的API是比较复杂的，反射，自定义ClassLoader，loadLibrary等非常规操作都是可以被利用来绕过java security manager的，尤其需要注意。当然，还得从代码和服务器层面来做好安全防控。\njava policy策略这么复杂，有什么工具能帮助我们配置吗？这个真的有，那就是JDK自带的policytool，界面如图。 如果要在springboot里配置一个policy，会比较复杂，可能会多大几百条指令，这里仅给出一个最小的支持数据库连接的springboot的policy文件\ngrant codeBase \u0026quot;file:G:/data/project/bcdemo/target/bcdemo-0.0.1-SNAPSHOT.jar\u0026quot; {\rpermission java.util.PropertyPermission \u0026quot;*\u0026quot;, \u0026quot;read\u0026quot;;\r//\rpermission java.util.PropertyPermission \u0026quot;java.awt.headless\u0026quot;, \u0026quot;read,write\u0026quot;;\rpermission java.util.PropertyPermission \u0026quot;spring.beaninfo.ignore\u0026quot;, \u0026quot;read,write\u0026quot;;\rpermission java.util.PropertyPermission \u0026quot;org.graalvm.nativeimage.imagecode\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.util.PropertyPermission \u0026quot;user.dir\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.util.PropertyPermission \u0026quot;java.protocol.handler.pkgs\u0026quot;, \u0026quot;read,write\u0026quot;;\rpermission java.util.PropertyPermission \u0026quot;PID\u0026quot;, \u0026quot;write\u0026quot;;\rpermission java.util.PropertyPermission \u0026quot;catalina.*\u0026quot;, \u0026quot;read,write\u0026quot;;\rpermission java.lang.reflect.ReflectPermission \u0026quot;suppressAccessChecks\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.io.FilePermission \u0026quot;${java.io.tmpdir}/-\u0026quot;, \u0026quot;read,write,delete\u0026quot;;\rpermission java.io.FilePermission \u0026quot;./config/application.properties\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.io.FilePermission \u0026quot;./config/-\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.io.FilePermission \u0026quot;./application.properties\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.io.FilePermission \u0026quot;./application.xml\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.io.FilePermission \u0026quot;./application.yml\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.io.FilePermission \u0026quot;./application.yaml\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.io.FilePermission \u0026quot;./-\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.io.FilePermission \u0026quot;G:/data/project/bcdemo/target/\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.io.FilePermission \u0026quot;C:/-\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;getenv.SPRING_BOOT_ENABLEAUTOCONFIGURATION\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;getenv.spring.boot.enableautoconfiguration\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;getenv.spring.application.name\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;getenv.spring.*\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;getenv.logging.*\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;getenv.LOGGING_REGISTER_SHUTDOWN_HOOK\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;getenv.*\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;createClassLoader\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;setContextClassLoader\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;accessDeclaredMembers\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.net.SocketPermission \u0026quot;localhost:9010\u0026quot;, \u0026quot;listen\u0026quot;;\rpermission java.net.SocketPermission \u0026quot;127.0.0.1:1024-\u0026quot;, \u0026quot;accept,resolve\u0026quot;;\r//db\rpermission java.net.SocketPermission \u0026quot;10.180.249.85:3306\u0026quot;, \u0026quot;connect,resolve\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;getProtectionDomain\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;setFactory\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;accessClassInPackage.sun.reflect\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;getClassLoader\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.net.NetPermission \u0026quot;specifyStreamHandler\u0026quot;, \u0026quot;read\u0026quot;;\rpermission javax.security.auth.AuthPermission \u0026quot;doAsPrivileged\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.security.SecurityPermission \u0026quot;getProperty.authconfigprovider.factory\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;modifyThread\u0026quot;, \u0026quot;read\u0026quot;;\r};\r这份配置仅供参考，如果你有引入更多依赖或外部连接，那就需要根据报错添加对应策略。\n一点闲话 java policy有啥实际应用吗？百度应用引擎BAE (Baidu App Engine) 大概是2011年或更早搞的，是模仿SAE（新浪云,2009年11月推出）的一个产品。至于GAE，就不提了，比它们不知高了几个level。\n不过SAE那时逼格比较高，刚开始只支持PHP，而且得邀请制开通，还搞了什么新浪豆机制，所以我用的是免费BAE。继续闲话，当时新浪搞了个SAE认证，会玩SAE的颁发个初中高级SAE开发者认证，据说面试可以加分，然后产生了SAE认证一条龙产业，花钱买认证，甚至有人给自己的不识字的父母也搞了个SAE中级认证。。。别笑，是真的。这个圈子可把老哥我当年给整乐了，而且一圈人一直在整乐子，整到了2021年。\nPHP比较简单就一句略过，就是Nginx虚拟主机+自定义php.ini那套，说下Java沙箱。BAE对Java的支持也比较有意思，BAE那个年代有kvm和虚拟机了（但是还没有docker），但BAE也好，SAE也好，使用的并不是虚拟技术，同样是更接近虚拟主机的方案。其中BAE对Java的支持我记得是通过SVN提交代码文件到一个固定的目录下就可以了，操作体验非常接近虚拟主机。\n那脚本小子就来劲了啊，我得给你穿了，访问别人的文件或系统的文件。还真有人这么做了，穿透BAE/SAE的沙箱读取系统配置文件或者弹个计算器。BAE/SAE当时都是用的java policy搞的Java沙箱技术来实现隔离的，一样有人用反射来绕过沙箱。当然，沙箱实现还不止这种技术，还包括网络的隔离等。\n不过现在都2021年了，docker和K8S的广泛使用让Java沙箱的用武之地已经不是那么很大了，docker的隔离也更彻底了，沙箱或许已经成为了历史。\n","date":"2021-06-17","permalink":"http://localhost:1313/post/java%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5%E9%85%8D%E7%BD%AE%E5%92%8C%E6%B2%99%E7%AE%B1%E9%97%B2%E8%AF%9D/","tags":["Java"],"title":"Java安全策略配置和沙箱闲话"},{"content":"之前文章提到服务器上一个进程启动后不到三分钟就挂掉，到底是什么原因挂掉了，这个问题可以写篇文章了。进程死了，无非就两种可能：自杀，他杀。他杀又包括第三方杀害和系统判死刑。\n先来看自杀。\n1.自杀 我们以Java为例，Java程序在main方法运行完就会退出，这种属于自杀。或者像下面这样\nSystem.exit();\r这样也属于自杀。\n比如下面的代码\npublic class SelfKill {\rpublic static void main(String[] args) throws InterruptedException {\rwhile(true){\rThread.sleep(5000);\rSystem.exit(4);\r}\r}\r}\r运行如下：\n[koudai@koudai-pc classes]$ java baicai.other.SelfKill\r[koudai@koudai-pc classes]$ echo $?4\r我们能用shutdownHook来在临死前记日志。\npublic class SelfKill {\rpublic static void main(String[] args) throws InterruptedException {\rRuntime.getRuntime().addShutdownHook(new Thread(() -\u0026gt; {\rSystem.out.println(\u0026quot;关闭应用，释放资源\u0026quot;);\r}));\rwhile(true){\rThread.sleep(2000);\rSystem.exit(4);\r}\r}\r}\r执行结果\n[koudai@koudai-pc classes]$ java baicai.other.SelfKill\r关闭应用，释放资源\r可以看到，无论是主动自杀，还是被自杀，shutdownHook都能保持现场。那如果是不支持shutdownHook的语言呢，或者程序里没有做Hook，那我们是不知道的。另外，不只是自杀shutdownHook能触发，它杀shutdownHook也会被触发。\n总结下：对于主动自杀，如果我们有使用了shutdownHook，是能记录下自杀时间和现场的。如果是被自杀（恶意后门调用System.exit），并且我们没有做Hook，那对自杀现场是不知情的。代码里一定要有完善的shutdownHook。\n主动自杀是我们的主动行为，那怎样避免被动自杀呢？刚才说了，被动自杀一般是恶意调用System.exit导致，一种是开发者加入的后门，一种是脚本小子加入的后门。System.exit导致JVM直接退出，且没有日志可以查询到是哪个类里的代码导致，因此通常情况下需要屏蔽。System.exit是可以被禁止的，方法就是自定义SecurityManager：\npublic class SelfSecurityManager extends SecurityManager{\r@Override\rpublic void checkPermission(Permission perm) {\rif (perm instanceof java.lang.RuntimePermission) {\rString name = perm.getName();\rif (name != null \u0026amp;\u0026amp; name.contains(\u0026quot;setSecurityManager\u0026quot;)) {\rthrow new SecurityException(\u0026quot;System.setSecurityManager denied!\u0026quot;);\r}\r}\r}\r@Override\rpublic void checkPermission(Permission perm, Object context) {\r//\r}\r@Override\rpublic void checkExit(int status) {\rsuper.checkExit(status);\rthrow new ExitException(status);//自定义异常\r}\r}\rSystem.setSecurityManager(new SelfSecurityManager());//main方法中\r需要注意的是，你可以自定义SecurityManager，脚本小子也可以自定义。因此光在Java类中自定义SecurityManager是不够的，你需要在JVM启动参数上定义更精细的policy文件，以及保护自己的SecurityManager不被重置。尤其需要注意不要被反射绕过。\n2.他杀 前面说了，不只是自杀shutdownHook能触发，以下场景都会触发 ShutdownHook :\n代码执行结束，JVM 正常退出 应用代码中调用 System#exit 方法 应用中发生 OOM 错误，导致 JVM 关闭 终端中使用 Ctrl+C(非后台运行) 主动关闭应用 我们模拟Ctrl+C试试。如下所示\n[koudai@koudai-pc classes]$ java baicai.other.SelfKill^C关闭应用，释放资源[koudai@koudai-pc classes]$\r可以看到ctrl+C是能被捕获到的。那么kill指令能被捕获吗\n[koudai@koudai-pc classes]$ kill 14675[koudai@koudai-pc classes]$ java baicai.other.SelfKill关闭应用，释放资源\r可以看到普通的kill是能被捕获的，那么kill -9呢\n[koudai@koudai-pc classes]$ ps -ef|grep Kill\rkoudai 14948 8231 0 00:57 pts/1 00:00:00 java baicai.other.SelfKill\rkoudai 15235 14640 0 00:58 pts/2 00:00:00 grep --colour=auto Kill\r[koudai@koudai-pc classes]$ kill -9 14948\r[koudai@koudai-pc classes]$ java baicai.other.SelfKill\r已杀死\r可以看到kill -9是无法被进程自身所捕获的。\n到这里就结束了吗？\n真正的问题来了，就算我有shutdownHook能记下临终遗言，但是最关键的是我无法知道是谁杀死了我。尤其是分析某些木马的场景下\n如果是系统杀死我的，那一般就是OOM，这种情况也还好。\nLinux内核有个机制叫OOM killer(Out Of Memory killer)，该机制会监控那些占用内存过大，尤其是瞬间占用内存很快的进程，然后防止内存耗尽而自动把该进程杀掉。内核检测到系统内存不足、挑选并杀掉某个进程的过程可以参考内核源代码linux/mm/oom_kill.c，当系统内存不足的时候，out_of_memory()被触发，然后调用select_bad_process()选择一个”bad”进程杀掉。\n这种OOM，是有日志记录的，可以用下面的方法查看\ngrep \u0026quot;Out of memory\u0026quot; /var/log/messagessudo dmesg|grep \u0026quot;Out of memory\u0026quot;\r系统杀的，自认倒霉。\n最麻烦的是被第三方杀的，比如木马，各种监控脚本，各种sh脚本，我咋样才知道是哪个进程杀的呢？这就需要用到systemtap了。\n3.systemtap使用 systemtap是一个用于简化linux系统运行形态信息收集的开源工具。它立足于性能诊断和bug调试，对内核及用户态程序提供了动态追踪功能，用户可以自定探测事件来跟踪程序的运行情况，如函数的调用路径、CPU占用和磁盘IO等一系列可以探测的情况。有了systemtap，可以在程序不修改代码，甚至不用重启就能分析出程序的运行情况。\nsystemtap 的核心思想是定义一个事件（event），以及给出处理该事件的句柄（Handler）。当一个特定的事件发生时，内核运行该处理句柄，就像快速调用一个子函数一样，处理完之后恢复到内核原始状态。\n先来安装它\nyum install systemtap systemtap-runtime\rstap-prep\rstap -e 'probe begin{printf(\u0026quot;Hello, World\u0026quot;); exit();}' #测试验证\r由于我们并不需要高级功能，所以暂不安装内核符号文件。接下来，我们写一个stap脚本\nvim sigmon.stp\r# 内容如下\rprobe begin\r{\rprintf(\u0026quot;%-8s %-16s %-5s %-16s %6s %-16s\\n\u0026quot;,\r\u0026quot;SPID\u0026quot;, \u0026quot;SNAME\u0026quot;, \u0026quot;RPID\u0026quot;, \u0026quot;RNAME\u0026quot;, \u0026quot;SIGNUM\u0026quot;, \u0026quot;SIGNAME\u0026quot;)\r}\rprobe signal.send\r{\rif (sig_name == @1 \u0026amp;\u0026amp; sig_pid == target())\rprintf(\u0026quot;%-8d %-16s %-5d %-16s %-6d %-16s\\n\u0026quot;,\rpid(), execname(), sig_pid, pid_name, sig, sig_name)\r}\r现在我们需要监控某个进程，就这么调用\n(base) [root@VM-0-7-centos ~]# stap -x 28262 sigmon.stp SIGKILLSPID SNAME RPID RNAME SIGNUM SIGNAME 2362819 bash 28262 rsyslogd 9 SIGKILL\r这样我们就知道28262这个进程是被2362819这个进程，也就是bash所杀死的。\n当然，如果不在事前监控，事后我们是拿不到日志信息的。\n如果我们即不做ShutdownHook，也不使用systemtap进行监控，仅仅靠操作系统自带日志，那我们是无法保存死亡现场，也很难知道谁是进程killed背后的凶手了\n","date":"2021-06-15","permalink":"http://localhost:1313/post/%E8%B0%81%E6%9D%80%E6%AD%BB%E4%BA%86%E8%BF%99%E4%B8%AA%E8%BF%9B%E7%A8%8B/","tags":["Linux","Java"],"title":"谁杀死了这个进程"},{"content":"坚果3，发布于2018年4月，骁龙625处理器，4G内存，安卓7.1系统。\n我手里这台，已经退役两个多月了，屏幕摔得到处是裂缝，老罗破产了，系统最后一次更新是2020年2月了，而且安卓7.1也老了一点。锤子手机其实不是太喜欢，它的特色功能我一个都不喜欢，什么one step，大爆炸，胶囊，我都用不上，当时买它只是因为便宜，性价比不错。另外，锤子的手机也不够开放，我也卸载或冻结了很多它自带的系统APP，导致系统APP卸载了，菜单还保留着，但不能点击，额，不能忍受，所以越用越不顺眼，正好换了新手机，就刷机了。\n准备工具 高通 EDL 线 （也称为 9008 线、救砖线、工程线），自行上淘宝购买（10几块的就够了，反正就用一次。淘宝上有些卖家会写着「小米工程线」，其实是同一个东西，通用的）。 QPST 线刷工具、TWRP 线刷包、底包、魔趣 ROM 等相关资源，详见：坚果手机 3 (oscar) 底包、TWRP 及相关工具 不建议自己 DIY 刷机线，type-c接口的线DIY比较复杂，用micro b的线自制还得配个转接头。所以能买就买吧。\n一、刷入 TWRP 安装 QPST 工具包中的线刷工具和驱动，打开 Qfil 软件； 进 Configuration，确保 Device Type 选了 eMMC； 拔掉数据线， 关机。等待手机彻底关机、屏幕不亮为止； 把 EDL 线插到电脑上，按住 EDL 线上的小开关把另一头插入手机。等待大概 3 秒**（注意：不长不短，掐好3秒，否则可能不能成功识别）**松手，此时电脑上的 Qfil 应该会识别到 Qualcomm HS-USB QDLoader 设备； 在 Qfil 里选择 Flat Build； 点击 Programmer 的那个 Browse，选择线刷包中的 prog_ 开头的文件； 点击 Load XML，选择工具包里的 rawprogram_unsparse.xml； 它会再次弹出选择框，点取消； 深呼吸； 点击 Download 按钮，稍等片刻，TWRP 刷入完成； 长按音量增和电源键。直到你看到白色锤子的时候松开电源键（继续按住音量减键）；直到你看到 TWRP 的时候才松开所有按键，进入 TWRP，继续进行下面的步骤。 二、刷入魔趣 进 Wipe（清除），把下面那个条条拖住向右划一下。此时电脑上已经出现手机所在的存储盘，拷贝底包和魔趣的包到手机上。\n返回上一层，进 Install（安装），刷入底包（RADIO- 开头的那个）\n返回上一层（不要重启），再次进安装，刷入魔趣（MK 开头的那个）\n刷完重启，完成\n第一次需要花费2分钟重启。\n刷Magisk 因为Magisk V19的作者用了错的密钥生成boot.img签名，这个在大多数手机上均没问题，但是在锤子这种没有解锁Bootloader的手机来说，会导致无法解开锁屏。但是导演适配了错误密钥。所以坚果3可以刷Magisk V19；但是，Magisk V20作者密钥又重新改对了，所以目前坚果3不支持V20. 提供一个V19.3的安装包：链接:https://pan.baidu.com/s/1UgLGnM5AdpUgv4wQwBp5Wg 密码:prmf\n注意事项 由于坚果的 Bootloader 仍然会校验 boot.img 的签名，所以请勿自己刷入 Magisk 等需要改动 boot 的模块。否则会导致卡在白锤子。也不是不可以，但是要注意版本 刷机后原手机已经安装的APP还在，但由于魔趣最新包是安卓9版本，会导致软件不兼容，频繁弹出app停止运行的错误窗口。此时，需要恢复出厂设置，手机自动重启进入TWRP ,清空data分区，重启即可。 如果需要root，需要去官方下载一个apk，安装即可。 即使没有root魔趣，建设银行这类APP仍然无法运行。它会认为系统不安全，拒绝运行。所以你如果很依赖银行APP，慎重考虑下。当然，也有解决办法。 如何刷回原厂 Smartisan OS 系统 2021年了，不建议刷回去了。原厂系统已经死了。 魔趣体验 才700多M的安装包，基本没有捆绑软件，原生接近AOSP，那个丝滑流畅啊，太舒服了。原生万岁，国产流氓可耻。我都想把手里的onePlus 8刷了\n参考 https://www.mintimate.cn/2019/11/30/%E5%9D%9A%E6%9E%9C3%E5%88%B7%E9%AD%94%E8%B6%A3/\n","date":"2021-05-21","permalink":"http://localhost:1313/post/%E5%9D%9A%E6%9E%9C3%E6%89%8B%E6%9C%BA%E5%88%B7%E9%AD%94%E8%B6%A3%E4%BD%93%E9%AA%8C/","tags":["闲扯淡"],"title":"坚果3手机刷魔趣体验"},{"content":"起因是某客户的服务器上，只要一启动server，过不了几秒就被kill，然后错误日志也看不出啥。 server是基于jvm的，怎么看一个进程被哪个进程杀死，这个可以写一篇文章了。\n自信一点，这肯定不是我们代码的问题导致JVM崩溃啊，毫无疑问是那些做安全的脚本小子搞的。\n找啊找，套路无非是crontab，mount伪装这些玩意。至于篡改ps,top隐藏进程这类，我相信大部分脚本小子也没这能力，当然了，干这一行很多都是有传承的，扛不住其所在的家族雄厚，有祖传神器也难说。 好吧，最后找到是一个放到.log目录起名为x86-64的可执行程序。是我以小人之心度君子之腹了，人家也没搞隐藏ps的操作，就是每秒钟起来杀一次占用CPU最多的程序以免影响它干活。。这心机婊，还起个这么有迷惑性的名字，我就信了你是系统文件不去碰？\ncp一份，保留备份，killall，然后分析下。vim一看，不是脚本，那就是elf喽。\nLinux下用来快速分析elf文件有几个工具，一个是readelf，一个是objdump，另外一个是ldd。 通常用ldd来分析动态加载的库，objdump用来反编译。但是这几个工具面对一些恶意文件并不总是有效。 比如对于静态编译的程序，或者变种脚本，ldd就无效了。 对于没有section table的程序，objdump也就可能无法得出结果了。\n#objdump -d ./wi\r./wi: file format elf64-x86-64\r因为objdump需要依赖code sections或section table，可以用readelf看看\n[root@localhost ~]# readelf -a ./wi\rELF Header:\rMagic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00\rClass: ELF64\rData: 2's complement, little endian\rVersion: 1 (current)\rOS/ABI: UNIX - System V\rABI Version: 0\rType: EXEC (Executable file)\rMachine: Advanced Micro Devices X86-64\rVersion: 0x1\rEntry point address: 0x5c9e70\rStart of program headers: 64 (bytes into file)\rStart of section headers: 0 (bytes into file)\rFlags: 0x0\rSize of this header: 64 (bytes)\rSize of program headers: 56 (bytes)\rNumber of program headers: 3\rSize of section headers: 64 (bytes)\rNumber of section headers: 0\rSection header string table index: 0\rThere are no sections in this file.\rThere are no sections to group in this file.\rProgram Headers:\rType Offset VirtAddr PhysAddr\rFileSiz MemSiz Flags Align\rLOAD 0x0000000000000000 0x0000000000400000 0x0000000000400000\r0x00000000001ca78b 0x00000000001ca78b R E 200000\rLOAD 0x0000000000000000 0x00000000005cb000 0x00000000005cb000\r0x0000000000000000 0x0000000000597d58 RW 1000\rGNU_STACK 0x0000000000000000 0x0000000000000000 0x0000000000000000\r0x0000000000000000 0x0000000000000000 RW 10\rThere is no dynamic section in this file.\rThere are no relocations in this file.\rThe decoding of unwind sections for machine type Advanced Micro Devices X86-64 is not currently supported.\rDynamic symbol information is not available for displaying symbols.\rNo version information found in this file.\r所以这种情况下，可以这么来，-D表示对全部文件进行反汇编，-b表示二进制，-m表示指令集架构\n[root@localhost ~]# objdump -b binary -D -m i386 ./wi\r./wi: file format binary\rDisassembly of section .data:\r00000000 \u0026lt;.data\u0026gt;:\r0: 7f 45 jg 0x47\r2: 4c dec %esp\r3: 46 inc %esi\r4: 02 01 add (%ecx),%al\r6: 01 00 add %eax,(%eax)\r...\r10: 02 00 add (%eax),%al\r12: 3e 00 01 add %al,%ds:(%ecx)\r15: 00 00 add %al,(%eax)\r另外，strace，gdb等工具也有一定的帮助。当然，上IDA这种大型武器就更有效了。 这只是浅尝辄止，就算dump出了这么一堆汇编代码，又有什么用，没那么容易看懂。\n我又凭啥让别人相信这东西不是个正常的二进制文件？仅仅凭它各种龌龊的隐藏行为还不够。\n所以，好端端的一个ELF可执行文件，怎么就没了section table呢？很简单，脚本小子就是喜欢玩些小把戏，很容易就想到是加壳了，Linux下最容易想到的壳就是UPX。\n[root@localhost ~]# strings ./wi |grep UPX\rnUPX!(\r$Info: This file is packed with the UPX executable packer http://upx.sf.net $\r$Id: UPX 3.95 Copyright (C) 1996-2018 the UPX Team. All Rights Reserved. $\rUPX!u\rUPX!\rUPX!\r脚本小子做事还是毛糙，也不晓得隐藏一下壳。把它的王八壳子扒了\n[root@localhost ~]# ./upx -d wi\rUltimate Packer for eXecutables\rCopyright (C) 1996 - 2020\rUPX 3.96 Markus Oberhumer, Laszlo Molnar \u0026amp; John Reiser Jan 23rd 2020\rFile size Ratio Format Name\r-------------------- ------ ----------- -----------\r5011080 \u0026lt;- 1878380 37.48% linux/amd64 wi\rUnpacked 1 file.\r要是脚本小子把UPX壳的信息给隐藏了，那么UPX自带的-d命令就没法脱壳了，这个时候就得用IDA了。加壳的本质就是把原来的程序的数据全部压缩加密了，在静态文件中无法分析，随着程序的执行，运行时会将代码释放到内存中。我们可以用ida远程调试test程序，找到upx自解壳后的 OEP，再把内存给dump出来，就可以实现手动脱壳了。怎样找OEP，这就得看经验了。\n脱壳之后呢，继续用strings，strace，netstat等命令做定性分析。\n其实到了这一步,strings命令已经足够分析出其行为了。\n[1;37monnection\r* COMMANDS 'h' hashrate, 'p' pause, 'r' resume, 's' results, 'c' connection\r\u0026gt;wz *ctz\u0026gt;3\u0026gt;c)\r:w 3\r[32m||\r[31m ERROR [32m||\r[37m Invalid Port Use In This Range [36m'1-65535' [37me.g\r[31m ( ./xmrig -p 3333 )\r[32m||\r[31m ERROR [32m||\r[37m Invalid Class You Can Use Only These Classes [36m'192.168'\r[32m, [36m'172'\r[32m, [36m'100'\r[32m, [36m'10'\r[37m e.g\r[31m ( ./xmrig -lan 192.168.0.1 )\r[32m||\r[31m ERROR [32m||\r[37m Empty Or Invalid Pool Address\r还能分析出是C++写的木马。想要反汇编出C++源文件，你吃屁呢。objdump得依赖debug信息才行，脚本小子再菜鸡也不会这么做啊。要C++源文件，那只能用IDA dump了，这也得出近似的源文件。\n当然了，最简单的就是直接上传到virustotal，最后得出的结果果然是一个Linux.Risk.Bitcoinminer.Tbix。\n呵呵，脚本小子。\n","date":"2021-05-17","permalink":"http://localhost:1313/post/linux%E6%81%B6%E6%84%8Felf%E6%96%87%E4%BB%B6%E5%88%86%E6%9E%90/","tags":["Linux"],"title":"Linux恶意ELF文件分析"},{"content":"简介 keycloak是一个非常强大的权限认证系统，我们使用keycloak可以方便的实现SSO的功能。虽然keycloak底层使用的wildfly，但是提供了非常方便的Client Adapters和各种服务器进行对接，比如wildfly，tomcat，Jetty等。\n对于最流行的SpringBoot来说，keycloak有官方Adapter，只需要修改配置即可。如果非SpringBoot应用呢，那就只能使用Java Servlet Filter Adapter了。\nSpringBoot接入keycloak的例子比较多，我就不赘述了。这里只简单说明下。\n接入前的前置准备 在接入各种应用之前，需要在keycloak中做好相应的配置。一般来说需要使用下面的步骤：\n创建新的realm\n一般来说，为了隔离不同类型的系统，我们建议为不同的client创建不同的realm。当然，如果这些client是相关联的，则可以创建在同一个realm中。\n创建新的用户和角色。\n用户是用来登录keycloak用的，如果是不同的realm，则需要分别创建用户。用户密码也是在这一步创建的\n添加和配置client\n这一步是非常重要的，我们需要根据应用程序的不同，配置不同的root URL，redirect URI等。\n还可以配置mapper和scope信息。\n最后，如果是服务器端的配置的话，还需要installation的一些信息。\n有了这些基本的配置之后，我们就可以准备接入应用程序了。\nSpringboot接入keycloak 引入依赖 \u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.keycloak\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;keycloak-spring-boot-starter\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;11.0.2\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r然后配置application.yml keycloak:\rauth-server-url: http://localhost:8080/auth\rrealm: wildfly\rpublic-client: true\rresource: product-app\rsecurityConstraints:\r- authRoles:\r# 以下路径需要user角色才能访问\r- user\rsecurityCollections:\r# name可以随便写\r- name: user-role-mappings\rpatterns:\r- /users/*\r至此就接入完成了，不需要编写任何代码。\n获取KeycloakSecurityContext 但是实际使用中，光能控制登陆权限还不够，业务代码中还需要能获取到当前角色，用户名等信息，这就需要用到KeycloakSecurityContext了。KeycloakSecurityContext是keycloak的上下文，我们可以从其中获取到AccessToken，IDToken，AuthorizationContext和realm信息。\nIdentity.java\nimport java.util.List;\rimport org.keycloak.AuthorizationContext;\rimport org.keycloak.KeycloakSecurityContext;\rimport org.keycloak.representations.idm.authorization.Permission;\r/**\r* \u0026lt;p\u0026gt;This is a simple facade to obtain information from authenticated users. You should see usages of instances of this class when\r* rendering the home page (@code home.ftl).\r*\r* \u0026lt;p\u0026gt;Instances of this class are are added to models as attributes in order to make them available to templates.\r*\r* @author \u0026lt;a href=\u0026quot;mailto:psilva@redhat.com\u0026quot;\u0026gt;Pedro Igor\u0026lt;/a\u0026gt;\r* @see com.github.your.demo.controller.HomeController\r*/\rpublic class Identity {\rprivate final KeycloakSecurityContext securityContext;\rpublic Identity(KeycloakSecurityContext securityContext) {\rthis.securityContext = securityContext;\r}\r/**\r* An example on how you can use the {@link org.keycloak.AuthorizationContext} to check for permissions granted by Keycloak for a particular user.\r*\r* @param name the name of the resource\r* @return true if user has was granted with a permission for the given resource. Otherwise, false.\r*/\rpublic boolean hasResourcePermission(String name) {\rreturn getAuthorizationContext().hasResourcePermission(name);\r}\r/**\r* An example on how you can use {@link KeycloakSecurityContext} to obtain information about user's identity.\r*\r* @return the user name\r*/\rpublic String getName() {\rreturn securityContext.getIdToken().getPreferredUsername();\r}\r/**\r* An example on how you can use the {@link org.keycloak.AuthorizationContext} to obtain all permissions granted for a particular user.\r*\r* @return\r*/\rpublic List\u0026lt;Permission\u0026gt; getPermissions() {\rreturn getAuthorizationContext().getPermissions();\r}\r/**\r* Returns a {@link AuthorizationContext} instance holding all permissions granted for an user. The instance is build based on\r* the permissions returned by Keycloak. For this particular application, we use the Entitlement API to obtain permissions for every single\r* resource on the server.\r*\r* @return\r*/\rprivate AuthorizationContext getAuthorizationContext() {\rreturn securityContext.getAuthorizationContext();\r}\r}\r使用\n@RestController\rpublic class HomeController {\rprivate Logger logger = LoggerFactory.getLogger(HomeController.class);\r@Autowired\rprivate JdbcTemplate jdbcTemplate;\r@Autowired\rprivate HttpServletRequest request;\r@RequestMapping(\u0026quot;/users\u0026quot;)\r@ResponseBody\rpublic List\u0026lt;Users\u0026gt; users() {\rlogIdentity();\rlogger.info(\u0026quot;使用JdbcTemplate查询数据库\u0026quot;);\rString sql = \u0026quot;SELECT * FROM users \u0026quot;;\rList\u0026lt;Users\u0026gt; queryAllList = jdbcTemplate.query(sql, new Object[]{},\rnew BeanPropertyRowMapper\u0026lt;\u0026gt;(Users.class));\rlogger.info(\u0026quot;查询用户列表\u0026quot; + queryAllList);\rreturn queryAllList;\r}\r@RequestMapping(\u0026quot;/\u0026quot;)\rpublic String home() {\rreturn \u0026quot;Hello Docker World\u0026quot;;\r}\rprivate void logIdentity() {\rKeycloakSecurityContext context=getKeycloakSecurityContext();\rif(context!=null){\rIdentity identity=new Identity(context);\rlogger.info(\u0026quot;KeycloakSecurityContext identity={}\u0026quot;,identity);\r}else{\rlogger.info(\u0026quot;KeycloakSecurityContext is null\u0026quot;);\r}\r}\rprivate KeycloakSecurityContext getKeycloakSecurityContext() {\rreturn (KeycloakSecurityContext) request.getAttribute(KeycloakSecurityContext.class.getName());\r}\r}\rIdentity类来自Keycloak的官方example。上面介绍的Spring Boot中的其实是隐藏的做法，adaptor自动为我们做了和Keycloak认证服务连接的事情，如果我们需要手动去处理，则需要用到Authorization Client Java API。\n添加maven依赖：\n\u0026lt;dependencies\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.keycloak\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;keycloak-authz-client\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;${KEYCLOAK_VERSION}\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;/dependencies\u0026gt;\r具体使用AuthzClient可查看官方文档。\nRest接口 有了这些配置，我们基本上就可以创建一个基于spring boot和keycloak的一个rest服务了。\n假如我们为keycloak的client创建了新的用户：alice。\n第一步我们需要拿到alice的access token，则可以这样操作：\nexport access_token=$(\\\rcurl -X POST http://localhost:8180/auth/realms/spring-boot-quickstart/protocol/openid-connect/token \\\r-H 'Authorization: Basic YXBwLWF1dGh6LXJlc3Qtc3ByaW5nYm9vdDpzZWNyZXQ=' \\\r-H 'content-type: application/x-www-form-urlencoded' \\\r-d 'username=alice\u0026amp;password=alice\u0026amp;grant_type=password' | jq --raw-output '.access_token' \\\r)\r这个命令是直接通过用户名密码的方式去keycloak服务器中拿取access_token,除了access_token，这个命令还会返回refresh_token和session state的信息。\n因为是直接和keycloak进行交换，所以keycloak的directAccessGrantsEnabled一定要设置为true。\n上面命令中的Authorization是什么值呢？\n这个值是为了防止未授权的client对keycloak服务器的非法访问，所以需要请求客户端提供client-id和对应的client-secret并且以下面的方式进行编码得到的：\nAuthorization: basic BASE64(client-id + ':' + client-secret)\raccess_token是JWT格式的，我们可以简单解密一下上面命令得出的token:\n{\ralg: \u0026quot;RS256\u0026quot;,\rtyp: \u0026quot;JWT\u0026quot;,\rkid: \u0026quot;FJ86GcF3jTbNLOco4NvZkUCIUmfYCqoqtOQeMfbhNlE\u0026quot;\r}.\r{\rexp: 1603614445,\riat: 1603614145,\rjti: \u0026quot;b69c784d-5b2d-46ad-9f8d-46214add7afb\u0026quot;,\riss: \u0026quot;http://localhost:8180/auth/realms/spring-boot-quickstart\u0026quot;,\rsub: \u0026quot;e6606d93-99f6-4829-ba99-1329be604159\u0026quot;,\rtyp: \u0026quot;Bearer\u0026quot;,\razp: \u0026quot;app-authz-springboot\u0026quot;,\rsession_state: \u0026quot;bdc33764-fd1a-400e-9fe0-90a82f4873c1\u0026quot;,\racr: \u0026quot;1\u0026quot;,\rallowed-origins: [\r\u0026quot;http://localhost:8080\u0026quot;\r],\rrealm_access: {\rroles: [\r\u0026quot;user\u0026quot;\r]\r},\rscope: \u0026quot;email profile\u0026quot;,\remail_verified: false,\rpreferred_username: \u0026quot;alice\u0026quot;\r}.\r[signature]\r有了access_token,我们就可以根据access_token去做很多事情了。\n比如：访问受限的资源：\ncurl http://localhost:8080/api/resourcea \\\r-H \u0026quot;Authorization: Bearer \u0026quot;$access_token\r这里的api/resourcea只是我们本地spring boot应用中一个非常简单的请求资源链接，一切的权限校验工作都会被keycloak拦截，我们看下这个api的实现：\n@RequestMapping(value = \u0026quot;/api/resourcea\u0026quot;, method = RequestMethod.GET)\rpublic String handleResourceA() {\rreturn createResponse();\r}\rprivate String createResponse() {\rreturn \u0026quot;Access Granted\u0026quot;;\r}\r可以看到这个只是一个简单的txt返回，但是因为有keycloak的加持，就变成了一个带权限的资源调用。\n上面的access_token解析过后，我们可以看到里面是没有包含权限信息的，我们可以使用access_token来交换一个特殊的RPT的token，这个token里面包含用户的权限信息：\ncurl -X POST \\\rhttp://localhost:8180/auth/realms/spring-boot-quickstart/protocol/openid-connect/token \\\r-H \u0026quot;Authorization: Bearer \u0026quot;$access_token \\\r--data \u0026quot;grant_type=urn:ietf:params:oauth:grant-type:uma-ticket\u0026quot; \\\r--data \u0026quot;audience=app-authz-rest-springboot\u0026quot; \\\r--data \u0026quot;permission=Default Resource\u0026quot; | jq --raw-output '.access_token'\r将得出的结果解密之后，看下里面的内容：\n{\ralg: \u0026quot;RS256\u0026quot;,\rtyp: \u0026quot;JWT\u0026quot;,\rkid: \u0026quot;FJ86GcF3jTbNLOco4NvZkUCIUmfYCqoqtOQeMfbhNlE\u0026quot;\r}.\r{\rexp: 1603614507,\riat: 1603614207,\rjti: \u0026quot;93e42d9b-4bc6-486a-a650-b912185c35db\u0026quot;,\riss: \u0026quot;http://localhost:8180/auth/realms/spring-boot-quickstart\u0026quot;,\raud: \u0026quot;app-authz-springboot\u0026quot;,\rsub: \u0026quot;e6606d93-99f6-4829-ba99-1329be604159\u0026quot;,\rtyp: \u0026quot;Bearer\u0026quot;,\razp: \u0026quot;app-authz-springboot\u0026quot;,\rsession_state: \u0026quot;bdc33764-fd1a-400e-9fe0-90a82f4873c1\u0026quot;,\racr: \u0026quot;1\u0026quot;,\rallowed-origins: [\r\u0026quot;http://localhost:8080\u0026quot;\r],\rrealm_access: {\rroles: [\r\u0026quot;user\u0026quot;\r]\r},\rauthorization: {\rpermissions: [\r{\rrsid: \u0026quot;e26d5d63-5976-4959-8683-94b7d85318e7\u0026quot;,\rrsname: \u0026quot;Default Resource\u0026quot;\r}\r]\r},\rscope: \u0026quot;email profile\u0026quot;,\remail_verified: false,\rpreferred_username: \u0026quot;alice\u0026quot;\r}.\r[signature]\r可以看到，这个RPT和之前的access_token的区别是这个里面包含了authorization信息。\n我们可以将这个RPT的token和之前的access_token一样使用。\nJetty+Jersey框架接入Keycloak 我们有一个老系统，用的embeded Jetty+Jersey，虽然官方提供了Jetty 9.x Adapters，但这是针对standalone而言的，现在几乎没人这么用了，所以还是得自己来。官方有Java Servlet Filter Adapter的教程，但是用的是web.xml的例子，而且语焉不详，所以这里就我自己的摸索提供一点参考。\nJetty整合Jersey框架 先来看一下Jetty+Jersey的原生例子，涉及两个文件 App.java\npackage xyz.chen;\rimport org.eclipse.jetty.server.Server;\rimport org.eclipse.jetty.servlet.ServletContextHandler;\rimport org.eclipse.jetty.servlet.ServletHolder;\rimport org.glassfish.jersey.servlet.ServletContainer;\rpublic class App {\rpublic static void main(String[] args) {\rServer server = new Server(9999);\rServletContextHandler context = new ServletContextHandler(ServletContextHandler.NO_SESSIONS);\rcontext.setContextPath(\u0026quot;/\u0026quot;);\rserver.setHandler(context);\r// 配置Servlet\rServletHolder holder = context.addServlet(ServletContainer.class.getCanonicalName(), \u0026quot;/rest/*\u0026quot;);\rholder.setInitOrder(1);\rholder.setInitParameter(\u0026quot;jersey.config.server.provider.packages\u0026quot;, \u0026quot;xyz.chen\u0026quot;);\rholder.setInitParameter(\u0026quot;jersey.config.server.provider.classnames\u0026quot;, \u0026quot;org.glassfish.jersey.server.filter.CsrfProtectionFilter\u0026quot;);\rtry {\rserver.start();\rserver.join();\r} catch (Exception e) {\re.printStackTrace();\r} finally {\rserver.destroy();\r}\r}\r}\r然后是业务类： HelloResource.java\npackage xyz.chen;\rimport javax.ws.rs.*;\rimport javax.ws.rs.core.MediaType;\rimport javax.ws.rs.core.MultivaluedMap;\rimport javax.ws.rs.core.PathSegment;\rimport javax.ws.rs.core.Response;\rimport java.util.HashMap;\rimport java.util.List;\rimport java.util.Map;\rimport java.util.Map.Entry;\r@Path(\u0026quot;hello\u0026quot;)\rpublic class HelloResource {\r@Path(\u0026quot;index\u0026quot;)\r@GET\r@Consumes(MediaType.TEXT_PLAIN)\r@Produces(MediaType.TEXT_PLAIN)\rpublic Response helloworld() {\rreturn Response.ok(\u0026quot;hello jersey\u0026quot;).build();\r}\r@GET\r@Path(\u0026quot;/user/{userName}\u0026quot;)\rpublic Response getThemeCss(@PathParam(\u0026quot;userName\u0026quot;) String userName) {\rStringBuilder sb = new StringBuilder(userName);\rreturn Response.ok(sb.toString()).build();\r}\r}\rpom.xml文件\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt;\r\u0026lt;project xmlns=\u0026quot;http://maven.apache.org/POM/4.0.0\u0026quot; xmlns:xsi=\u0026quot;http://www.w3.org/2001/XMLSchema-instance\u0026quot;\rxsi:schemaLocation=\u0026quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026quot;\u0026gt;\r\u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt;\r\u0026lt;groupId\u0026gt;org.example\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jersey-demo\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt;\r\u0026lt;name\u0026gt;Maven\u0026lt;/name\u0026gt;\r\u0026lt;url\u0026gt;http://maven.apache.org/\u0026lt;/url\u0026gt;\r\u0026lt;inceptionYear\u0026gt;2001\u0026lt;/inceptionYear\u0026gt;\r\u0026lt;properties\u0026gt;\r\u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt;\r\u0026lt;/properties\u0026gt;\r\u0026lt;dependencies\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.glassfish.jersey.core\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jersey-server\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.27\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.glassfish.jersey.inject\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jersey-hk2\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.27\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.glassfish.jersey.containers\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jersey-container-servlet-core\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.27\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.glassfish.jersey.containers\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jersey-container-jetty-http\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.27\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.eclipse.jetty\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jetty-server\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;9.4.12.v20180830\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.eclipse.jetty\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jetty-servlet\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;9.4.12.v20180830\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.eclipse.jetty\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jetty-util\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;9.4.12.v20180830\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;/dependencies\u0026gt;\r\u0026lt;build\u0026gt;\r\u0026lt;plugins\u0026gt;\r\u0026lt;plugin\u0026gt;\r\u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;maven-shade-plugin\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.4.3\u0026lt;/version\u0026gt;\r\u0026lt;configuration\u0026gt;\r\u0026lt;createDependencyReducedPom\u0026gt;true\u0026lt;/createDependencyReducedPom\u0026gt;\r\u0026lt;filters\u0026gt;\r\u0026lt;filter\u0026gt;\r\u0026lt;artifact\u0026gt;*:*\u0026lt;/artifact\u0026gt;\r\u0026lt;excludes\u0026gt;\r\u0026lt;exclude\u0026gt;META-INF/*.SF\u0026lt;/exclude\u0026gt;\r\u0026lt;exclude\u0026gt;META-INF/*.DSA\u0026lt;/exclude\u0026gt;\r\u0026lt;exclude\u0026gt;META-INF/*.RSA\u0026lt;/exclude\u0026gt;\r\u0026lt;/excludes\u0026gt;\r\u0026lt;/filter\u0026gt;\r\u0026lt;/filters\u0026gt;\r\u0026lt;/configuration\u0026gt;\r\u0026lt;executions\u0026gt;\r\u0026lt;execution\u0026gt;\r\u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt;\r\u0026lt;goals\u0026gt;\r\u0026lt;goal\u0026gt;shade\u0026lt;/goal\u0026gt;\r\u0026lt;/goals\u0026gt;\r\u0026lt;configuration\u0026gt;\r\u0026lt;transformers\u0026gt;\r\u0026lt;transformer\rimplementation=\u0026quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer\u0026quot; /\u0026gt;\r\u0026lt;transformer\rimplementation=\u0026quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\u0026quot;\u0026gt;\r\u0026lt;manifestEntries\u0026gt;\r\u0026lt;Main-Class\u0026gt;xyz.chen.App\u0026lt;/Main-Class\u0026gt;\r\u0026lt;/manifestEntries\u0026gt;\r\u0026lt;/transformer\u0026gt;\r\u0026lt;/transformers\u0026gt;\r\u0026lt;/configuration\u0026gt;\r\u0026lt;/execution\u0026gt;\r\u0026lt;/executions\u0026gt;\r\u0026lt;/plugin\u0026gt;\r\u0026lt;/plugins\u0026gt;\r\u0026lt;/build\u0026gt;\r\u0026lt;/project\u0026gt;\r运行就不再举例了。\n整合keycloak 引入依赖\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.keycloak\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;keycloak-servlet-filter-adapter\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;11.0.2\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r修改App类，加入Filter\nServletHandler handler = new ServletHandler();\rFilterHolder fh=handler.addFilterWithMapping(org.keycloak.adapters.servlet.KeycloakOIDCFilter.class,\u0026quot;/*\u0026quot;, EnumSet.of(DispatcherType.REQUEST));\rfh.setInitParameter(\u0026quot;keycloak.config.file\u0026quot;, \u0026quot;keycloak.json\u0026quot;);\rcontext.addFilter(fh, \u0026quot;/*\u0026quot;, EnumSet.of(DispatcherType.REQUEST));\rserver.setHandler(context);\r其中，keycloak.json文件来自keycloak-clients-installtion，形如\n{\r\u0026quot;realm\u0026quot;: \u0026quot;wildfly\u0026quot;,\r\u0026quot;auth-server-url\u0026quot;: \u0026quot;http://localhost:8080/auth/\u0026quot;,\r\u0026quot;ssl-required\u0026quot;: \u0026quot;external\u0026quot;,\r\u0026quot;resource\u0026quot;: \u0026quot;product-app\u0026quot;,\r\u0026quot;public-client\u0026quot;: true,\r\u0026quot;confidential-port\u0026quot;: 0\r}\rkeycloak的配置不再赘述。\n获取用户权限信息 这块不再举例，自己写个Filter去KeycloakSecurityContext里拿就可以了。\n其它问题 1.如何用代码完成在KeyCloak注册和配置过程，实现自动化配置？ KeyCloark有restApi，也有命令行工具。下面是简单暴力的做法，使用命令行\n#添加管理员用户\r.../bin/add-user-keycloak.sh -r master -u \u0026lt;username\u0026gt; -p \u0026lt;password\u0026gt;\r$ kcadm.sh config credentials --server http://localhost:8080/auth --realm master --user admin $ kcadm.sh create realms -s realm=demorealm -s enabled=true -o\r$ CID=$(kcadm.sh create clients -r demorealm -s clientId=my_client -s 'redirectUris=[\u0026quot;http://localhost:8980/myapp/*\u0026quot;]' -i)\r$ kcadm.sh get clients/$CID/installation/providers/keycloak-oidc-keycloak-json\r如下所示，使用windows举例\nPS G:\\keycloak11\\bin\u0026gt; .\\kcadm config credentials --server http://localhost:8080/auth --realm master --user admin Logging into http://localhost:8080/auth as user admin of realm master\rEnter password: admin\rPS G:\\keycloak11\\bin\u0026gt; .\\kcadm create realms -s realm=demorealm -s enabled=true -o\rPS G:\\keycloak11\\bin\u0026gt; .\\kcadm create clients -r demorealm -s clientId=my_client -s 'redirectUris=[\\\u0026quot;http://localhost:8980/myapp/*\\\u0026quot;]' -i \u0026gt; clientid.txt\rPS G:\\keycloak11\\bin\u0026gt; set /p CID=\u0026lt;clientid.txt\rPS G:\\keycloak11\\bin\u0026gt; .\\kcadm get http://localhost:8080/auth/admin/realms/demorealm/clients/8aba2b1f-4587-43ba-8f51-d2e75db5f65d/installation/providers/keycloak-oidc-keycloak-json\r{\r\u0026quot;realm\u0026quot; : \u0026quot;demorealm\u0026quot;,\r\u0026quot;auth-server-url\u0026quot; : \u0026quot;http://localhost:8080/auth/\u0026quot;,\r\u0026quot;ssl-required\u0026quot; : \u0026quot;external\u0026quot;,\r\u0026quot;resource\u0026quot; : \u0026quot;my_client\u0026quot;,\r\u0026quot;credentials\u0026quot; : {\r\u0026quot;secret\u0026quot; : \u0026quot;54b8027b-6d7f-4e2b-9b6a-5c1e85b685fa\u0026quot;\r},\r\u0026quot;confidential-port\u0026quot; : 0\r}\rPS G:\\keycloak11\\bin\u0026gt;\r基本操作：\n$ kcadm.sh create ENDPOINT [ARGUMENTS]\r$ kcadm.sh get ENDPOINT [ARGUMENTS]\r$ kcadm.sh update ENDPOINT [ARGUMENTS]\r$ kcadm.sh delete ENDPOINT [ARGUMENTS]\rENDPOINT is a target resource URI and can either be absolute (starting with http: or https:) or relative, used to compose an absolute URL of the following format:\nSERVER_URI/admin/realms/REALM/ENDPOINT\rFor example, if you authenticate against the server http://localhost:8080/auth and realm is master, then using users as ENDPOINT results in the resource URL http://localhost:8080/auth/admin/realms/master/users.\nIf you set ENDPOINT to clients, the effective resource URI would be http://localhost:8080/auth/admin/realms/master/clients.\n角色和用户的管理等也能用kcadm命令来完成。\n2.如何退出 HttpServletRequest.logout()\r3.更暴力的接入方式KeyCloak Proxy（已停止维护） 把KeyCloak作为一个proxy来使用，免去修改现有代码。\nhttps://hub.docker.com/r/jboss/keycloak-proxy/ 这里有简单的使用方式说明。这种方式只能代理一个client。\nThis image is deprecated as the Java based Proxy will be replaced by a new Go based implementation soon.\nkeycloak-proxy在2018年已停止维护，用Golang实现的继任者louketo-proxy也已在2020年停止更新维护。\n官方文档已不推荐使用这种方式，相关文档已移除。\nouketo-proxy停止更新和维护，官网说明：https://www.keycloak.org/2020/08/sunsetting-louketo-project.adoc\n官网提供的一种类似替代方案：https://github.com/oauth2-proxy/oauth2-proxy （Golang实现，未验证）\n参考 https://www.keycloak.org/docs/latest/securing_apps/#_jetty9_adapter\nhttps://stackoverflow.com/questions/22188285/does-embedded-jetty-have-the-ability-to-set-the-init-params-of-a-filter\n","date":"2021-04-07","permalink":"http://localhost:1313/post/keycloak%E6%8E%A5%E5%85%A5%E8%87%AA%E7%A0%94%E7%B3%BB%E7%BB%9F/","tags":["Java"],"title":"Keycloak接入自研系统"},{"content":"Centos8安装Superset。Superset 是 Airbnb （知名在线房屋短租公司）开源的数据探查与可视化平台（曾用名 Panoramix、Caravel ），也就是BI，该工具在可视化、易用性和交互性上非常有特色。\n不建议使用python3.8以下版本。低版本建议使用docker-composer或者helm安装。当然，想要低版本Python安装也不是不可以，其实也就一个conda create 的操作而已。我在Centos7+Python 2.7.5 环境下也安装成功。 我是新环境，直接升级就好。\n初始化，升级到python 3.8（非必须） wget https://www.python.org/ftp/python/3.8.1/Python-3.8.1.tgz\ryum install gcc gcc-c++ libffi-devel\rtar -xvf Python-3.8.1.tgz\rcd Python-3.8.1\r./configure --prefix=/usr/local/python3\rmake \u0026amp;\u0026amp; make install\rrm -f /usr/bin/python\rrm -f /usr/bin/pip\rln -s /usr/local/python3/bin/python3 /usr/bin/python\rln -s /usr/local/python3/bin/python3 /usr/bin/python\rpython -V\r安装miniconda wget -c https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\rchmod 777 Miniconda3-latest-Linux-x86_64.sh\rbash Miniconda3-latest-Linux-x86_64.sh\r一步一步来，最后把conda的路径加入环境变量。\nconda list #验证安装是否成功\rconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/\rconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/\rconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/\rconda config --add channels conda create -n superset python=3.8\rconda config --get channels\r使用conda安装SuperSet 最后进入安装superset环节。创建虚拟环境，这也是低版本python安装高版本python软件的关键。为什么不直接用pip，还是考虑到python版本比较混乱的问题。为什么不用virtualenv，主要是conda能安装一些依赖，减少手动操作。最新版的superset应该是不需要这么麻烦，pip一路到底就可以，不过我还是参考了老的安装教程。有闲的可以直接看官方教程，更简单。\nconda create -n superset python=3.8\ractivate superset\rpip install apache-superset\r要退出conda创建的虚拟环节可以用conda deactivate指令。\n查看和切换虚拟环境\nconda info --envs\rconda env list\rconda activate base\r如果pip太慢，可以加入国内源\n#新建配置文件\rtouch ~/.pip/pip.conf\r#加入如下配置\r[global]\rindex-url = https://pypi.tuna.tsinghua.edu.cn/simple\r[install]\rtrusted-host = https://pypi.tuna.tsinghua.edu.cn\r如果出现了类似的报错\ngcc: error trying to exec 'cc1plus': execvp: No such file or directory\rerror: command 'gcc' failed with exit status 1\r----------------------------------------\rERROR: Failed building wheel for python-geohash\r是因为缺少了 gcc-c++，安装即可。这就是第一步里面的初始化所做的。\n配置和启动 如果顺利的话，superset应该是安装成功了。接下来就是官方文档里的初始化操作了。\nsuperset db upgrade\r# Create an admin user (you will be prompted to set a username, first and last name before setting a password)\r$ export FLASK_APP=superset\rsuperset fab create-admin\r# Load some data to play with\rsuperset load_examples\r# Create default roles and permissions\rsuperset init\r# To start a development web server on port 8088, use -p to bind to another port\rsuperset run -p 8088 --with-threads --reload --debugger\r在superset load_examples这一步，可能会卡很久然后失败，原因是example数据是存放在github的，然而某些人没有妈，所以就不能访问了。可以直接中止就好了。或者从github上手动下载回来（压缩包大约28M），然后手动导入（需要起一个HTTP服务，修改Superset源码superset/examples/helpers.py替换BASE_URL，比较麻烦）。\n另外superset默认只绑定localhost，想要外网可访问，可以绑定一个主机。\n#hosts文件里添加一条映射\r0.0.0.0 ten\r#绑定ten\rsuperset run -h ten -p 8080 --with-threads --reload\r#这样直接绑定IP地址是会报错的\rsuperset run -h 110.6.7.8 -p 8080 --with-threads --reload\r这操作也有点诡异了些。。\n2021-04-13更新\n导入样例 前面说过，在superset load_examples这一步会失败，原因是example数据是存放在github的，这个网站被司马佬吃了。这个路径配置在examples/helpers.py里的BASE_URL项。\n#github上下载examples压缩包\rwget https://github.com/apache-superset/examples-data/archive/refs/heads/master.zip\r#解压，启动本地server\runzip master.zip\rpython -m SimpleHTTPServer 18089\r#PYTHONPATH处理\rcp /root/miniconda2/envs/superset/lib/python3.8/site-packages/superset/examples/ /root/py/examples\r#修改helpers.py\rBASE_URL = \u0026quot;http://10.180.210.146:18089/\u0026quot;\r#导入\rsuperset load_examples\r成功的话，输出应该如下：\nLoaded your LOCAL configuration at [/root/py/superset_config.py]\rLoaded your LOCAL configuration at [/root/py/superset_config.py]\rlogging was configured successfully\rINFO:superset.utils.logging_configurator:logging was configured successfully\r/root/miniconda2/envs/superset/lib/python3.8/site-packages/flask_caching/__init__.py:201: UserWarning: Flask-Caching: CACHE_TYPE is set to null, caching is effectively disabled.\rwarnings.warn(\rNo PIL installation found\rINFO:superset.utils.screenshots:No PIL installation found\rLoading examples metadata and related data into examples\rCreating default CSS templates\rLoading energy related dataset\rCreating table [wb_health_population] reference\rLoading [World Bank's Health Nutrition and Population Stats]\rCreating table [wb_health_population] reference\rCreating a World's Health Bank dashboard\rLoading [Birth names]\rDone loading table!\r--------------------------------------------------------------------------------\rCreating table [birth_names] reference\rCreating some slices\rCreating a dashboard\rLoading [Random time series data]\rDone loading table!\r--------------------------------------------------------------------------------\rCreating table [random_time_series] reference\rCreating a slice\rLoading [Random long/lat data]\rDone loading table!\r--------------------------------------------------------------------------------\rCreating table reference\rCreating a slice\rLoading [Country Map data]\rDone loading table!\r--------------------------------------------------------------------------------\rCreating table reference\rCreating a slice\rLoading [Multiformat time series]\rDone loading table!\r--------------------------------------------------------------------------------\rCreating table [multiformat_time_series] reference\rCreating Heatmap charts\rLoading [Paris GeoJson]\rCreating table paris_iris_mapping reference\r...\r自定义配置及汉化 编辑配置文件后重启即可\nvim /root/miniconda2/envs/superset/lib/python3.8/site-packages/superset/config.py\r# Setup default language\rBABEL_DEFAULT_LOCALE = \u0026quot;zh\u0026quot;\r这样直接修改配置文件很麻烦（路径太深），可以把自定义配置文件放到指定位置：\nTo configure your application, you need to create a file superset_config.py and add it to your PYTHONPATH.\nAll the parameters and default values defined in https://github.com/apache/superset/blob/master/superset/config.py can be altered in your local superset_config.py.\nAPI文档 API 文档地址：http://10.180.210.146:18088/swagger/v1\n虽然SuperSet支持Oauth，但由于SuperSet用的是FlaskAB框架（不是Flask框架），支持比较弱，需要自己写python代码。如果是外部系统对接Superset，只能用cookie登陆的方式调用。\n","date":"2021-04-02","permalink":"http://localhost:1313/post/superset%E5%AE%89%E8%A3%85/","tags":["大数据"],"title":"SuperSet安装配置"},{"content":"安装依赖 yum list | grep google-authenticator\ryum install google-authenticator\ryum install qrencode\r配置Google Authenticator 安装完直接跑下面的命令进行配置，注意只在当前用户生效\n\u0026gt; google-authenticator\r之后会需要确认几点信息\nDo you want authentication tokens to be time-based (y/n) y\r是否配置基于时间的动态密钥，选择y，之后会出现超级大一个二维码，下面还会有一些小字,这里的key就是用于配置手机端app的，我们先保存下来，不用慌，因为这个key随时都可以查得到.\nDo you want me to update your \u0026quot;/root/.google_authenticator\u0026quot; file? (y/n) y\r是否将配置信息更新到自己家目录，选择y进行更新，这个文件里面就保存着上面的key信息，以防后续还有新的手机设备需要用到key\nDo you want to disallow multiple uses of the same authentication\rtoken? This restricts you to one login about every 30s, but it increases\ryour chances to notice or even prevent man-in-the-middle attacks (y/n) y\r是否禁止同一密钥在30秒内被多次使用，如果想要更安全就选择y，如果想要更方便就选择n\nBy default, a new token is generated every 30 seconds by the mobile app.\rIn order to compensate for possible time-skew between the client and the server,\rwe allow an extra token before and after the current time. This allows for a\rtime skew of up to 30 seconds between authentication server and client. If you\rexperience problems with poor time synchronization, you can increase the window\rfrom its default size of 3 permitted codes (one previous code, the current\rcode, the next code) to 17 permitted codes (the 8 previous codes, the current\rcode, and the 8 next codes). This will permit for a time skew of up to 4 minutes\rbetween client and server.\rDo you want to do so? (y/n) n\r是否允许前8次和后8次的动态密钥也有效，如果客户端和手机端都是基于网络的时间同步，选择n提高安全性\nIf the computer that you are logging into isn't hardened against brute-force\rlogin attempts, you can enable rate-limiting for the authentication module.\rBy default, this limits attackers to no more than 3 login attempts every 30s.\rDo you want to enable rate-limiting? (y/n) y\r是否限制30秒内最多3次尝试，为了防止恶意试错，选择y 这样服务端的Google Authenticator就配置完毕。下面做一些系统设置，使上面的配置用作ssh。\n配置pam vim /etc/pam.d/sshd\rauth required pam_google_authenticator.so nullok\rvim /etc/ssh/sshd_config\rUsePAM yes\rPasswordAuthentication no\rChallengeResponseAuthentication yes\rsshd -t\rsystemctl restart sshd\r需要注意的是必须设置PasswordAuthentication no（禁用密码登陆，但是并非必须使用公钥），否则二次验证无法使用，会报如下错误：\nsshd[2690384]: fatal: PAM: pam_setcred(): Permission denied\r手机设置 推荐使用 andotp 这个APP，扫码添加即可。\n如果换了手机也很容易，登录到服务器，找到~/.google_authenticator文件，里面会有之前保存的key，重新在新手机进行添加即可。\nXshell登录验证 下面还是正常ssh登陆服务器，不过输入完用户名以后只能选择交互键盘，依次输入密码和OTP验证码即可。关于登录的一些报错都在/var/log/secure这个日志文件中，不管是什么场景登陆失败都可以先查看下失败日志，对症下药。\n注意保持时间同步。 直接使用ntpdate即可，国内可以使用国家授时中心的地址\nntpdate -u 210.72.145.44\r基本上服务器和手机都是用的网络时间就不太会有时间同步的问题。\nrefer:https://blog.csdn.net/Victor2code/\u0026hellip;\n","date":"2020-12-29","permalink":"http://localhost:1313/post/centos%E9%85%8D%E7%BD%AEgoogleauthenticator%E5%8A%A8%E6%80%81%E5%AF%86%E9%92%A5%E8%BF%9B%E8%A1%8Cssh%E4%BA%8C%E6%AC%A1%E9%AA%8C%E8%AF%81/","tags":["Linux"],"title":"Centos配置GoogleAuthenticator动态密钥进行ssh二次验证"},{"content":"TUI ConsoleLauncher basically transforms your Android into a terminal window, requiring you to type out commands to start apps and explore your phone\u0026rsquo;s system as opposed to the familiar process of tapping on icons. It\u0026rsquo;s a great way to practice or learn about Linux commands, and it has the added benefit of securing your phone against unwanted access.\n常用命令：\n-- 不允许别人用exit命令退出\ralias add exit=echo \u0026quot;No\u0026quot;\r-- 定制化界面，取消不必要元素\rconfig -set show_session_info false\rconfig -set show_storage_info false\rconfig -set show_device_name false\rconfig -set show_ram false\rconfig -set show_network_info false\r-- 优化\rconfig -set time_size 20 --调大时间字体\rconfig -set system_wallpaper true --显示系统壁纸\rconfig -set fullscreen true\rconfig -set enable_music true\r-- 记日志/备忘录\rnote -add 明早九点加班\r修改配置后需要restart才能生效。\n结合shellcommand等，还可以自定义出各种小工具。\n","date":"2020-12-25","permalink":"http://localhost:1313/post/tui-consolelauncher-%E5%8F%AF%E5%AE%9A%E5%88%B6%E5%8C%96geek%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%A1%8C%E9%9D%A2%E5%90%AF%E5%8A%A8%E5%99%A8/","tags":["闲扯淡"],"title":"TUI ConsoleLauncher 可定制化geek命令行桌面启动器"},{"content":"Ambari里主机，集群，用户等等都视为一种资源，对它们的增删改查就是对资源的增删改查。\n了解实现Ambari里增加一个资源的流程，就更方便修改Ambari的实现。\n1.新建控制器层 ambari的控制器层在service包里\npackage org.apache.ambari.server.api.services.dataspace;\rimport io.swagger.annotations.Api;\rimport org.apache.ambari.server.api.resources.ResourceInstance;\rimport org.apache.ambari.server.api.services.BaseService;\rimport org.apache.ambari.server.api.services.Request;\rimport org.apache.ambari.server.controller.spi.Resource;\rimport javax.ws.rs.GET;\rimport javax.ws.rs.Path;\rimport javax.ws.rs.Produces;\rimport javax.ws.rs.core.Context;\rimport javax.ws.rs.core.HttpHeaders;\rimport javax.ws.rs.core.Response;\rimport javax.ws.rs.core.UriInfo;\rimport java.util.Collections;\r@Path(\u0026quot;/hdfs/\u0026quot;)\r@Api(value = \u0026quot;Hdfss\u0026quot;, description = \u0026quot;Endpoint for user specific operations\u0026quot;)\rpublic class HdfsService extends BaseService {\r@GET//查询全部\r@Produces(\u0026quot;text/plain\u0026quot;)\rpublic Response getHdfses(String body, @Context HttpHeaders headers, @Context UriInfo ui) {\rreturn handleRequest(headers, body, ui, Request.Type.GET, createHdfsResource(null));\r}\r@GET\r@Path(\u0026quot;{path}\u0026quot;)//查询单个\r@Produces(\u0026quot;text/plain\u0026quot;)\rpublic Response getHdfs(String body, @Context HttpHeaders headers, @Context UriInfo ui) {\rreturn handleRequest(headers, body, ui, Request.Type.GET, createHdfsResource(path));\r}\rprivate ResourceInstance createHdfsResource(String path) {\rreturn createResource(Resource.Type.Hdfs,\rCollections.singletonMap(Resource.Type.Hdfs, path));\r}\r}\r继承BaseService。这里定义访问路径和参数。serivice的方法参数上是看不出VO的类型的。复杂的控制器，可以在一个service里调用另外一个service.\n访问参数可以封装成对象，需要新建一个XXXRequest对象，比如\npackage org.apache.ambari.server.controller;\rpublic class HdfsRequest {\rprivate Integer id;\rprivate String path;\rprivate Integer size;\r//getter,setter略\r}\r这里的xxxRequest是不会像springboot一样自动封装成对象的。\n2.继承ResourceProvide，实现具体的handleRequest方法 package org.apache.ambari.server.controller.internal;\rimport com.google.common.collect.ImmutableMap;\rimport com.google.common.collect.Sets;\rimport org.apache.ambari.server.controller.AmbariManagementController;\rimport org.apache.ambari.server.controller.HdfsRequest;\rimport org.apache.ambari.server.controller.spi.Predicate;\rimport org.apache.ambari.server.controller.spi.Request;\rimport org.apache.ambari.server.controller.spi.Resource;\rimport org.slf4j.Logger;\rimport org.slf4j.LoggerFactory;\rimport java.util.HashSet;\rimport java.util.Map;\rimport java.util.Set;\rpublic class HdfsResourceProvider extends AbstractControllerResourceProvider{\rprivate static final Logger LOG = LoggerFactory.getLogger(HdfsResourceProvider.class);\rpublic static final String HDFS_RESOURCE_CATEGORY=\u0026quot;Hdfses\u0026quot;;\rpublic static final String HDFS_ID_PROPERTY_ID =\u0026quot;hdfs_id\u0026quot;;\rpublic static final String HDFS_PATH_PROPERTY_ID =\u0026quot;hdfs_path\u0026quot;;\rpublic static final String HDFS_SIZE_PROPERTY_ID =\u0026quot;hdfs_size\u0026quot;;\rpublic static final String HDFS_RESOURCE_HDFS_ID_PROPERTY_ID =HDFS_RESOURCE_CATEGORY+\u0026quot;/\u0026quot;+HDFS_ID_PROPERTY_ID;\rpublic static final String HDFS_RESOURCE_HDFS_PATH_PROPERTY_ID =HDFS_RESOURCE_CATEGORY+\u0026quot;/\u0026quot;+HDFS_PATH_PROPERTY_ID;\rpublic static final String HDFS_RESOURCE_HDFS_SIZE_PROPERTY_ID =HDFS_RESOURCE_CATEGORY+\u0026quot;/\u0026quot;+HDFS_SIZE_PROPERTY_ID;\rprivate static Map\u0026lt;Resource.Type, String\u0026gt; keyPropertyIds = ImmutableMap.\u0026lt;Resource.Type, String\u0026gt;builder()\r.put(Resource.Type.Hdfs, HDFS_RESOURCE_HDFS_ID_PROPERTY_ID)\r.build();\rprivate static Set\u0026lt;String\u0026gt; propertyIds = Sets.newHashSet(\rHDFS_RESOURCE_HDFS_ID_PROPERTY_ID,\rHDFS_RESOURCE_HDFS_PATH_PROPERTY_ID,\rHDFS_RESOURCE_HDFS_SIZE_PROPERTY_ID\r);\rpublic static void init(){\r//注入操作在此\r}\rHdfsResourceProvider(AmbariManagementController managementController) {\rsuper(Resource.Type.Hdfs, propertyIds, keyPropertyIds, managementController);\r}\r@Override\rprotected Set\u0026lt;Resource\u0026gt; getResourcesAuthorized(Request request, Predicate predicate){\rSet\u0026lt;String\u0026gt; hdfsIds=getRequestPropertyIds(request,predicate);\rSet\u0026lt;Resource\u0026gt; resources=new HashSet\u0026lt;\u0026gt;();\r//查询数据库略\rfor(int i=0;i\u0026lt;3;i++){\rResourceImpl resource=new ResourceImpl(Resource.Type.Hdfs);\rsetResourceProperty(resource,HDFS_RESOURCE_HDFS_ID_PROPERTY_ID,i,hdfsIds);\rsetResourceProperty(resource,HDFS_RESOURCE_HDFS_PATH_PROPERTY_ID,\u0026quot;path\u0026quot;+i,hdfsIds);\rsetResourceProperty(resource,HDFS_RESOURCE_HDFS_SIZE_PROPERTY_ID,i*100,hdfsIds);\rresources.add(resource);\r}\rreturn resources;\r}\rprivate HdfsRequest getRequest(Map\u0026lt;String,Object\u0026gt; properties){\rif(properties==null){\rreturn new HdfsRequest();\r}\rHdfsRequest hdfsRequest=new HdfsRequest();\rif(properties.get(\u0026quot;HDFS_RESOURCE_HDFS_ID_PROPERTY_ID\u0026quot;)!=null){\rhdfsRequest.setId(Integer.parseInt(properties.get(\u0026quot;HDFS_RESOURCE_HDFS_ID_PROPERTY_ID\u0026quot;).toString()));\r}\rif(properties.get(\u0026quot;HDFS_RESOURCE_HDFS_SIZE_PROPERTY_ID\u0026quot;)!=null){\rhdfsRequest.setSize(Integer.parseInt(properties.get(\u0026quot;HDFS_RESOURCE_HDFS_SIZE_PROPERTY_ID\u0026quot;).toString()));\r}\rhdfsRequest.setPath(properties.get(\u0026quot;HDFS_RESOURCE_HDFS_ID_PROPERTY_ID\u0026quot;).toString());\rreturn hdfsRequest;\r}\r@Override\rpublic RequestStatus updateResources(Request request, Predicate predicate){\r//更新操作略\rreturn getRequestStatus(null);\r}\r@Override\rprotected Set\u0026lt;String\u0026gt; getPKPropertyIds() {\rreturn new HashSet\u0026lt;\u0026gt;(keyPropertyIds.values());\r}\r}\r这里面定义了各种参数字段和参数完整性校验，对应前端传值，实现CRUD逻辑，调用dao等。ResourceProvider和Request类的作用有交叉。\ngetRequest()用于从request Map里获取字符串参数组装成对象。\n同时需要在AbstractControllerResourceProvider里增加一条记录\ncase AlertTarget:\rreturn resourceProviderFactory.getAlertTargetResourceProvider();\rcase ViewInstance:\rreturn resourceProviderFactory.getViewInstanceResourceProvider();\rcase Hdfs:\rreturn new HdfsResourceProvider(managementController);\rdefault: throw new IllegalArgumentException(\u0026quot;Unknown type \u0026quot; + type);\r3.实现ResourceDefinition package org.apache.ambari.server.api.resources;\rimport org.apache.ambari.server.controller.spi.Resource;\rimport java.util.HashSet;\rimport java.util.Set;\rpublic class HdfsResourceDefinition extends BaseResourceDefinition {\r{\r}\r/**\r* Constructor.\r*\r* @param resourceType resource type\r*/\rpublic HdfsResourceDefinition() {\rsuper(Resource.Type.Hdfs);\r}\r/**\r* Obtain the plural name of the resource.\r*\r* @return the plural name of the resource\r*/\r@Override\rpublic String getPluralName() {\rreturn \u0026quot;hdfses\u0026quot;;\r}\r/**\r* Obtain the singular name of the resource.\r*\r* @return the singular name of the resource\r*/\r@Override\rpublic String getSingularName() {\rreturn \u0026quot;hdfs\u0026quot;;\r}\r@Override\rpublic Set\u0026lt;SubResourceDefinition\u0026gt; getSubResourceDefinitions() {\rfinal Set\u0026lt;SubResourceDefinition\u0026gt; subResourceDefinitions = new HashSet\u0026lt;\u0026gt;();\rsubResourceDefinitions.add(new SubResourceDefinition(Resource.Type.Hdfs));\rreturn subResourceDefinitions;\r}\r}\r这里跟权限应该就有了关系。\n修改ResourceInstanceFactoryImpl，加入自己定义的新类型\ncase RemoteCluster:\rresourceDefinition = new RemoteClusterResourceDefinition();\rbreak;\rcase Hdfs:\rresourceDefinition = new HdfsResourceDefinition();\rbreak;\rdefault:\rthrow new IllegalArgumentException(\u0026quot;Unsupported resource type: \u0026quot; + type);\r}\rspi包下Resource接口新增一个枚举\npackage org.apache.ambari.server.controller.spi;\rpublic interface Resource {\renum InternalType {\rCluster,\rService,\rSetting,\r4.数据库相关 orm包下添加对应的实体类和Dao实现，resource/META-INF下需要手动添加实体类对象全名，比如\n\u0026lt;persistence-unit name=\u0026quot;ambari-server\u0026quot; transaction-type=\u0026quot;RESOURCE_LOCAL\u0026quot;\u0026gt;\r\u0026lt;provider\u0026gt;org.eclipse.persistence.jpa.PersistenceProvider\u0026lt;/provider\u0026gt;\r\u0026lt;class\u0026gt;org.apache.ambari.server.orm.entities.AlertCurrentEntity\u0026lt;/class\u0026gt;\r\u0026lt;class\u0026gt;org.apache.ambari.server.orm.entities.AlertDefinitionEntity\u0026lt;/class\u0026gt;\r\u0026lt;/persistence-unit\u0026gt; entity举例：\npackage org.apache.ambari.server.orm.entities;\rimport javax.persistence.*;\r@Entity\r@Table(name = \u0026quot;admin_cluster_host\u0026quot;)\rpublic class AdminClusterHostEntity {\r@Id\r@GeneratedValue(strategy = GenerationType.AUTO)\r@Column(name = \u0026quot;id\u0026quot;, nullable = false, updatable = false)\rprivate Integer id;\r@Column(name = \u0026quot;host\u0026quot;, length = 255)\rprivate String host;\r@Column(name = \u0026quot;cluster\u0026quot;, length = 255)\rprivate String cluster;\rpublic Integer getId() {\rreturn id;\r}\rpublic void setId(Integer id) {\rthis.id = id;\r}\rpublic String getHost() {\rreturn host;\r}\rpublic void setHost(String host) {\rthis.host = host;\r}\rpublic String getCluster() {\rreturn cluster;\r}\rpublic void setCluster(String cluster) {\rthis.cluster = cluster;\r}\r}\rdao举例\npackage org.apache.ambari.server.orm.dao;\rimport com.google.inject.Inject;\rimport com.google.inject.Provider;\rimport com.google.inject.Singleton;\rimport org.apache.ambari.server.orm.RequiresSession;\rimport org.apache.ambari.server.orm.entities.AdminClusterHostEntity;\rimport org.apache.ambari.server.orm.entities.AlertHistoryEntity;\rimport javax.persistence.EntityManager;\rimport javax.persistence.NoResultException;\rimport javax.persistence.TypedQuery;\rimport java.util.Collections;\rimport java.util.List;\r@Singleton\rpublic class AdminClusterDAO {\r@Inject\rprivate Provider\u0026lt;EntityManager\u0026gt; m_entityManagerProvider;\r@RequiresSession\rpublic List\u0026lt;AdminClusterHostEntity\u0026gt; findAll() {\rTypedQuery\u0026lt;AdminClusterHostEntity\u0026gt; query = m_entityManagerProvider.get().createQuery(\r\u0026quot;SELECT ac FROM AdminClusterHostEntity ac\u0026quot;, AdminClusterHostEntity.class);\rtry {\rreturn query.getResultList();\r} catch (NoResultException e) {\rreturn Collections.emptyList();\r}\r}\r}\r5.注入相关 AmbariServer类里也需要相应注入类依赖的对象，一种方式是手动注入，例如：\nermissionResourceProvider.init(injector.getInstance(PermissionDAO.class));\rViewPermissionResourceProvider.init(injector.getInstance(PermissionDAO.class));\rPrivilegeResourceProvider.init(injector.getInstance(PrivilegeDAO.class), injector.getInstance(UserDAO.class),\rinjector.getInstance(GroupDAO.class), injector.getInstance(PrincipalDAO.class),\rinjector.getInstance(PermissionDAO.class), injector.getInstance(ResourceDAO.class));\r还有一种方式是注解注入，参考org.apache.ambari.server.controller.ControllerModule\nAmbari注入这块比较迷，比如dao里用到的m_entityManagerProvider对象就不需要手动注入，在它原有的类里使用新加的dao也不需要手动注入。但是有些自己写的ResourceProvider里就需要注入。\n6.postman模拟验证 请求\ncurl --location --request GET 'http://10.180.210.146:8080/api/v1/hdfs?fields=Hdfses/*' \\\r--header 'Content-Typ: application/x-www-form-urlencoded; charset=UTF-8' \\\r--header 'Cookie: AMBARISESSIONID=node0qm8s4v2muk61199wsf0jqgmg1.node0' \\\r--header 'X-Requested-By: X-Requested-By' \\\r--data-raw ''\r返回\n{\r\u0026quot;href\u0026quot; : \u0026quot;http://10.180.210.146:8080/api/v1/hdfs?fields=Hdfses/*\u0026quot;,\r\u0026quot;items\u0026quot; : [\r{\r\u0026quot;href\u0026quot; : \u0026quot;http://10.180.210.146:8080/api/v1/hdfs/0\u0026quot;,\r\u0026quot;Hdfses\u0026quot; : {\r\u0026quot;hdfs_id\u0026quot; : 0,\r\u0026quot;hdfs_path\u0026quot; : \u0026quot;path0\u0026quot;,\r\u0026quot;hdfs_size\u0026quot; : 0\r}\r},\r{\r\u0026quot;href\u0026quot; : \u0026quot;http://10.180.210.146:8080/api/v1/hdfs/1\u0026quot;,\r\u0026quot;Hdfses\u0026quot; : {\r\u0026quot;hdfs_id\u0026quot; : 1,\r\u0026quot;hdfs_path\u0026quot; : \u0026quot;path1\u0026quot;,\r\u0026quot;hdfs_size\u0026quot; : 100\r}\r},\r{\r\u0026quot;href\u0026quot; : \u0026quot;http://10.180.210.146:8080/api/v1/hdfs/2\u0026quot;,\r\u0026quot;Hdfses\u0026quot; : {\r\u0026quot;hdfs_id\u0026quot; : 2,\r\u0026quot;hdfs_path\u0026quot; : \u0026quot;path2\u0026quot;,\r\u0026quot;hdfs_size\u0026quot; : 200\r}\r}\r]\r}\r请求必须带上?fields=Hdfses/*,表示展示所有字段，否则查询结果是显示不完整的。\n7.自由风格Controller 也可以抛开ambari的规则，自由使用javax.ws风格。\n但这样就没法使用Ambari内置的权限和谓词风格URL查询了\n8.异常和参数校验 参数校验在ResourceProvider里，抛出SystemException即可返回给页面\n权限异常\nif (!AuthorizationHelper.isAuthorized(resourceType, resourceId, RoleAuthorization.SERVICE_RUN_SERVICE_CHECK)) {\rthrow new AuthorizationException(\u0026quot;The authenticated user is not authorized to execute service checks.\u0026quot;);\r}\r","date":"2020-10-13","permalink":"http://localhost:1313/post/ambari%E9%87%8C%E8%87%AA%E5%AE%9A%E4%B9%89%E8%B5%84%E6%BA%90%E6%A8%A1%E5%9D%97%E7%9A%84%E5%AE%9E%E7%8E%B0/","tags":["Java","大数据"],"title":"Ambari里自定义资源模块的实现"},{"content":"按惯例上Prosody 自己的文档: https://prosody.im/doc/\n安装 使用centos8安装\nyum install prosody\rdnf --enablerepo=PowerTools install lua-filesystem\r其它版本linux则无需单独安装lua-filesystem依赖。\n配置 主配置文件 prosody.cfg.lua 一般不需要修改。\n下面写些咱做的修改😂\n在 modules_enabled 中取消启用 version 和 uptime 模块，顺便启动些其他的模块，比如offline。 如果需要允许在客户端上注册的话，把 allow_registration 设置成 true 。 其它配置保持默认即可。\n另外一个配置文件就是具体和域名对应的配置文件了，位于/etc/prosody/conf.d目录下 我的配置是： baidecai.xyz.cfg.lua\nVirtualHost \u0026quot;baidecai.xyz\u0026quot;\rhttp_host = \u0026quot;www.baidecai.xyz\u0026quot;\r-- enabled = false -- Remove this line to enable this host\r-- Prosody will automatically search for a certificate and key\r-- in /etc/prosody/certs/ unless a path is manually specified\r-- in the config file, see https://prosody.im/doc/certificates\rssl = {\rkey = \u0026quot;/etc/prosody/cer/baidecai.xyz.key\u0026quot;;\rcertificate = \u0026quot;/etc/prosody/cer/baidecai.xyz.crt\u0026quot;;\rprotocol = \u0026quot;tlsv1_1+\u0026quot;;\r--- 为客户端到服务器（c2s）和服务器到服务器（s2s）打开认证\rverify = { \u0026quot;peer\u0026quot;, \u0026quot;peer\u0026quot; };\rciphers = \u0026quot;EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH\u0026quot;;\rdhparam = \u0026quot;/etc/prosody/certs/dh-1024.pem\u0026quot;\r}\rdisco_items = {\r{ \u0026quot;upload.baidecai.xyz\u0026quot; },\r}\rComponent \u0026quot;upload.baidecai.xyz\u0026quot; \u0026quot;http_upload\u0026quot;\rhttp_upload_file_size_limit = 1024000\rhttp_upload_expire_after = 60 * 60 * 24 * 7\rhttp_upload_path = \u0026quot;/uploaded/files\u0026quot;\rhttp_files_dir = \u0026quot;/uploaded/files\u0026quot;\r为了支持聊天中发送文件，我加入了http_upload模块。需要注意的是，这个模块来自社区，并不是prosody自带的，所以需要自己去下载放入prosody的插件目录（在这个问题上，我折腾了好几天才搞定，官方文档没有说清楚），要不然你的xmpp就没法发文件了，及时客户端支持发送操作也会报错。\nprosody的插件目录位置可以通过这个命令查看：\nprosodyctl about\r社区插件下载地址： https://hg.prosody.im/prosody-modules/file/tip 记得给http_upload_path赋予可写权限 重启即可。\n注意 现在的xmpp client基本都不再支持非SSL登陆了，所以你必须要有一个证书。也就是前文配置中的certificate和key文件，这个很好申请，推荐网址： https://freessl.cn/ 。 dhparam文件生成指令 openssl dhparam -out dh.pem 1024 如果没开启允许客户端注册的话，用 prosodyctl 注册账户 prosodyctl adduser \u0026lt;JID\u0026gt;\r到此为止，你已经拥有了一个可以加密聊天，可以发文件的xmpp server了。\n","date":"2020-08-26","permalink":"http://localhost:1313/post/prosody%E6%90%AD%E5%BB%BAxmpp%E6%9C%8D%E5%8A%A1%E5%99%A8/","tags":["Linux","闲扯淡"],"title":"Prosody搭建xmpp服务器"},{"content":"k8s rest api对rc、svc、ingress、pod、deployment等都提供的watch接口，可以实时的监听应用部署状态。\n在此之前简单先说一下http长连接\n分块传输编码（Chunked transfer encoding） 超文本传输协议（HTTP）中的一种数据传输机制，允许HTTP由应用服务器发送给客户端应用（ 通常是网页浏览器）的数据可以分成多个部分。分块传输编码只在HTTP协议1.1版本（HTTP/1.1）中提供。 通常，HTTP应答消息中发送的数据是整个发送的，Content-Length消息头字段表示数据的长度。数据的长度很重要，因为客户端需要知道哪里是应答消息的结束，以及后续应答消息的开始。然而，使用分块传输编码，数据分解成一系列数据块，并以一个或多个块发送，这样服务器可以发送数据而不需要预先知道发送内容的总大小。通常数据块的大小是一致的，但也不总是这种情况。\nTransfer-Encoding 消息首部指明了将 entity 安全传递给用户所采用的编码形式。\nTransfer-Encoding 是一个逐跳传输消息首部，即仅应用于两个节点之间的消息传递，而不是所请求的资源本身。一个多节点连接中的每一段都可以应用不同的Transfer-Encoding 值。如果你想要将压缩后的数据应用于整个连接，那么请使用端到端传输消息首部 Content-Encoding 。\n当这个消息首部出现在 HEAD 请求的响应中，而这样的响应没有消息体，那么它其实指的是应用在相应的 GET 请求的应答的值。\n指令 chunked 数据以一系列分块的形式进行发送。 Content-Length 首部在这种情况下不被发送。。在每一个分块的开头需要添加当前分块的长度，以十六进制的形式表示，后面紧跟着 \u0026lsquo;\\r\\n\u0026rsquo; ，之后是分块本身，后面也是\u0026rsquo;\\r\\n\u0026rsquo; 。终止块是一个常规的分块，不同之处在于其长度为0。终止块后面是一个挂载（trailer），由一系列（或者为空）的实体消息首部构成。\n分块编码 分块编码主要应用于如下场景，即要传输大量的数据，但是在请求在没有被处理完之前响应的长度是无法获得的。例如，当需要用从数据库中查询获得的数据生成一个大的HTML表格的时候，或者需要传输大量的图片的时候。一个分块响应形式如下：\nHTTP/1.1 200 OK Content-Type: text/plain Transfer-Encoding: chunked\r7\\r\\n\rMozilla\\r\\n 9\\r\\n\rDeveloper\\r\\n\r7\\r\\n\rNetwork\\r\\n\r0\\r\\n \\r\\n\rHTTP 1.1引入分块传输编码提供了以下几点好处：\nHTTP分块传输编码允许服务器为动态生成的内容维持HTTP持久连接。通常，持久链接需要服务器在开始发送消息体前发送Content-Length消息头字段，但是对于动态生成的内容来说，在内容创建完之前是不可知的。[动态内容，content-length无法预知] 分块传输编码允许服务器在最后发送消息头字段。对于那些头字段值在内容被生成之前无法知道的情形非常重要，例如消息的内容要使用散列进行签名，散列的结果通过HTTP消息头字段进行传输。没有分块传输编码时，服务器必须缓冲内容直到完成后计算头字段的值并在发送内容前发送这些头字段的值。[散列签名，需缓冲完成才能计算] HTTP服务器有时使用压缩 （gzip或deflate）以缩短传输花费的时间。分块传输编码可以用来分隔压缩对象的多个部分。在这种情况下，块不是分别压缩的，而是整个负载进行压缩，压缩的输出使用本文描述的方案进行分块传输。在压缩的情形中，分块编码有利于一边进行压缩一边发送数据，而不是先完成压缩过程以得知压缩后数据的大小。[gzip压缩，压缩与传输同时进行] 一般情况HTTP的Header包含Content-Length域来指明报文体的长度。有时候服务生成HTTP回应是无法确定消息大小的，比如大文件的下载，或者后台需要复杂的逻辑才能全部处理页面的请求，这时用需要实时生成消息长度，服务器一般使用chunked编码\n原理 k8s提供的watch功能是建立在对etcd的watch之上的，当etcd的key-value出现变化时，会通知kube-apiserver，这里的Key-vlaue其实就是k8s资源的持久化。\n早期的k8s架构中，kube-apiserver、kube-controller-manager、kube-scheduler、kubelet、kube-proxy，都是直接去watch etcd的，这样就造成etcd的连接数太大（节点成千上万时），对etcd压力太大，浪费资源，因此到了后面，只有kube-apiserver去watch etcd，而kube-apiserver对外提供watch api，也就是kube-controller-manager、kube-scheduler、kubelet、kube-proxy去watch kube-apiserver，这样大大减小了etcd的压力\nWatch API 通过k8s 官网 rest api的描述，可以看到，Watch API实际上一个标准的HTTP GET请求，我们以Pod的Watch API为例\nHTTP Request\rGET /api/v1/watch/namespaces/{namespace}/pods\rPath Parameters\rParameter Description\rnamespace object name and auth scope, such as for teams and projects\rQuery Parameters\rParameter Description\rfieldSelector A selector to restrict the list of returned objects by their fields. Defaults to everything.\rlabelSelector A selector to restrict the list of returned objects by their labels. Defaults to everything.\rpretty If ‘true’, then the output is pretty printed.\rresourceVersion When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it’s 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\rtimeoutSeconds Timeout for the list/watch call.\rwatch Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\rResponse\rCode Description\r200 WatchEvent OK\r从上面可以看出Watch其实就是一个GET请求，和一般请求不同的是，它有一个watch的query parameter，也就是kube-apiserver接到这个请求，当发现query parameter里面包含watch，就知道这是一个Watch API，watch参数默认为true。\n==返回值是200和WatchEvent。apiserver首先会返回一个200的状态码，建立长连接，然后不断的返回watch event==\n源码 原理都讲完了，现在到源码了，很简单。\nOkHttpClient client = makeSSLClient();\rRequest request = new Request.Builder()\r.url(\u0026quot;https://10.1.1.11:6443/api/v1/watch/namespaces/default/pods\u0026quot;)\r.addHeader(\u0026quot;Authorization\u0026quot;,\u0026quot;Bearer \u0026quot;+\u0026quot;eyJhbGciOiBnlQ\u0026quot;)\r.get()\r.build();\rclient.newCall(request).enqueue(new Callback() {\r@Override\rpublic void onFailure(Call call, IOException e) {\rlog.info(\u0026quot;Watch connection failed. reason: {}\u0026quot;, e.getMessage());\r}\r@Override\rpublic void onResponse(Call call, Response response) throws IOException {\rif (!response.isSuccessful()) {\rlog.info(\u0026quot;!response.isSuccessful() {}\u0026quot;, response.code());\r}\rtry {\rBufferedSource source = response.body().source();\rwhile (!source.exhausted()) {\rString message = source.readUtf8LineStrict();\rlog.info(message);\r}\r} catch (Exception e) {\rlog.info(\u0026quot;Watch terminated unexpectedly. reason: {}\u0026quot;, e.getMessage());\r}\r}\r});\r剩下的就待自己完善了。\n需要注意的是：\nk8s提供的restful API在此处并不是网上常说的HTTP2协议，它就是HTTP 1.1 长连接 要注意http connection的超时，这里是长连接，超时应该是-1 如果是Java k8s client，可以使用fabric8的watch机制，使用如下：\nKubernetesClient client = new DefaultKubernetesClient(config);//使用默认的就足够了\r//由于4.10.2版本有个影响events使用的回归bug，暂时回退到4.9.2版本。详情见官网issue#2328\r//4.10.3已修复\rclient.v1().events().inAnyNamespace().watch(new Watcher\u0026lt;Event\u0026gt;() {\r@Override\rpublic void eventReceived(Action action, Event resource) {\rlog.info(\u0026quot;event {} resource:{}\u0026quot; , action.name(),resource.toString());\rredisService.lSet(\u0026quot;k8sevent\u0026quot;,resource,3600*24*5);\r}\r@Override\rpublic void onClose(KubernetesClientException cause) {\rlog.info(\u0026quot;Watcher close due to {}\u0026quot; , cause);\r}\r});\r其本质也是调用的restful API。\n","date":"2020-08-11","permalink":"http://localhost:1313/post/%E5%9F%BA%E4%BA%8Erestfulapi%E5%AE%9E%E7%8E%B0k8s%E7%9A%84%E7%9B%91%E5%90%AC%E6%9C%BA%E5%88%B6/","tags":["k8s","Java"],"title":"基于restfulAPI实现k8s的监听机制"},{"content":"helm3集成minio搭建私有仓库 我们一般是从本地的目录结构中的chart去进行部署，如果要集中管理chart,就需要涉及到repository的问题可以通过minio建立一个私有的存放仓库。\nminio安装 安装过程略去，直接下载执行文件即可\n.\\minio.exe server g:/tmp/\r配置mc\nmc config host add minio http://192.168.1.51 BKIKJAA5BMMU2RHO6IBB V7f1CwQqAcwo80UEIJEjc5gVQUSSx5ohQ9GSrr12\r仓库创建 helm create helm-chart\rhelm package ./helm-chart --debug\r#构建索引\rhelm repo index ./\r接下来是复制生成的index.yaml到minio中\n.\\mc.exe policy set download minio/data\r.\\mc.exe cp G:\\data\\project\\helm\\index.yaml minio/data/\r到这一步基本就快好了，然后\nhelm repo add mi http://10.180.204.129:9000/data/\rhelm repo list\r最终可以看到如下结果，说明添加仓库成功：\nPS G:\\data\\project\\helm\u0026gt; helm repo list\rNAME URL\rstable https://kubernetes-charts.storage.googleapis.com/\rmi http://10.180.204.129:9000/data/\rPS G:\\data\\project\\helm\u0026gt;\r搜索下\nPS G:\\tmp\\data\u0026gt; helm search repo mi/helm-chart\rNAME CHART VERSION APP VERSION DESCRIPTION\rmi/helm-chart 0.2.0 1.16.4 A Helm chart for Kubernetes\r也能搜到新加的Chart，完工。\n注意 1.minio虽然是一个文件对象服务器，但是也支持直接在OS文件系统下的操作。也就是说，直接在文件夹上的操作会同步到minio的数据库中。此前一直顾虑minio这种文件系统是否适合用来做repo，其实是多虑的。\n2.官网 https://helm.sh/docs/topics/chart_repository/ 的helm仓库格式如下，典型的tgz+index.yaml格式\ncharts/\r|\r|- index.yaml\r|\r|- alpine-0.1.2.tgz\r|\r|- alpine-0.1.2.tgz.prov\r然而，helm安装是支持文件夹格式的包路径，所以有些应用商店如rancher内置了一些仓库是git+文件夹格式的组织结构，这不是标准的helm仓库，但是也是可以使用的，只是不能被helm repo add而已。这样的仓库需要下载一个文件夹到临时目录再调用helm安装。\n3.如果你发布了两个版本的chart包，也update了，但是仓库默认只能搜到高版本的。需要这么做\nPS G:\\tmp\\data\u0026gt; helm search repo mi/helm-chart --versions\rNAME CHART VERSION APP VERSION DESCRIPTION\rmi/helm-chart 0.2.0 1.16.4 A Helm chart for Kubernetes\rmi/helm-chart 0.1.0 1.16.0 A Helm chart for Kubernetes\r安装\nhelm install mi/helm-chart --version 0.1.0 ","date":"2020-07-03","permalink":"http://localhost:1313/post/helm%E9%9B%86%E6%88%90minio%E6%90%AD%E5%BB%BA%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/","tags":["k8s"],"title":"Helm集成minio搭建私有仓库"},{"content":"在后端项目中，难免遇到需要写接口文档方便第三方调用的场景，一般业界最常用的方案是使用swagger。Java项目中，一般采用springfox项目，它集成了swagger和swagger-ui，不需要单独部署项目，可让文档随着项目一起发布。\n但是开源项目往往是开源一时热，事后拂衣去，缺少维护。这个项目已经两年多没有维护了，很多人在issue反馈过bug，作者一年前表示自己比较忙，没空维护。\nspringfox最新的版本是2.9.2，不支持spring5（虽然有个快照版支持spring5，但一直没发布，整合也有点麻烦）。spring5比较大的一个改变就是增加了webflux，因此旧版springfox无法兼容spring5的。\n其实用快照版，稍作修改也能让springfox支持webflux，但是我不是很喜欢这种做法。一个是增加了打包体积和运行内存占用，另一个则是swagger的使用污染了Java源码，很是不美观，强迫症不能忍。\n@RestController\r@RequestMapping(\u0026quot;/dataspace/api/v1/hive\u0026quot;)\r@Api(value = \u0026quot;hive\u0026quot;, description = \u0026quot;hive资源管理\u0026quot;)\rpublic class HiveManagerController {\r@Autowired\rHiveManagerService hiveManagerService;\r@RequestMapping(value = \u0026quot;/list\u0026quot;, method = {RequestMethod.POST})\r@ApiOperation(value = \u0026quot;资源列表\u0026quot;, notes = \u0026quot;\u0026quot;)\rpublic PageResult\u0026lt;HiveVO\u0026gt; showPublic(@ApiParam(value = \u0026quot;hive查询对象\u0026quot;)\r@RequestBody PageReqParam\u0026lt;HiveReq\u0026gt; hiveReq) {\rPageResult\u0026lt;HiveVO\u0026gt; result = new PageResult\u0026lt;\u0026gt;();\rif (hiveReq.getReqParam() == null) {\rresult.setCode(-1);\rresult.setMsg(\u0026quot;参数不完整\u0026quot;);\rreturn result;\r}\rif (hiveReq.getPageSize() \u0026gt; 50 || hiveReq.getPageSize() \u0026lt; 0) {\rresult.setCode(-1);\rresult.setMsg(\u0026quot;页码非法\u0026quot;);\rreturn result;\r}\rresult = hiveManagerService.getList(hiveReq);\rreturn result;\r}\r源码中混入了各种ApiParam、Api、ApiOperation注解。\n再加上我现在使用的springcloud套件，需要在gateway的feign接口上加注释，这样的话，无论是springfox，还是很多第三方的api doc工具都很难胜任。\n于是，我想到了另外一种方法，就是javadoc。然而javadoc自带的注解很有限，不能满足第三方对文档的需求，比如\n/**\r* 根据节点名删除主机\r* @method DELETE\r* @path host/delHostByNodeName\r* @param nodeName 节点名\r* @param cluster 集群名\r* @return JSON\r*/\r@DeleteMapping(\u0026quot;/delHostByNodeName\u0026quot;)\rpublic String delHostByNodeName(@RequestParam(\u0026quot;nodeName\u0026quot;) String nodeName,@RequestParam(\u0026quot;cluster\u0026quot;) String cluster);\rjavadoc并不认识method和path这两个标签，生成的文档还是缺少一些必须要的信息。\n这个不难，扩展下taglet即可。\n先引入maven依赖\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;jdk.tools\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jdk.tools\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;1.8\u0026lt;/version\u0026gt;\r\u0026lt;scope\u0026gt;system\u0026lt;/scope\u0026gt;\r\u0026lt;systemPath\u0026gt;${JAVA_HOME}/lib/tools.jar\u0026lt;/systemPath\u0026gt;\r\u0026lt;/dependency\u0026gt;\r扩展taglet代码\npackage com.github.cloud.ali.common.tool;\rimport com.sun.javadoc.Tag;\rimport com.sun.tools.doclets.Taglet;\rimport java.util.Map;\rpublic class MethodTaglet implements Taglet {\rprivate String NAME = \u0026quot;HTTP请求类型\u0026quot;;\rprivate String HEADER = \u0026quot;HTTP请求类型:\u0026quot;;\r@Override\rpublic boolean inField() {\rreturn false;\r}\r@Override\rpublic boolean inConstructor() {\rreturn false;\r}\r@Override\rpublic boolean inMethod() {\rreturn true;\r}\r@Override\rpublic boolean inOverview() {\rreturn true;\r}\r@Override\rpublic boolean inPackage() {\rreturn true;\r}\r@Override\rpublic boolean inType() {\rreturn true;\r}\r@Override\rpublic boolean isInlineTag() {\rreturn false;\r}\rpublic static void register(Map tagletMap) {\rMethodTaglet tag = new MethodTaglet();\rTaglet t = (Taglet) tagletMap.get(tag.getName());\rif (t != null) {\rtagletMap.remove(tag.getName());\r}\rtagletMap.put(tag.getName(), tag);\r}\r@Override\rpublic String getName() {\rreturn NAME;\r}\r@Override\rpublic String toString(Tag tag) {\rreturn \u0026quot;\u0026lt;DT\u0026gt;\u0026lt;B\u0026gt;\u0026quot; + HEADER + \u0026quot;\u0026lt;/B\u0026gt;\u0026lt;DD\u0026gt;\u0026quot;\r+ \u0026quot;\u0026lt;table cellpadding=2 cellspacing=0\u0026gt;\u0026lt;tr\u0026gt;\u0026lt;td bgcolor=\\\u0026quot;yellow\\\u0026quot;\u0026gt;\u0026quot;\r+ tag.text()\r+ \u0026quot;\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;/table\u0026gt;\u0026lt;/DD\u0026gt;\\n\u0026quot;;\r}\r@Override\rpublic String toString(Tag[] tags) {\rif (tags.length == 0) {\rreturn null;\r}\rString result = \u0026quot;\\n\u0026lt;DT\u0026gt;\u0026lt;B\u0026gt;\u0026quot; + HEADER + \u0026quot;\u0026lt;/B\u0026gt;\u0026lt;DD\u0026gt;\u0026quot;;\rresult += \u0026quot;\u0026lt;table cellpadding=2 cellspacing=0\u0026gt;\u0026lt;tr\u0026gt;\u0026lt;td bgcolor=\\\u0026quot;yellow\\\u0026quot;\u0026gt;\u0026quot;;\rfor (int i = 0; i \u0026lt; tags.length; i++) {\rif (i \u0026gt; 0) {\rresult += \u0026quot;, \u0026quot;;\r}\rresult += tags[i].text();\r}\rreturn result + \u0026quot;\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;/table\u0026gt;\u0026lt;/DD\u0026gt;\\n\u0026quot;;\r}\r}\r同理，path注解也是类似的实现。编译命令如下：\njavadoc -protected -splitindex -use -author -version -encoding utf-8 -charset utf-8 -d /usr/jackma/doc -windowtitle \u0026quot;ali 文档\u0026quot; $(ls /usr/jackma/ali/ali-common/src/main/java/com/github/cloud/ali/common/model/*.java |tr \u0026quot;\\n\u0026quot; \u0026quot; \u0026quot;) $(ls /usr/jackma/ali/ali-gateway/src/main/java/com/github/cloud/ali/feign/*.java |tr \u0026quot;\\n\u0026quot; \u0026quot; \u0026quot;) -tag method:a:\u0026quot;HTTP请求方法:\u0026quot; -tag path:a:\u0026quot;请求路径:\u0026quot; -tagletpath /usr/jackma/ali/ali-common/src/main/java/com/github/cloud/ali/common/tool/MethodTaglet.java -tagletpath /usr/jackma/ali/ali-common/src/main/java/com/github/cloud/ali/common/tool/PathTaglet.java -taglet com.github.cloud.ali.common.tool.MethodTaglet -taglet com.github.cloud.ali.common.tool.PathTaglet\r最终效果如下：\n还可以进一步，加上数据类型的注解，这样就更完善了。\n虽然离swagger-ui还有点差距，但是还是比原版javadoc好多了。最大的优点是没有任何限制和对源码的污染。\n不得不说，Java的扩展性不是盖的。\n","date":"2020-05-12","permalink":"http://localhost:1313/post/%E4%B8%80%E7%A7%8Dswagger-ui%E7%9A%84%E6%9B%BF%E4%BB%A3%E6%96%B9%E6%A1%88%E4%B8%8D%E5%BC%95%E5%85%A5%E4%BB%BB%E4%BD%95%E6%BA%90%E7%A0%81%E6%B1%A1%E6%9F%93/","tags":["Java"],"title":"一种swagger Ui的替代方案不引入任何源码污染"},{"content":"​ 这个问题纠结我快一年了。某次manjaro升级后，我的manjaro在系统自带应用上如konsole,kate,Yakuake上都不能切换输入法（目测系统自带的软件都不能），鼠标放键盘图标上提示“无输入窗口”。但是浏览器和其他软件是可以的。这个问题不是太影响使用，就忍了很久，大不了其他地方写好了再复制到kate里，但是就好像衣服上落沾了一坨黄泥，始终感觉不爽，每隔一两个月就要尝试解决一次，始终无果。\n尝试过的解决方案有下面几种：\n修改/etc/profile 修改.xprofile 修改/etc/environment 更换其他中文输入法 用fcitx-diagnose诊断配置 配置文件肯定是正确的，按照网上说的 Linux下输入中文的配置也检查了很多，作为一个有六七年经验的 Linux老司机，怎么可能翻车呢。搜了很多文章，死马当作活马医，一直无解。\nfcitx-diagnose诊断结果如下，然而确认配置了，可为什么就是不认识一直没理解。\n\u0026quot; 而不是 \u0026quot;fcitx\u0026quot;. 请检查您是否在某个初始化文件中错误的设置了它的值.**\r**您可能会在 qt4 程序中使用 fcitx 时遇到问题.**\r**请使用您发行版提供的工具将环境变量 QT_IM_MODULE 设为 \u0026quot;fcitx\u0026quot; 或者将 `export QT_IM_MODULE=fcitx` 添加到您的 `~/.xprofile` 中. 参见 [输入法相关的环境变量: QT_IM_MODULE](http://fcitx-im.org/wiki/Input_method_related_environment_variables/zh-cn#QT_IM_MODULE).**\rgtk - `${GTK_IM_MODULE}`:\r\u0026quot; 而不是 \u0026quot;fcitx\u0026quot;. 请检查您是否在某个初始化文件中错误的设置了它的值.**\r**您可能会在 gtk 程序中使用 fcitx 时遇到问题.**\r**请使用您发行版提供的工具将环境变量 GTK_IM_MODULE 设为 \u0026quot;fcitx\u0026quot; 或者将 `export GTK_IM_MODULE=fcitx` 添加到您的 `~/.xprofile` 中. 参见 [输入法相关的环境变量: GTK_IM_MODULE](http://fcitx-im.org/wiki/Input_method_related_environment_variables/zh-cn#GTK_IM_MODULE).**\r直到今天，偶尔搜到了这篇文章，出现的问题和我遇到的一模一样。原来是我的.xprofile里环境变量 XMODIFIERS、QT_IM_MODULE、GTK_IM_MODULE 值的末尾有一个回车符。也就是说，设置这些环境变量的那个文件错误地使用了 DOS / Windows 的换行符。\n解决方案就很简单了，在 Vim 中打开并执行 :set ff=unix，然后保存并退出 :wq。\n重新注销，解决了。\n然后想起来，快一年前更新系统，结果挂了。这是唯一一次更新 manjaro滚挂了（这是manjaro软件源的一次bug 导致），修复系统后用了百度复制来的代码，竟然疏忽了。\n要是没那篇文章，真不知何年何月能解决。放狗一搜，还有许许多多受害者遇到这种情况至今没有解决，甚至在manjaro官网提问也无解。所以记录下，希望更多人能看到。\n","date":"2020-03-07","permalink":"http://localhost:1313/post/kde%E6%A1%8C%E9%9D%A2%E4%B8%8B%E9%83%A8%E5%88%86%E5%BA%94%E7%94%A8%E6%97%A0%E6%B3%95%E8%BE%93%E5%85%A5%E4%B8%AD%E6%96%87/","tags":["linux"],"title":"Kde桌面下自带应用无法输入中文"},{"content":"1.安装k8s 安装K8S的步骤略去，使用k3s安装会更快捷方便，方便测试环境。\n如果使用k3s会有个坑，k3s默认使用container而不是docker作为容器，会导致运行时出现一些问题，后面会详细分析。\n安装k3s后，需要按照如下修改 /etc/systemd/system/k3s.service\nExecStartPre=-/sbin/modprobe overlay\rExecStart=/usr/local/bin/k3s \\\rserver --docker \\\r#添加 --docker 参数\r2.springboot镜像准备 pom.xml\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt;\r\u0026lt;project xmlns=\u0026quot;http://maven.apache.org/POM/4.0.0\u0026quot; xmlns:xsi=\u0026quot;http://www.w3.org/2001/XMLSchema-instance\u0026quot;\rxsi:schemaLocation=\u0026quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026quot;\u0026gt;\r\u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt;\r\u0026lt;parent\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.2.5.RELEASE\u0026lt;/version\u0026gt;\r\u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt;\r\u0026lt;/parent\u0026gt;\r\u0026lt;groupId\u0026gt;com.github.iminto\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;bcdemo\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt;\r\u0026lt;name\u0026gt;bcdemo\u0026lt;/name\u0026gt;\r\u0026lt;description\u0026gt;Demo project for Spring Boot\u0026lt;/description\u0026gt;\r\u0026lt;properties\u0026gt;\r\u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt;\r\u0026lt;/properties\u0026gt;\r\u0026lt;dependencies\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;/dependencies\u0026gt;\r\u0026lt;build\u0026gt;\r\u0026lt;plugins\u0026gt;\r\u0026lt;plugin\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt;\r\u0026lt;/plugin\u0026gt;\r\u0026lt;/plugins\u0026gt;\r\u0026lt;/build\u0026gt;\r\u0026lt;/project\u0026gt;\rBcdemoApplication.java 启动器代码略。\nsrc\\main\\java\\com\\github\\iminto\\bcdemo\\controller\\HomeController.java\npackage com.github.iminto.bcdemo.controller;\rimport org.springframework.web.bind.annotation.RequestMapping;\rimport org.springframework.web.bind.annotation.RestController;\r@RestController\rpublic class HomeController {\r@RequestMapping(\u0026quot;/\u0026quot;)\rpublic String home() {\rreturn \u0026quot;Hello Docker World\u0026quot;;\r}\r}\rsrc\\main\\resources\\application.yaml\nserver:\rport: 9010\rmvn打包。\nDockerfile文件如下：\nFROM openjdk:8-jdk-alpine\rENV TZ=Asia/Shanghai\rRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime \u0026amp;\u0026amp; echo $TZ \u0026gt; /etc/timezone\rCOPY bcdemo.jar /opt/app.jar\rCOPY run.sh /opt/run.sh\rEXPOSE 9010\rENTRYPOINT [\u0026quot;/bin/sh\u0026quot;, \u0026quot;/opt/run.sh\u0026quot;]\rrun.sh\n#!/bin/bash\r# do other things here\rjava -jar /opt/app.jar 2\u0026gt;\u0026amp;1 需要注意，docker必须要有一个前台进程，不然运行后会马上退出，所以不能使用下面的命令\n#这么写是错的\rjava -jar /opt/app.jar 2\u0026gt;\u0026amp;1 \u0026amp; docker镜像构建\ndocker build . -t bcdemo:1.0\r测试docker镜像是否正确时，需要用ctrl+p+q终止控制台日志打印，不要用ctrl+c。\n3.k8s部署 编写yaml文件\napiVersion: v1\rkind: Deployment\rmetadata:\rname: k8s-springboot-demo\rlabels:\rapp: k8s-springboot-demo\rspec:\rreplicas: 1\rrevisionHistoryLimit: 10\rselector:\rmatchLabels:\rapp: k8s-springboot-demo\rtemplate:\rmetadata:\rlabels:\rapp: k8s-springboot-demo\rspec:\rcontainers:\r- name: k8s-springboot-demo\rimage: bcdemo:1.0\rports:\r- containerPort: 9010\rprotocol: TCP\rlivenessProbe:\rhttpGet:\rpath: /\rport: 9010\rinitialDelaySeconds: 30\rtimeoutSeconds: 30\rimagePullPolicy: IfNotPresent\rtolerations:\r- key: node-role.kubernetes.io/master\reffect: NoSchedule\r---\rapiVersion: v1\rkind: Service\rmetadata:\rname: k8s-springboot-demo\rnamespace: default\rlabels:\rapp: k8s-springboot-demo\rspec:\rports:\r- port: 9010\rtargetPort: 9010\rselector:\rapp: k8s-springboot-demo\rtype: NodePort\r部署\n#部署\rkubectl apply -f sp.yaml\r#查看运行状态\rkubectl get po,svc,deploy -o wide\r#删除Deployment\rkubectl delete -f sp.yaml\r#删除节点\rkubectl delete pod k8s-springboot-demo-fc778b44-f4p49\r#查看节点详细运行状态，可用于排错\rkubectl describe pod k8s-springboot-demo-fc778b44-f4p49\r最终部署结果如下：\n[root@chenwork2 project]# kubectl get po,svc,deploy -o wide\rNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES\rpod/k8s-springboot-demo-fc778b44-zfjnx 1/1 Running 0 16h 10.42.0.11 chenwork2 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt;\rNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR\rservice/k8s-springboot-demo NodePort 10.43.35.126 \u0026lt;none\u0026gt; 9010:31622/TCP 16h app=k8s-springboot-demo\rservice/kubernetes ClusterIP 10.43.0.1 \u0026lt;none\u0026gt; 443/TCP 51d \u0026lt;none\u0026gt;\rNAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR\rdeployment.extensions/k8s-springboot-demo 1/1 1 1 16h k8s-springboot-demo bcdemo:1.0 app=k8s-springboot-demo\r验证：\n[root@chenwork2 project]# curl -i -X GET chenwork2:31622/\rHTTP/1.1 200 Content-Type: text/plain;charset=UTF-8\rContent-Length: 18\rDate: Fri, 06 Mar 2020 01:55:40 GMT\rHello Docker World\r这样的端口，只能在集群内访问，集群外是无法访问的。\n4.k3s的问题 如果pod一直是 ContainerCreating 状态，那就是pod没有创建成功，用describe命令看一下，最后几行一般会看到如下报错\nWarning FailedCreatePodSandBox 91s (x29 over 21m) kubelet, host123 Failed create pod sandbox: rpc error: code = Unknown desc = failed to get sandbox image \u0026quot;k8s.gcr.io/pause:3.1\u0026quot;: failed to pull image \u0026quot;k8s.gcr.io/pause:3.1\u0026quot;: failed to pull and unpack image \u0026quot;k8s.gcr.io/pause:3.1\u0026quot;: failed to resolve reference \u0026quot;k8s.gcr.io/pause:3.1\u0026quot;: failed to do request: Head https://k8s.gcr.io/v2/pause/manifests/3.1: dial tcp 108.177.97.82:443: i/o timeout\r原因已经非常清楚了，failed to pull image \u0026ldquo;k8s.gcr.io/pause:3.1\u0026rdquo;，镜像拉不到。\n解决方法：\ndocker pull mirrorgooglecontainers/pause:3.1\r#其实直接把rancher/pause镜像命名成k8s.gcr.io/pause即可\rdocker tag mirrorgooglecontainers/pause:3.1 k8s.gcr.io/pause:3.1\r重启k3s，你会发现pod还是启动不起来，这就是前面说的原因：k3s默认使用container而不是docker作为容器\n你有了pause镜像，但是k3s不认docker镜像，而是认container容器，所以需要把k3s改成docker运行时。\n或者如下操作：\nctr --version\r#需要预先导出pause镜像\rctr images import pause-amd64-3.1.tar\r#看看有没有加载进来\rctr images list\r#如果加载了，但是名字不匹配，需要打标签\rctr images tag gcr.io/google_containers/pause-amd64:3.1 k8s.gcr.io/pause:3.1\r5.LoadBalancer服务暴露给外部访问 K8S Service 暴露服务类型有三种：ClusterIP、NodePort、LoadBalancer，三种类型分别有不同的应用场景。\n对内服务发现，可以使用 ClusterIP 方式对内暴露服务，因为存在 Service 重新创建 IP 会更改的情况，所以不建议直接使用分配的 ClusterIP 方式来内部访问，可以使用 K8S DNS 方式解析，DNS 命名规则为：\u0026lt;svc_name\u0026gt;.\u0026lt;namespace_name\u0026gt;.svc.cluster.local，按照该方式可以直接在集群内部访问对应服务。\n对外服务暴露，可以采用 NodePort、LoadBalancer 方式对外暴露服务，NodePort 方式使用集群固定 IP，但是端口号是指定范围内随机选择的，每次更新 Service 该 Port 就会更改，不太方便，当然也可以指定固定的 NodePort，但是需要自己维护 Port 列表，也不方便。LoadBalancer 方式使用集群固定 IP 和 NodePort，会额外申请申请一个负载均衡器来转发到对应服务，但是需要底层平台支撑。如果使用 Aliyun、GCE 等云平台商，可以使用该种方式，他们底层会提供 LoadBalancer 支持，直接使用非常方便。\n以上方式或多或少都会存在一定的局限性，所以建议如果在公有云上运行，可以使用 LoadBalancer、 Ingress 方式对外提供服务，私有云的话，可以使用 Ingress 通过域名解析来对外提供服务。\n下面使用LoadBalancer方式。\nyaml文件修改 修改k8s-springboot-demo.yaml\napiVersion: v1 kind: Service metadata: name: k8s-springboot-demo\rnamespace: default\rlabels: app: k8s-springboot-demo\rspec: ports: - port: 8080 targetPort: 8080\rselector: app: k8s-springboot-demo type: LoadBalancer\rservice的type修改为LoadBalancer，然后\nkubectl apply -f k8s-springboot-demo.yaml\r命令修改 用命令修改的方式更方便。\n[root@chenwork2 project]# kubectl delete svc k8s-springboot-demo\rservice \u0026quot;k8s-springboot-demo\u0026quot; deleted\r[root@chenwork2 project]# kubectl get po,svc,deploy\rNAME READY STATUS RESTARTS AGE\rpod/k8s-springboot-demo-fc778b44-zfjnx 1/1 Running 0 16h\rNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\rservice/kubernetes ClusterIP 10.43.0.1 \u0026lt;none\u0026gt; 443/TCP 51d\rNAME READY UP-TO-DATE AVAILABLE AGE\rdeployment.extensions/k8s-springboot-demo 1/1 1 1 16h\r[root@chenwork2 project]# kubectl expose deploy k8s-springboot-demo --type=LoadBalancer\rservice/k8s-springboot-demo exposed\r[root@chenwork2 project]# kubectl get po,svc,deploy\rNAME READY STATUS RESTARTS AGE\rpod/k8s-springboot-demo-fc778b44-zfjnx 1/1 Running 0 16h\rpod/svclb-k8s-springboot-demo-crfvw 1/1 Running 0 4s\rNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\rservice/k8s-springboot-demo LoadBalancer 10.43.112.54 10.180.249.73 9010:32219/TCP 4s\rservice/kubernetes ClusterIP 10.43.0.1 \u0026lt;none\u0026gt; 443/TCP 51d\rNAME READY UP-TO-DATE AVAILABLE AGE\rdeployment.extensions/k8s-springboot-demo 1/1 1 1 16h\r这样就能在集群外，直接用浏览器访问了。\n也可以使用 ClusterIP+kubectl proxy 方式，但不推荐。\n6.容器部署yaml中传递参数 可以向容器传递参数到脚本执行一些特殊操作，而且这里变成脚本来启动，这样后续构建镜像基本不需要改 Dockerfile 了\n#!/bin/bash\r# do other things here\rjava -jar $JAVA_OPTS /opt/project/app.jar $1 2\u0026gt;\u0026amp;1\r上边示例中，我们就注入 $JAVA_OPTS 环境变量，来优化 JVM 参数，还可以传递一个变量，这个变量大家应该就猜到了，就是服务启动加载哪个配置文件参数，例如：\u0026ndash;spring.profiles.active=prod 那么，在 Deployment 中就可以通过如下方式配置了：\nspec:\rcontainers:\r- name: project-name\rimage: registry.docker.com/project/app:v1.0.0\rargs: [\u0026quot;--spring.profiles.active=prod\u0026quot;]\renv:\r- name: JAVA_OPTS\rvalue: \u0026quot;-XX:PermSize=512M -XX:MaxPermSize=512M -Xms1024M -Xmx1024M...\u0026quot;\r7.参考 Spring Boot 项目转容器化 K8S 部署实用经验分享\nK8s 集群使用 ConfigMap 优雅加载 Spring Boot 配置文件\n[Spring Boot应用容器化及Kubernetes部署](http://fly-luck.github.io/2018/11/10/Spring Boot App on Kubernetes/)\n基于Kubernetes和Springboot构建微服务\nDocker / Kubernetes部署Java / SpringBoot项目\n在Kubernetes中部署spring boot应用\n","date":"2020-03-06","permalink":"http://localhost:1313/post/k8s%E9%83%A8%E7%BD%B2springboot/","tags":["k8s","Java"],"title":"K8s部署springboot"},{"content":"rancher 是一个为DevOps团队提供的完整的Kubernetes与容器管理解决方案。rancher最大的优点就是安装部署方便，极大地简化了K8S的安装配置。在官网上，推荐的是使用docker方式安装rancher，这种方式隐藏了大量的细节。在网上搜了下现有的资料，几乎都是照抄官方文档，更没有在windows上安装rancher的先例。\nrancher是用golang写的，跨平台问题不大，但也需要一些修改。正好最近要对rancher做二次开发，于是记录下了在windows上编译安装rancher的步骤。\n1.修改源码 rancher要在windows上编译通过并运行，需要修改以下源码\nmain.go\nfunc run(cfg app.Config) error {\rlogrus.Infof(\u0026quot;Rancher version %s is starting\u0026quot;, VERSION)\rlogrus.Infof(\u0026quot;Rancher arguments %+v\u0026quot;, cfg)\rdump.GoroutineDumpOn(syscall.SIGUSR1, syscall.SIGILL)\rctx := signals.SetupSignalHandler(context.Background())\r改为如下，此处修改基本不会有副作用\nfunc run(cfg app.Config) error {\rlogrus.Infof(\u0026quot;Rancher version %s is starting\u0026quot;, VERSION)\rlogrus.Infof(\u0026quot;Rancher arguments %+v\u0026quot;, cfg)\rdump.GoroutineDumpOn(syscall.SIGILL, syscall.SIGILL)\rctx := signals.SetupSignalHandler(context.Background())\r然后屏蔽以下几个文件中相关syscall的处理：（这几处修改可能会导致K8S相关的功能带来影响，但影响未知.建议使用条件编译方式）\npkg/controllers/user/helm/common/common.go\nfunc JailCommand(cmd *exec.Cmd, jailPath string) (*exec.Cmd, error) {\rif os.Getenv(\u0026quot;CATTLE_DEV_MODE\u0026quot;) != \u0026quot;\u0026quot; {\rreturn cmd, nil\r} else {\r//cred, err := jailer.GetUserCred()\r//if err != nil {\r// return nil, errors.WithMessage(err, \u0026quot;get user cred error\u0026quot;)\r//}\r//\r//cmd.SysProcAttr = \u0026amp;syscall.SysProcAttr{}\r//cmd.SysProcAttr.Credential = cred\r//cmd.SysProcAttr.Chroot = jailPath\r//cmd.Env = jailer.WhitelistEnvvars(cmd.Env)\rreturn cmd, nil\r}\r}\rpkg/controllers/management/node/utils.go 修改同理\nfunc buildCommand(nodeDir string, node *v3.Node, cmdArgs []string) (*exec.Cmd, error) {\r// In dev_mode, don't need jail or reference to jail in command\rif os.Getenv(\u0026quot;CATTLE_DEV_MODE\u0026quot;) != \u0026quot;\u0026quot; {\renv := initEnviron(nodeDir)\rcommand := exec.Command(nodeCmd, cmdArgs...)\rcommand.Env = env\rreturn command, nil\r}\r//cred, err := jailer.GetUserCred()\r//if err != nil {\r// return nil, errors.WithMessage(err, \u0026quot;get user cred error\u0026quot;)\r//}\rcommand := exec.Command(nodeCmd, cmdArgs...)\r//command.SysProcAttr = \u0026amp;syscall.SysProcAttr{}\r//command.SysProcAttr.Credential = cred\r//command.SysProcAttr.Chroot = path.Join(jailer.BaseJailPath, node.Namespace)\renvvars := []string{\rnodeDirEnvKey + nodeDir,\r\u0026quot;PATH=/usr/bin:/var/lib/rancher/management-state/bin\u0026quot;,\r}\rcommand.Env = jailer.WhitelistEnvvars(envvars)\rreturn command, nil\r}\r屏蔽jailer的处理\npkg/jailer/jailer.go 注释掉这个方法\n// GetUserCred looks up the user and provides it in syscall.Credential\r//func GetUserCred() (*syscall.Credential, error) {\r//\r//}\r修改一个依赖库里的文件 （比较正规的方式是在go mod中使用replace语法，而不是直接修改第三方package）\nvendor/github.com/rancher/kontainer-engine/service/service.go\n#446行开始注释这段代码\r//if os.Getenv(\u0026quot;CATTLE_DEV_MODE\u0026quot;) == \u0026quot;\u0026quot; {\r// cred, err := getUserCred()\r// if err != nil {\r// return \u0026quot;\u0026quot;, errors.WithMessage(err, \u0026quot;get user cred error\u0026quot;)\r// }\r//\r// cmd.SysProcAttr = \u0026amp;syscall.SysProcAttr{}\r// cmd.SysProcAttr.Credential = cred\r// cmd.SysProcAttr.Chroot = \u0026quot;/opt/jail/driver-jail\u0026quot;\r// cmd.Env = whitelistEnvvars([]string{\u0026quot;PATH=/usr/bin\u0026quot;})\r//}\r628行注释掉这个方法\n// getUserCred looks up the user and provides it in syscall.Credential\r//func getUserCred() (*syscall.Credential, error) {\r然后编译即可生成exe文件。\n2.运行 如果笔记本内存在8G以上，可以安装windows版本k8s或者minikube\n由于我本机配置太低，所以使用了linux服务器上的配置。\n#每次运行一定要执行这个命令，或者在环境变量里配置加下也可一劳永逸\rset CATTLE_DEV_MODE=true\rgo build -mod=vendor\r#生成可执行文件 rancher.exe 运行文件需要k8s 在服务器上安装k8s 然后将配置文件k3s.yaml下载到本地windows上，修改配置文件的ip为k8s所在服务器上的ip #修改完成后执行下面指令 其中：g:\\data\\k3s.yaml为配置文件所在本地路径\rrancher.exe --k8s-mode=external --kubeconfig g:\\data\\k3s.yaml --no-cacerts=true\rk3s.yaml是Linux服务器上的K8S配置文件。不要使用服务器上已经被rancher使用过的k8s，而是用一个崭新的K8S环境。\n服务器上安装k8s可以参考这里：https://k3s.io/\n#这一步可能需要翻墙\rcurl -sfL https://get.k3s.io | sh -\r#Check for Ready node, takes maybe 30 seconds\rk3s kubectl get node\r新增一个用户试一下，可以新增成功\n3.条件编译 条件编译不需要在原有文件内容上做修改，编译出的文件可以保证在linux上是完整的。\n以修改pkg/controllers/user/helm/common/common.go 为例，将原文件重命名未common_linux.go，然后新建一个common_windows_amd64.go，里面是windows版本的源码。\n然后编译即可。\n看起来条件编译对源文件做了重命名操作，但是保证了linux上代码的完整，不会让windows上的修改导致linux上产生隐患。\ngolang条件编译的源里可以参考此处：https://www.jianshu.com/p/4bb03e67e7ae\n4.问题 1.未测试更多高级功能，还未知。\n","date":"2020-02-28","permalink":"http://localhost:1313/post/windows%E4%B8%8A%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%E8%BF%90%E8%A1%8Crancher/","tags":["k8s"],"title":"Windows上编译安装运行rancher"},{"content":"今天群里有位360的安全大佬，发了个链接http://93.175.29.89:8008/，说爬这个网址的时候，IO会一直卡在那，一直没有返回响应。 那个网址是他构造的一个特殊请求，输出一个视频流，但是服务器端不返回Content-Length，也不输出真实数据，就是输出不到1024字节的流后就一直停在那也不close，浏览器打开的效果就是看到了视频的前几帧，然后一直卡在哪转圈。\n这么说来，感觉不是个大问题，设置下ReadTimeout不就好了么，大佬说他也设置了，但是无效，他使用的python代码实现，刚开始我觉得是他代码的问题，或者那个API库实现的问题，就用Java也实现了一把\npackage sms.bai.util;\rimport com.squareup.okhttp.Headers;\rimport com.squareup.okhttp.OkHttpClient;\rimport com.squareup.okhttp.Request;\rimport com.squareup.okhttp.Response;\rimport java.io.IOException;\rimport java.util.concurrent.*;\rpublic class Req {\rpublic static void reqUrl() throws IOException {\rOkHttpClient client = new OkHttpClient();\rclient.setConnectTimeout(5,TimeUnit.SECONDS);\rclient.setReadTimeout(5,TimeUnit.SECONDS);\rRequest request = new Request.Builder()\r.url(\u0026quot;http://93.175.29.89:8008/\u0026quot;)\r.build();\rResponse response = client.newCall(request).execute();\rif (!response.isSuccessful()) {\rthrow new IOException(\u0026quot;服务器端错误: \u0026quot; + response);\r}\rHeaders responseHeaders = response.headers();\rfor (int i = 0; i \u0026lt; responseHeaders.size(); i++) {\rSystem.out.println(responseHeaders.name(i) + \u0026quot;: \u0026quot; + responseHeaders.value(i));\r}\rSystem.out.println(response.body().string());\r}\rpublic static void main(String[] args) throws IOException {\rreqUrl();\r}\r}\r果然如其所言，无论设置ConnectTimeout还是ReadTimeout都是无效的，代码一直停留在输出那里，不输出任何body（浏览器里还能勉强看到画面），程序也不stop\nContent-Type: multipart/x-mixed-replace;boundary=---nessy2jpegboundary\rOkHttp-Sent-Millis: 1582028133591\rOkHttp-Received-Millis: 1582028133875\r这里用的是OkHttp库 ,换其它库或者用Java自带的HttpUrlConnection理论上效果也是一样的。\n用ffmpeg来看看这个请求\n[kk@kk ~]$ ffmpeg -i http://93.175.29.89:8008/ -f mp4 out.mp4\rffmpeg version n4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\rbuilt with gcc 9.2.0 (GCC)\rlibavutil 56. 31.100 / 56. 31.100\rlibavcodec 58. 54.100 / 58. 54.100\rlibavformat 58. 29.100 / 58. 29.100\rlibavdevice 58. 8.100 / 58. 8.100\rlibavfilter 7. 57.100 / 7. 57.100\rlibswscale 5. 5.100 / 5. 5.100\rlibswresample 3. 5.100 / 3. 5.100\rlibpostproc 55. 5.100 / 55. 5.100\rInput #0, mpjpeg, from 'http://93.175.29.89:8008/':\rDuration: N/A, bitrate: N/A\rStream #0:0: Video: mjpeg (Baseline), yuvj420p(pc, bt470bg/unknown/unknown), 640x480 [SAR 1:1 DAR 4:3], 25 tbr, 25 tbn, 25 tbc\rStream mapping:\rStream #0:0 -\u0026gt; #0:0 (mjpeg (native) -\u0026gt; h264 (libx264))\rPress [q] to stop, [?] for help\r[libx264 @ 0x562ad6812cc0] using SAR=1/1\r[libx264 @ 0x562ad6812cc0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\r[libx264 @ 0x562ad6812cc0] profile High, level 3.0, 4:2:0, 8-bit\r[libx264 @ 0x562ad6812cc0] 264 - core 159 r2991 1771b55 - H.264/MPEG-4 AVC codec - Copyleft 2003-2019 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\rOutput #0, mp4, to 'out.mp4':\rMetadata:\rencoder : Lavf58.29.100\rStream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuvj420p(pc), 640x480 [SAR 1:1 DAR 4:3], q=-1--1, 25 fps, 12800 tbn, 25 tbc\rMetadata:\rencoder : Lavc58.54.100 libx264\rSide data:\rcpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\rframe= 83 fps=1.1 q=-1.0 Lsize= 336kB time=00:00:03.20 bitrate= 859.8kbits/s speed=0.0436x ffmpeg 能识别出是一个视频流，但是会一直卡在frame=xx这里，一直读取帧而不停止。强行终止后能输出一个时长有几秒的视频\n看来依靠HttpUrlConnection中的SocketTimeoutException是无解了，只能在外面套一层了。main方法改成如下\npublic static void main(String[] args) throws Exception {\rfinal ExecutorService exec = Executors.newFixedThreadPool(1);\rCallable\u0026lt;String\u0026gt; call = new Callable\u0026lt;String\u0026gt;() {\rpublic String call() throws Exception {\r//开始执行耗时操作\rreqUrl();\rreturn \u0026quot;线程执行完成.\u0026quot;;\r}\r};\rFuture\u0026lt;String\u0026gt; future = null;\rtry {\rfuture = exec.submit(call);\rString obj = future.get(1000 * 10, TimeUnit.MILLISECONDS); //任务处理超时时间设为 10 秒\rSystem.out.println(\u0026quot;任务成功返回:\u0026quot; + obj);\r} catch (TimeoutException ex) {\rSystem.out.println(\u0026quot;处理超时啦....\u0026quot;);\rex.printStackTrace();\rfuture.cancel(true);\r} catch (Exception e) {\rSystem.out.println(\u0026quot;处理失败.\u0026quot;);\re.printStackTrace();\r}finally {\r// 关闭线程池\rSystem.out.println(\u0026quot;关闭线程池\u0026quot;);\rexec.shutdown();\r}\r}\r这下能得到期望的结果了\nContent-Type: multipart/x-mixed-replace;boundary=---nessy2jpegboundary\rOkHttp-Sent-Millis: 1582028854911\rOkHttp-Received-Millis: 1582028855178\r处理超时啦....\rjava.util.concurrent.TimeoutException\rat java.util.concurrent.FutureTask.get(FutureTask.java:205)\rat sms.bai.util.Req.main(Req.java:47)\r关闭线程池\rProcess finished with exit code 0\r那这个HttpUrlConnection里的超时到底是啥意思呢？为什么无效呢？看一下文档。 ConnectTimeout , java 是这样解释的：\nSets a specified timeout value, in milliseconds, to be used when opening a communications link to the resource referenced by this URLConnection. If the timeout expires before the connection can be established, a java.net.SocketTimeoutException is raised. A timeout of zero is interpreted as an infinite timeout.\nSome non-standard implmentation of this method may ignore the specified timeout. To see the connect timeout set, please call getConnectTimeout().\n意思是用来建立连接的时间。如果到了指定的时间，还没建立连接，则报异常。 这个比较好理解。\nReadTimeout , Java 是这样解释的：\nSets the read timeout to a specified timeout, in milliseconds. A non-zero value specifies the timeout when reading from Input stream when a connection is established to a resource. If the timeout expires before there is data available for read, a java.net.SocketTimeoutException is raised. A timeout of zero is interpreted as an infinite timeout.\nSome non-standard implementation of this method ignores the specified timeout. To see the read timeout set, please call getReadTimeout().\n意思是已经建立连接，并开始读取服务端资源。如果到了指定的时间，没有可能的数据被客户端读取，则报异常。\n也就是说setReadTimeout not mean read complete, it mean when wait for 10s, when there\u0026rsquo;re no more data read in, will throw a timeoutexception。\n所以针对这种特殊的服务器构造的异常流，是没法用SocketTimeoutException来解决超时的，只能在外面再设置一层，通过线程的超时来控制。\n另外提一句，python是通过设置gevent超时来解决的，原理是一样的。\ntips：360大佬认为，这种特殊URL，不失为一种给爬虫挖坑的做法。\n","date":"2020-02-18","permalink":"http://localhost:1313/post/httpurlconnection%E9%87%8Csetreadtimeout%E8%B6%85%E6%97%B6%E6%97%A0%E6%95%88/","tags":["Java"],"title":"HttpURLConnection里setReadTimeout超时无效"},{"content":"k8s每个版本看起来兼容性不是太好，很多网上的例子跑起来往往都有问题。\n目前用的版本\nroot@de001:/develop# kubectl version\rClient Version: version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;17\u0026quot;, GitVersion:\u0026quot;v1.17.2+k3s1\u0026quot;, GitCommit:\u0026quot;cdab19b09a84389ffbf57bebd33871c60b1d6b28\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2020-01-27T18:09:26Z\u0026quot;, GoVersion:\u0026quot;go1.13.6\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;}\rServer Version: version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;17\u0026quot;, GitVersion:\u0026quot;v1.17.2+k3s1\u0026quot;, GitCommit:\u0026quot;cdab19b09a84389ffbf57bebd33871c60b1d6b28\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2020-01-27T18:09:26Z\u0026quot;, GoVersion:\u0026quot;go1.13.6\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;}\r1.编写Spec文档 apiVersion: apiextensions.k8s.io/v1beta1\rkind: CustomResourceDefinition\rmetadata:\r# name must match the spec fields below, and be in the form: \u0026lt;plural\u0026gt;.\u0026lt;group\u0026gt;\rname: crontabs.chenwen.com\rspec:\r# group name to use for REST API: /apis/\u0026lt;group\u0026gt;/\u0026lt;version\u0026gt;\rgroup: chenwen.com\r# list of versions supported by this CustomResourceDefinition\rversions:\r- name: v2\r# Each version can be enabled/disabled by Served flag.\rserved: true\r# One and only one version must be marked as the storage version.\rstorage: true\r# A schema is required\r# The conversion section is introduced in Kubernetes 1.13+ with a default value of\r# None conversion (strategy sub-field set to None).\rconversion:\r# None conversion assumes the same schema for all versions and only sets the apiVersion\r# field of custom resources to the proper value\rstrategy: None\r# either Namespaced or Cluster\rscope: Namespaced\rnames:\r# plural name to be used in the URL: /apis/\u0026lt;group\u0026gt;/\u0026lt;version\u0026gt;/\u0026lt;plural\u0026gt;\rplural: crontabs\r# singular name to be used as an alias on the CLI and for display\rsingular: crontab\r# kind is normally the CamelCased singular type. Your resource manifests use this.\rkind: Crontab\rlistKind: CrontabList\r# shortNames allow shorter string to match your resource on the CLI\rshortNames:\r- ct 2.导入K8S ln -s /etc/rancher/k3s/k3s.yaml ~/.kube/config\rkubectl apply -f crontab_crd.yml\rkubectl get crd\r可以看到自己创建的crd了。\n查看这个CRD\nroot@de001:/develop# kubectl describe crontabs.chenwen.com\rName: my-test-crontab\rNamespace: default\rLabels: \u0026lt;none\u0026gt;\rAnnotations: kubectl.kubernetes.io/last-applied-configuration:\r{\u0026quot;apiVersion\u0026quot;:\u0026quot;chenwen.com/v2\u0026quot;,\u0026quot;kind\u0026quot;:\u0026quot;Crontab\u0026quot;,\u0026quot;metadata\u0026quot;:{\u0026quot;annotations\u0026quot;:{},\u0026quot;name\u0026quot;:\u0026quot;my-test-crontab\u0026quot;,\u0026quot;namespace\u0026quot;:\u0026quot;default\u0026quot;},\u0026quot;spec\u0026quot;:{\u0026quot;cron...\rAPI Version: chenwen.com/v2\rKind: Crontab\rMetadata:\rCreation Timestamp: 2020-02-05T06:09:10Z\rGeneration: 1\rResource Version: 19965\rSelf Link: /apis/chenwen.com/v2/namespaces/default/crontabs/my-test-crontab\rUID: 27beca8a-0ddb-4861-8643-90bb2f850b0d\rSpec:\rCron Spec: * * * * */10\rImage: my-test-image\rReplicas: 2\rEvents: \u0026lt;none\u0026gt;\rroot@de001:/develop# rancher启动的时候也会给K8S注册一些CRD\n不太清楚这样创建的CRD里用rancher的API是否能看到（rancher环境未搭建好测试 ）\n添加一个自定义对象\napiVersion: chenwen.com/v2\rkind: Crontab\rmetadata:\rname: my-test-crontab\rspec:\rcronSpec: \u0026quot;* * * * */10\u0026quot;\rimage: my-test-image\rreplicas: 2\r导入\nkubectl apply -f test_crd.yml\rkubectl get ct\r#删除自定义对象\rkubectl delete ct my-test-crontab\r#删除CRD\rkubectl delete crd crontabs.chenwen.com\r运行结果：\nroot@de001:/develop# kubectl get crd|grep cron\rcrontabs.chenwen.com 2020-02-05T06:08:53Z\rroot@de001:/develop# kubectl get ct\rNAME AGE\rmy-test-crontab 75s\rroot@de001:/develop# 3.代码生成 先在gopath下建立如下目录\ngo\r└── src\r└── github.com\r└── examplechen\r└── go.mod\r└── hack\r└── pkg\r└── apis\r└── chenwen.com\r└── v1\r├── doc.go\r└── types.go\r└── pkg\r└── bin\r然后安装https://github.com/kubernetes/code-generator 项目的代码到gopath下。\ndoc.go文件内容\n// FileName: doc.go\r// Distributed under terms of the GPL license.\r// +k8s:deepcopy-gen=package\r// Package v1 is the v1 version of the API.\r// +groupName=chenwen.com\rpackage v1 上述代码中的两行注释，都是代码生成工具会用到的，一个是声明为整个v1包下的类型定义生成DeepCopy方法，另一个声明了这个包对应的API的组名，和CRD中的组名一致\n“// +k8s:deepcopy-gen=package”：为这个package中的所有type生成deepcopy代码。\n“// +groupName=crd.lijiaocn.com”：设置这个package对应的api group。\ntypes.go文件内容\npackage v1\rimport (\rmetav1 \u0026quot;k8s.io/apimachinery/pkg/apis/meta/v1\u0026quot;\r)\r// +genclient\r// +genclient:noStatus\r// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object\r// CronTab is a top-level type. A client is created for it.\r// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object\rtype Crontab struct {\rmetav1.TypeMeta `json:\u0026quot;,inline\u0026quot;`\r// +optional\rmetav1.ObjectMeta `json:\u0026quot;metadata,omitempty\u0026quot;`\r// Username unique username of the consumer.\rUsername string `json:\u0026quot;username,omitempty\u0026quot;`\r// CustomID existing unique ID for the consumer - useful for mapping\r// Kong with users in your existing database\rCustomID string `json:\u0026quot;custom_id,omitempty\u0026quot;`\r// Spec is the custom resource spec\rSpec CrontabSpec `json:\u0026quot;spec\u0026quot;`\r}\r// the spec for a MyResource resource\rtype CrontabSpec struct {\rMin int `json:\u0026quot;min\u0026quot;`\r}\r// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object\rtype CrontabList struct {\rmetav1.TypeMeta `json:\u0026quot;,inline\u0026quot;`\rmetav1.ListMeta `json:\u0026quot;metadata\u0026quot;`\rItems []Crontab `json:\u0026quot;items\u0026quot;`\r}\r// Configuration contains a plugin configuration\r// +k8s:deepcopy-gen=false\rtype Configuration map[string]interface{} “// +genclient”：为该type生成client代码。\n“// +genclient:noStatus”：为该type生成的client代码，不包含UpdateStatus方法。\n“// +genclient:nonNamespaced”：如果是集群资源，设置为不带namespace。\n还支持在注释中使用以下tag：\n// +genclient:noVerbs\r// +genclient:onlyVerbs=create,delete\r// +genclient:skipVerbs=get,list,create,update,patch,delete,deleteCollection,watch\r// +genclient:method=Create,verb=create,result=k8s.io/apimachinery/pkg/apis/meta/v1.Status\r==CrontabSpec结构体的字段不需要和yaml文件里的Spec 部分一一对应==。\n同级目录编写register.go (这个文件非必须，此文件的作用是通过addKnownTypes方法使得client可以知道Crontab类型的API对象)\npackage v1\rimport (\rmetav1 \u0026quot;k8s.io/apimachinery/pkg/apis/meta/v1\u0026quot;\r\u0026quot;k8s.io/apimachinery/pkg/runtime\u0026quot;\r\u0026quot;k8s.io/apimachinery/pkg/runtime/schema\u0026quot;\rexamplecom \u0026quot;github.com/examplechen/pkg/apis/chenwen.com\u0026quot;\r)\r// SchemeGroupVersion is group version used to register these objects\rvar SchemeGroupVersion = schema.GroupVersion{Group: examplecom.GroupName, Version: \u0026quot;v1\u0026quot;}\r// Resource takes an unqualified resource and returns a Group qualified GroupResource\rfunc Resource(resource string) schema.GroupResource {\rreturn SchemeGroupVersion.WithResource(resource).GroupResource()\r}\rvar (\r// localSchemeBuilder and AddToScheme will stay in k8s.io/kubernetes.\rSchemeBuilder runtime.SchemeBuilder\rlocalSchemeBuilder = \u0026amp;SchemeBuilder\rAddToScheme = localSchemeBuilder.AddToScheme\r)\rfunc init() {\r// We only register manually written functions here. The registration of the\r// generated functions takes place in the generated files. The separation\r// makes the code compile even when the generated files are missing.\rlocalSchemeBuilder.Register(addKnownTypes)\r}\r// Adds the list of known types to api.Scheme.\rfunc addKnownTypes(scheme *runtime.Scheme) error {\rscheme.AddKnownTypes(SchemeGroupVersion,\r\u0026amp;Crontab{},\r\u0026amp;CrontabList{},\r)\rmetav1.AddToGroupVersion(scheme, SchemeGroupVersion)\rreturn nil\r}\rgo.mod文件内容\nmodule github.com/examplechen\rgo 1.13\r生成代码只需要以上三个文件和其对应的目录结构\n生成代码\n[koudai@koudai-pc v1]$ /develop/go/src/k8s.io/code-generator/generate-groups.sh all github.com/examplechen/pkg/client/crontab github.com/examplechen/pkg/apis chenwen.com:v1\rGenerating deepcopy funcs\rGenerating clientset for chenwen.com:v1 at github.com/examplechen/pkg/client/crontab/clientset\rGenerating listers for chenwen.com:v1 at github.com/examplechen/pkg/client/crontab/listers\rGenerating informers for chenwen.com:v1 at github.com/examplechen/pkg/client/crontab/informers\r尤其需要注意的是generate-groups.sh必须是==绝对路径==，不能是进入到code-generator目录下执行相对路径，不然会报找不到包的报错。\n另外，需要进入到examplechen目录执行，不然会报莫名其妙如下的错误\nGenerating deepcopy funcs\rF0210 17:31:46.418659 16605 deepcopy.go:885] Hit an unsupported type invalid type for invalid type, from github.com/examplechen/pkg/apis/chenwen.com/v1.Crontab\r生成后的目录树如下：\n[koudai@koudai-pc examplechen]$ tree\r.\r├── go.mod\r├── go.sum\r├── hack\r│ └── boilerplate.go.txt\r└── pkg\r├── apis\r│ └── chenwen.com\r│ ├── register.go\r│ └── v1\r│ ├── doc.go\r│ ├── types.go\r│ └── zz_generated.deepcopy.go\r└── client\r└── crontab\r├── clientset\r│ └── versioned\r│ ├── clientset.go\r│ ├── doc.go\r│ ├── fake\r│ │ ├── clientset_generated.go\r│ │ ├── doc.go\r│ │ └── register.go\r│ ├── scheme\r│ │ ├── doc.go\r│ │ └── register.go\r│ └── typed\r│ └── chenwen.com\r│ └── v1\r│ ├── chenwen.com_client.go\r│ ├── crontab.go\r│ ├── doc.go\r│ ├── fake\r│ │ ├── doc.go\r│ │ ├── fake_chenwen.com_client.go\r│ │ └── fake_crontab.go\r│ └── generated_expansion.go\r├── informers\r│ └── externalversions\r│ ├── chenwen.com\r│ │ ├── interface.go\r│ │ └── v1\r│ │ ├── crontab.go\r│ │ └── interface.go\r│ ├── factory.go\r│ ├── generic.go\r│ └── internalinterfaces\r│ └── factory_interfaces.go\r└── listers\r└── chenwen.com\r└── v1\r├── crontab.go\r└── expansion_generated.go\r23 directories, 29 files\r4.使用自动生成的代码 examplechen 下新建main.go用来测试\npackage main\rimport (\r\u0026quot;flag\u0026quot;\r\u0026quot;fmt\u0026quot;\r\u0026quot;github.com/golang/glog\u0026quot;\rmetav1 \u0026quot;k8s.io/apimachinery/pkg/apis/meta/v1\u0026quot;\r\u0026quot;k8s.io/client-go/tools/clientcmd\u0026quot;\r\u0026quot;k8s.io/client-go/rest\u0026quot;\rexamplecomclientset \u0026quot;github.com/examplechen/pkg/client/crontab/clientset/versioned\u0026quot;\r)\rvar (\rkuberconfig = flag.String(\u0026quot;kubeconfig\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;Path to a kubeconfig. Only required if out-of-cluster.\u0026quot;)\rmaster = flag.String(\u0026quot;master\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;The address of the Kubernetes API server. Overrides any value in kubeconfig. Only required if out-of-cluster.\u0026quot;)\r)\rfunc main() {\rflag.Parse()\rcfg, err := buildConfig(\u0026quot;https://127.0.0.1:6443\u0026quot;, \u0026quot;/root/.kube/config\u0026quot;)\rif err != nil {\rfmt.Printf(\u0026quot;%v\\n\u0026quot;, err)\rreturn\r}\rexampleClient, err := examplecomclientset.NewForConfig(cfg)\rif err != nil {\rglog.Fatalf(\u0026quot;Error building example clientset: %v\u0026quot;, err)\r}\rlist, err := exampleClient.ChenwenV1().Crontabs(\u0026quot;default\u0026quot;).List(metav1.ListOptions{})\rif err != nil {\rglog.Fatalf(\u0026quot;Error listing all databases: %v\u0026quot;, err)\r}\rfor _, db := range list.Items {\rfmt.Printf(\u0026quot;database %s with user %q\\n\u0026quot;, db.Name, db.Spec.Min)\r}\r}\rfunc buildConfig(master, kubeconfig string) (*rest.Config, error) {\rif master != \u0026quot;\u0026quot; || kubeconfig != \u0026quot;\u0026quot; {\rreturn clientcmd.BuildConfigFromFlags(master, kubeconfig)\r}\rreturn rest.InClusterConfig()\r}\r编译通过，但运行报错。\nF0210 14:19:32.477583 1845 main.go:39] Error listing all databases: the server could not find the requested resource (get crontabs.chenwen.com)\r经检查，是版本号不一致造成，将yml文件里的版本号v2换成v1，另一个yml文件同理\nspec:\r# group name to use for REST API: /apis/\u0026lt;group\u0026gt;/\u0026lt;version\u0026gt;\rgroup: chenwen.com\r# list of versions supported by this CustomResourceDefinition\rversions:\r- name: v1 # 把v2换成v1，需要和API对应\r重新编译，运行结果如下，符合预期\n#go build\r#./examplechenold -kubeconfig=$HOME/.kube/config database my-test-crontab with user '\\x00'\rdatabase my-test-crontab2 with user '\\x00'\r5.进一步了解API 再写个稍微复杂点的例子\n在 项目根目录下新建controller.go文件\npackage main\rimport (\r\u0026quot;fmt\u0026quot;\r\u0026quot;time\u0026quot;\r\u0026quot;github.com/golang/glog\u0026quot;\rcorev1 \u0026quot;k8s.io/api/core/v1\u0026quot;\r\u0026quot;k8s.io/apimachinery/pkg/api/errors\u0026quot;\r\u0026quot;k8s.io/apimachinery/pkg/util/runtime\u0026quot;\rutilruntime \u0026quot;k8s.io/apimachinery/pkg/util/runtime\u0026quot;\r\u0026quot;k8s.io/apimachinery/pkg/util/wait\u0026quot;\r\u0026quot;k8s.io/client-go/kubernetes\u0026quot;\r\u0026quot;k8s.io/client-go/kubernetes/scheme\u0026quot;\rtypedcorev1 \u0026quot;k8s.io/client-go/kubernetes/typed/core/v1\u0026quot;\r\u0026quot;k8s.io/client-go/tools/cache\u0026quot;\r\u0026quot;k8s.io/client-go/tools/record\u0026quot;\r\u0026quot;k8s.io/client-go/util/workqueue\u0026quot;\rbolingcavalryv1 \u0026quot;github.com/examplechen/pkg/apis/chenwen.com/v1\u0026quot;\rclientset \u0026quot;github.com/examplechen/pkg/client/crontab/clientset/versioned\u0026quot;\rcronscheme \u0026quot;github.com/examplechen/pkg/client/crontab/clientset/versioned/scheme\u0026quot;\rinformers \u0026quot;github.com/examplechen/pkg/client/crontab/informers/externalversions/chenwen.com/v1\u0026quot;\rlisters \u0026quot;github.com/examplechen/pkg/client/crontab/listers/chenwen.com/v1\u0026quot;\r)\rconst controllerAgentName = \u0026quot;student-controller\u0026quot;\rconst (\rSuccessSynced = \u0026quot;Synced\u0026quot;\rMessageResourceSynced = \u0026quot;Student synced successfully\u0026quot;\r)\r// Controller is the controller implementation for Student resources\rtype Controller struct {\r// kubeclientset is a standard kubernetes clientset\rkubeclientset kubernetes.Interface\r// cronclientset is a clientset for our own API group\rcronclientset clientset.Interface\rcronsLister listers.CrontabLister\rcronsSynced cache.InformerSynced\rworkqueue workqueue.RateLimitingInterface\rrecorder record.EventRecorder\r}\r// NewController returns a new student controller\rfunc NewController(\rkubeclientset kubernetes.Interface,\rcronclientset clientset.Interface,\rcronInformer informers.CrontabInformer) *Controller {\rutilruntime.Must(cronscheme.AddToScheme(scheme.Scheme))\rglog.V(4).Info(\u0026quot;Creating event broadcaster\u0026quot;)\reventBroadcaster := record.NewBroadcaster()\reventBroadcaster.StartLogging(glog.Infof)\reventBroadcaster.StartRecordingToSink(\u0026amp;typedcorev1.EventSinkImpl{Interface: kubeclientset.CoreV1().Events(\u0026quot;\u0026quot;)})\rrecorder := eventBroadcaster.NewRecorder(scheme.Scheme, corev1.EventSource{Component: controllerAgentName})\rcontroller := \u0026amp;Controller{\rkubeclientset: kubeclientset,\rcronclientset: cronclientset,\rcronsLister: cronInformer.Lister(),\rcronsSynced: cronInformer.Informer().HasSynced,\rworkqueue: workqueue.NewNamedRateLimitingQueue(workqueue.DefaultControllerRateLimiter(), \u0026quot;Students\u0026quot;),\rrecorder: recorder,\r}\rglog.Info(\u0026quot;Setting up event handlers\u0026quot;)\r// Set up an event handler for when Student resources change\rcronInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{\rAddFunc: controller.enqueueStudent,\rUpdateFunc: func(old, new interface{}) {\roldStudent := old.(*bolingcavalryv1.Crontab)\rnewStudent := new.(*bolingcavalryv1.Crontab)\rif oldStudent.ResourceVersion == newStudent.ResourceVersion {\r//版本一致，就表示没有实际更新的操作，立即返回\rreturn\r}\rcontroller.enqueueStudent(new)\r},\rDeleteFunc: controller.enqueueStudentForDelete,\r})\rreturn controller\r}\r//在此处开始controller的业务\rfunc (c *Controller) Run(threadiness int, stopCh \u0026lt;-chan struct{}) error {\rdefer runtime.HandleCrash()\rdefer c.workqueue.ShutDown()\rglog.Info(\u0026quot;开始controller业务，开始一次缓存数据同步\u0026quot;)\rif ok := cache.WaitForCacheSync(stopCh, c.cronsSynced); !ok {\rreturn fmt.Errorf(\u0026quot;failed to wait for caches to sync\u0026quot;)\r}\rglog.Info(\u0026quot;worker启动\u0026quot;)\rfor i := 0; i \u0026lt; threadiness; i++ {\rgo wait.Until(c.runWorker, time.Second, stopCh)\r}\rglog.Info(\u0026quot;worker已经启动\u0026quot;)\r\u0026lt;-stopCh\rglog.Info(\u0026quot;worker已经结束\u0026quot;)\rreturn nil\r}\rfunc (c *Controller) runWorker() {\rfor c.processNextWorkItem() {\r}\r}\r// 取数据处理\rfunc (c *Controller) processNextWorkItem() bool {\robj, shutdown := c.workqueue.Get()\rif shutdown {\rreturn false\r}\r// We wrap this block in a func so we can defer c.workqueue.Done.\rerr := func(obj interface{}) error {\rdefer c.workqueue.Done(obj)\rvar key string\rvar ok bool\rif key, ok = obj.(string); !ok {\rc.workqueue.Forget(obj)\rruntime.HandleError(fmt.Errorf(\u0026quot;expected string in workqueue but got %#v\u0026quot;, obj))\rreturn nil\r}\r// 在syncHandler中处理业务\rif err := c.syncHandler(key); err != nil {\rreturn fmt.Errorf(\u0026quot;error syncing '%s': %s\u0026quot;, key, err.Error())\r}\rc.workqueue.Forget(obj)\rglog.Infof(\u0026quot;Successfully synced '%s'\u0026quot;, key)\rreturn nil\r}(obj)\rif err != nil {\rruntime.HandleError(err)\rreturn true\r}\rreturn true\r}\r// 处理\rfunc (c *Controller) syncHandler(key string) error {\r// Convert the namespace/name string into a distinct namespace and name\rnamespace, name, err := cache.SplitMetaNamespaceKey(key)\rif err != nil {\rruntime.HandleError(fmt.Errorf(\u0026quot;invalid resource key: %s\u0026quot;, key))\rreturn nil\r}\r// 从缓存中取对象\rstudent, err := c.cronsLister.Crontabs(namespace).Get(name)\rif err != nil {\r// 如果Cron对象被删除了，就会走到这里，所以应该在这里加入执行\rif errors.IsNotFound(err) {\rglog.Infof(\u0026quot;Student对象被删除，请在这里执行实际的删除业务: %s/%s ...\u0026quot;, namespace, name)\rreturn nil\r}\rruntime.HandleError(fmt.Errorf(\u0026quot;failed to list student by: %s/%s\u0026quot;, namespace, name))\rreturn err\r}\rglog.Infof(\u0026quot;这里是cron对象的期望状态: %#v ...\u0026quot;, student)\rglog.Infof(\u0026quot;实际状态是从业务层面得到的，此处应该去的实际状态，与期望状态做对比，并根据差异做出响应(新增或者删除)\u0026quot;)\rc.recorder.Event(student, corev1.EventTypeNormal, SuccessSynced, MessageResourceSynced)\rreturn nil\r}\r// 数据先放入缓存，再入队列\rfunc (c *Controller) enqueueStudent(obj interface{}) {\rvar key string\rvar err error\r// 将对象放入缓存\rif key, err = cache.MetaNamespaceKeyFunc(obj); err != nil {\rruntime.HandleError(err)\rreturn\r}\r// 将key放入队列\rc.workqueue.AddRateLimited(key)\r}\r// 删除操作\rfunc (c *Controller) enqueueStudentForDelete(obj interface{}) {\rvar key string\rvar err error\r// 从缓存中删除指定对象\rkey, err = cache.DeletionHandlingMetaNamespaceKeyFunc(obj)\rif err != nil {\rruntime.HandleError(err)\rreturn\r}\r//再将key放入队列\rc.workqueue.AddRateLimited(key)\r}\r然后是 main.go\npackage main\rimport (\r\u0026quot;flag\u0026quot;\r\u0026quot;fmt\u0026quot;\r\u0026quot;time\u0026quot;\r\u0026quot;github.com/golang/glog\u0026quot;\r\u0026quot;k8s.io/client-go/tools/clientcmd\u0026quot;\r\u0026quot;k8s.io/client-go/kubernetes\u0026quot;\rinformers \u0026quot;github.com/examplechen/pkg/client/crontab/informers/externalversions\u0026quot;\r\u0026quot;github.com/examplechen/pkg/signals\u0026quot;\rexamplecomclientset \u0026quot;github.com/examplechen/pkg/client/crontab/clientset/versioned\u0026quot;\r)\rvar (\rkubeconfig string\rmaster string\r)\rfunc main() {\rflag.Parse()\r// 处理信号量\rstopCh := signals.SetupSignalHandler()\rcfg, err := clientcmd.BuildConfigFromFlags(master, kubeconfig)\rif err != nil {\rfmt.Printf(\u0026quot;%v\\n\u0026quot;, err)\rreturn\r}\rkubeClient, err := kubernetes.NewForConfig(cfg)\rif err != nil {\rglog.Fatalf(\u0026quot;Error building kubernetes clientset: %s\u0026quot;, err.Error())\r}\rexampleClient, err := examplecomclientset.NewForConfig(cfg)\rif err != nil {\rglog.Fatalf(\u0026quot;Error building example clientset: %v\u0026quot;, err)\r}\rstudentInformerFactory := informers.NewSharedInformerFactory(exampleClient, time.Second*30)\r//得到controller\rcontroller := NewController(kubeClient, exampleClient,\rstudentInformerFactory.Chenwen().V1().Crontabs())\r//启动informer\rgo studentInformerFactory.Start(stopCh)\r//controller开始处理消息\rif err = controller.Run(2, stopCh); err != nil {\rglog.Fatalf(\u0026quot;Error running controller: %s\u0026quot;, err.Error())\r}\r}\rfunc init() {\rflag.StringVar(\u0026amp;kubeconfig, \u0026quot;kubeconfig\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;Path to a kubeconfig. Only required if out-of-cluster.\u0026quot;)\rflag.StringVar(\u0026amp;master, \u0026quot;master\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;The address of the Kubernetes API server. Overrides any value in kubeconfig. Only required if out-of-cluster.\u0026quot;)\r}\r编译运行\nroot@de001:/develop# ./examplechen -kubeconfig=$HOME/.kube/config I0210 17:40:22.161175 18552 controller.go:72] Setting up event handlers\rI0210 17:40:22.161769 18552 controller.go:96] 开始controller业务，开始一次缓存数据同步\rI0210 17:40:22.262540 18552 controller.go:101] worker启动\rI0210 17:40:22.262616 18552 controller.go:106] worker已经启动\rI0210 17:40:22.262693 18552 controller.go:181] 这里是student对象的期望状态: \u0026amp;v1.Crontab{TypeMeta:v1.TypeMeta{Kind:\u0026quot;Crontab\u0026quot;, APIVersion:\u0026quot;chenwen.com/v1\u0026quot;}, ObjectMeta:v1.ObjectMeta{Name:\u0026quot;my-test-crontab2\u0026quot;, GenerateName:\u0026quot;\u0026quot;, Namespace:\u0026quot;default\u0026quot;, SelfLink:\u0026quot;/apis/chenwen.com/v1/namespaces/default/crontabs/my-test-crontab2\u0026quot;, UID:\u0026quot;ab5e00e6-88e4-4b7e-b587-f5797baec3eb\u0026quot;, ResourceVersion:\u0026quot;29576\u0026quot;, Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63716923534, loc:(*time.Location)(0x1e56c60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string{\u0026quot;kubectl.kubernetes.io/last-applied-configuration\u0026quot;:\u0026quot;{\\\u0026quot;apiVersion\\\u0026quot;:\\\u0026quot;chenwen.com/v1\\\u0026quot;,\\\u0026quot;kind\\\u0026quot;:\\\u0026quot;Crontab\\\u0026quot;,\\\u0026quot;metadata\\\u0026quot;:{\\\u0026quot;annotations\\\u0026quot;:{},\\\u0026quot;name\\\u0026quot;:\\\u0026quot;my-test-crontab2\\\u0026quot;,\\\u0026quot;namespace\\\u0026quot;:\\\u0026quot;default\\\u0026quot;},\\\u0026quot;spec\\\u0026quot;:{\\\u0026quot;cronSpec\\\u0026quot;:\\\u0026quot;* * * * */10\\\u0026quot;,\\\u0026quot;image\\\u0026quot;:\\\u0026quot;my-test-image\\\u0026quot;,\\\u0026quot;replicas\\\u0026quot;:2}}\\n\u0026quot;}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:\u0026quot;\u0026quot;, ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Username:\u0026quot;\u0026quot;, CustomID:\u0026quot;\u0026quot;, Spec:v1.CrontabSpec{Min:0}} ...\rI0210 17:40:22.262988 18552 controller.go:182] 实际状态是从业务层面得到的，此处应该去的实际状态，与期望状态做对比，并根据差异做出响应(新增或者删除)\rI0210 17:40:22.263039 18552 controller.go:145] Successfully synced 'default/my-test-crontab2'\rI0210 17:40:22.263063 18552 controller.go:181] 这里是student对象的期望状态: \u0026amp;v1.Crontab{TypeMeta:v1.TypeMeta{Kind:\u0026quot;Crontab\u0026quot;, APIVersion:\u0026quot;chenwen.com/v1\u0026quot;}, ObjectMeta:v1.ObjectMeta{Name:\u0026quot;my-test-crontab\u0026quot;, GenerateName:\u0026quot;\u0026quot;, Namespace:\u0026quot;default\u0026quot;, SelfLink:\u0026quot;/apis/chenwen.com/v1/namespaces/default/crontabs/my-test-crontab\u0026quot;, UID:\u0026quot;72036436-451a-4ec5-9851-bc27342faa5f\u0026quot;, ResourceVersion:\u0026quot;29532\u0026quot;, Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63716923360, loc:(*time.Location)(0x1e56c60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string{\u0026quot;kubectl.kubernetes.io/last-applied-configuration\u0026quot;:\u0026quot;{\\\u0026quot;apiVersion\\\u0026quot;:\\\u0026quot;chenwen.com/v1\\\u0026quot;,\\\u0026quot;kind\\\u0026quot;:\\\u0026quot;Crontab\\\u0026quot;,\\\u0026quot;metadata\\\u0026quot;:{\\\u0026quot;annotations\\\u0026quot;:{},\\\u0026quot;name\\\u0026quot;:\\\u0026quot;my-test-crontab\\\u0026quot;,\\\u0026quot;namespace\\\u0026quot;:\\\u0026quot;default\\\u0026quot;},\\\u0026quot;spec\\\u0026quot;:{\\\u0026quot;cronSpec\\\u0026quot;:\\\u0026quot;* * * * */10\\\u0026quot;,\\\u0026quot;image\\\u0026quot;:\\\u0026quot;my-test-image\\\u0026quot;,\\\u0026quot;replicas\\\u0026quot;:2}}\\n\u0026quot;}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:\u0026quot;\u0026quot;, ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Username:\u0026quot;\u0026quot;, CustomID:\u0026quot;\u0026quot;, Spec:v1.CrontabSpec{Min:0}} ...\rI0210 17:40:22.263157 18552 controller.go:182] 实际状态是从业务层面得到的，此处应该去的实际状态，与期望状态做对比，并根据差异做出响应(新增或者删除)\rI0210 17:40:22.263185 18552 controller.go:145] Successfully synced 'default/my-test-crontab'\rI0210 17:40:22.265730 18552 event.go:278] Event(v1.ObjectReference{Kind:\u0026quot;Crontab\u0026quot;, Namespace:\u0026quot;default\u0026quot;, Name:\u0026quot;my-test-crontab\u0026quot;, UID:\u0026quot;72036436-451a-4ec5-9851-bc27342faa5f\u0026quot;, APIVersion:\u0026quot;chenwen.com/v1\u0026quot;, ResourceVersion:\u0026quot;29532\u0026quot;, FieldPath:\u0026quot;\u0026quot;}): type: 'Normal' reason: 'Synced' Student synced successfully\rI0210 17:40:22.265885 18552 event.go:278] Event(v1.ObjectReference{Kind:\u0026quot;Crontab\u0026quot;, Namespace:\u0026quot;default\u0026quot;, Name:\u0026quot;my-test-crontab2\u0026quot;, UID:\u0026quot;ab5e00e6-88e4-4b7e-b587-f5797baec3eb\u0026quot;, APIVersion:\u0026quot;chenwen.com/v1\u0026quot;, ResourceVersion:\u0026quot;29576\u0026quot;, FieldPath:\u0026quot;\u0026quot;}): type: 'Normal' reason: 'Synced' Student synced successfully\rI0210 17:41:00.324824 18552 controller.go:181] 这里是student对象的期望状态: \u0026amp;v1.Crontab{TypeMeta:v1.TypeMeta{Kind:\u0026quot;\u0026quot;, APIVersion:\u0026quot;\u0026quot;}, ObjectMeta:v1.ObjectMeta{Name:\u0026quot;my-test-crontab2\u0026quot;, GenerateName:\u0026quot;\u0026quot;, Namespace:\u0026quot;default\u0026quot;, SelfLink:\u0026quot;/apis/chenwen.com/v1/namespaces/default/crontabs/my-test-crontab2\u0026quot;, UID:\u0026quot;ab5e00e6-88e4-4b7e-b587-f5797baec3eb\u0026quot;, ResourceVersion:\u0026quot;29811\u0026quot;, Generation:2, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63716923534, loc:(*time.Location)(0x1e56c60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string{\u0026quot;kubectl.kubernetes.io/last-applied-configuration\u0026quot;:\u0026quot;{\\\u0026quot;apiVersion\\\u0026quot;:\\\u0026quot;chenwen.com/v1\\\u0026quot;,\\\u0026quot;kind\\\u0026quot;:\\\u0026quot;Crontab\\\u0026quot;,\\\u0026quot;metadata\\\u0026quot;:{\\\u0026quot;annotations\\\u0026quot;:{},\\\u0026quot;name\\\u0026quot;:\\\u0026quot;my-test-crontab2\\\u0026quot;,\\\u0026quot;namespace\\\u0026quot;:\\\u0026quot;default\\\u0026quot;},\\\u0026quot;spec\\\u0026quot;:{\\\u0026quot;cronSpec\\\u0026quot;:\\\u0026quot;* 5 * * */10\\\u0026quot;,\\\u0026quot;image\\\u0026quot;:\\\u0026quot;my-test-image\\\u0026quot;,\\\u0026quot;replicas\\\u0026quot;:2}}\\n\u0026quot;}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:\u0026quot;\u0026quot;, ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Username:\u0026quot;\u0026quot;, CustomID:\u0026quot;\u0026quot;, Spec:v1.CrontabSpec{Min:0}} ...\r6.验证controller 新开一个窗口连接到k8s环境，新建一个名为test2_crd.yml的文件，内容如下\napiVersion: chenwen.com/v1\rkind: Crontab\rmetadata:\rname: my-test-crontab2\rspec:\rcronSpec: \u0026quot;* 5 * * */10\u0026quot;\rimage: my-test-image\rreplicas: 2\r执行命令\nkubectl apply -f test2_crd.yml 返回controller所在的控制台窗口，发现新输出了如下内容，可见新增Crontab对象的事件已经被controller监听并处理：\nI0210 17:41:00.324974 18552 controller.go:182] 实际状态是从业务层面得到的，此处应该去的实际状态，与期望状态做对比，并根据差异做出响应(新增或者删除)\rI0210 17:41:00.325006 18552 controller.go:145] Successfully synced 'default/my-test-crontab2'\rI0210 17:41:00.332401 18552 event.go:278] Event(v1.ObjectReference{Kind:\u0026quot;Crontab\u0026quot;, Namespace:\u0026quot;default\u0026quot;, Name:\u0026quot;my-test-crontab2\u0026quot;, UID:\u0026quot;ab5e00e6-88e4-4b7e-b587-f5797baec3eb\u0026quot;, APIVersion:\u0026quot;chenwen.com/v1\u0026quot;, ResourceVersion:\u0026quot;29811\u0026quot;, FieldPath:\u0026quot;\u0026quot;}): type: 'Normal' reason: 'Synced' Student synced successfully\r接下来您也可以尝试修改和删除已有的Crontab对象，观察controller控制台的输出，确定是否已经监听到所有Crontab变化的事件.\n7.总结 三步走：\n创建CRD（Custom Resource Definition），令k8s明白我们自定义的API对象； 编写代码，将CRD的情况写入对应的代码中，然后通过自动代码生成工具，将controller之外的informer，client等内容较为固定的代码通过工具生成； 编写controller，在里面判断实际情况是否达到了API对象的声明情况，如果未达到，就要进行实际业务处理，而这也是controller的通用做法； 实际要自己动手写的文件不多，就3-4个，但是理解起来比较难。\n8.refer https://blog.csdn.net/weixin_41806245/article/details/94451734\nhttps://blog.csdn.net/aixiaoyang168/article/details/81875907\nhttps://github.com/kubernetes/sample-controller/blob/master/README.md\nhttps://blog.openshift.com/kubernetes-deep-dive-code-generation-customresources/\nhttps://www.jianshu.com/p/4910da4c8285\nhttps://blog.csdn.net/boling_cavalry/article/details/88924194\n","date":"2020-02-11","permalink":"http://localhost:1313/post/k8s%E7%AE%A1%E7%90%86crd%E5%92%8Ck8sapi%E7%BC%96%E7%A8%8B/","tags":["k8s"],"title":"K8s管理crd和K8SAPI编程"},{"content":"hadoop 3.1.2 单机模式安装配置 现在搞大数据记录一下，方便查阅。\n1.安装配置jdk和下载hadoop略。 hadoop 下载地址：http://mirror.bit.edu.cn/apache/hadoop/common/ 使用了较新且保守的3.1.2版本\n2.配置修改 环境变量修改\nexport HADOOP_HOME=/soft/hadoop\rexport PATH=$PATH:$HADOOP_HOME/bin\r配置etc/hadoop/hadoop-env.sh\nexport JAVA_HOME=/soft/java\rexport HADOOP_HOME=/soft/hadoop\r配置etc/hadoop/core-site.xml\n\u0026lt;configuration\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;hadoop.tmp.dir\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;file:///develop/data/hadoop\u0026lt;/value\u0026gt;\r\u0026lt;description\u0026gt;Abase for other temporary directories.\u0026lt;/description\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;fs.defaultFS\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;hdfs://192.168.0.104:8888\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;/configuration\u0026gt;\r配置etc/hadoop/hdfs-site.xml\n\u0026lt;configuration\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.replication\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;1\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.namenode.name.dir\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;file:///develop/data/hadoop/dfs/name\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.datanode.data.dir\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;file:///develop/data/hadoop/dfs/data\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.datanode.du.reserved\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;1073741824\u0026lt;/value\u0026gt;\r\u0026lt;description\u0026gt;Reserved space in bytes per volume..\u0026lt;/description\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;/configuration\u0026gt;\r3.配置免密码SSH登录 ssh-keygen -t rsa\rcat ~/ssh/id_rsa.pub\u0026gt;\u0026gt;~/ssh/authorized_keys\r#ssh localhost 测试是否成功 4.启动测试 #格式化\rhdfs namenode -format\r#启动hdfs\r./sbin/start-dfs.sh\r#停止hdfs\r./sbin/stop-dfs.sh\r#验证是否成功\rhttp://localhost:9870/\r至此，hadoop的单机模式基本安装结束。\n简单的验证hadoop命令：\nhadoop fs -mkdir /test\r在浏览器中应该可以看到新建的目录了。\n注意： 1.网上的教程很多是2.x老版本，3.1.0版本后，hdfs的web 50070端口 -\u0026gt; 9870端口了 。\n2.如果webHDFS出错，提示\u0026quot;Failed to retrieve data from /webhdfs/v1/?op=LISTSTATUS:Server Error“，也无法透过Web界面上传文件，一般是JDK版本过高引起的，目前hadoop还只支持JDK8版本。如果是JDK9以上版本，可以编辑hadoop-env.sh\nexport HADOOP_OPTS=\u0026quot;--add-modules java.activation\u0026quot;\r3.上传文件/创建目录报错 Permission Denied，修改hdfs-site.xml，设定dfs.permissions=false。按照本文的最新配置就不会遇到这个问题。\n","date":"2019-08-25","permalink":"http://localhost:1313/post/hadoop3.1.2%E5%8D%95%E6%9C%BA%E6%A8%A1%E5%BC%8F%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","tags":["Java","大数据"],"title":"hadoop 3.1.2 单机模式安装配置"},{"content":"互联网低潮，老是会看到别人发面试经验，看到很多人谈乐观锁，谈CAS，但是都没有说清楚。忍不住叨叨几句。\n那什么是乐观锁呢，比较书面的定义是 “它假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据。在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，正在提交的事务会进行回滚。”，在多线程中则指对于数据冲突保持一种乐观态度，操作数据时不会对操作的数据进行加锁（这使得多个任务可以并行的对数据进行操作），只有到数据提交的时候才通过一种机制来验证数据是否存在冲突。在Java中，是通过CAS来实现乐观锁的。\nCAS是英文单词Compare And Swap的缩写，翻译过来就是比较并替换。CAS机制当中使用了3个基本操作数：内存地址V，旧的预期值A，要修改的新值B。\n更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B。\nCAS比较难于理解的地方就在于V、A、B这三个变量到底代表什么含义，很容易混淆，也不容易讲清楚。单纯看书上的文章会觉得晦涩，我们可以来看个例子。\n举个例子：\n1.在内存地址V当中，存储着值为10的变量\n2.此时线程1想要把变量的值增加1。对线程1来说，旧的预期值A=10，要修改的新值B=11。\n3.在线程1要提交更新之前，另一个线程2抢先一步，把内存地址V中的变量值率先更新成了11。\n4.线程1开始提交更新，首先进行A和地址V的实际值比较（Compare），发现A不等于V的实际值，提交失败。\n5.线程1重新获取内存地址V的当前值，并重新计算想要修改的新值。此时对线程1来说，A=11，B=12。这个重新尝试的过程被称为自旋。\n6.这一次比较幸运，没有其他线程改变地址V的值。线程1进行Compare，发现A和地址V的实际值是相等的，线程1进行Swap，把地址V的值替换为B，也就是12。在这一步，Compare和Swap这个过程是原子的(由操作系统和硬件保证)，比较并更新的过程是不会被其他线程打断的。\n到这里，其实基本说请了CAS的过程，但是CAS的API，还是不够清晰，很多人能够进行到这里，但如果让他实际使用CAS的API时则又没辙了，这里我们通过一个例子来演示CAS的API实际用例。\n/**\r* 使用CAS来获取单例\r*/\rpublic class CasSingleton {\rprivate static final AtomicReference\u0026lt;CasSingleton\u0026gt; INSTANCE=new AtomicReference\u0026lt;\u0026gt;();\rprivate CasSingleton(){}\rpublic static CasSingleton getInstance(){\rfor(;;){\rCasSingleton singleton=INSTANCE.get();\rif(null!=singleton){\rreturn singleton;\r}\rsingleton=new CasSingleton();\rif(INSTANCE.compareAndSet(null,singleton)){\rreturn singleton;\r}\r}\r}\rpublic static void main(String[] args) {\rCasSingleton singleton=getInstance();\rCasSingleton singleton1=getInstance();\rSystem.out.println(singleton);\rSystem.out.println(singleton1);\r}\r}\r这里使用CAS来实现单例，我们对照着compareAndSet的API来看看\n/**\r* Atomically sets the value to {@code newValue}\r* if the current value {@code == expectedValue},\r* with memory effects as specified by {@link VarHandle#compareAndSet}.\r*\r* @param expectedValue the expected value\r* @param newValue the new value\r* @return {@code true} if successful. False return indicates that\r* the actual value was not equal to the expected value.\r*/\rpublic final boolean compareAndSet(V expectedValue, V newValue) {\rreturn VALUE.compareAndSet(this, expectedValue, newValue);\r}\r上面CAS实现单例的代码中，第一个参数null就是A，第二个参数singleton就是B，调用者INSTANCE就是V。在调用compareAndSet的同时，已经完成了更新的过程，并且返回了更新与否的结果。这样就比较好理解了（虽然CAS能实现单例，但在这个场景下并不是最佳方案，为什么，大家可以思考下）。\n现在再来看看AtomicInteger的源码，能理解++i这块的实现了吗？\npublic final int incrementAndGet() {\rfor (;;) {\rint current = get();\rint next = current + 1;\rif (compareAndSet(current, next))\rreturn next;\r}\r}\r至于什么ABA问题和CPU底层实现，则不是本文重点。\n","date":"2019-07-16","permalink":"http://localhost:1313/post/%E8%AE%B2%E6%B8%85%E6%A5%9Acas%E7%9A%84%E9%82%A3%E7%82%B9%E4%BA%8B/","tags":["Java"],"title":"讲清楚CAS的那点事"},{"content":"netty实现http服务器keep-alive无效的问题排查 今天在用netty实现一个http服务器的时候，发现keep-alive并没有生效，具体表现是在request和response的header里都能看到keep-alive的标志：\nrequest:\rAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\rAccept-Encoding: gzip, deflate, br\rAccept-Language: zh-CN,zh;q=0.9,en;q=0.8\rCache-Control: max-age=0\rConnection: keep-alive\rresponse:\rHTTP/1.1 200 OK\rcontent-type: text/html;charset=UTF-8\rcontent-length: 0\rconnection: keep-alive\r可以看出，无论是请求还是响应，都是keep-alive的，但是请求两次，服务器端日志如下：\n七月 06, 2019 9:51:27 下午 io.netty.handler.logging.LoggingHandler channelRead\r信息: [id: 0xade39344, L:/0:0:0:0:0:0:0:0:8080] READ: [id: 0x26d40041, L:/0:0:0:0:0:0:0:1:8080 - R:/0:0:0:0:0:0:0:1:33130]\r七月 06, 2019 9:51:27 下午 io.netty.handler.logging.LoggingHandler channelReadComplete\r信息: [id: 0xade39344, L:/0:0:0:0:0:0:0:0:8080] READ COMPLETE\rkeepAlive=true\rchannel id=26d40041\rhttp uri: /a.txt?name=chen\u0026amp;f=123;key=456\rname=chen\rf=123\rkey=456\r七月 06, 2019 9:51:29 下午 io.netty.handler.logging.LoggingHandler channelRead\r信息: [id: 0xade39344, L:/0:0:0:0:0:0:0:0:8080] READ: [id: 0x600995e6, L:/0:0:0:0:0:0:0:1:8080 - R:/0:0:0:0:0:0:0:1:33156]\r七月 06, 2019 9:51:29 下午 io.netty.handler.logging.LoggingHandler channelReadComplete\r信息: [id: 0xade39344, L:/0:0:0:0:0:0:0:0:8080] READ COMPLETE\rkeepAlive=true\rchannel id=600995e6\rhttp uri: /a.txt?name=chen\u0026amp;f=123;key=456\rname=chen\rf=123\rkey=456\r客户端两次连接的socket端口一次是33130,第二次是33156，channel id也不一样，证明确实是两个连接，keep-alive并没有生效。\n其中，channel id来自这里\n@Override\rpublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\r//\rSystem.out.println(\u0026quot;channel id=\u0026quot;+ctx.channel().id());\r}\r为什么呢，看下代码中Server和ServerHandle也没什么问题，关键代码如下：\nserverBootstrap.channel(NioServerSocketChannel.class)\r.group(boss, work)\r.handler(new LoggingHandler(LogLevel.INFO)) // handler在初始化时就会执行，可以设置打印日志级别\r.childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() {\r@Override\rprotected void initChannel(SocketChannel ch) throws Exception {\rch.pipeline().addLast(\u0026quot;http-coder\u0026quot;,new HttpServerCodec());\rch.pipeline().addLast(\u0026quot;aggregator\u0026quot;,new HttpObjectAggregator(1024*1024)); //在处理 POST消息体时需要加上\rch.pipeline().addLast(new HttpServerHandler());\r}\r})\r.option(ChannelOption.SO_BACKLOG, 1024)\r.childOption(ChannelOption.SO_KEEPALIVE, true)\r.childOption(ChannelOption.TCP_NODELAY, true);\r//handle代码\rhttpResponse.headers().set(HttpHeaderNames.CONTENT_TYPE, \u0026quot;text/html;charset=UTF-8\u0026quot;);\rhttpResponse.headers().setInt(HttpHeaderNames.CONTENT_LENGTH, httpResponse.content().readableBytes());\rif (keepAlive) {\rhttpResponse.headers().set(HttpHeaderNames.CONNECTION, HttpHeaderValues.KEEP_ALIVE);\rctx.writeAndFlush(httpResponse);\r} else {\rctx.writeAndFlush(httpResponse).addListener(ChannelFutureListener.CLOSE);\r}\r代码很明显，如果请求是 keep-alive的，那么响应头也加上keep-alive标志，从而实现了长连接。看了半天代码没看出端倪来，突然注意到了在浏览器中，F12看到了/favicon.ico的请求一直是pending的，也就是阻塞在了这里，代码里是这么写的\n//去除浏览器\u0026quot;/favicon.ico\u0026quot;的干扰\rif (uri.equals(FAVICON_ICO)) {\rreturn ;\r}\r这段代码来自我参考的别人的代码，本意是要忽略 /favicon.ico这种无效的请求，但是由于直接return了，导致当前连接被阻塞了，如果这时刷新，就会导致新开一个连接来处理请求。要解决这个问题很简单，只需要注释掉这段代码，对于/favicon.ico请求，直接返回空的200状态码就好了。\n现在再来看下请求日志：\n信息: [id: 0xee8bc5e1, L:/0:0:0:0:0:0:0:0:8080] READ: [id: 0x734e2ebb, L:/0:0:0:0:0:0:0:1:8080 - R:/0:0:0:0:0:0:0:1:37386]\r七月 06, 2019 10:03:48 下午 io.netty.handler.logging.LoggingHandler channelReadComplete\r信息: [id: 0xee8bc5e1, L:/0:0:0:0:0:0:0:0:8080] READ COMPLETE\rkeepAlive=true\rchannel id=734e2ebb\rhttp uri: /a.txt?name=chen\u0026amp;f=123;key=456\rname=chen\rf=123\rkey=456\rkeepAlive=true\rchannel id=734e2ebb\rhttp uri: /favicon.ico\rkeepAlive=true\rchannel id=734e2ebb\rhttp uri: /a.txt?name=chen\u0026amp;f=123;key=456\rname=chen\rf=123\rkey=456\rkeepAlive=true\rchannel id=734e2ebb\rhttp uri: /favicon.ico\r无论刷新多少次，服务器端日志里也只记录了一次socket连接日志，并且每次的channel id都是一样的。\n顺便再测试下，如果把server中的ChannelOption.SO_KEEPALIVE设置为false，是不会影响http的keep-alive的。\n","date":"2019-07-06","permalink":"http://localhost:1313/post/netty%E5%AE%9E%E7%8E%B0http%E6%9C%8D%E5%8A%A1%E5%99%A8keep-alive%E6%97%A0%E6%95%88%E7%9A%84%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/","tags":["Java"],"title":"Netty实现http服务器keep Alive无效的问题排查"},{"content":"我用的filebeat7来收集日志发给Elastic search，版本是7.1.1，对应的elasticsearch版本和其相同。\n默认的，filebeat生成的索引名字是filebeat-7.1.1-2019.06.24这种，不利于区分不同的业务，需要自定义索引，看了下官方文档， 是这么写的\nindexedit\rThe index name to write events to. The default is \u0026quot;filebeat-%{[agent.version]}-%{+yyyy.MM.dd}\u0026quot; (for example, \u0026quot;filebeat-7.2.0-2019-06-26\u0026quot;). If you change this setting, you also need to configure the setup.template.name and setup.template.pattern options (see Load the Elasticsearch index template).\rIf you are using the pre-built Kibana dashboards, you also need to set the setup.dashboards.index option (see Load the Kibana dashboards).\rYou can set the index dynamically by using a format string to access any event field. For example, this configuration uses a custom field, fields.log_type, to set the index:\routput.elasticsearch:\rhosts: [\u0026quot;http://localhost:9200\u0026quot;]\rindex: \u0026quot;%{[fields.log_type]}-%{[agent.version]}-%{+yyyy.MM.dd}\u0026quot; 重点提到了还需要修改setup.template.name和setup.template.pattern，于是我配置如下：\noutput.elasticsearch:\rhosts: [\u0026quot;127.0.0.1:9200\u0026quot;]\rindex: \u0026quot;ngerr-%{[agent.version]}-%{+yyyy.MM.dd}\u0026quot;\rsetup.template.name: \u0026quot;ngerr\u0026quot;\rsetup.template.pattern: \u0026quot;ngerr-*\u0026quot;\r结果发现无论如何都不生效，找了很多文章都说配置这几个地方就行，包括google也搜不到结果。我试了不同的配置，甚至把setup.template配置调了位置，还是徒劳，控制台永远都是输出如下\n2019-06-26T13:11:20.287+0800 INFO pipeline/output.go:95 Connecting to backoff(elasticsearch(http://127.0.0.1:9200))\r2019-06-26T13:11:20.294+0800 INFO elasticsearch/client.go:734 Attempting to connect to Elasticsearch version 7.1.1\r2019-06-26T13:11:20.379+0800 INFO [index-management] idxmgmt/std.go:223 Auto ILM enable success.\r2019-06-26T13:11:20.380+0800 INFO [index-management.ilm] ilm/std.go:134 do not generate ilm policy: exists=true, overwrite=false\r2019-06-26T13:11:20.380+0800 INFO [index-management] idxmgmt/std.go:238 ILM policy successfully loaded.\r2019-06-26T13:11:20.380+0800 INFO [index-management] idxmgmt/std.go:361 Set setup.template.name to '{filebeat-7.1.1 {now/d}-000001}' as ILM is enabled.\r2019-06-26T13:11:20.380+0800 INFO [index-management] idxmgmt/std.go:366 Set setup.template.pattern to 'filebeat-7.1.1-*' as ILM is enabled.\r2019-06-26T13:11:20.380+0800 INFO [index-management] idxmgmt/std.go:400 Set settings.index.lifecycle.rollover_alias in template to {filebeat-7.1.1 {now/d}-000001} as ILM is enabled.\r2019-06-26T13:11:20.380+0800 INFO [index-management] idxmgmt/std.go:404 Set settings.index.lifecycle.name in template to {filebeat-7.1.1 map[policy:{\u0026quot;phases\u0026quot;:{\u0026quot;hot\u0026quot;:{\u0026quot;actions\u0026quot;:{\u0026quot;rollover\u0026quot;:{\u0026quot;max_age\u0026quot;:\u0026quot;30d\u0026quot;,\u0026quot;max_size\u0026quot;:\u0026quot;50gb\u0026quot;}}}}}]} as ILM is enabled.\r2019-06-26T13:11:20.383+0800 INFO template/load.go:129 Template already exists and will not be overwritten.\r2019-06-26T13:11:20.383+0800 INFO [index-management] idxmgmt/std.go:272 Loaded index template.\r2019-06-26T13:11:20.524+0800 INFO [index-management] idxmgmt/std.go:283 Write alias successfully generated.\r{filebeat-7.1.1 {now/d}-000001} 这个名字总是会覆盖我自己的配置。反复尝试，觉得是 ILM 这个东西在作梗，于是试着搜索了下“filebeat ILM is enabled”，发现了这个issue ，有不少人踩坑了。提出issue的人也指出了文档没有说清楚。\n指向了这个官方文档：https://www.elastic.co/guide/en/beats/filebeat/current/ilm.html\n原来\nStarting with version 7.0, Filebeat uses index lifecycle management by default when it connects to a cluster that supports lifecycle management. Filebeat loads the default policy automatically and applies it to any indices created by Filebeat.\n可惜的是filebeat的配置项那里一直没有说清楚。网上由于大多数人用的都是很保守的配置和较老的版本，所以很难搜索到类似的问题，我基本上是头几个踩坑的了。\n加上这个配置就好了：\nsetup.ilm.enabled: false\r希望能帮到踩坑的人，我已经在这个问题上浪费了三四个小时了。\n","date":"2019-06-26","permalink":"http://localhost:1313/post/filebeat%E4%BF%AE%E6%94%B9index%E7%9A%84%E4%B8%80%E4%B8%AA%E5%9D%91/","tags":["Java"],"title":"Filebeat7自定义index的一个坑"},{"content":"本来我一个软件工程师，是很不屑提产品的，但时不时总见到一些产品人吹牛皮，也忍不住凑个热闹。\n钉钉(DingTalk)是一款由阿里巴巴集团开发的用于商务沟通和工作协同的IM，其和企业版微信占据了中国的大部分企业IM市场。阿里并不是一个擅长做社交的公司，钉钉也是一款命途多舛的产品。2014年左右阿里在内部强行推广来往，一款承载了阿里社交梦的产品，花了巨额的研发和营销费用后，依然是折戟沉沙。后来，来往的团队保留了部分下来，做起了钉钉，针对办公社交，居然做成功了。\n在办公社交上，钉钉的崛起甚至早于以社交闻名的腾讯，在社交上扳回了一局，甚至可以说是唯一的一局。微信和QQ在钉钉后也快速推出了办公社交QQ和企业微信等功能，但是在它们推出后，钉钉在很多城市使用的频率已经很高了。\n我用的是linux操作系统，钉钉并没有官方linux版本，所以有时候我会使用手机钉钉和网页版钉钉凑合。但是某一次打开钉钉设置的时候，发现了一个问题。\n不知大家注意到没有，网页版钉钉的设置使用了流行的switch开关，但是用了红色和绿色的搭配。可能钉钉的设计和开发者觉得“红灯停，绿灯行”的概念已经深入人心，但是他们是否想到了一个事实：中国存在近亿的色盲和色弱用户，这其中又以红绿色盲色弱最多！\n红色和绿色，是两个对比度比较接近的颜色，也是最难辨识的两个颜色，别说对色盲和色弱用户来说，即使是对于普通人来说，在某些光线条件下，红绿色也是很难于辨识的。实际上在打开这个页面的时候，我也愣了一会，才辨清了这两个颜色状态。\n正因为红绿色是很难于辨识的两种颜色，现在城市的红绿灯，大部分都是掺了蓝色的，所以大家看到的绿灯，都是泛蓝的，而不是单纯的绿色。还有的城市，绿灯不仅掺了蓝色，还会使用动画或声音提示行人车辆，目的就是为了减少了特殊用户甚至是正常用户的困扰。\n阿里一直宣传产品的人文关怀，比如雇佣残疾人客服，支付宝支持语音支付等，但是可曾想到，他们另外一款最流行的企业IM软件，却忽略了上亿人！\n产品的设计开发中，有许多细节，只有真正用心的人才会注意到，并设计出用户友好的软件，减少用户的困扰。\n作者使用了钉钉很久了，最早的APP版设置页面就是使用红色和绿色来作为swith开关的，作者曾经在微博等多个渠道向阿里反馈，可惜一直没有收到阿里的回复，直到一年后的某天，钉钉悄悄地改了这个细节，也不知道是无意中修改还是真的收到了用户的反馈。遗憾的是，网页版钉钉至今没有修改这个细节。\n","date":"2019-05-06","permalink":"http://localhost:1313/post/oh-dingtalk/","tags":["闲扯淡"],"title":"从钉钉一个忽略了近亿人的产品细节谈谈产品思维"},{"content":"公司的生产服务器买了QiZhi Technologie的堡垒机，每次登录都得输入密码+空格+OTOP验证码，都得打开手机APP操作一把，烦不胜烦。\n不可忍，想了想，还是借助Java在每次调用时自动生成验证码，然后搞个ssh自动登录（别问我问啥不用公钥，哪有权限啊）得了。\n结合之前写的博客 TOTP算法Java版本，很容易就写出计算验证码的代码：\npublic long getCode(String secret, long timeMsec) throws Exception {\rBase32 codec = new Base32();\rbyte[] decodedKey = codec.decode(secret);\rlong t = (timeMsec / 1000L) / 30L;\rfor (int i = -window_size; i \u0026lt;= window_size; ++i) {\rlong hash;\rtry {\rhash = verify_code(decodedKey, t + i);\rreturn hash;\r} catch (Exception e) {\re.printStackTrace();\r}\r}\rreturn 0L;\r}\r写一个类，专门调用这个方法生成验证码，获取程序执行结果\njava -Dfile.encoding=UTF-8 -classpath /soft/tool/authcode/ GoogleAuthTest\r，接下来，要实现自动登录就简单多了，先写一个shell\n#!/bin/bash\rpasswd=$(java -Dfile.encoding=UTF-8 -classpath /soft/tool/authcode/ GoogleAuthTest)\r./prod.exp $passwd\rshell调用java生成验证码，然后传给expect脚本\n#!/bin/expect\rset timeout 10\rset fullpasswd [lindex $argv 0]\rspawn ssh -l chenwen 172.10.3.110\rexpect \u0026quot;*ssword*\u0026quot;\rsend \u0026quot;dev744988 $fullpasswd\\r\u0026quot;\rinteract\r不到100行新代码，搞定收工，全程不到半小时。最耗时的还是传递变量给expact花了不少时间。\n","date":"2018-11-16","permalink":"http://localhost:1313/post/auto-login-bastion-with-otop-by-java/","tags":["Java","Linux"],"title":"使用Java自动登录需要动态密码的堡垒机"},{"content":"在Linux里，用户层面并没有文件创建时间的概念，无论是用ls还是stat 指令，都无法获取到文件的创建时间\n[tudou@tudou-pc statx]$ stat test-statx.c\r文件：test-statx.c\r大小：6656 块：16 IO 块：4096 普通文件\r设备：805h/2053d Inode：6684737 硬链接：1\r权限：(0644/-rw-r--r--) Uid：( 1000/ tudou) Gid：( 1001/ tudou)\r最近访问：2018-10-07 13:16:29.000000000 +0800\r最近更改：2018-10-07 13:21:09.855461986 +0800\r最近改动：2018-10-07 13:21:09.855461986 +0800\r创建时间：-\r可以看到「创建时间」一行总是「-」。\n如果我们使用百度的话，会看到很多文章说，最近改动时间就是创建时间。的确，我们拿很多文件试验了下，这个最近改动时间（Change Time）确实和创建时间很相近，然而Change time并不是Create time，它实际是文件属性修改时间。 试一下即知：\n[tudou@tudou-pc 下载]$ ./statx ~/.face\rstatx(/home/tudou/.face) = 0\rresults=fff\rSize: 7589 Blocks: 16 IO Block: 4096 regular file\rDevice: 08:05 Inode: 5505043 Links: 1\rAccess: (0644/-rw-r--r--) Uid: 1000 Gid: 1001\rAccess: 2018-09-16 01:15:52.320014139+0800\rModify: 2018-09-16 01:15:52.320014139+0800\rChange: 2018-09-16 01:15:52.320014139+0800\rBirth: 2018-09-16 01:15:52.320014139+0800\rAttributes: 0000000000000000 (........ ........ ........ ........ ........ ........ ....-... .---.-..)\r[tudou@tudou-pc 下载]$ chattr +u ~/.face\r[tudou@tudou-pc 下载]$ ./statx ~/.face\rstatx(/home/tudou/.face) = 0\rresults=fff\rSize: 7589 Blocks: 16 IO Block: 4096 regular file\rDevice: 08:05 Inode: 5505043 Links: 1\rAccess: (0644/-rw-r--r--) Uid: 1000 Gid: 1001\rAccess: 2018-09-16 01:15:52.320014139+0800\rModify: 2018-09-16 01:15:52.320014139+0800\rChange: 2018-10-07 16:17:10.929769171+0800\rBirth: 2018-09-16 01:15:52.320014139+0800\rAttributes: 0000000000000000 (........ ........ ........ ........ ........ ........ ....-... .---.-..)\r不过，linux也不是完全不支持文件创建时间，文件系统如ext4其实是支持的，只是没有API可以获取到这个数据。比如Java提供的文件API，也就因此无法获取文件创建时间。\n不过，自内核 4.11 版本引入的 statx 系统调用支持获取创建时间了，字段名里用的是 btime（Birth time）。\n如果用户想要实现在代码里获取这个创建时间，那么只需要调用glibc提供的API即可。但是目前glibc还没有支持，所以只能自己用syscall函数调用。如果仅仅只是想自己实现一个小工具来获取这个时间，那么内核源码树里 samples/statx/test-statx.c 这个文件就是现成的实现。 下载源码：https://cdn.kernel.org/pub/linux/kernel/v4.x/linux-4.18.12.tar.xz，选择一个和自己操作系统版本最近的源码分支 . 你要是不想下载几十M的linux源码的话，也可以从这里获取到各个linux版本的源码 编译文件：\n[tudou@tudou-pc statx]$ gcc -O2 -o statx test-statx.c\rIn file included from /usr/include/sys/stat.h:446,\rfrom test-statx.c:28:\r/usr/include/bits/statx.h:25:8: 错误：‘struct statx_timestamp’重定义\rstruct statx_timestamp\r^~~~~~~~~~~~~~~\rIn file included from test-statx.c:26:\r/usr/include/linux/stat.h:56:8: 附注：原先在这里定义\rstruct statx_timestamp {\r^~~~~~~~~~~~~~~\rIn file included from /usr/include/sys/stat.h:446,\rfrom test-statx.c:28:\r/usr/include/bits/statx.h:36:8: 错误：‘struct statx’重定义\r注释如下两行代码：\n#define _GNU_SOURCE\r#define _ATFILE_SOURCE\r再次编译即可。\n[tudou@tudou-pc statx]$ gcc -O2 -o statx test-statx.c\r[tudou@tudou-pc statx]$ ./statx test-statx.c\rstatx(test-statx.c) = 0\rresults=fff\rSize: 6656 Blocks: 16 IO Block: 4096 regular file\rDevice: 08:05 Inode: 6684737 Links: 1\rAccess: (0644/-rw-r--r--) Uid: 1000 Gid: 1001\rAccess: 2018-10-07 13:16:29.000000000+0800\rModify: 2018-10-07 13:21:09.855461986+0800\rChange: 2018-10-07 13:21:09.855461986+0800\rBirth: 2018-10-07 13:16:47.771175840+0800\rAttributes: 0000000000000000 (........ ........ ........ ........ ........ ........ ....-... .---.-..)\r另外一个思路， 使用debugfs来搞。\n附：glibc即将支持statx调用Glibc Support For Statx Is Finally Under Review\n参考： https://blog.lilydjwg.me/2018/7/11/get-file-birth-time-in-linux.213101.html\n","date":"2018-10-07","permalink":"http://localhost:1313/post/get-createtime-in-linux/","tags":["Linux"],"title":"Linux 下获取文件创建时间"},{"content":"现在的一些Linux软件很流行使用bin这种安装包格式，只需要下载个安装包就能自动安装解压，比tar.gz省事，比.deb，.rpm的安装包兼容性强，适应范围广。但也有一个问题，bin安装包让人无法知道里面的细节，还是有所顾虑的。比如我前几天需要下载一个JRE6，但Oracle官方在JDK7之前都没有tar.gz包，只有bin包。我肯定不能直接安装bin文件啊，这会破坏我本机已有的JDK8开发环境。\n怎么从bin文件里提取出原始安装包呢？其实很简单。用vi打开一个bin文件就知道了，bin文件其实就是一个sh文件和二进制文件的合并文件，前面一段是sh命令，负责实际的安装，它会提取后半部分的二进制数据，后半部分一般是个压缩文件包或者自解压文件的二进制流。\nvi jre-for-linux.bin\r可以看到，第一行是\n#!/bin/bash\r接下来就是一堆安装和设置环境变量，提取解压部分了，最关键的部分在这几行\noutname=install.sfx.$$\rtail ${tail_args} +162 \u0026quot;$0\u0026quot;\u0026gt;$outname\rchmod +x $outname\r继续往下看，267行是exit 0，从第268行开始，就是一堆看似乱码的二进制了，到这里那就清晰多了\n# 从268行起提取二进制文件\rtail -n +268 jre-for-linux.bin \u0026gt;install.sfx\r# 因为是sfx格式，就用7z解压\r7z x install.sfx\r到此解压成功。手动安装，使用export设置临时变量，就用上了JRE6了。\n","date":"2018-06-02","permalink":"http://localhost:1313/post/linux%E4%B8%8B%E8%A7%A3%E5%8E%8Bbin%E6%96%87%E4%BB%B6/","tags":["Linux"],"title":"linux下解压bin文件"},{"content":"今天在修一个老项目，使用的是jfinal框架，这个框架算是一个比较传统的框架，只支持打包成war运行放入容器中运行，但是在开发过程中可以使用jetty快速启动和调试。个人不是很喜欢jetty，遂换成了undertow。 引入如下依赖\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;io.undertow\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;undertow-core\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.0.1.Final\u0026lt;/version\u0026gt;\r\u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;io.undertow\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;undertow-servlet\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.0.1.Final\u0026lt;/version\u0026gt;\r\u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r再写一个启动类就好了\npublic class Main {\rpublic static void main(String[] args) throws Exception {\rDeploymentInfo servletBuilder = Servlets.deployment()\r.setContextPath(\u0026quot;/\u0026quot;)\r.setClassLoader(Main.class.getClassLoader())\r.setDeploymentName(\u0026quot;zooadmin.war\u0026quot;)\r;\rFilterInfo jfinalFilter=new FilterInfo(\u0026quot;jfinal\u0026quot;,JFinalFilter.class);\rjfinalFilter.addInitParam(\u0026quot;configClass\u0026quot;,\u0026quot;com.baicai.core.Config\u0026quot;);\rservletBuilder.addFilter(jfinalFilter);\rservletBuilder.addFilterUrlMapping(\u0026quot;jfinal\u0026quot;,\u0026quot;/*\u0026quot;, DispatcherType.REQUEST);\rservletBuilder.addFilterUrlMapping(\u0026quot;jfinal\u0026quot;,\u0026quot;/*\u0026quot;, DispatcherType.FORWARD);\rservletBuilder.setResourceManager(new FileResourceManager(new File(\u0026quot;src/main/webapp\u0026quot;), 1024));\rDeploymentManager manager = Servlets.defaultContainer().addDeployment(servletBuilder);\rmanager.deploy();\rPathHandler path = Handlers.path(Handlers.redirect(\u0026quot;/\u0026quot;))\r.addPrefixPath(\u0026quot;/\u0026quot;, manager.start());\rUndertow server = Undertow.builder()\r.addHttpListener(1080, \u0026quot;localhost\u0026quot;)\r.setHandler(path)\r.build();\r// start server\rserver.start();\r}\r}\r直接在这个类上运行main方法即可。关键的地方就是把传统的web项目的web.xml翻译成Java代码而已。 本来想继续实现springboot那种fatjar的打包方式，最后发现现有的maven插件都无法满足需求，spring是自己扩展了jar的一套协议实现的，实现起来颇有难度。留待以后折腾吧\n","date":"2018-05-19","permalink":"http://localhost:1313/post/%E4%BD%BF%E7%94%A8%E5%86%85%E5%B5%8Cundertow%E5%BC%80%E5%8F%91%E8%B0%83%E8%AF%95jfinal%E9%A1%B9%E7%9B%AE/","tags":["Java"],"title":"使用内嵌undertow开发调试jfinal项目"},{"content":"之前公司的一个网站使用了OTP来做二次验证，然后我就在手机上安装了freeotp这款软件来管理OTP密码，等到换手机了，才发现没法导出原手机的配置，这就尴尬了。FreeOTP is sponsored and officially published by Red Hat，也算是大家闺秀出品的软件，居然不支持这么重要的功能。\n试了很多方法，在手机的文件管理器中到处搜索，都没有找到这个配置，基本可以确定freeotp把密钥存放在了系统目录，没有root的话，是没法查看和处理系统目录下的文件，即使用备份工具也备份不出来。\n当初网站的OTP二维码也找不到了，网站也没找到重新设置OTP的入口，本着万事不求人的想法，暂时还不想最后求助运维。看来唯一的办法就是root手机了，试了很多工具，没想到kingroot居然支持root魅蓝手机了。\nroot成功后，马上去freeotp的配置存储目录找到配置文件，找到 /data/data/org.fedorahosted.freeotp/shared_prefs/tokens.xml 文件，得到如下的配置,配置中的引号被转义了\n\u0026lt;?xml version='1.0' encoding='utf-8' standalone='yes' ?\u0026gt;\r\u0026lt;map\u0026gt;\r\u0026lt;string name=\u0026quot;bbcx@qq.com:chen\u0026quot;\u0026gt;{\u0026quot;algo\u0026quot;:\u0026quot;SHA256\u0026quot;,\u0026quot;counter\u0026quot;:0,\u0026quot;digits\u0026quot;:6,\u0026quot;issuerExt\u0026quot;:\u0026quot;bbcx@qq.com\u0026quot;,\u0026quot;label\u0026quot;:\u0026quot;chen\u0026quot;,\u0026quot;period\u0026quot;:30,\u0026quot;secret\u0026quot;:[17,-56,-42,-70,-48,-79,53],\u0026quot;type\u0026quot;:\u0026quot;TOTP\u0026quot;}\u0026lt;/string\u0026gt;\r\u0026lt;string name=\u0026quot;bbc\u0026quot;\u0026gt;{\u0026quot;algo\u0026quot;:\u0026quot;SHA1\u0026quot;,\u0026quot;counter\u0026quot;:0,\u0026quot;digits\u0026quot;:6,\u0026quot;issuerExt\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;label\u0026quot;:\u0026quot;bbc\u0026quot;,\u0026quot;period\u0026quot;:30,\u0026quot;secret\u0026quot;:[0,1,2,3],\u0026quot;type\u0026quot;:\u0026quot;TOTP\u0026quot;}\u0026lt;/string\u0026gt;\r\u0026lt;string name=\u0026quot;tokenOrder\u0026quot;\u0026gt;[\u0026quot;bbcx@qq.com:bbcx\u0026quot;,\u0026quot;bbc\u0026quot;]\u0026lt;/string\u0026gt;\r\u0026lt;/map\u0026gt;\r可以看出，这里面是就是关于otp的全部配置了，最关键的就是secret字段，这里做了加密，反复试验了半天，没找到解决方案，最终想到Google，找到了这个解决方案： https://github.com/viljoviitanen/freeotp-export/blob/master/README.md ，只需要把tokens.xml贴到这里，https://rawgit.com/viljoviitanen/freeotp-export/master/export-xml.html，就能还原出二维码来，用新手机扫描就好了。\n事情还没完，最后想去freeotp的官方那里反应下，没想到官方的态度让我大跌眼镜，https://github.com/freeotp/freeotp-android/issues/20，“出门右转买收费软件去，老子就是不增加备份功能，你能咋地”。\n\u0026quot;'''Can I create backupcodes'''?\r''No, but if you're using an Android smartphone you can replace the Google Authenticator app with Authenticator Plus.\rIt's a really nice app that can import your existing settings, sync between devices and backup/restore using your sd-card.\rIt's not a free app, but it's well worth the money.''\u0026quot;\rThis proprietary app, Authenticator Plus, does look very nice and has some nice features, but the most beneficial I think is its ability to backup and restore codes.\rThis could be a huge addition to FreeOTP and I would like to request that someone considers this feature and looks at a way of implementing it. I am not able to code myself.\r最终，在用户义愤填膺的评论下，发现这个软件 andOTP，真是兴奋，满足了我对OTP软件的所有需求，也支持备份和导入，极力推荐。\n立马卸载了拽拽的freeOTP，装上andOTP，感觉整个世界都阳光明媚。开源的傲慢真是领悟了，惹不起惹不起。\n","date":"2018-05-14","permalink":"http://localhost:1313/post/export-freeopt-config/","tags":null,"title":"导出freeOTP中的配置"},{"content":"很久没更新博客了，想到几个小坑，虽然没啥技术含量，但或许有人不知道呢。\n1.删除sublist的元素导致原对象元素被删除 看下面这段代码\nList\u0026lt;Integer\u0026gt; students=new ArrayList\u0026lt;Integer\u0026gt;();\rfor (int i = 0; i \u0026lt;5 ; i++) {\rstudents.add(i);\r}\rList\u0026lt;Integer\u0026gt; subList=new ArrayList\u0026lt;Integer\u0026gt;();\rsubList=students.subList(0,5);\rsubList.remove(0);\rsubList.remove(1);\rfor (int i = 0; i \u0026lt;5 ; i++) {\rSystem.out.println(i+\u0026quot;=\u0026quot;+students.get(i));\r}\rstudents是个list，然后我们新建立了一个subList对象，这个对象截取了students的一部分，我们删除了subList对象里的一些元素，看下运行结果。\n0=1\r1=3\r2=4\rException in thread \u0026quot;main\u0026quot; java.lang.IndexOutOfBoundsException: Index: 3, Size: 3\rat java.util.ArrayList.rangeCheck(ArrayList.java:657)\rat java.util.ArrayList.get(ArrayList.java:433)\rat bai.ListDo.main(ListDo.java:17)\r难道说，删除subList对象里的元素也会导致students里的元素被删除？我明明是新建了一个对象啊。然而，事实确实是这样的。 我们要理解一个事情，使用new新建一个对象，只是开辟了一块空间，用来存放这个对象的地址指针，但是这个新建的对象地址，指向的却是原有对象，也就是说，使用subList这个方法的时候，并没有从students里把内容拷贝了一份，仅仅是纪录了一个指针的移动，这样从某种角度来说，是提高了性能节省内存的做法。 看一下subList这个方法的JavaDoc我们就更清楚了。\nReturns a view of the portion of this list between the specified\r* \u0026lt;tt\u0026gt;fromIndex\u0026lt;/tt\u0026gt;, inclusive, and \u0026lt;tt\u0026gt;toIndex\u0026lt;/tt\u0026gt;, exclusive. (If\r* \u0026lt;tt\u0026gt;fromIndex\u0026lt;/tt\u0026gt; and \u0026lt;tt\u0026gt;toIndex\u0026lt;/tt\u0026gt; are equal, the returned list is\r* empty.) The returned list is backed by this list, so non-structural\r* changes in the returned list are reflected in this list, and vice-versa.\r* The returned list supports all of the optional list operations supported\r* by this list.\u0026lt;p\u0026gt;\r什么时候会用到subList方法呢，通常是接收到了一个大的list，需要切割成一个个小的子list再加工处理，以减少内存占用和提高性能，如果不注意的话，就很容易触发这种隐形的bug。所以，使用subList时不要轻易做增删操作，要么不使用subList方法，而是手动add.\n2.SimpleDateFormat的线程安全问题 很多博客和文章都会告诉我们，一定要注意SimpleDateFormat的线程安全问题，那究竟是怎么回事呢？ 看下面的代码\npublic class DateFormatTest extends Thread {\r@Override\rpublic void run() {\rwhile(true) {\rtry {\rthis.join(2000);\r} catch (InterruptedException e1) {\re1.printStackTrace();\r}\rtry {\rSystem.out.println(this.getName()+\u0026quot;:\u0026quot;+DateUtil.parse(\u0026quot;2018-05-05 12:12:12\u0026quot;));\r} catch (ParseException e) {\re.printStackTrace();\r}\r}\r}\rpublic static void main(String[] args) {\rfor(int i = 0; i \u0026lt; 3; i++){\rnew DateFormatTest().start();\r}\r}\r}\rclass DateUtil {\rprivate static final SimpleDateFormat sdf = new SimpleDateFormat(\u0026quot;yyyy-MM-dd HH:mm:ss\u0026quot;);\rpublic static String formatDate(Date date)throws ParseException{\rreturn sdf.format(date);\r}\rpublic static Date parse(String strDate) throws ParseException{\rreturn sdf.parse(strDate);\r}\r}\r运行这段代码后，会发现Thread-1会报出Exception in thread \u0026ldquo;Thread-0\u0026rdquo; Exception in thread \u0026ldquo;Thread-1\u0026rdquo; java.lang.NumberFormatException: multiple points 的异常，并且导致Thread-2有一些错误的日期输出。为什么呢，原因在于SimpleDataFormat不是线程安全的，因为SimpleDataFormat里面用了Calendar 这个成员变量来实现SimpleDataFormat,并且在Parse 和Format的时候对Calendar 进行了修改，calendar.clear()，calendar.setTime(date); 为了线程安全和效率的双重兼顾，建议使用ThreadLocal，代码如下：\npublic class DateUtil1 {\rprivate static final ThreadLocal\u0026lt;DateFormat\u0026gt; messageFormat = new ThreadLocal\u0026lt;DateFormat\u0026gt;();\rprivate static final String MESSAGE_FORMAT = \u0026quot;MM-dd HH:mm:ss.ms\u0026quot;;\rprivate static final DateFormat getDateFormat() {\rDateFormat format = messageFormat.get();\rif (format == null) {\rformat = new SimpleDateFormat(MESSAGE_FORMAT, Locale.getDefault());\rmessageFormat.set(format);\r}\rreturn format;\r}\r}\r如果自己没有把握的话，还是建议每次new一个SimpleDataFormat对象。 Java里面还有许多线程不安全的类，使用这些类的时候，务必注意使用同步原语，或者使用new新建一个对象省事，或者使用对应的线程安全的类。比如hashMap对应的ConcurrentHashMap.\n3.split的坑 看下面的代码，\nString[] re=\u0026quot;2|33|4\u0026quot;.split(\u0026quot;|\u0026quot;);\rfor (int i = 0; i \u0026lt;re.length ; i++) {\rSystem.out.println(re[i]);\r}\r你以为输出的结果会是2,33,4，实际上却是 2,|，3,3，|，4。为什么呢，稍微看一下split的方法注释就知道了，原来split的分隔符参数实际上是一个正则表达式，而不是普通的字符串。 所以，正确的写法应该是String.split(\u0026quot;\\|\u0026quot;) 当然，这种坑纯粹是由于对Java基本方法的使用不熟悉造成的，是完全可以避免的。\n","date":"2018-05-05","permalink":"http://localhost:1313/post/java_trap/","tags":["Java"],"title":"Java里常见的几个语法小坑"},{"content":" 这两天想给博客做个插件,利用阿里云的OSS来存储文件.但阿里的文档和代码都烂的超乎想象,要么代码老旧不堪,要么跟小脚老太一样引入一坨依赖,想必这块是外包团队做的吧,或者阿里非核心业务员的技术水平也就这样吧.\n所以想绕开阿里云官方提供的代码自己整一套OSS的API,先跑一个上传文件的demo,能在客户端跑通后再用代码去实现.最简单的方法就是用REST client来模拟.折腾了一下,还挺费劲,记录下折腾过程\n先来试试上传文件,选择PUT方法,要请求的URL为http://baicaidoc.oss-cn-shenzhen.aliyuncs.com/image/small/mm1.jpg ,添加以下header,header头需要包含哪些内容可以看这里\nAuthorization:OSS\rLTAIxkX6Qj2OuMZ6:tLZ7nYYP/hkCJbG/6gkOJ7Mi4E=\rDate:Thu, 25 Jan 2018 15:20:39 GMT\rContent-Disposition:attachment;filename=ivy.jpg\rHost:baicaidoc.oss-cn-shenzhen.aliyuncs.com\rContent-Encoding:utf-8\r然后在body里添加file body. 至于header头怎么写和Authorization字段计算的方法,文档里说的比较清晰了https://help.aliyun.com/document_detail/31951.html. 尤其需要注意的是Date必须是GMT格式,这个对Java来说也好办,不过要注意时区的问题,GMT时间比东八区慢了8个小时.还有Host需要带上bucket,这在早期是不需要的(早期带上反而会报错SignatureDoesNotMatch) 另外就是这个Authorization字段的签名需要注意,base64需要处理byte[]数组,而不是字符串.所以用网上的在线验证工具是验证不了的. Java版的签名代码如下:\nimport bai.tool.Base64;\rimport javax.crypto.Mac;\rimport javax.crypto.spec.SecretKeySpec;\rimport java.security.InvalidKeyException;\rimport java.security.NoSuchAlgorithmException;\r/**\r* Hello world!\r*\r*/\rpublic class App\r{\rpublic static byte[] hamcsha1(byte[] data, byte[] key)\r{\rtry {\rSecretKeySpec signingKey = new SecretKeySpec(key, \u0026quot;HmacSHA1\u0026quot;);\rMac mac = Mac.getInstance(\u0026quot;HmacSHA1\u0026quot;);\rmac.init(signingKey);\rreturn mac.doFinal(data);\r} catch (NoSuchAlgorithmException e) {\re.printStackTrace();\r} catch (InvalidKeyException e) {\re.printStackTrace();\r}\rreturn null;\r}\rpublic static void main( String[] args ) {\rString toSign=\u0026quot;PUT\\n\u0026quot; +\r\u0026quot;\\n\u0026quot; +\r\u0026quot;image/jpeg; charset=UTF-8\\n\u0026quot; +\r\u0026quot;Thu, 25 Jan 2018 15:20:39 GMT\\n\u0026quot; +\r\u0026quot;/baicaidoc/image/small/mm1.jpg\u0026quot;;\rString accessKey=\u0026quot;OrzrzxIsfpFjA7S7yk0Lwy8Bw21TLhquhboiip56\u0026quot;;\rbyte[] hm=hamcsha1(toSign.getBytes(),accessKey.getBytes());\rSystem.out.println(\u0026quot;OSS LTAIxkX6Qj2OuMZ6:\u0026quot;+Base64.encodeToString(hm));\r}\r}\r客户端能跑通就好办了，最后是代码，使用HttpURLConnection来实现PUT上传代码。阿里云的OSS SDK太重了，而一般常用的就上传和删除功能\nimport java.io.*;\rimport java.net.HttpURLConnection;\rimport java.net.MalformedURLException;\rimport java.net.URL;\rimport java.text.SimpleDateFormat;\rimport java.util.Date;\rimport java.util.Locale;\rimport java.util.TimeZone;\rpublic class OSSUpload {\rpublic String httpUrlConnectionPut(String fileName) {\rString result = \u0026quot;\u0026quot;;\rURL url = null;\rString httpUrl = \u0026quot;http://baicaidoc.oss-cn-shenzhen.aliyuncs.com/image/small/test.jpg\u0026quot;;\rtry {\rurl = new URL(httpUrl);\r} catch (MalformedURLException e) {\re.printStackTrace();\r}\rif (url != null) {\rHttpURLConnection urlConn;\rtry {\rurlConn = (HttpURLConnection) url.openConnection();\rFile file = new File(fileName);\rurlConn.setRequestProperty(\u0026quot;content-type\u0026quot;, \u0026quot;image/jpeg; charset=UTF-8\u0026quot;);\rurlConn.setDoOutput(true);// http正文内，因此需要设为true, 默认情况下是false;\rurlConn.setDoInput(true);// 设置是否从httpUrlConnection读入，默认情况下是true;\rurlConn.setConnectTimeout(15 * 1000);\rurlConn.setRequestProperty(\u0026quot;User-Agent\u0026quot;, \u0026quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.84 Safari/537.36\u0026quot;);\r//设置请求方式为 PUT\rurlConn.setRequestMethod(\u0026quot;PUT\u0026quot;); urlConn.setRequestProperty(\u0026quot;Connection\u0026quot;, \u0026quot;Keep-Alive\u0026quot;);\rSimpleDateFormat sdf = new SimpleDateFormat(\u0026quot;EEE, dd MMM yyyy HH:mm:ss 'GMT'\u0026quot;, Locale.US);\rsdf.setTimeZone(TimeZone.getTimeZone(\u0026quot;GMT\u0026quot;));\rurlConn.setRequestProperty(\u0026quot;Host\u0026quot;, \u0026quot;baicaidoc.oss-cn-shenzhen.aliyuncs.com\u0026quot;);\rurlConn.setRequestProperty(\u0026quot;Content-Encoding\u0026quot;, \u0026quot;UTF-8\u0026quot;);\rurlConn.setRequestProperty(\u0026quot;Date\u0026quot;, sdf.format(new Date()));\rurlConn.setRequestProperty(\u0026quot;Content-Length\u0026quot;, String.valueOf(file.length()));\rurlConn.setRequestProperty(\u0026quot;Authorization\u0026quot;, \u0026quot;OSS LTAIxk223j2OuMZ6:tLZ74YYP/hkCJbG/6gkOJ7Mi4E=\u0026quot;);\rDataOutputStream dos = new DataOutputStream(urlConn.getOutputStream());\r//写入请求参数\rtry {\rInputStream in = new FileInputStream(file);\rint bytes = 0;\rbyte[] bufferOut = new byte[4096];\rwhile ((bytes = in.read(bufferOut)) != -1) {\rdos.write(bufferOut, 0, bytes);\r}\rdos.flush();\rdos.close();\rInputStream is = urlConn.getInputStream();\rint ch;\rStringBuffer b = new StringBuffer();\rwhile ((ch = is.read()) != -1) {\rb.append((char) ch);\r}\rSystem.out.println(\u0026quot;result:\u0026quot; + b.toString());\r}catch (IOException e){\re.printStackTrace();\rInputStream is=urlConn.getErrorStream();\rint ch;\rStringBuffer b = new StringBuffer();\rwhile ((ch = is.read()) != -1) {\rb.append((char) ch);\r}\rSystem.out.println(\u0026quot;error result:\u0026quot;+b.toString());\r}\rurlConn.disconnect();\r} catch (Exception e) {\re.printStackTrace();\r}finally {\r}\r}\rreturn result;\r}\rpublic static void main(String[] args) {\rOSSUpload oss = new OSSUpload(); oss.httpUrlConnectionPut(\u0026quot;/home/chen/Desktop/tmp/sd.png\u0026quot;);\r}\r}\r","date":"2018-01-25","permalink":"http://localhost:1313/post/aliyun_oss_custom/","tags":["Java"],"title":"折腾阿里云OSS的API"},{"content":" 前不久,有人问到我一个问题，就是使用mb_check_encoding来侦测一段字符的编码，预期是GBK编码，但是PHP给出来UTF-8编码的错误判断。那么，mb_check_encoding的正确姿势是什么呢？ 我们来看一段代码，\n\u0026lt;?php\r$utf8Str = '别abc扯淡';\rvar_dump(mb_check_encoding($utf8Str, 'UTF-8')); //输出true\rvar_dump(mb_check_encoding($utf8Str, 'gbk')); //输出true\r这段代码的输出是啥呢？按理，我们的PHP文件保存为什么编码，那它输出的就应该是啥编码，然而以上输出的都是true。再换个例子，这样呢？\n\u0026lt;?php\r$utf8Str = '别abc扯淡啊';\rvar_dump(mb_check_encoding($utf8Str, 'UTF-8'));\rvar_dump(mb_check_encoding($utf8Str, 'gbk'));\r后面多加了一个汉字，这次PHP做出了正确的判断，给出了是UTF-8的判断。那么mb_check_encoding到底有没有用？是这个函数有bug还是我自己不懂姿势？\n难道是，只要汉字是3的整数倍就会判断失灵？试验后确实是的，当然这只是表面现象，但无疑说明这个函数是不可靠的。为什么呢？其实原理说起来也不难理解，计算机并不懂什么叫乱码。一段文字，解释成UTF8或GBK其实都是可以的，我们用肉眼看到有了乱码，根据我们的经验，觉得解释成这种编码是错误的，而解释成另外一种编码才算正确。可是计算机不懂啊，你觉得有个字符很奇怪，你不认识所以认定是乱码，可计算机认识啊，它不觉得奇怪。除非字节数解释成另外一种编码，会多出一个字节，并且ASCII码也不是常见范围，计算机才能大胆判定解释成这种编码不对。所以这样去检测编码是无法完全可靠地.\n那既然mb_check_encoding这个函数不可靠，那么用正则可靠么？或许吧。 但是我们更应该关注的是PHP为什么会有这么一个功能？为什么其他语言没有这个方法，或者根本不会遇到这个问题？\n问题还是出在PHP本身。因为客户端可能会有多种编码输入，PHP为了解决这个问题就引入这么一个贴心的函数给使用者。可是PHP不应该是遇到问题就去动歪脑筋解决问题啊，而且规范问题。为什么其他语言不需要在SDK里引入这个方法呢？或者说是PHP程序员的使用姿势不正确?\n最后，其实PHP给出这个函数也不算错，但是一定要参照其他语言里的惯行做法，在文档里说清楚，这个函数的判断的是一种“可信度”，而不是给出一个非此即彼的“权威”结果。但是遗憾的是，这个函数的文档里没说很好的说清楚，而是这么写的，\n“Checks if the specified byte stream is valid for the specified encoding. It is useful to prevent so-called \u0026ldquo;Invalid Encoding Attack Returns TRUE on success or FALSE on failure.”\n其实加上这样一句话“This function only give the confidence level of the result”就好了，也就不会平白引起那么多的疑虑。\n比如，Python的做法就比较专业，chardet模块给出的是一个置信检测，而不是非true即false的判断。java里面的第三方工具包cpdetector也指出了其规则，按照“谁最先返回非空的探测结果，就以该结果为准”的原则返回探测到的字符集编码。其是基于统计学原理的，不保证完全正确。\n","date":"2018-01-12","permalink":"http://localhost:1313/post/php%E7%9A%84mb_check_encoding%E5%87%BD%E6%95%B0%E7%9A%84%E5%AD%98%E5%9C%A8%E6%98%AF%E9%B8%A1%E8%82%8B%E5%90%97/","tags":["PHP"],"title":"PHP的mb_check_encoding函数的存在是鸡肋吗"},{"content":" 针对最新火狐浏览器50+以上版本的firebug协议，类似FirePHP，但是FirePHP已经很久不更新，并且对最新的浏览器也已失效。\n这个在Firebug之上运行的扩展，结合一个服务器端的库，就可以让你的PHP代码向浏览器发送调试信息，该信息以HTTP响应头（HTTP headers）的方式编码。经过设置，你可以像在Firebug控制台调试JavaScript代码一样得到PHP脚本的警告和错误提示。下面我们来看看具体步骤。\n直接上代码\nimport com.alibaba.fastjson.JSON;\rimport java.util.ArrayList;\rimport java.util.HashMap;\rimport java.util.Map;\rimport java.util.Objects;\r/**\r* @version V1.0\r* @Description:直接输出服务器端调试日志到控制台，简易版本。\r* @date 2017/6/13 16:51\r*/\rpublic class DebugTool {\rpublic final String VERSION = \u0026quot;2.0.j1\u0026quot;;\rpublic final String HEADER_NAME = \u0026quot;X-ChromeLogger-Data\u0026quot;;\rprotected Map\u0026lt;String, Object\u0026gt; console = new HashMap\u0026lt;\u0026gt;();\rprivate String response=\u0026quot;\u0026quot;;\rpublic DebugTool() {\rconsole.put(\u0026quot;version\u0026quot;, VERSION);\rconsole.put(\u0026quot;columns\u0026quot;, new String[]{\u0026quot;log\u0026quot;, \u0026quot;backtrace\u0026quot;, \u0026quot;type\u0026quot;});\rconsole.put(\u0026quot;rows\u0026quot;, new ArrayList\u0026lt;Objects\u0026gt;());\rconsole.put(\u0026quot;request_uri\u0026quot;, this.getClass().getName());\r}\rpublic DebugTool(Class cls) {\rthis();\rconsole.put(\u0026quot;request_uri\u0026quot;, cls.getName());\r}\rpublic void log(Object o) {\rlog(o,\u0026quot;\u0026quot;);\r}\rpublic void info(Object o) {\rlog(o,\u0026quot;info\u0026quot;);\r}\rpublic void warn(Object o) {\rlog(o,\u0026quot;warn\u0026quot;);\r}\rpublic void error(Object o) {\rlog(o,\u0026quot;error\u0026quot;);\r}\rpublic void log(Object o,String type) {\rObject[] info;\rif(o instanceof Map){\rinfo = new Object[]{o};\r}else {\rinfo = new Object[]{o.toString()};\r}\rObject[] obj = new Object[]{info, console.get(\u0026quot;request_uri\u0026quot;), type};\rArrayList\u0026lt;Object\u0026gt; rows = (ArrayList\u0026lt;Object\u0026gt;) console.get(\u0026quot;rows\u0026quot;);\rrows.add(obj);\rconsole.put(\u0026quot;rows\u0026quot;, rows);\r}\rpublic String getResponse(){\rString json = JSON.toJSONString(console);\rjson = Base64.encodeToString(json);\rreturn json;\r}\r}\r使用方法：\nDebugTool debug=new DebugTool(this.getClass());\rtool.log(\u0026quot;hello 八阿哥\u0026quot;);\rMap hash=new HashMap();\rhash.put(\u0026quot;25\u0026quot;,\u0026quot;张三\u0026quot;);\rhash.put(\u0026quot;19\u0026quot;,\u0026quot;李四\u0026quot;);\rtool.warn(hash);\rresponse.add(DebugTool.HEADER_NAME,tool.response);\r仅对最新版Firefox有效。新版chrome有自己的debug协议（使用websocket）。有趣的是，这本来是一个chrome浏览器支持的协议，后来chrome放弃了，而Firefox拿过来了。 参考：https://craig.is/writing/chrome-logger\n","date":"2018-01-10","permalink":"http://localhost:1313/post/firejava%E8%BE%93%E5%87%BAjava%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E8%B0%83%E8%AF%95%E6%97%A5%E5%BF%97%E5%88%B0%E6%8E%A7%E5%88%B6%E5%8F%B0/","tags":["Java"],"title":"FireJava输出Java服务器端调试日志到控制台"},{"content":"TOTP 概念 TOTP - Time-based One-time Password Algorithm is an extension of the HMAC-based One Time Password algorithm HOTP to support a time based moving factor.\nTOTP（基于时间的一次性密码算法）是支持时间作为动态因素基于HMAC一次性密码算法的扩展。它是OTP算法的一种\n算法如下: TOTP = Truncate(HMAC-SHA-1(K, (T - T0) / X))\nK 共享密钥 T 时间 T0 开始计数的时间步长 X 时间步长\n代码实现 最简实现需要如下两个类 1.Base32.java\npublic class Base32 {\rprivate static final char[] ALPHABET = { 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O',\r'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '2', '3', '4', '5', '6', '7' };\rprivate static final byte[] DECODE_TABLE;\rstatic {\rDECODE_TABLE = new byte[128];\rfor (int i = 0; i \u0026lt; DECODE_TABLE.length; i++) {\rDECODE_TABLE[i] = (byte) 0xFF;\r}\rfor (int i = 0; i \u0026lt; ALPHABET.length; i++) {\rDECODE_TABLE[(int) ALPHABET[i]] = (byte) i;\rif (i \u0026lt; 24) {\rDECODE_TABLE[(int) Character.toLowerCase(ALPHABET[i])] = (byte) i;\r}\r}\r}\rpublic static String encode(byte[] data) {\rchar[] chars = new char[((data.length * 8) / 5) + ((data.length % 5) != 0 ? 1 : 0)];\rfor (int i = 0, j = 0, index = 0; i \u0026lt; chars.length; i++) {\rif (index \u0026gt; 3) {\rint b = data[j] \u0026amp; (0xFF \u0026gt;\u0026gt; index);\rindex = (index + 5) % 8;\rb \u0026lt;\u0026lt;= index;\rif (j \u0026lt; data.length - 1) {\rb |= (data[j + 1] \u0026amp; 0xFF) \u0026gt;\u0026gt; (8 - index);\r}\rchars[i] = ALPHABET[b];\rj++;\r} else {\rchars[i] = ALPHABET[((data[j] \u0026gt;\u0026gt; (8 - (index + 5))) \u0026amp; 0x1F)];\rindex = (index + 5) % 8;\rif (index == 0) {\rj++;\r}\r}\r}\rreturn new String(chars);\r}\rpublic static byte[] decode(String s) throws Exception {\rchar[] stringData = s.toCharArray();\rbyte[] data = new byte[(stringData.length * 5) / 8];\rfor (int i = 0, j = 0, index = 0; i \u0026lt; stringData.length; i++) {\rint val;\rtry {\rval = DECODE_TABLE[stringData[i]];\r} catch (ArrayIndexOutOfBoundsException e) {\rthrow new Exception(\u0026quot;Illegal character\u0026quot;);\r}\rif (val == 0xFF) {\rthrow new Exception(\u0026quot;Illegal character\u0026quot;);\r}\rif (index \u0026lt;= 3) {\rindex = (index + 5) % 8;\rif (index == 0) {\rdata[j++] |= val;\r} else {\rdata[j] |= val \u0026lt;\u0026lt; (8 - index);\r}\r} else {\rindex = (index + 5) % 8;\rdata[j++] |= (val \u0026gt;\u0026gt; index);\rif (j \u0026lt; data.length) {\rdata[j] |= val \u0026lt;\u0026lt; (8 - index);\r}\r}\r}\rreturn data;\r}\r}\r2.GoogleAuthenticator.java\nimport javax.crypto.spec.SecretKeySpec;\rimport java.security.InvalidKeyException;\rimport java.security.NoSuchAlgorithmException;\rimport java.security.SecureRandom;\rimport java.util.Base64;\rimport javax.crypto.Mac;\rpublic class GoogleAuthenticator {\r// taken from Google pam docs - we probably don't need to mess with these\rpublic static final int SECRET_SIZE = 10;\rpublic static final String SEED = \u0026quot;g8GjEvTbW5oVSV7avLBdwIHqGlUYNzKFI7izOF8GwLDVKs2m0QN7vxRs2im5MDaNCWGmcD2rvcZx\u0026quot;;\rpublic static final String RANDOM_NUMBER_ALGORITHM = \u0026quot;SHA1PRNG\u0026quot;;\rint window_size = 3; // default 3 - max 17 (from google docs)最多可偏移的时间\r/**\r* set the windows size. This is an integer value representing the number of 30 second windows\r* we allow\r* The bigger the window, the more tolerant of clock skew we are.\r* @param s window size - must be \u0026gt;=1 and \u0026lt;=17. Other values are ignored\r*/\rpublic void setWindowSize(int s) {\rif (s \u0026gt;= 1 \u0026amp;\u0026amp; s \u0026lt;= 17)\rwindow_size = s;\r}\r/**\r* Generate a random secret key. This must be saved by the server and associated with the\r* users account to verify the code displayed by Google Authenticator.\r* The user must register this secret on their device.\r* @return secret key\r*/\rpublic static String generateSecretKey() {\rSecureRandom sr = null;\rtry {\rsr = SecureRandom.getInstance(RANDOM_NUMBER_ALGORITHM);\rsr.setSeed(Base64.getDecoder().decode(SEED));\rbyte[] buffer = sr.generateSeed(SECRET_SIZE);\rBase32 codec = new Base32();\rbyte[] bEncodedKey = codec.encode(buffer).getBytes();\rString encodedKey = new String(bEncodedKey);\rreturn encodedKey;\r}catch (NoSuchAlgorithmException e) {\r// should never occur... configuration error\r}\rreturn null;\r}\r/**\r* Return a URL that generates and displays a QR barcode. The user scans this bar code with the\r* Google Authenticator application on their smartphone to register the auth code. They can also\r* manually enter the\r* secret if desired\r* @param user user id (e.g. fflinstone)\r* @param host host or system that the code is for (e.g. myapp.com)\r* @param secret the secret that was previously generated for this user\r* @return the URL for the QR code to scan\r*/\rpublic static String getQRBarcodeURL(String user, String host, String secret) {\rString format = \u0026quot;https://www.google.com/chart?chs=200x200\u0026amp;chld=M%%7C0\u0026amp;cht=qr\u0026amp;chl=otpauth://totp/%s@%s%%3Fsecret%%3D%s\u0026quot;;\rreturn String.format(format, user, host, secret);\r}\r/**\r* Check the code entered by the user to see if it is valid\r* @param secret The users secret.\r* @param code The code displayed on the users device\r* @param t The time in msec (System.currentTimeMillis() for example)\r* @return\r* @throws Exception\r*/\rpublic boolean check_code(String secret, long code, long timeMsec) throws Exception {\rBase32 codec = new Base32();\rbyte[] decodedKey = codec.decode(secret);\r// convert unix msec time into a 30 second \u0026quot;window\u0026quot;\r// this is per the TOTP spec (see the RFC for details)\rlong t = (timeMsec / 1000L) / 30L;\r// Window is used to check codes generated in the near past.\r// You can use this value to tune how far you're willing to go.\rfor (int i = -window_size; i \u0026lt;= window_size; ++i) {\rlong hash;\rtry {\rhash = verify_code(decodedKey, t + i);\r}catch (Exception e) {\r// Yes, this is bad form - but\r// the exceptions thrown would be rare and a static configuration problem\re.printStackTrace();\rthrow new RuntimeException(e.getMessage());\r//return false;\r}\rif (hash == code) {\rreturn true;\r}\r}\r// The validation code is invalid.\rreturn false;\r}\rprivate static int verify_code(byte[] key, long t) throws NoSuchAlgorithmException, InvalidKeyException {\rbyte[] data = new byte[8];\rlong value = t;\rfor (int i = 8; i-- \u0026gt; 0; value \u0026gt;\u0026gt;\u0026gt;= 8) {\rdata[i] = (byte) value;\r}\rSecretKeySpec signKey = new SecretKeySpec(key, \u0026quot;HmacSHA1\u0026quot;);\rMac mac = Mac.getInstance(\u0026quot;HmacSHA1\u0026quot;);\rmac.init(signKey);\rbyte[] hash = mac.doFinal(data);\rint offset = hash[20 - 1] \u0026amp; 0xF;\r// We're using a long because Java hasn't got unsigned int.\rlong truncatedHash = 0;\rfor (int i = 0; i \u0026lt; 4; ++i) {\rtruncatedHash \u0026lt;\u0026lt;= 8;\r// We are dealing with signed bytes:\r// we just keep the first byte.\rtruncatedHash |= (hash[offset + i] \u0026amp; 0xFF);\r}\rtruncatedHash \u0026amp;= 0x7FFFFFFF;\rtruncatedHash %= 1000000;\rreturn (int) truncatedHash;\r}\r}\r测试类如下:\nimport org.junit.Test;\rpublic class GoogleAuthTest {\r@Test\rpublic void genSecretTest() {\rString secret = GoogleAuthenticator.generateSecretKey();\rSystem.out.println(\u0026quot;secret=\u0026quot;+secret);\rString url = GoogleAuthenticator.getQRBarcodeURL(\u0026quot;testuser\u0026quot;, \u0026quot;testhost\u0026quot;, secret);\rSystem.out.println(\u0026quot;Please register \u0026quot; + url);\rSystem.out.println(\u0026quot;Secret key is \u0026quot; + secret);\r}\r// Change this to the saved secret from the running the above test.\rstatic String savedSecret = \u0026quot;VGH25A7M54QPME5F\u0026quot;;\r@Test\rpublic void authTest() throws Exception {\r// enter the code shown on device. Edit this and run it fast before the code expires!\rlong code = 146841;\rlong t = System.currentTimeMillis();\rGoogleAuthenticator ga = new GoogleAuthenticator();\rga.setWindowSize(5); //should give 5 * 30 seconds of grace...\rboolean r = ga.check_code(savedSecret, code, t);\rSystem.out.println(\u0026quot;Check code = \u0026quot; + r);\r}\r}\rOTP Auth协议 在实际使用中,通常把secret嵌入一段URL中并以二维码的形式发布,这个URL一般称为otpauth协议.其URL如下所示: otpauth://totp/testuser@testhost?secret=VGH25A7M54QPME5F\u0026amp;algorithm=SHA1\u0026amp;digits=6\u0026amp;period=30\n","date":"2018-01-08","permalink":"http://localhost:1313/post/totp%E7%AE%97%E6%B3%95java%E7%89%88%E6%9C%AC/","tags":["Java"],"title":"TOTP算法Java版本"},{"content":" 前段时间用vala开发了一个很小的程序,体验了一把vala的使用,网上关于vala的文章比较少,所以写一篇博客,如果你有相同的使用经验可以交流下.\n根据百度百科的解释，vala是一种新的、为GNOME开发者提供的具有现代化编程语言功能的一种编程语言。Vala是一种和C#极度类似的语言。\n众所周知,C是一门古老而落后的语言,虽然由于历史原因,大量的操作系统底层仍然在使用C(毕竟最早写底层的那批人早就退休甚至不在人世了,谁又愿意没事找事去重构呢.不过,还别说,Google就在干这种事,开发全新的操作系统),但并不适用于大型项目和协作开发.尽管Linux的作者Linus极度憎恨C++这样的面向对象的语言,并拒绝C++在Linux内核的使用.但是,Linux的其它开发者也心知肚明,C并不是一切,并且在Linux的各个方面大量使用C++和面向对象的开发模式.知名的KDE桌面就是基于QT来构建的,而QT是对C++的一个扩展,Linux上的大部分可用的应用都是基于QT来构建的,而另一个桌面环境Gnome则使用了GTK绑定,同时也大量使用了面向对象的特性和组件,比如Gobject,Vala.Vala的一个重要使用场景就是Gnome环境的GUI开发.\nVala语言的主要特点：支持lambda表达式；支持对象反射与内省；使用引用计数进行内存管理，计数嵌入在对象内；使用Glib和Gobject的主循环、事件回调系统。\n安装 在Ubuntu/Debian下安装很简单，使用命令sudo apt-get install valac，测试valac编译器的版本号，可以输入valac \u0026ndash;version命令。 我现在使用的是0.36版本,最新版本应该是0.40 Beta.\nHelloWorld程序 class Demo.HelloWorld : GLib.Object {\rpublic static int main(string[] args)\r{\rstdout.printf(\u0026quot;Hello, World\\n\u0026quot;);\rreturn 0;\r}\r}\r其实在Vala里,类并不是必须的.类名和文件名并不需要一致,并且一个类里允许多个类.\n编译运行 编译这个程序使用命令valac hello.vala，编译成功之后生成hello这个可执行程序，运行这个程序，输入结果为： Hello, World\nVala一个比较有趣的地方就是可以直接从Vala源码编译成C源码,比如上面的代码可以使用如下的命令编译成C源码\nvalac -C ./hello.vala\r生成的C源码如下:\n/* hello.c generated by valac 0.36.5, the Vala compiler\r* generated from hello.vala, do not modify */\r#include \u0026lt;glib.h\u0026gt;\r#include \u0026lt;glib-object.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\r#include \u0026lt;string.h\u0026gt;\r#include \u0026lt;stdio.h\u0026gt;\r#define DEMO_TYPE_HELLO_WORLD (demo_hello_world_get_type ())\r#define DEMO_HELLO_WORLD(obj) (G_TYPE_CHECK_INSTANCE_CAST ((obj), DEMO_TYPE_HELLO_WORLD, DemoHelloWorld))\r#define DEMO_HELLO_WORLD_CLASS(klass) (G_TYPE_CHECK_CLASS_CAST ((klass), DEMO_TYPE_HELLO_WORLD, DemoHelloWorldClass))\r#define DEMO_IS_HELLO_WORLD(obj) (G_TYPE_CHECK_INSTANCE_TYPE ((obj), DEMO_TYPE_HELLO_WORLD))\r#define DEMO_IS_HELLO_WORLD_CLASS(klass) (G_TYPE_CHECK_CLASS_TYPE ((klass), DEMO_TYPE_HELLO_WORLD))\r#define DEMO_HELLO_WORLD_GET_CLASS(obj) (G_TYPE_INSTANCE_GET_CLASS ((obj), DEMO_TYPE_HELLO_WORLD, DemoHelloWorldClass))\rtypedef struct _DemoHelloWorld DemoHelloWorld;\rtypedef struct _DemoHelloWorldClass DemoHelloWorldClass;\rtypedef struct _DemoHelloWorldPrivate DemoHelloWorldPrivate;\rstruct _DemoHelloWorld {\rGObject parent_instance;\rDemoHelloWorldPrivate * priv;\r};\rstruct _DemoHelloWorldClass {\rGObjectClass parent_class;\r};\rstatic gpointer demo_hello_world_parent_class = NULL;\rGType demo_hello_world_get_type (void) G_GNUC_CONST;\renum {\rDEMO_HELLO_WORLD_DUMMY_PROPERTY\r};\rgint demo_hello_world_main (gchar** args, int args_length1);\rDemoHelloWorld* demo_hello_world_new (void);\rDemoHelloWorld* demo_hello_world_construct (GType object_type);\rgint demo_hello_world_main (gchar** args, int args_length1) {\rgint result = 0;\rFILE* _tmp0_;\r_tmp0_ = stdout;\rfprintf (_tmp0_, \u0026quot;Hello, World\\n\u0026quot;);\rresult = 0;\rreturn result;\r}\rint main (int argc, char ** argv) {\r#if !GLIB_CHECK_VERSION (2,35,0)\rg_type_init ();\r#endif\rreturn demo_hello_world_main (argv, argc);\r}\rDemoHelloWorld* demo_hello_world_construct (GType object_type) {\rDemoHelloWorld * self = NULL;\rself = (DemoHelloWorld*) g_object_new (object_type, NULL);\rreturn self;\r}\rDemoHelloWorld* demo_hello_world_new (void) {\rreturn demo_hello_world_construct (DEMO_TYPE_HELLO_WORLD);\r}\rstatic void demo_hello_world_class_init (DemoHelloWorldClass * klass) {\rdemo_hello_world_parent_class = g_type_class_peek_parent (klass);\r}\rstatic void demo_hello_world_instance_init (DemoHelloWorld * self) {\r}\rGType demo_hello_world_get_type (void) {\rstatic volatile gsize demo_hello_world_type_id__volatile = 0;\rif (g_once_init_enter (\u0026amp;demo_hello_world_type_id__volatile)) {\rstatic const GTypeInfo g_define_type_info = { sizeof (DemoHelloWorldClass), (GBaseInitFunc) NULL, (GBaseFinalizeFunc) NULL, (GClassInitFunc) demo_hello_world_class_init, (GClassFinalizeFunc) NULL, NULL, sizeof (DemoHelloWorld), 0, (GInstanceInitFunc) demo_hello_world_instance_init, NULL };\rGType demo_hello_world_type_id;\rdemo_hello_world_type_id = g_type_register_static (G_TYPE_OBJECT, \u0026quot;DemoHelloWorld\u0026quot;, \u0026amp;g_define_type_info, 0);\rg_once_init_leave (\u0026amp;demo_hello_world_type_id__volatile, demo_hello_world_type_id);\r}\rreturn demo_hello_world_type_id__volatile;\r}\r可以看出 vala实际是把vala源码编译成GObject的语法,并且加入了很多语法糖.由于vala的这个特性,从而也决定了vala是一种性能比较高的语言.既能获得面向对象的便利,又能获得接近于C语言的性能.\nvala可以大量使用glib的库,具有比较强的表现力和较高的开发效率.然而由于其定位的问题,不能在服务端市场分得一杯羹,导致发展极为有限,可惜了这门在我看来,在Linux上开发体验仅次于C++和Java的语言.如果你接触过C++ 17 以上标准的C++,你就会感觉到C++的表现能力和开发效率,已经是一门比较现代化的语言了,并不会比脚本语言低多少.\n","date":"2018-01-08","permalink":"http://localhost:1313/post/vala%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C/","tags":["Vala"],"title":"Vala使用体验"},{"content":"多播协议是个好东西。 服务端\nimport socket\rimport struct\r# 多播地址和端口\rMULTICAST_GROUP = '239.0.0.110'\rSERVER_PORT = 12345\r# 创建 UDP 套接字\rserver_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)\r# 允许地址重用\rserver_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\r# 绑定到指定端口\rserver_socket.bind(('', SERVER_PORT))\r# 将套接字加入多播组\rgroup = socket.inet_aton(MULTICAST_GROUP)\rmreq = struct.pack('4sL', group, socket.INADDR_ANY)\rserver_socket.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)\rprint(f\u0026quot;Listening on multicast address {MULTICAST_GROUP}:{SERVER_PORT}...\u0026quot;)\rtry:\rwhile True:\r# 接收数据\rdata, client_address = server_socket.recvfrom(1024)\rmessage = data.decode('utf-8')\rprint(f\u0026quot;Received message from {client_address}: {message}\u0026quot;)\r# 向客户端发送响应\rresponse = \u0026quot;Message received successfully!\u0026quot;\rserver_socket.sendto(response.encode('utf-8'), client_address)\rexcept KeyboardInterrupt:\rprint(\u0026quot;Shutting down...\u0026quot;)\rfinally:\rserver_socket.close()\r客户端\nimport socket\rMULTICAST_GROUP = '239.0.0.110'\rSERVER_PORT = 12345\rclient_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\rclient_socket.settimeout(3)\rmessage = \u0026quot;Hello, I'm a client!\u0026quot;\rtry:\rclient_socket.sendto(message.encode('utf-8'), (MULTICAST_GROUP, SERVER_PORT))\rprint(f\u0026quot;Sent message to {MULTICAST_GROUP}:{SERVER_PORT}\u0026quot;)\rtry:\rdata, server_address = client_socket.recvfrom(1024)\rprint(f\u0026quot;Received response from {server_address}: {data.decode('utf-8')}\u0026quot;)\rexcept socket.timeout:\rprint(\u0026quot;No response from server. Server may be unavailable.\u0026quot;)\rexcept socket.error as e:\rprint(f\u0026quot;Error: {e}\u0026quot;)\rfinally:\rclient_socket.close()\r","date":"2025-04-02","permalink":"http://localhost:1313/post/python%E5%A4%9A%E6%92%AD/","tags":["python"],"title":"Python多播"},{"content":"将图片/文件转为二维码动画\nyum install qrencode test=\u0026quot;$(cat dianlong.jpg| base64|tr '\\n' ' '|sed 's/[[:space:]]//g')\u0026quot;\recho $test \u0026gt;\u0026gt; base64.txt #文件转base64\rsplit -b 1k base64.txt 1_ #按1K分割\rfor x in $(find -type f -name \u0026quot;1_*\u0026quot;); do cat $x|qrencode -o $x.png -s 4 ;done\rffmpeg -framerate 6 -pattern_type glob -i '1_*.png' -loop 0 out1.gif #转GIF\rffmpeg -framerate 10 -pattern_type glob -i '1_*.png' -c:v libx264 -pix_fmt yuv420p out.mp4\r#计算帧数，验证\rffprobe -i out.mp4\rffmpeg -i out.mp4 -map 0:v:0 -c copy -f null -\rffprobe -v error -select_streams v:0 -show_entries stream=nb_frames -of default=nokey=1:noprint_wrappers=1 out.mp4\r还原：\nffmpeg -i out1.gif re/img_%2d.jpg\rbase64 -d base64.txt \u0026gt;b.jpg\r","date":"2023-06-16","permalink":"http://localhost:1313/post/%E6%96%87%E4%BB%B6%E7%94%9F%E6%88%90%E5%8A%A8%E6%80%81%E4%BA%8C%E7%BB%B4%E7%A0%81/","tags":["Linux"],"title":"文件生成动态二维码"},{"content":"最近测试反馈了一个问题，每次重启服务器，我们某个版本的业务系统中的机器码都会改变，导致根据机器码算出来的许可证失效，从而使软件无法使用。 这个问题反馈了有一段时间了，但是本地一直没复现。然后前几天测试说又复现了，马上去看了下测试环境，服务器是一台国产化FT S2500服务器,验证了下，果然如此，马上去看了下关键代码。\npublic static String executeLinuxCmd(int type) {\rtry {\rString cmd = \u0026quot;dmidecode |grep 'Serial Number'\u0026quot;;\rif (type == 1) {\rcmd = \u0026quot;fdisk -l\u0026quot;;\r}\r//...\r} catch (IOException e) {//\r}\rreturn null;\r}\rpublic static String getSerialNumber(int type, String record, String symbol) {\rString execResult = executeLinuxCmd(type);\rString[] infos = execResult.split(\u0026quot;\\n\u0026quot;);\rfor (String info : infos) {\rinfo = info.trim();\rif (info.indexOf(record) != -1) {\rString[] sn = info.replace(\u0026quot; \u0026quot;, \u0026quot;\u0026quot;).split(symbol);\rreturn sn[1];\r}\r}\r//...\r}\r/**\r* 获取CPUID、硬盘序列号、MAC地址、主板序列号\r*\r* @return\r*/\rpublic static Map\u0026lt;String, String\u0026gt; getAllSn() {\rString os = System.getProperty(\u0026quot;os.name\u0026quot;);\rMap\u0026lt;String, String\u0026gt; snVo = new HashMap();\rif (\u0026quot;LINUX\u0026quot;.equalsIgnoreCase(os)) {\rString mainboardNumber = getSerialNumber(0, \u0026quot;Serial Number\u0026quot;, \u0026quot;:\u0026quot;);\rString diskNumber = getSerialNumber(1, \u0026quot;Disk identifier\u0026quot;, \u0026quot;:\u0026quot;);\rsnVo.put(\u0026quot;diskid\u0026quot;, diskNumber == null ? \u0026quot;tmpDiskId\u0026quot; : diskNumber.toUpperCase().replace(\u0026quot; \u0026quot;, \u0026quot;\u0026quot;));\rsnVo.put(\u0026quot;mainboard\u0026quot;, mainboardNumber == null ? \u0026quot;tmpMainboard\u0026quot; : mainboardNumber.toUpperCase().replace(\u0026quot; \u0026quot;, \u0026quot;\u0026quot;));\r} else {\r这下明白了，它是取的CPU序列号作为机器码。dmidecode的输出中有多个Serial Number，它只取了第一个，恰恰就是Processor Information，也就是我们常说的CPU序列号。\nHandle 0x0001, DMI type 4, 48 bytes\rProcessor Information\rSocket Designation: CPU0\rType: Central Processor\rFamily: ARMv8\rManufacturer: Phytium\rID: 33 66 1F 70 00 00 00 00\rSignature: Implementor 0x70, Variant 0x1, Architecture 15, Part 0x663, Revision 3\rVersion: S2500\rVoltage: 0.8 V\rExternal Clock: 100 MHz\rMax Speed: 2100 MHz\rCurrent Speed: 2100 MHz\rStatus: Populated, Enabled\rUpgrade: Unknown\rL1 Cache Handle: 0x1001\rL2 Cache Handle: 0x1002\rL3 Cache Handle: 0x1003\rSerial Number: A5F9B0AD-E023-7E89-CF01-47772188AD003\rAsset Tag: 9EEC0F35-D6DB-EE11-4788-C0EE56755439\rPart Number: ABD15C29-35D3-1659-BFAF-AD57F39874C3\rCore Count: 64\rCore Enabled: 64\rThread Count: 64\rCharacteristics:\r64-bit capable\rMulti-Core\rExecute Protection\rEnhanced Virtualization\rPower/Performance Control\rCPU支持过序列号功能，但是被人指责侵犯隐私，所以现在的规范中，CPU完全没有所谓的序列号。\n关于CPU序列号，其实还有一段历史。在奔腾3中短暂的引入过这个功能，但是后来很快就移除了。\nEAX=3: Processor Serial Number\nSee also: Pentium III § Controversy about privacy issues（https://en.wikipedia.org/wiki/Pentium_III#Controversy_about_privacy_issues）\nThis returns the processor\u0026rsquo;s serial number. The processor serial number was introduced on Intel Pentium III, but due to privacy concerns, this feature is no longer implemented on later models (PSN feature bit is always cleared). Transmeta\u0026rsquo;s Efficeon and Crusoe processors also provide this feature. AMD CPUs however, do not implement this feature in any CPU models.\nFor Intel Pentium III CPUs, the serial number is returned in EDX:ECX registers. For Transmeta Efficeon CPUs, it is returned in EBX:EAX registers. And for Transmeta Crusoe CPUs, it is returned in EBX register only.\nNote that the processor serial number feature must be enabled in the BIOS setting in order to function.\n所以，我们不应该使用CPU Serial Number来作为设备唯一性判断，而应该使用CPU ID来判断。\n1.Windows下获取CPU ID 如果是windows系统，根据MSDN文档：http://msdn.microsoft.com/en-us/library/aa394373(v=vs.85).aspx ProcessorId\nData type: string\nAccess type: Read-only\nProcessor information that describes the processor features. For an x86 class CPU, the field format depends on the processor support of the CPUID instruction. If the instruction is supported, the property contains 2 (two) DWORD formatted values. The first is an offset of 08h-0Bh, which is the EAX value that a CPUID instruction returns with input EAX set to 1. The second is an offset of 0Ch-0Fh, which is the EDX value that the instruction returns. Only the first two bytes of the property are significant and contain the contents of the DX register at CPU reset—all others are set to 0 (zero), and the contents are in DWORD format.\u0026quot;\n可以用如下代码获取CPU ID\n#include \u0026quot;stdafx.h\u0026quot;\r#include\u0026lt;iostream\u0026gt;\rint main()\r{\rint32_t deBuf[4];\r__cpuidex(deBuf, 01, 0);\rprintf(\u0026quot;%.8x%.8x\u0026quot;, deBuf[3], deBuf[0]);\rgetchar();\rreturn 0;\r}\r本地没有msvc编译环境，就不做测试了。\n2.linux x86/amd64获取CPU ID 在Linux上呢，我们也可以用C内联汇编来实现\n#include \u0026lt;stdio.h\u0026gt;\rstatic inline void native_cpuid(unsigned int *eax, unsigned int *ebx,\runsigned int *ecx, unsigned int *edx)\r{\r/* ecx is often an input as well as an output. */\rasm volatile(\u0026quot;cpuid\u0026quot;\r: \u0026quot;=a\u0026quot; (*eax),\r\u0026quot;=b\u0026quot; (*ebx),\r\u0026quot;=c\u0026quot; (*ecx),\r\u0026quot;=d\u0026quot; (*edx)\r: \u0026quot;0\u0026quot; (*eax), \u0026quot;2\u0026quot; (*ecx));\r}\rint main(int argc, char **argv)\r{\runsigned eax, ebx, ecx, edx;\reax = 1; /* processor info and feature bits */\rnative_cpuid(\u0026amp;eax, \u0026amp;ebx, \u0026amp;ecx, \u0026amp;edx);\rprintf(\u0026quot;stepping %d\\n\u0026quot;, eax \u0026amp; 0xF);\rprintf(\u0026quot;model %d\\n\u0026quot;, (eax \u0026gt;\u0026gt; 4) \u0026amp; 0xF);\rprintf(\u0026quot;family %d\\n\u0026quot;, (eax \u0026gt;\u0026gt; 8) \u0026amp; 0xF);\rprintf(\u0026quot;processor type %d\\n\u0026quot;, (eax \u0026gt;\u0026gt; 12) \u0026amp; 0x3);\rprintf(\u0026quot;extended model %d\\n\u0026quot;, (eax \u0026gt;\u0026gt; 16) \u0026amp; 0xF);\rprintf(\u0026quot;extended family %d\\n\u0026quot;, (eax \u0026gt;\u0026gt; 20) \u0026amp; 0xFF);\r/* EDIT */\reax = 3; /* processor serial number */\rnative_cpuid(\u0026amp;eax, \u0026amp;ebx, \u0026amp;ecx, \u0026amp;edx);\r/** see the CPUID Wikipedia article on which models return the serial number in which registers. The example here is for Pentium III */\rprintf(\u0026quot;cpu serial number 0x%08x%08x\\n\u0026quot;, edx, ecx);\rnative_cpuid这段代码来自linux kernel里的源码，其实gcc里有cpuid.h这个文件，它封装了ASM代码，直接引入即可。\n看下运行结果：\n[root@localhost xx]# gcc cpu_x86.c -o cpu_x86\r[root@localhost xx]# ./cpu_x86\rstepping 4\rmodel 5\rfamily 6\rprocessor type 0\rextended model 5\rextended family 0\rserial number 0x0000000000000000\r如上所示，eax, ebx, ecx, edx这四个寄存器对应的内容就是cpu id。跟dmidecode的结果比较下，可以对应上。\n[root@localhost xx]# dmidecode -t 4\r# dmidecode 3.0\rGetting SMBIOS data from sysfs.\rSMBIOS 2.7 present.\rHandle 0x0004, DMI type 4, 42 bytes\rProcessor Information\rSocket Designation: CPU #000\rType: Central Processor\rFamily: Unknown\rManufacturer: GenuineIntel\rID: 54 06 05 00 FF FB AB 0F\rVersion: Intel(R) Xeon(R) Gold 6152 CPU @ 2.10GHz\rVoltage: 3.3 V\rExternal Clock: Unknown\rMax Speed: 30000 MHz\rCurrent Speed: 2100 MHz\rStatus: Populated, Enabled\rUpgrade: ZIF Socket\rL1 Cache Handle: 0x0016\rL2 Cache Handle: 0x0018\rL3 Cache Handle: Not Provided\rSerial Number: Not Specified\rAsset Tag: Not Specified\rPart Number: Not Specified\rCore Count: 1\rCore Enabled: 1\rCharacteristics:\r64-bit capable\rExecute Protection\r3.aarch64下获取CPU ID 如果是aarch64架构，CPU架构不一样，就不能用同样的ASM汇编了，找了下ARM官方文档，https://developer.arm.com/documentation/ddi0500/d/system-control/aarch64-register-descriptions/main-id-register\u0026ndash;el1?lang=en，参考CPU架构，可以从MIDR_EL1寄存器获取\n#include \u0026lt;stdio.h\u0026gt;\rint main(int argc, char **argv)\r{\runsigned long arm_cpuid;\r__asm__(\u0026quot;mrs %0, MIDR_EL1\u0026quot; : \u0026quot;=r\u0026quot;(arm_cpuid));\rprintf(\u0026quot;%-20s: 0x%016lx\\n\u0026quot;, \u0026quot;MIDR_EL1=\u0026quot;, arm_cpuid);\r}\r输出如下\n[root@master98 xx]# gcc cpu.c -o cpu\r[root@master98 xx]# ./cpu\rMIDR_EL1= : 0x00000000701f6633\r正好与dmidecode中的ID对应。经过测试，重启后cpuid是不会改变的。\n4.CPU ID or Serial Number？ Java代码里匹配的是Serial Number，这里一直说的是CPU ID，这俩东西到底是不是同一个事呢？\n结论是： 1.CPU Serial Number是一个Embedded 96-bit code during chip fabrication，但废弃标准，不应该使用，而应该使用CPU ID来判断。\n2.因为涉及隐私问题（Serial Number is Readable by networks \u0026amp; applications），现在的服务器架构已经不支持CPU Serial Number的获取了，用dmidecode获取到的Serial Number不保证有值的。\n3.CPU ID包含的是CPU架构的一些信息，更接近条形码的概念，并不是唯一身份标识，不保证唯一性。\n4.dmidecode在国产服务器架构下获取到的CPU Serial Number，其实又叫PSN（Processor Serial Number）。之所以国产化服务器能拿到PSN，是因为国产服务器是aarch64架构，并且是自主化研发，并没有遵循Intel的规范。另外同为国产化服务器，不同的厂家实现也不一样，有的重启即变，有的并不会变化。关于PSN的开启，应该是可以在BIOS里配置。其实，PSN should NOT exist at all。为什么国产服务器还保留PSN，就不做过多展开了。有兴趣的可以自行阅读PSN相关文档\n最后，修改很简单，如果使用场景不严格，可以使用CPU ID，或者System Information中的UUID即可，两者都能保证重启不变，但System Information中的UUID能保证唯一性，而CPU ID不能 。\n","date":"2022-02-09","permalink":"http://localhost:1313/post/cpuid%E5%92%8C%E5%BA%8F%E5%88%97%E5%8F%B7%E8%83%8C%E5%90%8E%E7%9A%84%E9%82%A3%E4%BA%9B%E6%95%85%E4%BA%8B/","tags":["Linux"],"title":"Cpuid和序列号背后的那些故事"},{"content":"前几天看到有人发的一个面试题，问的是MySQL连接的进程描述符的问题。\n在Linux里，一切皆文件，那进程描述符，实际就是文件描述符了。\n我们还知道Linux 内核提供了一种通过 proc文件系统，/proc 文件系统是一个虚拟文件系统，通过它可以使用一种新的方法在 Linux内核空间和用户间之间进行通信。在 /proc文件系统中，我们可以将对虚拟文件的读写作为与内核中实体进行通信的一种手段，但是与普通文件不同的是，这些虚拟文件的内容都是动态创建的。用户和应用程序可以通过proc得到系统的信息，并可以改变内核的某些参数。\n/proc目录通常对用户来说是只读的，如果你直接在bash下想要修改一个文件是权限不足的。但是对系统来说是可写的，因此也就可以通过编程来实现增删改查。\n查看socket描述符 那么，这个文件描述符就一定是在/proc 目录了。想必那就是在相应进程的/proc/$pid/fd 目录下存放了此进程所有打开的fd。\n[root@localhost fd]# pwd\r/proc/1723/fd\r[root@manager 1723]# ll fd|grep socket\rlrwx------ 1 root root 64 Jul 7 13:49 103 -\u0026gt; socket:[5722374]\rlrwx------ 1 root root 64 Jul 7 13:49 104 -\u0026gt; socket:[5057632]\rlrwx------ 1 root root 64 Jul 7 13:49 105 -\u0026gt; socket:[5722375]\rlrwx------ 1 root root 64 Jul 7 13:49 106 -\u0026gt; socket:[5057636]\rlrwx------ 1 root root 64 Jul 7 13:49 107 -\u0026gt; socket:[5983188]\rlrwx------ 1 root root 64 Jul 7 13:49 124 -\u0026gt; socket:[5983189]\rlrwx------ 1 root root 64 Jul 7 13:49 130 -\u0026gt; socket:[27456]\rlrwx------ 1 root root 64 Jul 7 13:49 131 -\u0026gt; socket:[27458]\rlrwx------ 1 root root 64 Jul 7 13:49 132 -\u0026gt; socket:[27460]\rlrwx------ 1 root root 64 Jul 7 13:49 51 -\u0026gt; socket:[23447]\rlrwx------ 1 root root 64 Jul 7 13:49 52 -\u0026gt; socket:[23448]\rlrwx------ 1 root root 64 Jul 7 13:49 78 -\u0026gt; socket:[5057630]\rlrwx------ 1 root root 64 Jul 7 13:49 79 -\u0026gt; socket:[5721339]\rlrwx------ 1 root root 64 Jul 7 13:49 80 -\u0026gt; socket:[3639663]\rlrwx------ 1 root root 64 Jul 7 13:49 81 -\u0026gt; socket:[5057631]\rlrwx------ 1 root root 64 Jul 7 13:49 82 -\u0026gt; socket:[5721340]\rlrwx------ 1 root root 64 Jul 7 13:49 95 -\u0026gt; socket:[5722372]\r这个结果，和netant看到的相差无几\n[root@manager ~]# netstat -antp | grep 1723 | wc -l\r16\r当然，这和用lsof统计到的结果应该也是差不多的。之所以说差不多，而不是一样，是因为虽然netstat和lsof虽然也是读取的/proc文件系统，但是有自己的过滤和判断条件，比如这两个工具除了读取/proc/pid/fd目录，还会读取/proc/net/tcp(udp)文件。因此，如果socket创建了，没有被使用，那么就只会在/proc/pid/fd下面有，而不会在/proc/net/tcp(udp)，那么netstat就统计不到了。\n那么这个socket:后面的一串数字是什么呢？看起来像是端口号，有些又明显不是，其实是该socket的inode号。 那么，知道了某个进程打开的socket的inode号后，我们可以做什么呢？这就涉及到/proc/net/tcp(udp对应/proc/net/udp)文件了，其中也列出了相应socket的inode号通过比对此字段，我们能在/proc/net/tcp下获得此套接口的其他信息，如对应的\u0026lt;本地地址：端口号，远端地址：端口号\u0026gt;四元组，窗口大小，状态等信息。具体字段含义详见net/ipv4/tcp_ipv4.c 中的 tcp4_seq_show 函数。\n[root@manager net]# cat /proc/net/tcp\rsl local_address rem_address st tx_queue rx_queue tr tm-\u0026gt;when retrnsmt uid timeout inode\r0: 00000000:006F 00000000:0000 0A 00000000:00000000 00:00000000 00000000 0 0 15528 1 ffff880426f60000 100 0 0 10 0\r1: 00000000:0016 00000000:0000 0A 00000000:00000000 00:00000000 00000000 0 0 19300 1 ffff880426f607c0 100 0 0 10 0\r2: 0100007F:0019 00000000:0000 0A 00000000:00000000 00:00000000 00000000 0 0 20170 1 ffff88042dfc8000 100 0 0 10 0\r3: 00000000:21DE 00000000:0000 0A 00000000:00000000 00:00000000 00000000 0 0 21513 1 ffff88042dfc87c0 100 0 0 10 0\r4: 55F9B40A:0016 59CDB40A:2779 01 00000000:00000000 02:000936FD 00000000 0 0 6004930 2 ffff88042dfca6c0 22 6 1 10 -1\r5: 55F9B40A:0016 59CDB40A:2733 01 00000030:00000000 01:00000018 00000000 0 0 5984362 4 ffff880426f645c0 25 4 31 10 -1\r6: 55F9B40A:0016 59CDB40A:2778 01 00000000:00000000 02:000936FD 00000000 0 0 6004866 2 ffff88042dfcae80 24 7 1 10 -1\r7: 55F9B40A:8F2E 55F9B40A:20F9 01 00000000:00000000 00:00000000 00000000 0 0 22051 1 ffff88042dfc9f00 20 4 30 10 -1\r8: 55F9B40A:0016 59CDB40A:2738 01 00000000:00000000 02:000843C9 00000000 0 0 5983909 2 ffff880426f664c0 22 4 21 7 6\r[root@manager net]#\r这个文件怎么解读呢，我们暂时只看第一部分\n8: 55F9B40A:0016 59CDB40A:2738 01 | | | | | |--\u0026gt; connection state（套接字状态）\r| | | | |------\u0026gt; remote TCP port number（远端端口，主机字节序）\r| | | |-------------\u0026gt; remote IPv4 address（远端IP，网络字节序）\r| | |--------------------\u0026gt; local TCP port number（本地端口，主机字节序）\r| |---------------------------\u0026gt; local IPv4 address（本地IP，网络字节序）\r|----------------------------------\u0026gt; number of entry\r比如我们看到59CDB40A:2738这个rem_address，很自然它就是TCP的四元组，十六进制转为二进制后就是 89.205.180.10:10040，注意此处IP地址应该是10.180.205.89。用lsof验证下\n[root@manager net]# lsof -i|grep 10040\rsshd 17757 root 3u IPv4 5983909 0t0 TCP manager.bigdata:ssh-\u0026gt;10.180.205.89:10040 (ESTABLISHED)\rconnection state(套接字状态)，不同的数值代表不同的状态，参照如下：\nTCP_ESTABLISHED:1 TCP_SYN_SENT:2\rTCP_SYN_RECV:3 TCP_FIN_WAIT1:4\rTCP_FIN_WAIT2:5 TCP_TIME_WAIT:6\rTCP_CLOSE:7 TCP_CLOSE_WAIT:8\rTCP_LAST_ACL:9 TCP_LISTEN:10\rTCP_CLOSING:11\r我们看的这条数据并不是MySQL的连接。问题来了，为什么MySQL里看到那么多fd，netstat也看到了很多，但是 /proc/net/tcp 下并没有那么多socket描述符呢。前面说过了，/proc/net/tcp(udp)可以认为是proc/pid/fd的子集，但是这也差的太离谱了。其实原因很简单，如果你在 /proc/net/tcp下找不到，试试去/proc/net/tcp6 下找找呢。\n关闭指定socket连接 如果我们再进一步，我们现在可以找到每个pid下的socket描述符，如果我想断掉这个描述符也就是断开这个连接，怎么做呢？用防火墙显然不是好主意，防火墙通常是针对某个IP和固定端口的。这个时候，socket fd号就派上用场了。注意，fd和inode是两码事。\n查看当前fd\n(base) [root@manager ~]# ll /proc/1723/fd|grep socket\rlrwx------ 1 root root 64 Jul 7 13:49 103 -\u0026gt; socket:[10232948]\rlrwx------ 1 root root 64 Jul 7 13:49 105 -\u0026gt; socket:[9490029]\rlrwx------ 1 root root 64 Jul 7 13:49 107 -\u0026gt; socket:[10232952]\rlrwx------ 1 root root 64 Jul 7 13:49 124 -\u0026gt; socket:[10232954]\rlrwx------ 1 root root 64 Jul 7 13:49 130 -\u0026gt; socket:[27456]\rlrwx------ 1 root root 64 Jul 7 13:49 131 -\u0026gt; socket:[27458]\rlrwx------ 1 root root 64 Jul 7 13:49 132 -\u0026gt; socket:[27460]\rlrwx------ 1 root root 64 Jul 7 13:49 51 -\u0026gt; socket:[23447]\rlrwx------ 1 root root 64 Jul 7 13:49 52 -\u0026gt; socket:[23448]\rlrwx------ 1 root root 64 Jul 7 13:49 79 -\u0026gt; socket:[10882498]\r现在在另外一台服务器，直接用命令行mysql -h连接本机的mysql服务，然后再查看下fd列表\n(base) [root@manager ~]# ll /proc/1723/fd|grep socket\rlrwx------ 1 root root 64 Jul 7 13:49 103 -\u0026gt; socket:[10232948]\rlrwx------ 1 root root 64 Jul 7 13:49 105 -\u0026gt; socket:[9490029]\rlrwx------ 1 root root 64 Jul 7 13:49 107 -\u0026gt; socket:[10232952]\rlrwx------ 1 root root 64 Jul 7 13:49 124 -\u0026gt; socket:[10232954]\rlrwx------ 1 root root 64 Jul 7 13:49 130 -\u0026gt; socket:[27456]\rlrwx------ 1 root root 64 Jul 7 13:49 131 -\u0026gt; socket:[27458]\rlrwx------ 1 root root 64 Jul 7 13:49 132 -\u0026gt; socket:[27460]\rlrwx------ 1 root root 64 Jul 7 13:49 51 -\u0026gt; socket:[23447]\rlrwx------ 1 root root 64 Jul 7 13:49 52 -\u0026gt; socket:[23448]\rlrwx------ 1 root root 64 Jul 7 13:49 79 -\u0026gt; socket:[10882498]\rlrwx------ 1 root root 64 Jul 7 13:49 80 -\u0026gt; socket:[11222776]\r对比下，最下面多出来的一行就是新增的那个连接，fd=80,socket inode=11222776。\n我们使用gdb调用syscall，关闭这个fd\ngdb -p 1723\rcall close(80)\rquit\r然后看一下，远程mysql连接已经断了。\n","date":"2021-07-09","permalink":"http://localhost:1313/post/socket%E6%8F%8F%E8%BF%B0%E7%AC%A6%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/","tags":["Linux"],"title":"进程Socket描述符的那些事"},{"content":"之前一篇文章提到了System.exit和SecurityManager,引入了下面的代码\npublic class SelfSecurityManager extends SecurityManager{\r..//\r@Override\rpublic void checkExit(int status) {\rsuper.checkExit(status);\rthrow new ExitException(status);\r}\r}\r通过自定义SecurityManager来禁止System.exit的执行，这里我们来分析下其实现原理，看下super.checkExit方法\n/*\r* @param status the exit status.\r* @exception SecurityException if the calling thread does not have\r* permission to halt the Java Virtual Machine with\r* the specified status.\r* @see java.lang.Runtime#exit(int) exit\r* @see #checkPermission(java.security.Permission) checkPermission\r*/\rpublic void checkExit(int status) {\rcheckPermission(new RuntimePermission(\u0026quot;exitVM.\u0026quot;+status));\r}\r可以看到checkPermission方法检查了RuntimePermission类型中的exitVM操作。RuntimePermission是JVM对运行时权限的一个集合，提供了对Java运行时的权限定义，那RuntimePermission有哪些权限呢，我们可以看下RuntimePermission类上的注释，或者直接看官方文档\nPermission 可以看到仅仅是RuntimePermission类型就非常之多 ，包括之前我们提到的setSecurityManager和exitVM。\nPermission Target Name What the Permission Allows Risks of Allowing this Permission createClassLoader Creation of a class loader This is an extremely dangerous permission to grant. Malicious applications that can instantiate their own class loaders could then load their own rogue classes into the system. These newly loaded classes could be placed into any protection domain by the class loader, thereby automatically granting the classes the permissions for that domain. getClassLoader Retrieval of a class loader (e.g., the class loader for the calling class) This would grant an attacker permission to get the class loader for a particular class. This is dangerous because having access to a class\u0026rsquo;s class loader allows the attacker to load other classes available to that class loader. The attacker would typically otherwise not have access to those classes. setContextClassLoader Setting of the context class loader used by a thread The context class loader is used by system code and extensions when they need to lookup resources that might not exist in the system class loader. Granting setContextClassLoader permission would allow code to change which context class loader is used for a particular thread, including system threads. enableContextClassLoaderOverride Subclass implementation of the thread context class loader methods The context class loader is used by system code and extensions when they need to lookup resources that might not exist in the system class loader. Granting enableContextClassLoaderOverride permission would allow a subclass of Thread to override the methods that are used to get or set the context class loader for a particular thread. closeClassLoader Closing of a ClassLoader Granting this permission allows code to close any URLClassLoader that it has a reference to. setSecurityManager Setting of the security manager (possibly replacing an existing one) The security manager is a class that allows applications to implement a security policy. Granting the setSecurityManager permission would allow code to change which security manager is used by installing a different, possibly less restrictive security manager, thereby bypassing checks that would have been enforced by the original security manager. createSecurityManager Creation of a new security manager This gives code access to protected, sensitive methods that may disclose information about other classes or the execution stack. getenv.{variable name} Reading of the value of the specified environment variable This would allow code to read the value, or determine the existence, of a particular environment variable. This is dangerous if the variable contains confidential data. exitVM.{exit status} Halting of the Java Virtual Machine with the specified exit status This allows an attacker to mount a denial-of-service attack by automatically forcing the virtual machine to halt. Note: The \u0026ldquo;exitVM.\u0026rdquo; permission is automatically granted to all code loaded from the application class path, thus enabling applications to terminate themselves. Also, the \u0026ldquo;exitVM\u0026rdquo; permission is equivalent to \u0026ldquo;exitVM.\u0026rdquo;. shutdownHooks Registration and cancellation of virtual-machine shutdown hooks This allows an attacker to register a malicious shutdown hook that interferes with the clean shutdown of the virtual machine. .. .. .. 也就是说，Java代码里，禁止执行哪些方法，允许执行哪些方法，都是有开关可以控制的。除了RuntimePermission，还有 AudioPermission, AuthPermission, AWTPermission, DelegationPermission, JAXBPermission, LinkPermission, LoggingPermission, ManagementPermission, MBeanServerPermission, MBeanTrustPermission, NetPermission, PropertyPermission, ReflectPermission, RuntimePermission, SecurityPermission, SerializablePermission, SQLPermission, SSLPermission, SubjectDelegationPermission, WebServicePermission等类型，比如设置Java代码对操作系统和JVM常量读取的PropertyPermission，设置读写文件位置和操作的FilePermission等。\n需要说明的是，RuntimePermission是java.security.BasicPermission的子类，BasicPermission又是java.security.Permission的子类，因此FilePermission和RuntimePermission不在一个同级别的包下。\n要让这些Permission生效，我们需要在JVM启动时就指定对应的策略文件，比如 java -jar aa.jar -Djava.security.manager -Djava.security.policy==d:/other/security.policy\npolicy策略文件 我们接着讲下policy策略文件是啥。\npolicy文件的作用是指定哪些类有哪些权限。policy文件根据类的url和类的签名来确定类，指定权限，例如：\ngrant codeBase \u0026quot;file:${{java.ext.dirs}}/*\u0026quot; {\rpermission java.security.AllPermission;\r};\rgrant {\rpermission java.io.FilePermission \u0026quot;\u0026lt;\u0026lt;ALL FILES\u0026gt;\u0026gt;\u0026quot;, \u0026quot;execute\u0026quot;;\r};\rpolicy文件的具体语法可以看oracle的文档，DSL如下：\ngrant signedBy \u0026quot;signer_names\u0026quot;, codeBase \u0026quot;URL\u0026quot;,\rprincipal principal_class_name \u0026quot;principal_name\u0026quot;,\rprincipal principal_class_name \u0026quot;principal_name\u0026quot;,\r... {\rpermission permission_class_name \u0026quot;target_name\u0026quot;, \u0026quot;action\u0026quot;, signedBy \u0026quot;signer_names\u0026quot;;\rpermission permission_class_name \u0026quot;target_name\u0026quot;, \u0026quot;action\u0026quot;, signedBy \u0026quot;signer_names\u0026quot;;\r...\r};\rtarget有限支持 \u0026ldquo;*\u0026rdquo; 和\u0026quot;-\u0026ldquo;这种通配符，但使用场景有限。\n一旦开启了policy策略，JVM的权限检查就变成了白名单模式。默认情况下，JVM的policy是AllPermission的（默认的policy文件位于java.home/lib/security/java.policy），如果你定义了自己的policy文件覆盖JVM的默认策略，那么就严格按照你的定义来走了，不在你policy策略里的代码一律无法执行。\nimport java.io.FileWriter;\rimport java.io.IOException;\rpublic class Poc {\rpublic static void main(String[] args) throws IOException {\rexec(\u0026quot;calc\u0026quot;);\rSystem.setSecurityManager(null);\rwrite();\r}\rpublic static void write() {\rfinal String str = \u0026quot;Hi \u0026quot;;\rtry {\rFileWriter writer = new FileWriter(\u0026quot;d:\\\\a.txt\u0026quot;);\rwriter.write(str);\rwriter.close();\r} catch (IOException e) {\re.printStackTrace();\r}\r}\rpublic static void exec(String command) {\rtry {\rRuntime.getRuntime().exec(command);\r} catch (Exception e) {\re.printStackTrace();\r}\r}\r}\r脚本小子要想再执行exec弹个计算器就不行了，异常如下\nLauncher failed - \u0026quot;Dump Threads\u0026quot; and \u0026quot;Exit\u0026quot; actions are unavailable (access denied (\u0026quot;java.lang.RuntimePermission\u0026quot; \u0026quot;loadLibrary.G:\\idea\\bin\\breakgen64.dll\u0026quot;))\rjava.security.AccessControlException: access denied (\u0026quot;java.io.FilePermission\u0026quot; \u0026quot;\u0026lt;\u0026lt;ALL FILES\u0026gt;\u0026gt;\u0026quot; \u0026quot;execute\u0026quot;)\rat java.security.AccessControlContext.checkPermission(AccessControlContext.java:472)\r可以看到execute被阻止了，甚至连idea的javaagent挂载都被禁止了。因为前面说过，policy策略是白名单模式。\n实用性 想要把policy策略用起来，看来是很困难的，因为默认的白名单模式也会导致很多常规操作受阻，包括文件读写，一些反射API。要想白名单起作用，需要严格的测试和复杂的policy策略，当然为了安全，这些都是值得的。\n在java中，反射是一个常见的操作，如果由于业务需要，无法禁用反射，尤其是Spring，对反射强依赖，这种情况可以设置禁止反射的方法和变量的黑名单，方法就是sun.reflect.Reflection类的registerFieldsToFilter和registerMethodsToFilter方法。\n那么policy策略有黑名单模式吗？没有。如果你非要有，也可以自定义java.security.manager类，但是黑名单策略明显是比白名单安全隐患要大的。\n要实现安全和易用之间的平衡，还是很难的。另外，Java体系的API是比较复杂的，反射，自定义ClassLoader，loadLibrary等非常规操作都是可以被利用来绕过java security manager的，尤其需要注意。当然，还得从代码和服务器层面来做好安全防控。\njava policy策略这么复杂，有什么工具能帮助我们配置吗？这个真的有，那就是JDK自带的policytool，界面如图。 如果要在springboot里配置一个policy，会比较复杂，可能会多大几百条指令，这里仅给出一个最小的支持数据库连接的springboot的policy文件\ngrant codeBase \u0026quot;file:G:/data/project/bcdemo/target/bcdemo-0.0.1-SNAPSHOT.jar\u0026quot; {\rpermission java.util.PropertyPermission \u0026quot;*\u0026quot;, \u0026quot;read\u0026quot;;\r//\rpermission java.util.PropertyPermission \u0026quot;java.awt.headless\u0026quot;, \u0026quot;read,write\u0026quot;;\rpermission java.util.PropertyPermission \u0026quot;spring.beaninfo.ignore\u0026quot;, \u0026quot;read,write\u0026quot;;\rpermission java.util.PropertyPermission \u0026quot;org.graalvm.nativeimage.imagecode\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.util.PropertyPermission \u0026quot;user.dir\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.util.PropertyPermission \u0026quot;java.protocol.handler.pkgs\u0026quot;, \u0026quot;read,write\u0026quot;;\rpermission java.util.PropertyPermission \u0026quot;PID\u0026quot;, \u0026quot;write\u0026quot;;\rpermission java.util.PropertyPermission \u0026quot;catalina.*\u0026quot;, \u0026quot;read,write\u0026quot;;\rpermission java.lang.reflect.ReflectPermission \u0026quot;suppressAccessChecks\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.io.FilePermission \u0026quot;${java.io.tmpdir}/-\u0026quot;, \u0026quot;read,write,delete\u0026quot;;\rpermission java.io.FilePermission \u0026quot;./config/application.properties\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.io.FilePermission \u0026quot;./config/-\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.io.FilePermission \u0026quot;./application.properties\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.io.FilePermission \u0026quot;./application.xml\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.io.FilePermission \u0026quot;./application.yml\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.io.FilePermission \u0026quot;./application.yaml\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.io.FilePermission \u0026quot;./-\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.io.FilePermission \u0026quot;G:/data/project/bcdemo/target/\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.io.FilePermission \u0026quot;C:/-\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;getenv.SPRING_BOOT_ENABLEAUTOCONFIGURATION\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;getenv.spring.boot.enableautoconfiguration\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;getenv.spring.application.name\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;getenv.spring.*\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;getenv.logging.*\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;getenv.LOGGING_REGISTER_SHUTDOWN_HOOK\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;getenv.*\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;createClassLoader\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;setContextClassLoader\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;accessDeclaredMembers\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.net.SocketPermission \u0026quot;localhost:9010\u0026quot;, \u0026quot;listen\u0026quot;;\rpermission java.net.SocketPermission \u0026quot;127.0.0.1:1024-\u0026quot;, \u0026quot;accept,resolve\u0026quot;;\r//db\rpermission java.net.SocketPermission \u0026quot;10.180.249.85:3306\u0026quot;, \u0026quot;connect,resolve\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;getProtectionDomain\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;setFactory\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;accessClassInPackage.sun.reflect\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;getClassLoader\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.net.NetPermission \u0026quot;specifyStreamHandler\u0026quot;, \u0026quot;read\u0026quot;;\rpermission javax.security.auth.AuthPermission \u0026quot;doAsPrivileged\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.security.SecurityPermission \u0026quot;getProperty.authconfigprovider.factory\u0026quot;, \u0026quot;read\u0026quot;;\rpermission java.lang.RuntimePermission \u0026quot;modifyThread\u0026quot;, \u0026quot;read\u0026quot;;\r};\r这份配置仅供参考，如果你有引入更多依赖或外部连接，那就需要根据报错添加对应策略。\n一点闲话 java policy有啥实际应用吗？百度应用引擎BAE (Baidu App Engine) 大概是2011年或更早搞的，是模仿SAE（新浪云,2009年11月推出）的一个产品。至于GAE，就不提了，比它们不知高了几个level。\n不过SAE那时逼格比较高，刚开始只支持PHP，而且得邀请制开通，还搞了什么新浪豆机制，所以我用的是免费BAE。继续闲话，当时新浪搞了个SAE认证，会玩SAE的颁发个初中高级SAE开发者认证，据说面试可以加分，然后产生了SAE认证一条龙产业，花钱买认证，甚至有人给自己的不识字的父母也搞了个SAE中级认证。。。别笑，是真的。这个圈子可把老哥我当年给整乐了，而且一圈人一直在整乐子，整到了2021年。\nPHP比较简单就一句略过，就是Nginx虚拟主机+自定义php.ini那套，说下Java沙箱。BAE对Java的支持也比较有意思，BAE那个年代有kvm和虚拟机了（但是还没有docker），但BAE也好，SAE也好，使用的并不是虚拟技术，同样是更接近虚拟主机的方案。其中BAE对Java的支持我记得是通过SVN提交代码文件到一个固定的目录下就可以了，操作体验非常接近虚拟主机。\n那脚本小子就来劲了啊，我得给你穿了，访问别人的文件或系统的文件。还真有人这么做了，穿透BAE/SAE的沙箱读取系统配置文件或者弹个计算器。BAE/SAE当时都是用的java policy搞的Java沙箱技术来实现隔离的，一样有人用反射来绕过沙箱。当然，沙箱实现还不止这种技术，还包括网络的隔离等。\n不过现在都2021年了，docker和K8S的广泛使用让Java沙箱的用武之地已经不是那么很大了，docker的隔离也更彻底了，沙箱或许已经成为了历史。\n","date":"2021-06-17","permalink":"http://localhost:1313/post/java%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5%E9%85%8D%E7%BD%AE%E5%92%8C%E6%B2%99%E7%AE%B1%E9%97%B2%E8%AF%9D/","tags":["Java"],"title":"Java安全策略配置和沙箱闲话"},{"content":"之前文章提到服务器上一个进程启动后不到三分钟就挂掉，到底是什么原因挂掉了，这个问题可以写篇文章了。进程死了，无非就两种可能：自杀，他杀。他杀又包括第三方杀害和系统判死刑。\n先来看自杀。\n1.自杀 我们以Java为例，Java程序在main方法运行完就会退出，这种属于自杀。或者像下面这样\nSystem.exit();\r这样也属于自杀。\n比如下面的代码\npublic class SelfKill {\rpublic static void main(String[] args) throws InterruptedException {\rwhile(true){\rThread.sleep(5000);\rSystem.exit(4);\r}\r}\r}\r运行如下：\n[koudai@koudai-pc classes]$ java baicai.other.SelfKill\r[koudai@koudai-pc classes]$ echo $?4\r我们能用shutdownHook来在临死前记日志。\npublic class SelfKill {\rpublic static void main(String[] args) throws InterruptedException {\rRuntime.getRuntime().addShutdownHook(new Thread(() -\u0026gt; {\rSystem.out.println(\u0026quot;关闭应用，释放资源\u0026quot;);\r}));\rwhile(true){\rThread.sleep(2000);\rSystem.exit(4);\r}\r}\r}\r执行结果\n[koudai@koudai-pc classes]$ java baicai.other.SelfKill\r关闭应用，释放资源\r可以看到，无论是主动自杀，还是被自杀，shutdownHook都能保持现场。那如果是不支持shutdownHook的语言呢，或者程序里没有做Hook，那我们是不知道的。另外，不只是自杀shutdownHook能触发，它杀shutdownHook也会被触发。\n总结下：对于主动自杀，如果我们有使用了shutdownHook，是能记录下自杀时间和现场的。如果是被自杀（恶意后门调用System.exit），并且我们没有做Hook，那对自杀现场是不知情的。代码里一定要有完善的shutdownHook。\n主动自杀是我们的主动行为，那怎样避免被动自杀呢？刚才说了，被动自杀一般是恶意调用System.exit导致，一种是开发者加入的后门，一种是脚本小子加入的后门。System.exit导致JVM直接退出，且没有日志可以查询到是哪个类里的代码导致，因此通常情况下需要屏蔽。System.exit是可以被禁止的，方法就是自定义SecurityManager：\npublic class SelfSecurityManager extends SecurityManager{\r@Override\rpublic void checkPermission(Permission perm) {\rif (perm instanceof java.lang.RuntimePermission) {\rString name = perm.getName();\rif (name != null \u0026amp;\u0026amp; name.contains(\u0026quot;setSecurityManager\u0026quot;)) {\rthrow new SecurityException(\u0026quot;System.setSecurityManager denied!\u0026quot;);\r}\r}\r}\r@Override\rpublic void checkPermission(Permission perm, Object context) {\r//\r}\r@Override\rpublic void checkExit(int status) {\rsuper.checkExit(status);\rthrow new ExitException(status);//自定义异常\r}\r}\rSystem.setSecurityManager(new SelfSecurityManager());//main方法中\r需要注意的是，你可以自定义SecurityManager，脚本小子也可以自定义。因此光在Java类中自定义SecurityManager是不够的，你需要在JVM启动参数上定义更精细的policy文件，以及保护自己的SecurityManager不被重置。尤其需要注意不要被反射绕过。\n2.他杀 前面说了，不只是自杀shutdownHook能触发，以下场景都会触发 ShutdownHook :\n代码执行结束，JVM 正常退出 应用代码中调用 System#exit 方法 应用中发生 OOM 错误，导致 JVM 关闭 终端中使用 Ctrl+C(非后台运行) 主动关闭应用 我们模拟Ctrl+C试试。如下所示\n[koudai@koudai-pc classes]$ java baicai.other.SelfKill^C关闭应用，释放资源[koudai@koudai-pc classes]$\r可以看到ctrl+C是能被捕获到的。那么kill指令能被捕获吗\n[koudai@koudai-pc classes]$ kill 14675[koudai@koudai-pc classes]$ java baicai.other.SelfKill关闭应用，释放资源\r可以看到普通的kill是能被捕获的，那么kill -9呢\n[koudai@koudai-pc classes]$ ps -ef|grep Kill\rkoudai 14948 8231 0 00:57 pts/1 00:00:00 java baicai.other.SelfKill\rkoudai 15235 14640 0 00:58 pts/2 00:00:00 grep --colour=auto Kill\r[koudai@koudai-pc classes]$ kill -9 14948\r[koudai@koudai-pc classes]$ java baicai.other.SelfKill\r已杀死\r可以看到kill -9是无法被进程自身所捕获的。\n到这里就结束了吗？\n真正的问题来了，就算我有shutdownHook能记下临终遗言，但是最关键的是我无法知道是谁杀死了我。尤其是分析某些木马的场景下\n如果是系统杀死我的，那一般就是OOM，这种情况也还好。\nLinux内核有个机制叫OOM killer(Out Of Memory killer)，该机制会监控那些占用内存过大，尤其是瞬间占用内存很快的进程，然后防止内存耗尽而自动把该进程杀掉。内核检测到系统内存不足、挑选并杀掉某个进程的过程可以参考内核源代码linux/mm/oom_kill.c，当系统内存不足的时候，out_of_memory()被触发，然后调用select_bad_process()选择一个”bad”进程杀掉。\n这种OOM，是有日志记录的，可以用下面的方法查看\ngrep \u0026quot;Out of memory\u0026quot; /var/log/messagessudo dmesg|grep \u0026quot;Out of memory\u0026quot;\r系统杀的，自认倒霉。\n最麻烦的是被第三方杀的，比如木马，各种监控脚本，各种sh脚本，我咋样才知道是哪个进程杀的呢？这就需要用到systemtap了。\n3.systemtap使用 systemtap是一个用于简化linux系统运行形态信息收集的开源工具。它立足于性能诊断和bug调试，对内核及用户态程序提供了动态追踪功能，用户可以自定探测事件来跟踪程序的运行情况，如函数的调用路径、CPU占用和磁盘IO等一系列可以探测的情况。有了systemtap，可以在程序不修改代码，甚至不用重启就能分析出程序的运行情况。\nsystemtap 的核心思想是定义一个事件（event），以及给出处理该事件的句柄（Handler）。当一个特定的事件发生时，内核运行该处理句柄，就像快速调用一个子函数一样，处理完之后恢复到内核原始状态。\n先来安装它\nyum install systemtap systemtap-runtime\rstap-prep\rstap -e 'probe begin{printf(\u0026quot;Hello, World\u0026quot;); exit();}' #测试验证\r由于我们并不需要高级功能，所以暂不安装内核符号文件。接下来，我们写一个stap脚本\nvim sigmon.stp\r# 内容如下\rprobe begin\r{\rprintf(\u0026quot;%-8s %-16s %-5s %-16s %6s %-16s\\n\u0026quot;,\r\u0026quot;SPID\u0026quot;, \u0026quot;SNAME\u0026quot;, \u0026quot;RPID\u0026quot;, \u0026quot;RNAME\u0026quot;, \u0026quot;SIGNUM\u0026quot;, \u0026quot;SIGNAME\u0026quot;)\r}\rprobe signal.send\r{\rif (sig_name == @1 \u0026amp;\u0026amp; sig_pid == target())\rprintf(\u0026quot;%-8d %-16s %-5d %-16s %-6d %-16s\\n\u0026quot;,\rpid(), execname(), sig_pid, pid_name, sig, sig_name)\r}\r现在我们需要监控某个进程，就这么调用\n(base) [root@VM-0-7-centos ~]# stap -x 28262 sigmon.stp SIGKILLSPID SNAME RPID RNAME SIGNUM SIGNAME 2362819 bash 28262 rsyslogd 9 SIGKILL\r这样我们就知道28262这个进程是被2362819这个进程，也就是bash所杀死的。\n当然，如果不在事前监控，事后我们是拿不到日志信息的。\n如果我们即不做ShutdownHook，也不使用systemtap进行监控，仅仅靠操作系统自带日志，那我们是无法保存死亡现场，也很难知道谁是进程killed背后的凶手了\n","date":"2021-06-15","permalink":"http://localhost:1313/post/%E8%B0%81%E6%9D%80%E6%AD%BB%E4%BA%86%E8%BF%99%E4%B8%AA%E8%BF%9B%E7%A8%8B/","tags":["Linux","Java"],"title":"谁杀死了这个进程"},{"content":"坚果3，发布于2018年4月，骁龙625处理器，4G内存，安卓7.1系统。\n我手里这台，已经退役两个多月了，屏幕摔得到处是裂缝，老罗破产了，系统最后一次更新是2020年2月了，而且安卓7.1也老了一点。锤子手机其实不是太喜欢，它的特色功能我一个都不喜欢，什么one step，大爆炸，胶囊，我都用不上，当时买它只是因为便宜，性价比不错。另外，锤子的手机也不够开放，我也卸载或冻结了很多它自带的系统APP，导致系统APP卸载了，菜单还保留着，但不能点击，额，不能忍受，所以越用越不顺眼，正好换了新手机，就刷机了。\n准备工具 高通 EDL 线 （也称为 9008 线、救砖线、工程线），自行上淘宝购买（10几块的就够了，反正就用一次。淘宝上有些卖家会写着「小米工程线」，其实是同一个东西，通用的）。 QPST 线刷工具、TWRP 线刷包、底包、魔趣 ROM 等相关资源，详见：坚果手机 3 (oscar) 底包、TWRP 及相关工具 不建议自己 DIY 刷机线，type-c接口的线DIY比较复杂，用micro b的线自制还得配个转接头。所以能买就买吧。\n一、刷入 TWRP 安装 QPST 工具包中的线刷工具和驱动，打开 Qfil 软件； 进 Configuration，确保 Device Type 选了 eMMC； 拔掉数据线， 关机。等待手机彻底关机、屏幕不亮为止； 把 EDL 线插到电脑上，按住 EDL 线上的小开关把另一头插入手机。等待大概 3 秒**（注意：不长不短，掐好3秒，否则可能不能成功识别）**松手，此时电脑上的 Qfil 应该会识别到 Qualcomm HS-USB QDLoader 设备； 在 Qfil 里选择 Flat Build； 点击 Programmer 的那个 Browse，选择线刷包中的 prog_ 开头的文件； 点击 Load XML，选择工具包里的 rawprogram_unsparse.xml； 它会再次弹出选择框，点取消； 深呼吸； 点击 Download 按钮，稍等片刻，TWRP 刷入完成； 长按音量增和电源键。直到你看到白色锤子的时候松开电源键（继续按住音量减键）；直到你看到 TWRP 的时候才松开所有按键，进入 TWRP，继续进行下面的步骤。 二、刷入魔趣 进 Wipe（清除），把下面那个条条拖住向右划一下。此时电脑上已经出现手机所在的存储盘，拷贝底包和魔趣的包到手机上。\n返回上一层，进 Install（安装），刷入底包（RADIO- 开头的那个）\n返回上一层（不要重启），再次进安装，刷入魔趣（MK 开头的那个）\n刷完重启，完成\n第一次需要花费2分钟重启。\n刷Magisk 因为Magisk V19的作者用了错的密钥生成boot.img签名，这个在大多数手机上均没问题，但是在锤子这种没有解锁Bootloader的手机来说，会导致无法解开锁屏。但是导演适配了错误密钥。所以坚果3可以刷Magisk V19；但是，Magisk V20作者密钥又重新改对了，所以目前坚果3不支持V20. 提供一个V19.3的安装包：链接:https://pan.baidu.com/s/1UgLGnM5AdpUgv4wQwBp5Wg 密码:prmf\n注意事项 由于坚果的 Bootloader 仍然会校验 boot.img 的签名，所以请勿自己刷入 Magisk 等需要改动 boot 的模块。否则会导致卡在白锤子。也不是不可以，但是要注意版本 刷机后原手机已经安装的APP还在，但由于魔趣最新包是安卓9版本，会导致软件不兼容，频繁弹出app停止运行的错误窗口。此时，需要恢复出厂设置，手机自动重启进入TWRP ,清空data分区，重启即可。 如果需要root，需要去官方下载一个apk，安装即可。 即使没有root魔趣，建设银行这类APP仍然无法运行。它会认为系统不安全，拒绝运行。所以你如果很依赖银行APP，慎重考虑下。当然，也有解决办法。 如何刷回原厂 Smartisan OS 系统 2021年了，不建议刷回去了。原厂系统已经死了。 魔趣体验 才700多M的安装包，基本没有捆绑软件，原生接近AOSP，那个丝滑流畅啊，太舒服了。原生万岁，国产流氓可耻。我都想把手里的onePlus 8刷了\n参考 https://www.mintimate.cn/2019/11/30/%E5%9D%9A%E6%9E%9C3%E5%88%B7%E9%AD%94%E8%B6%A3/\n","date":"2021-05-21","permalink":"http://localhost:1313/post/%E5%9D%9A%E6%9E%9C3%E6%89%8B%E6%9C%BA%E5%88%B7%E9%AD%94%E8%B6%A3%E4%BD%93%E9%AA%8C/","tags":["闲扯淡"],"title":"坚果3手机刷魔趣体验"},{"content":"起因是某客户的服务器上，只要一启动server，过不了几秒就被kill，然后错误日志也看不出啥。 server是基于jvm的，怎么看一个进程被哪个进程杀死，这个可以写一篇文章了。\n自信一点，这肯定不是我们代码的问题导致JVM崩溃啊，毫无疑问是那些做安全的脚本小子搞的。\n找啊找，套路无非是crontab，mount伪装这些玩意。至于篡改ps,top隐藏进程这类，我相信大部分脚本小子也没这能力，当然了，干这一行很多都是有传承的，扛不住其所在的家族雄厚，有祖传神器也难说。 好吧，最后找到是一个放到.log目录起名为x86-64的可执行程序。是我以小人之心度君子之腹了，人家也没搞隐藏ps的操作，就是每秒钟起来杀一次占用CPU最多的程序以免影响它干活。。这心机婊，还起个这么有迷惑性的名字，我就信了你是系统文件不去碰？\ncp一份，保留备份，killall，然后分析下。vim一看，不是脚本，那就是elf喽。\nLinux下用来快速分析elf文件有几个工具，一个是readelf，一个是objdump，另外一个是ldd。 通常用ldd来分析动态加载的库，objdump用来反编译。但是这几个工具面对一些恶意文件并不总是有效。 比如对于静态编译的程序，或者变种脚本，ldd就无效了。 对于没有section table的程序，objdump也就可能无法得出结果了。\n#objdump -d ./wi\r./wi: file format elf64-x86-64\r因为objdump需要依赖code sections或section table，可以用readelf看看\n[root@localhost ~]# readelf -a ./wi\rELF Header:\rMagic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00\rClass: ELF64\rData: 2's complement, little endian\rVersion: 1 (current)\rOS/ABI: UNIX - System V\rABI Version: 0\rType: EXEC (Executable file)\rMachine: Advanced Micro Devices X86-64\rVersion: 0x1\rEntry point address: 0x5c9e70\rStart of program headers: 64 (bytes into file)\rStart of section headers: 0 (bytes into file)\rFlags: 0x0\rSize of this header: 64 (bytes)\rSize of program headers: 56 (bytes)\rNumber of program headers: 3\rSize of section headers: 64 (bytes)\rNumber of section headers: 0\rSection header string table index: 0\rThere are no sections in this file.\rThere are no sections to group in this file.\rProgram Headers:\rType Offset VirtAddr PhysAddr\rFileSiz MemSiz Flags Align\rLOAD 0x0000000000000000 0x0000000000400000 0x0000000000400000\r0x00000000001ca78b 0x00000000001ca78b R E 200000\rLOAD 0x0000000000000000 0x00000000005cb000 0x00000000005cb000\r0x0000000000000000 0x0000000000597d58 RW 1000\rGNU_STACK 0x0000000000000000 0x0000000000000000 0x0000000000000000\r0x0000000000000000 0x0000000000000000 RW 10\rThere is no dynamic section in this file.\rThere are no relocations in this file.\rThe decoding of unwind sections for machine type Advanced Micro Devices X86-64 is not currently supported.\rDynamic symbol information is not available for displaying symbols.\rNo version information found in this file.\r所以这种情况下，可以这么来，-D表示对全部文件进行反汇编，-b表示二进制，-m表示指令集架构\n[root@localhost ~]# objdump -b binary -D -m i386 ./wi\r./wi: file format binary\rDisassembly of section .data:\r00000000 \u0026lt;.data\u0026gt;:\r0: 7f 45 jg 0x47\r2: 4c dec %esp\r3: 46 inc %esi\r4: 02 01 add (%ecx),%al\r6: 01 00 add %eax,(%eax)\r...\r10: 02 00 add (%eax),%al\r12: 3e 00 01 add %al,%ds:(%ecx)\r15: 00 00 add %al,(%eax)\r另外，strace，gdb等工具也有一定的帮助。当然，上IDA这种大型武器就更有效了。 这只是浅尝辄止，就算dump出了这么一堆汇编代码，又有什么用，没那么容易看懂。\n我又凭啥让别人相信这东西不是个正常的二进制文件？仅仅凭它各种龌龊的隐藏行为还不够。\n所以，好端端的一个ELF可执行文件，怎么就没了section table呢？很简单，脚本小子就是喜欢玩些小把戏，很容易就想到是加壳了，Linux下最容易想到的壳就是UPX。\n[root@localhost ~]# strings ./wi |grep UPX\rnUPX!(\r$Info: This file is packed with the UPX executable packer http://upx.sf.net $\r$Id: UPX 3.95 Copyright (C) 1996-2018 the UPX Team. All Rights Reserved. $\rUPX!u\rUPX!\rUPX!\r脚本小子做事还是毛糙，也不晓得隐藏一下壳。把它的王八壳子扒了\n[root@localhost ~]# ./upx -d wi\rUltimate Packer for eXecutables\rCopyright (C) 1996 - 2020\rUPX 3.96 Markus Oberhumer, Laszlo Molnar \u0026amp; John Reiser Jan 23rd 2020\rFile size Ratio Format Name\r-------------------- ------ ----------- -----------\r5011080 \u0026lt;- 1878380 37.48% linux/amd64 wi\rUnpacked 1 file.\r要是脚本小子把UPX壳的信息给隐藏了，那么UPX自带的-d命令就没法脱壳了，这个时候就得用IDA了。加壳的本质就是把原来的程序的数据全部压缩加密了，在静态文件中无法分析，随着程序的执行，运行时会将代码释放到内存中。我们可以用ida远程调试test程序，找到upx自解壳后的 OEP，再把内存给dump出来，就可以实现手动脱壳了。怎样找OEP，这就得看经验了。\n脱壳之后呢，继续用strings，strace，netstat等命令做定性分析。\n其实到了这一步,strings命令已经足够分析出其行为了。\n[1;37monnection\r* COMMANDS 'h' hashrate, 'p' pause, 'r' resume, 's' results, 'c' connection\r\u0026gt;wz *ctz\u0026gt;3\u0026gt;c)\r:w 3\r[32m||\r[31m ERROR [32m||\r[37m Invalid Port Use In This Range [36m'1-65535' [37me.g\r[31m ( ./xmrig -p 3333 )\r[32m||\r[31m ERROR [32m||\r[37m Invalid Class You Can Use Only These Classes [36m'192.168'\r[32m, [36m'172'\r[32m, [36m'100'\r[32m, [36m'10'\r[37m e.g\r[31m ( ./xmrig -lan 192.168.0.1 )\r[32m||\r[31m ERROR [32m||\r[37m Empty Or Invalid Pool Address\r还能分析出是C++写的木马。想要反汇编出C++源文件，你吃屁呢。objdump得依赖debug信息才行，脚本小子再菜鸡也不会这么做啊。要C++源文件，那只能用IDA dump了，这也得出近似的源文件。\n当然了，最简单的就是直接上传到virustotal，最后得出的结果果然是一个Linux.Risk.Bitcoinminer.Tbix。\n呵呵，脚本小子。\n","date":"2021-05-17","permalink":"http://localhost:1313/post/linux%E6%81%B6%E6%84%8Felf%E6%96%87%E4%BB%B6%E5%88%86%E6%9E%90/","tags":["Linux"],"title":"Linux恶意ELF文件分析"},{"content":"简介 keycloak是一个非常强大的权限认证系统，我们使用keycloak可以方便的实现SSO的功能。虽然keycloak底层使用的wildfly，但是提供了非常方便的Client Adapters和各种服务器进行对接，比如wildfly，tomcat，Jetty等。\n对于最流行的SpringBoot来说，keycloak有官方Adapter，只需要修改配置即可。如果非SpringBoot应用呢，那就只能使用Java Servlet Filter Adapter了。\nSpringBoot接入keycloak的例子比较多，我就不赘述了。这里只简单说明下。\n接入前的前置准备 在接入各种应用之前，需要在keycloak中做好相应的配置。一般来说需要使用下面的步骤：\n创建新的realm\n一般来说，为了隔离不同类型的系统，我们建议为不同的client创建不同的realm。当然，如果这些client是相关联的，则可以创建在同一个realm中。\n创建新的用户和角色。\n用户是用来登录keycloak用的，如果是不同的realm，则需要分别创建用户。用户密码也是在这一步创建的\n添加和配置client\n这一步是非常重要的，我们需要根据应用程序的不同，配置不同的root URL，redirect URI等。\n还可以配置mapper和scope信息。\n最后，如果是服务器端的配置的话，还需要installation的一些信息。\n有了这些基本的配置之后，我们就可以准备接入应用程序了。\nSpringboot接入keycloak 引入依赖 \u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.keycloak\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;keycloak-spring-boot-starter\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;11.0.2\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r然后配置application.yml keycloak:\rauth-server-url: http://localhost:8080/auth\rrealm: wildfly\rpublic-client: true\rresource: product-app\rsecurityConstraints:\r- authRoles:\r# 以下路径需要user角色才能访问\r- user\rsecurityCollections:\r# name可以随便写\r- name: user-role-mappings\rpatterns:\r- /users/*\r至此就接入完成了，不需要编写任何代码。\n获取KeycloakSecurityContext 但是实际使用中，光能控制登陆权限还不够，业务代码中还需要能获取到当前角色，用户名等信息，这就需要用到KeycloakSecurityContext了。KeycloakSecurityContext是keycloak的上下文，我们可以从其中获取到AccessToken，IDToken，AuthorizationContext和realm信息。\nIdentity.java\nimport java.util.List;\rimport org.keycloak.AuthorizationContext;\rimport org.keycloak.KeycloakSecurityContext;\rimport org.keycloak.representations.idm.authorization.Permission;\r/**\r* \u0026lt;p\u0026gt;This is a simple facade to obtain information from authenticated users. You should see usages of instances of this class when\r* rendering the home page (@code home.ftl).\r*\r* \u0026lt;p\u0026gt;Instances of this class are are added to models as attributes in order to make them available to templates.\r*\r* @author \u0026lt;a href=\u0026quot;mailto:psilva@redhat.com\u0026quot;\u0026gt;Pedro Igor\u0026lt;/a\u0026gt;\r* @see com.github.your.demo.controller.HomeController\r*/\rpublic class Identity {\rprivate final KeycloakSecurityContext securityContext;\rpublic Identity(KeycloakSecurityContext securityContext) {\rthis.securityContext = securityContext;\r}\r/**\r* An example on how you can use the {@link org.keycloak.AuthorizationContext} to check for permissions granted by Keycloak for a particular user.\r*\r* @param name the name of the resource\r* @return true if user has was granted with a permission for the given resource. Otherwise, false.\r*/\rpublic boolean hasResourcePermission(String name) {\rreturn getAuthorizationContext().hasResourcePermission(name);\r}\r/**\r* An example on how you can use {@link KeycloakSecurityContext} to obtain information about user's identity.\r*\r* @return the user name\r*/\rpublic String getName() {\rreturn securityContext.getIdToken().getPreferredUsername();\r}\r/**\r* An example on how you can use the {@link org.keycloak.AuthorizationContext} to obtain all permissions granted for a particular user.\r*\r* @return\r*/\rpublic List\u0026lt;Permission\u0026gt; getPermissions() {\rreturn getAuthorizationContext().getPermissions();\r}\r/**\r* Returns a {@link AuthorizationContext} instance holding all permissions granted for an user. The instance is build based on\r* the permissions returned by Keycloak. For this particular application, we use the Entitlement API to obtain permissions for every single\r* resource on the server.\r*\r* @return\r*/\rprivate AuthorizationContext getAuthorizationContext() {\rreturn securityContext.getAuthorizationContext();\r}\r}\r使用\n@RestController\rpublic class HomeController {\rprivate Logger logger = LoggerFactory.getLogger(HomeController.class);\r@Autowired\rprivate JdbcTemplate jdbcTemplate;\r@Autowired\rprivate HttpServletRequest request;\r@RequestMapping(\u0026quot;/users\u0026quot;)\r@ResponseBody\rpublic List\u0026lt;Users\u0026gt; users() {\rlogIdentity();\rlogger.info(\u0026quot;使用JdbcTemplate查询数据库\u0026quot;);\rString sql = \u0026quot;SELECT * FROM users \u0026quot;;\rList\u0026lt;Users\u0026gt; queryAllList = jdbcTemplate.query(sql, new Object[]{},\rnew BeanPropertyRowMapper\u0026lt;\u0026gt;(Users.class));\rlogger.info(\u0026quot;查询用户列表\u0026quot; + queryAllList);\rreturn queryAllList;\r}\r@RequestMapping(\u0026quot;/\u0026quot;)\rpublic String home() {\rreturn \u0026quot;Hello Docker World\u0026quot;;\r}\rprivate void logIdentity() {\rKeycloakSecurityContext context=getKeycloakSecurityContext();\rif(context!=null){\rIdentity identity=new Identity(context);\rlogger.info(\u0026quot;KeycloakSecurityContext identity={}\u0026quot;,identity);\r}else{\rlogger.info(\u0026quot;KeycloakSecurityContext is null\u0026quot;);\r}\r}\rprivate KeycloakSecurityContext getKeycloakSecurityContext() {\rreturn (KeycloakSecurityContext) request.getAttribute(KeycloakSecurityContext.class.getName());\r}\r}\rIdentity类来自Keycloak的官方example。上面介绍的Spring Boot中的其实是隐藏的做法，adaptor自动为我们做了和Keycloak认证服务连接的事情，如果我们需要手动去处理，则需要用到Authorization Client Java API。\n添加maven依赖：\n\u0026lt;dependencies\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.keycloak\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;keycloak-authz-client\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;${KEYCLOAK_VERSION}\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;/dependencies\u0026gt;\r具体使用AuthzClient可查看官方文档。\nRest接口 有了这些配置，我们基本上就可以创建一个基于spring boot和keycloak的一个rest服务了。\n假如我们为keycloak的client创建了新的用户：alice。\n第一步我们需要拿到alice的access token，则可以这样操作：\nexport access_token=$(\\\rcurl -X POST http://localhost:8180/auth/realms/spring-boot-quickstart/protocol/openid-connect/token \\\r-H 'Authorization: Basic YXBwLWF1dGh6LXJlc3Qtc3ByaW5nYm9vdDpzZWNyZXQ=' \\\r-H 'content-type: application/x-www-form-urlencoded' \\\r-d 'username=alice\u0026amp;password=alice\u0026amp;grant_type=password' | jq --raw-output '.access_token' \\\r)\r这个命令是直接通过用户名密码的方式去keycloak服务器中拿取access_token,除了access_token，这个命令还会返回refresh_token和session state的信息。\n因为是直接和keycloak进行交换，所以keycloak的directAccessGrantsEnabled一定要设置为true。\n上面命令中的Authorization是什么值呢？\n这个值是为了防止未授权的client对keycloak服务器的非法访问，所以需要请求客户端提供client-id和对应的client-secret并且以下面的方式进行编码得到的：\nAuthorization: basic BASE64(client-id + ':' + client-secret)\raccess_token是JWT格式的，我们可以简单解密一下上面命令得出的token:\n{\ralg: \u0026quot;RS256\u0026quot;,\rtyp: \u0026quot;JWT\u0026quot;,\rkid: \u0026quot;FJ86GcF3jTbNLOco4NvZkUCIUmfYCqoqtOQeMfbhNlE\u0026quot;\r}.\r{\rexp: 1603614445,\riat: 1603614145,\rjti: \u0026quot;b69c784d-5b2d-46ad-9f8d-46214add7afb\u0026quot;,\riss: \u0026quot;http://localhost:8180/auth/realms/spring-boot-quickstart\u0026quot;,\rsub: \u0026quot;e6606d93-99f6-4829-ba99-1329be604159\u0026quot;,\rtyp: \u0026quot;Bearer\u0026quot;,\razp: \u0026quot;app-authz-springboot\u0026quot;,\rsession_state: \u0026quot;bdc33764-fd1a-400e-9fe0-90a82f4873c1\u0026quot;,\racr: \u0026quot;1\u0026quot;,\rallowed-origins: [\r\u0026quot;http://localhost:8080\u0026quot;\r],\rrealm_access: {\rroles: [\r\u0026quot;user\u0026quot;\r]\r},\rscope: \u0026quot;email profile\u0026quot;,\remail_verified: false,\rpreferred_username: \u0026quot;alice\u0026quot;\r}.\r[signature]\r有了access_token,我们就可以根据access_token去做很多事情了。\n比如：访问受限的资源：\ncurl http://localhost:8080/api/resourcea \\\r-H \u0026quot;Authorization: Bearer \u0026quot;$access_token\r这里的api/resourcea只是我们本地spring boot应用中一个非常简单的请求资源链接，一切的权限校验工作都会被keycloak拦截，我们看下这个api的实现：\n@RequestMapping(value = \u0026quot;/api/resourcea\u0026quot;, method = RequestMethod.GET)\rpublic String handleResourceA() {\rreturn createResponse();\r}\rprivate String createResponse() {\rreturn \u0026quot;Access Granted\u0026quot;;\r}\r可以看到这个只是一个简单的txt返回，但是因为有keycloak的加持，就变成了一个带权限的资源调用。\n上面的access_token解析过后，我们可以看到里面是没有包含权限信息的，我们可以使用access_token来交换一个特殊的RPT的token，这个token里面包含用户的权限信息：\ncurl -X POST \\\rhttp://localhost:8180/auth/realms/spring-boot-quickstart/protocol/openid-connect/token \\\r-H \u0026quot;Authorization: Bearer \u0026quot;$access_token \\\r--data \u0026quot;grant_type=urn:ietf:params:oauth:grant-type:uma-ticket\u0026quot; \\\r--data \u0026quot;audience=app-authz-rest-springboot\u0026quot; \\\r--data \u0026quot;permission=Default Resource\u0026quot; | jq --raw-output '.access_token'\r将得出的结果解密之后，看下里面的内容：\n{\ralg: \u0026quot;RS256\u0026quot;,\rtyp: \u0026quot;JWT\u0026quot;,\rkid: \u0026quot;FJ86GcF3jTbNLOco4NvZkUCIUmfYCqoqtOQeMfbhNlE\u0026quot;\r}.\r{\rexp: 1603614507,\riat: 1603614207,\rjti: \u0026quot;93e42d9b-4bc6-486a-a650-b912185c35db\u0026quot;,\riss: \u0026quot;http://localhost:8180/auth/realms/spring-boot-quickstart\u0026quot;,\raud: \u0026quot;app-authz-springboot\u0026quot;,\rsub: \u0026quot;e6606d93-99f6-4829-ba99-1329be604159\u0026quot;,\rtyp: \u0026quot;Bearer\u0026quot;,\razp: \u0026quot;app-authz-springboot\u0026quot;,\rsession_state: \u0026quot;bdc33764-fd1a-400e-9fe0-90a82f4873c1\u0026quot;,\racr: \u0026quot;1\u0026quot;,\rallowed-origins: [\r\u0026quot;http://localhost:8080\u0026quot;\r],\rrealm_access: {\rroles: [\r\u0026quot;user\u0026quot;\r]\r},\rauthorization: {\rpermissions: [\r{\rrsid: \u0026quot;e26d5d63-5976-4959-8683-94b7d85318e7\u0026quot;,\rrsname: \u0026quot;Default Resource\u0026quot;\r}\r]\r},\rscope: \u0026quot;email profile\u0026quot;,\remail_verified: false,\rpreferred_username: \u0026quot;alice\u0026quot;\r}.\r[signature]\r可以看到，这个RPT和之前的access_token的区别是这个里面包含了authorization信息。\n我们可以将这个RPT的token和之前的access_token一样使用。\nJetty+Jersey框架接入Keycloak 我们有一个老系统，用的embeded Jetty+Jersey，虽然官方提供了Jetty 9.x Adapters，但这是针对standalone而言的，现在几乎没人这么用了，所以还是得自己来。官方有Java Servlet Filter Adapter的教程，但是用的是web.xml的例子，而且语焉不详，所以这里就我自己的摸索提供一点参考。\nJetty整合Jersey框架 先来看一下Jetty+Jersey的原生例子，涉及两个文件 App.java\npackage xyz.chen;\rimport org.eclipse.jetty.server.Server;\rimport org.eclipse.jetty.servlet.ServletContextHandler;\rimport org.eclipse.jetty.servlet.ServletHolder;\rimport org.glassfish.jersey.servlet.ServletContainer;\rpublic class App {\rpublic static void main(String[] args) {\rServer server = new Server(9999);\rServletContextHandler context = new ServletContextHandler(ServletContextHandler.NO_SESSIONS);\rcontext.setContextPath(\u0026quot;/\u0026quot;);\rserver.setHandler(context);\r// 配置Servlet\rServletHolder holder = context.addServlet(ServletContainer.class.getCanonicalName(), \u0026quot;/rest/*\u0026quot;);\rholder.setInitOrder(1);\rholder.setInitParameter(\u0026quot;jersey.config.server.provider.packages\u0026quot;, \u0026quot;xyz.chen\u0026quot;);\rholder.setInitParameter(\u0026quot;jersey.config.server.provider.classnames\u0026quot;, \u0026quot;org.glassfish.jersey.server.filter.CsrfProtectionFilter\u0026quot;);\rtry {\rserver.start();\rserver.join();\r} catch (Exception e) {\re.printStackTrace();\r} finally {\rserver.destroy();\r}\r}\r}\r然后是业务类： HelloResource.java\npackage xyz.chen;\rimport javax.ws.rs.*;\rimport javax.ws.rs.core.MediaType;\rimport javax.ws.rs.core.MultivaluedMap;\rimport javax.ws.rs.core.PathSegment;\rimport javax.ws.rs.core.Response;\rimport java.util.HashMap;\rimport java.util.List;\rimport java.util.Map;\rimport java.util.Map.Entry;\r@Path(\u0026quot;hello\u0026quot;)\rpublic class HelloResource {\r@Path(\u0026quot;index\u0026quot;)\r@GET\r@Consumes(MediaType.TEXT_PLAIN)\r@Produces(MediaType.TEXT_PLAIN)\rpublic Response helloworld() {\rreturn Response.ok(\u0026quot;hello jersey\u0026quot;).build();\r}\r@GET\r@Path(\u0026quot;/user/{userName}\u0026quot;)\rpublic Response getThemeCss(@PathParam(\u0026quot;userName\u0026quot;) String userName) {\rStringBuilder sb = new StringBuilder(userName);\rreturn Response.ok(sb.toString()).build();\r}\r}\rpom.xml文件\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt;\r\u0026lt;project xmlns=\u0026quot;http://maven.apache.org/POM/4.0.0\u0026quot; xmlns:xsi=\u0026quot;http://www.w3.org/2001/XMLSchema-instance\u0026quot;\rxsi:schemaLocation=\u0026quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026quot;\u0026gt;\r\u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt;\r\u0026lt;groupId\u0026gt;org.example\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jersey-demo\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt;\r\u0026lt;name\u0026gt;Maven\u0026lt;/name\u0026gt;\r\u0026lt;url\u0026gt;http://maven.apache.org/\u0026lt;/url\u0026gt;\r\u0026lt;inceptionYear\u0026gt;2001\u0026lt;/inceptionYear\u0026gt;\r\u0026lt;properties\u0026gt;\r\u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt;\r\u0026lt;/properties\u0026gt;\r\u0026lt;dependencies\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.glassfish.jersey.core\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jersey-server\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.27\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.glassfish.jersey.inject\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jersey-hk2\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.27\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.glassfish.jersey.containers\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jersey-container-servlet-core\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.27\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.glassfish.jersey.containers\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jersey-container-jetty-http\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.27\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.eclipse.jetty\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jetty-server\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;9.4.12.v20180830\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.eclipse.jetty\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jetty-servlet\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;9.4.12.v20180830\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.eclipse.jetty\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jetty-util\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;9.4.12.v20180830\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;/dependencies\u0026gt;\r\u0026lt;build\u0026gt;\r\u0026lt;plugins\u0026gt;\r\u0026lt;plugin\u0026gt;\r\u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;maven-shade-plugin\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.4.3\u0026lt;/version\u0026gt;\r\u0026lt;configuration\u0026gt;\r\u0026lt;createDependencyReducedPom\u0026gt;true\u0026lt;/createDependencyReducedPom\u0026gt;\r\u0026lt;filters\u0026gt;\r\u0026lt;filter\u0026gt;\r\u0026lt;artifact\u0026gt;*:*\u0026lt;/artifact\u0026gt;\r\u0026lt;excludes\u0026gt;\r\u0026lt;exclude\u0026gt;META-INF/*.SF\u0026lt;/exclude\u0026gt;\r\u0026lt;exclude\u0026gt;META-INF/*.DSA\u0026lt;/exclude\u0026gt;\r\u0026lt;exclude\u0026gt;META-INF/*.RSA\u0026lt;/exclude\u0026gt;\r\u0026lt;/excludes\u0026gt;\r\u0026lt;/filter\u0026gt;\r\u0026lt;/filters\u0026gt;\r\u0026lt;/configuration\u0026gt;\r\u0026lt;executions\u0026gt;\r\u0026lt;execution\u0026gt;\r\u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt;\r\u0026lt;goals\u0026gt;\r\u0026lt;goal\u0026gt;shade\u0026lt;/goal\u0026gt;\r\u0026lt;/goals\u0026gt;\r\u0026lt;configuration\u0026gt;\r\u0026lt;transformers\u0026gt;\r\u0026lt;transformer\rimplementation=\u0026quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer\u0026quot; /\u0026gt;\r\u0026lt;transformer\rimplementation=\u0026quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\u0026quot;\u0026gt;\r\u0026lt;manifestEntries\u0026gt;\r\u0026lt;Main-Class\u0026gt;xyz.chen.App\u0026lt;/Main-Class\u0026gt;\r\u0026lt;/manifestEntries\u0026gt;\r\u0026lt;/transformer\u0026gt;\r\u0026lt;/transformers\u0026gt;\r\u0026lt;/configuration\u0026gt;\r\u0026lt;/execution\u0026gt;\r\u0026lt;/executions\u0026gt;\r\u0026lt;/plugin\u0026gt;\r\u0026lt;/plugins\u0026gt;\r\u0026lt;/build\u0026gt;\r\u0026lt;/project\u0026gt;\r运行就不再举例了。\n整合keycloak 引入依赖\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.keycloak\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;keycloak-servlet-filter-adapter\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;11.0.2\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r修改App类，加入Filter\nServletHandler handler = new ServletHandler();\rFilterHolder fh=handler.addFilterWithMapping(org.keycloak.adapters.servlet.KeycloakOIDCFilter.class,\u0026quot;/*\u0026quot;, EnumSet.of(DispatcherType.REQUEST));\rfh.setInitParameter(\u0026quot;keycloak.config.file\u0026quot;, \u0026quot;keycloak.json\u0026quot;);\rcontext.addFilter(fh, \u0026quot;/*\u0026quot;, EnumSet.of(DispatcherType.REQUEST));\rserver.setHandler(context);\r其中，keycloak.json文件来自keycloak-clients-installtion，形如\n{\r\u0026quot;realm\u0026quot;: \u0026quot;wildfly\u0026quot;,\r\u0026quot;auth-server-url\u0026quot;: \u0026quot;http://localhost:8080/auth/\u0026quot;,\r\u0026quot;ssl-required\u0026quot;: \u0026quot;external\u0026quot;,\r\u0026quot;resource\u0026quot;: \u0026quot;product-app\u0026quot;,\r\u0026quot;public-client\u0026quot;: true,\r\u0026quot;confidential-port\u0026quot;: 0\r}\rkeycloak的配置不再赘述。\n获取用户权限信息 这块不再举例，自己写个Filter去KeycloakSecurityContext里拿就可以了。\n其它问题 1.如何用代码完成在KeyCloak注册和配置过程，实现自动化配置？ KeyCloark有restApi，也有命令行工具。下面是简单暴力的做法，使用命令行\n#添加管理员用户\r.../bin/add-user-keycloak.sh -r master -u \u0026lt;username\u0026gt; -p \u0026lt;password\u0026gt;\r$ kcadm.sh config credentials --server http://localhost:8080/auth --realm master --user admin $ kcadm.sh create realms -s realm=demorealm -s enabled=true -o\r$ CID=$(kcadm.sh create clients -r demorealm -s clientId=my_client -s 'redirectUris=[\u0026quot;http://localhost:8980/myapp/*\u0026quot;]' -i)\r$ kcadm.sh get clients/$CID/installation/providers/keycloak-oidc-keycloak-json\r如下所示，使用windows举例\nPS G:\\keycloak11\\bin\u0026gt; .\\kcadm config credentials --server http://localhost:8080/auth --realm master --user admin Logging into http://localhost:8080/auth as user admin of realm master\rEnter password: admin\rPS G:\\keycloak11\\bin\u0026gt; .\\kcadm create realms -s realm=demorealm -s enabled=true -o\rPS G:\\keycloak11\\bin\u0026gt; .\\kcadm create clients -r demorealm -s clientId=my_client -s 'redirectUris=[\\\u0026quot;http://localhost:8980/myapp/*\\\u0026quot;]' -i \u0026gt; clientid.txt\rPS G:\\keycloak11\\bin\u0026gt; set /p CID=\u0026lt;clientid.txt\rPS G:\\keycloak11\\bin\u0026gt; .\\kcadm get http://localhost:8080/auth/admin/realms/demorealm/clients/8aba2b1f-4587-43ba-8f51-d2e75db5f65d/installation/providers/keycloak-oidc-keycloak-json\r{\r\u0026quot;realm\u0026quot; : \u0026quot;demorealm\u0026quot;,\r\u0026quot;auth-server-url\u0026quot; : \u0026quot;http://localhost:8080/auth/\u0026quot;,\r\u0026quot;ssl-required\u0026quot; : \u0026quot;external\u0026quot;,\r\u0026quot;resource\u0026quot; : \u0026quot;my_client\u0026quot;,\r\u0026quot;credentials\u0026quot; : {\r\u0026quot;secret\u0026quot; : \u0026quot;54b8027b-6d7f-4e2b-9b6a-5c1e85b685fa\u0026quot;\r},\r\u0026quot;confidential-port\u0026quot; : 0\r}\rPS G:\\keycloak11\\bin\u0026gt;\r基本操作：\n$ kcadm.sh create ENDPOINT [ARGUMENTS]\r$ kcadm.sh get ENDPOINT [ARGUMENTS]\r$ kcadm.sh update ENDPOINT [ARGUMENTS]\r$ kcadm.sh delete ENDPOINT [ARGUMENTS]\rENDPOINT is a target resource URI and can either be absolute (starting with http: or https:) or relative, used to compose an absolute URL of the following format:\nSERVER_URI/admin/realms/REALM/ENDPOINT\rFor example, if you authenticate against the server http://localhost:8080/auth and realm is master, then using users as ENDPOINT results in the resource URL http://localhost:8080/auth/admin/realms/master/users.\nIf you set ENDPOINT to clients, the effective resource URI would be http://localhost:8080/auth/admin/realms/master/clients.\n角色和用户的管理等也能用kcadm命令来完成。\n2.如何退出 HttpServletRequest.logout()\r3.更暴力的接入方式KeyCloak Proxy（已停止维护） 把KeyCloak作为一个proxy来使用，免去修改现有代码。\nhttps://hub.docker.com/r/jboss/keycloak-proxy/ 这里有简单的使用方式说明。这种方式只能代理一个client。\nThis image is deprecated as the Java based Proxy will be replaced by a new Go based implementation soon.\nkeycloak-proxy在2018年已停止维护，用Golang实现的继任者louketo-proxy也已在2020年停止更新维护。\n官方文档已不推荐使用这种方式，相关文档已移除。\nouketo-proxy停止更新和维护，官网说明：https://www.keycloak.org/2020/08/sunsetting-louketo-project.adoc\n官网提供的一种类似替代方案：https://github.com/oauth2-proxy/oauth2-proxy （Golang实现，未验证）\n参考 https://www.keycloak.org/docs/latest/securing_apps/#_jetty9_adapter\nhttps://stackoverflow.com/questions/22188285/does-embedded-jetty-have-the-ability-to-set-the-init-params-of-a-filter\n","date":"2021-04-07","permalink":"http://localhost:1313/post/keycloak%E6%8E%A5%E5%85%A5%E8%87%AA%E7%A0%94%E7%B3%BB%E7%BB%9F/","tags":["Java"],"title":"Keycloak接入自研系统"},{"content":"Centos8安装Superset。Superset 是 Airbnb （知名在线房屋短租公司）开源的数据探查与可视化平台（曾用名 Panoramix、Caravel ），也就是BI，该工具在可视化、易用性和交互性上非常有特色。\n不建议使用python3.8以下版本。低版本建议使用docker-composer或者helm安装。当然，想要低版本Python安装也不是不可以，其实也就一个conda create 的操作而已。我在Centos7+Python 2.7.5 环境下也安装成功。 我是新环境，直接升级就好。\n初始化，升级到python 3.8（非必须） wget https://www.python.org/ftp/python/3.8.1/Python-3.8.1.tgz\ryum install gcc gcc-c++ libffi-devel\rtar -xvf Python-3.8.1.tgz\rcd Python-3.8.1\r./configure --prefix=/usr/local/python3\rmake \u0026amp;\u0026amp; make install\rrm -f /usr/bin/python\rrm -f /usr/bin/pip\rln -s /usr/local/python3/bin/python3 /usr/bin/python\rln -s /usr/local/python3/bin/python3 /usr/bin/python\rpython -V\r安装miniconda wget -c https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\rchmod 777 Miniconda3-latest-Linux-x86_64.sh\rbash Miniconda3-latest-Linux-x86_64.sh\r一步一步来，最后把conda的路径加入环境变量。\nconda list #验证安装是否成功\rconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/\rconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/\rconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/\rconda config --add channels conda create -n superset python=3.8\rconda config --get channels\r使用conda安装SuperSet 最后进入安装superset环节。创建虚拟环境，这也是低版本python安装高版本python软件的关键。为什么不直接用pip，还是考虑到python版本比较混乱的问题。为什么不用virtualenv，主要是conda能安装一些依赖，减少手动操作。最新版的superset应该是不需要这么麻烦，pip一路到底就可以，不过我还是参考了老的安装教程。有闲的可以直接看官方教程，更简单。\nconda create -n superset python=3.8\ractivate superset\rpip install apache-superset\r要退出conda创建的虚拟环节可以用conda deactivate指令。\n查看和切换虚拟环境\nconda info --envs\rconda env list\rconda activate base\r如果pip太慢，可以加入国内源\n#新建配置文件\rtouch ~/.pip/pip.conf\r#加入如下配置\r[global]\rindex-url = https://pypi.tuna.tsinghua.edu.cn/simple\r[install]\rtrusted-host = https://pypi.tuna.tsinghua.edu.cn\r如果出现了类似的报错\ngcc: error trying to exec 'cc1plus': execvp: No such file or directory\rerror: command 'gcc' failed with exit status 1\r----------------------------------------\rERROR: Failed building wheel for python-geohash\r是因为缺少了 gcc-c++，安装即可。这就是第一步里面的初始化所做的。\n配置和启动 如果顺利的话，superset应该是安装成功了。接下来就是官方文档里的初始化操作了。\nsuperset db upgrade\r# Create an admin user (you will be prompted to set a username, first and last name before setting a password)\r$ export FLASK_APP=superset\rsuperset fab create-admin\r# Load some data to play with\rsuperset load_examples\r# Create default roles and permissions\rsuperset init\r# To start a development web server on port 8088, use -p to bind to another port\rsuperset run -p 8088 --with-threads --reload --debugger\r在superset load_examples这一步，可能会卡很久然后失败，原因是example数据是存放在github的，然而某些人没有妈，所以就不能访问了。可以直接中止就好了。或者从github上手动下载回来（压缩包大约28M），然后手动导入（需要起一个HTTP服务，修改Superset源码superset/examples/helpers.py替换BASE_URL，比较麻烦）。\n另外superset默认只绑定localhost，想要外网可访问，可以绑定一个主机。\n#hosts文件里添加一条映射\r0.0.0.0 ten\r#绑定ten\rsuperset run -h ten -p 8080 --with-threads --reload\r#这样直接绑定IP地址是会报错的\rsuperset run -h 110.6.7.8 -p 8080 --with-threads --reload\r这操作也有点诡异了些。。\n2021-04-13更新\n导入样例 前面说过，在superset load_examples这一步会失败，原因是example数据是存放在github的，这个网站被司马佬吃了。这个路径配置在examples/helpers.py里的BASE_URL项。\n#github上下载examples压缩包\rwget https://github.com/apache-superset/examples-data/archive/refs/heads/master.zip\r#解压，启动本地server\runzip master.zip\rpython -m SimpleHTTPServer 18089\r#PYTHONPATH处理\rcp /root/miniconda2/envs/superset/lib/python3.8/site-packages/superset/examples/ /root/py/examples\r#修改helpers.py\rBASE_URL = \u0026quot;http://10.180.210.146:18089/\u0026quot;\r#导入\rsuperset load_examples\r成功的话，输出应该如下：\nLoaded your LOCAL configuration at [/root/py/superset_config.py]\rLoaded your LOCAL configuration at [/root/py/superset_config.py]\rlogging was configured successfully\rINFO:superset.utils.logging_configurator:logging was configured successfully\r/root/miniconda2/envs/superset/lib/python3.8/site-packages/flask_caching/__init__.py:201: UserWarning: Flask-Caching: CACHE_TYPE is set to null, caching is effectively disabled.\rwarnings.warn(\rNo PIL installation found\rINFO:superset.utils.screenshots:No PIL installation found\rLoading examples metadata and related data into examples\rCreating default CSS templates\rLoading energy related dataset\rCreating table [wb_health_population] reference\rLoading [World Bank's Health Nutrition and Population Stats]\rCreating table [wb_health_population] reference\rCreating a World's Health Bank dashboard\rLoading [Birth names]\rDone loading table!\r--------------------------------------------------------------------------------\rCreating table [birth_names] reference\rCreating some slices\rCreating a dashboard\rLoading [Random time series data]\rDone loading table!\r--------------------------------------------------------------------------------\rCreating table [random_time_series] reference\rCreating a slice\rLoading [Random long/lat data]\rDone loading table!\r--------------------------------------------------------------------------------\rCreating table reference\rCreating a slice\rLoading [Country Map data]\rDone loading table!\r--------------------------------------------------------------------------------\rCreating table reference\rCreating a slice\rLoading [Multiformat time series]\rDone loading table!\r--------------------------------------------------------------------------------\rCreating table [multiformat_time_series] reference\rCreating Heatmap charts\rLoading [Paris GeoJson]\rCreating table paris_iris_mapping reference\r...\r自定义配置及汉化 编辑配置文件后重启即可\nvim /root/miniconda2/envs/superset/lib/python3.8/site-packages/superset/config.py\r# Setup default language\rBABEL_DEFAULT_LOCALE = \u0026quot;zh\u0026quot;\r这样直接修改配置文件很麻烦（路径太深），可以把自定义配置文件放到指定位置：\nTo configure your application, you need to create a file superset_config.py and add it to your PYTHONPATH.\nAll the parameters and default values defined in https://github.com/apache/superset/blob/master/superset/config.py can be altered in your local superset_config.py.\nAPI文档 API 文档地址：http://10.180.210.146:18088/swagger/v1\n虽然SuperSet支持Oauth，但由于SuperSet用的是FlaskAB框架（不是Flask框架），支持比较弱，需要自己写python代码。如果是外部系统对接Superset，只能用cookie登陆的方式调用。\n","date":"2021-04-02","permalink":"http://localhost:1313/post/superset%E5%AE%89%E8%A3%85/","tags":["大数据"],"title":"SuperSet安装配置"},{"content":"安装依赖 yum list | grep google-authenticator\ryum install google-authenticator\ryum install qrencode\r配置Google Authenticator 安装完直接跑下面的命令进行配置，注意只在当前用户生效\n\u0026gt; google-authenticator\r之后会需要确认几点信息\nDo you want authentication tokens to be time-based (y/n) y\r是否配置基于时间的动态密钥，选择y，之后会出现超级大一个二维码，下面还会有一些小字,这里的key就是用于配置手机端app的，我们先保存下来，不用慌，因为这个key随时都可以查得到.\nDo you want me to update your \u0026quot;/root/.google_authenticator\u0026quot; file? (y/n) y\r是否将配置信息更新到自己家目录，选择y进行更新，这个文件里面就保存着上面的key信息，以防后续还有新的手机设备需要用到key\nDo you want to disallow multiple uses of the same authentication\rtoken? This restricts you to one login about every 30s, but it increases\ryour chances to notice or even prevent man-in-the-middle attacks (y/n) y\r是否禁止同一密钥在30秒内被多次使用，如果想要更安全就选择y，如果想要更方便就选择n\nBy default, a new token is generated every 30 seconds by the mobile app.\rIn order to compensate for possible time-skew between the client and the server,\rwe allow an extra token before and after the current time. This allows for a\rtime skew of up to 30 seconds between authentication server and client. If you\rexperience problems with poor time synchronization, you can increase the window\rfrom its default size of 3 permitted codes (one previous code, the current\rcode, the next code) to 17 permitted codes (the 8 previous codes, the current\rcode, and the 8 next codes). This will permit for a time skew of up to 4 minutes\rbetween client and server.\rDo you want to do so? (y/n) n\r是否允许前8次和后8次的动态密钥也有效，如果客户端和手机端都是基于网络的时间同步，选择n提高安全性\nIf the computer that you are logging into isn't hardened against brute-force\rlogin attempts, you can enable rate-limiting for the authentication module.\rBy default, this limits attackers to no more than 3 login attempts every 30s.\rDo you want to enable rate-limiting? (y/n) y\r是否限制30秒内最多3次尝试，为了防止恶意试错，选择y 这样服务端的Google Authenticator就配置完毕。下面做一些系统设置，使上面的配置用作ssh。\n配置pam vim /etc/pam.d/sshd\rauth required pam_google_authenticator.so nullok\rvim /etc/ssh/sshd_config\rUsePAM yes\rPasswordAuthentication no\rChallengeResponseAuthentication yes\rsshd -t\rsystemctl restart sshd\r需要注意的是必须设置PasswordAuthentication no（禁用密码登陆，但是并非必须使用公钥），否则二次验证无法使用，会报如下错误：\nsshd[2690384]: fatal: PAM: pam_setcred(): Permission denied\r手机设置 推荐使用 andotp 这个APP，扫码添加即可。\n如果换了手机也很容易，登录到服务器，找到~/.google_authenticator文件，里面会有之前保存的key，重新在新手机进行添加即可。\nXshell登录验证 下面还是正常ssh登陆服务器，不过输入完用户名以后只能选择交互键盘，依次输入密码和OTP验证码即可。关于登录的一些报错都在/var/log/secure这个日志文件中，不管是什么场景登陆失败都可以先查看下失败日志，对症下药。\n注意保持时间同步。 直接使用ntpdate即可，国内可以使用国家授时中心的地址\nntpdate -u 210.72.145.44\r基本上服务器和手机都是用的网络时间就不太会有时间同步的问题。\nrefer:https://blog.csdn.net/Victor2code/\u0026hellip;\n","date":"2020-12-29","permalink":"http://localhost:1313/post/centos%E9%85%8D%E7%BD%AEgoogleauthenticator%E5%8A%A8%E6%80%81%E5%AF%86%E9%92%A5%E8%BF%9B%E8%A1%8Cssh%E4%BA%8C%E6%AC%A1%E9%AA%8C%E8%AF%81/","tags":["Linux"],"title":"Centos配置GoogleAuthenticator动态密钥进行ssh二次验证"},{"content":"TUI ConsoleLauncher basically transforms your Android into a terminal window, requiring you to type out commands to start apps and explore your phone\u0026rsquo;s system as opposed to the familiar process of tapping on icons. It\u0026rsquo;s a great way to practice or learn about Linux commands, and it has the added benefit of securing your phone against unwanted access.\n常用命令：\n-- 不允许别人用exit命令退出\ralias add exit=echo \u0026quot;No\u0026quot;\r-- 定制化界面，取消不必要元素\rconfig -set show_session_info false\rconfig -set show_storage_info false\rconfig -set show_device_name false\rconfig -set show_ram false\rconfig -set show_network_info false\r-- 优化\rconfig -set time_size 20 --调大时间字体\rconfig -set system_wallpaper true --显示系统壁纸\rconfig -set fullscreen true\rconfig -set enable_music true\r-- 记日志/备忘录\rnote -add 明早九点加班\r修改配置后需要restart才能生效。\n结合shellcommand等，还可以自定义出各种小工具。\n","date":"2020-12-25","permalink":"http://localhost:1313/post/tui-consolelauncher-%E5%8F%AF%E5%AE%9A%E5%88%B6%E5%8C%96geek%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%A1%8C%E9%9D%A2%E5%90%AF%E5%8A%A8%E5%99%A8/","tags":["闲扯淡"],"title":"TUI ConsoleLauncher 可定制化geek命令行桌面启动器"},{"content":"Ambari里主机，集群，用户等等都视为一种资源，对它们的增删改查就是对资源的增删改查。\n了解实现Ambari里增加一个资源的流程，就更方便修改Ambari的实现。\n1.新建控制器层 ambari的控制器层在service包里\npackage org.apache.ambari.server.api.services.dataspace;\rimport io.swagger.annotations.Api;\rimport org.apache.ambari.server.api.resources.ResourceInstance;\rimport org.apache.ambari.server.api.services.BaseService;\rimport org.apache.ambari.server.api.services.Request;\rimport org.apache.ambari.server.controller.spi.Resource;\rimport javax.ws.rs.GET;\rimport javax.ws.rs.Path;\rimport javax.ws.rs.Produces;\rimport javax.ws.rs.core.Context;\rimport javax.ws.rs.core.HttpHeaders;\rimport javax.ws.rs.core.Response;\rimport javax.ws.rs.core.UriInfo;\rimport java.util.Collections;\r@Path(\u0026quot;/hdfs/\u0026quot;)\r@Api(value = \u0026quot;Hdfss\u0026quot;, description = \u0026quot;Endpoint for user specific operations\u0026quot;)\rpublic class HdfsService extends BaseService {\r@GET//查询全部\r@Produces(\u0026quot;text/plain\u0026quot;)\rpublic Response getHdfses(String body, @Context HttpHeaders headers, @Context UriInfo ui) {\rreturn handleRequest(headers, body, ui, Request.Type.GET, createHdfsResource(null));\r}\r@GET\r@Path(\u0026quot;{path}\u0026quot;)//查询单个\r@Produces(\u0026quot;text/plain\u0026quot;)\rpublic Response getHdfs(String body, @Context HttpHeaders headers, @Context UriInfo ui) {\rreturn handleRequest(headers, body, ui, Request.Type.GET, createHdfsResource(path));\r}\rprivate ResourceInstance createHdfsResource(String path) {\rreturn createResource(Resource.Type.Hdfs,\rCollections.singletonMap(Resource.Type.Hdfs, path));\r}\r}\r继承BaseService。这里定义访问路径和参数。serivice的方法参数上是看不出VO的类型的。复杂的控制器，可以在一个service里调用另外一个service.\n访问参数可以封装成对象，需要新建一个XXXRequest对象，比如\npackage org.apache.ambari.server.controller;\rpublic class HdfsRequest {\rprivate Integer id;\rprivate String path;\rprivate Integer size;\r//getter,setter略\r}\r这里的xxxRequest是不会像springboot一样自动封装成对象的。\n2.继承ResourceProvide，实现具体的handleRequest方法 package org.apache.ambari.server.controller.internal;\rimport com.google.common.collect.ImmutableMap;\rimport com.google.common.collect.Sets;\rimport org.apache.ambari.server.controller.AmbariManagementController;\rimport org.apache.ambari.server.controller.HdfsRequest;\rimport org.apache.ambari.server.controller.spi.Predicate;\rimport org.apache.ambari.server.controller.spi.Request;\rimport org.apache.ambari.server.controller.spi.Resource;\rimport org.slf4j.Logger;\rimport org.slf4j.LoggerFactory;\rimport java.util.HashSet;\rimport java.util.Map;\rimport java.util.Set;\rpublic class HdfsResourceProvider extends AbstractControllerResourceProvider{\rprivate static final Logger LOG = LoggerFactory.getLogger(HdfsResourceProvider.class);\rpublic static final String HDFS_RESOURCE_CATEGORY=\u0026quot;Hdfses\u0026quot;;\rpublic static final String HDFS_ID_PROPERTY_ID =\u0026quot;hdfs_id\u0026quot;;\rpublic static final String HDFS_PATH_PROPERTY_ID =\u0026quot;hdfs_path\u0026quot;;\rpublic static final String HDFS_SIZE_PROPERTY_ID =\u0026quot;hdfs_size\u0026quot;;\rpublic static final String HDFS_RESOURCE_HDFS_ID_PROPERTY_ID =HDFS_RESOURCE_CATEGORY+\u0026quot;/\u0026quot;+HDFS_ID_PROPERTY_ID;\rpublic static final String HDFS_RESOURCE_HDFS_PATH_PROPERTY_ID =HDFS_RESOURCE_CATEGORY+\u0026quot;/\u0026quot;+HDFS_PATH_PROPERTY_ID;\rpublic static final String HDFS_RESOURCE_HDFS_SIZE_PROPERTY_ID =HDFS_RESOURCE_CATEGORY+\u0026quot;/\u0026quot;+HDFS_SIZE_PROPERTY_ID;\rprivate static Map\u0026lt;Resource.Type, String\u0026gt; keyPropertyIds = ImmutableMap.\u0026lt;Resource.Type, String\u0026gt;builder()\r.put(Resource.Type.Hdfs, HDFS_RESOURCE_HDFS_ID_PROPERTY_ID)\r.build();\rprivate static Set\u0026lt;String\u0026gt; propertyIds = Sets.newHashSet(\rHDFS_RESOURCE_HDFS_ID_PROPERTY_ID,\rHDFS_RESOURCE_HDFS_PATH_PROPERTY_ID,\rHDFS_RESOURCE_HDFS_SIZE_PROPERTY_ID\r);\rpublic static void init(){\r//注入操作在此\r}\rHdfsResourceProvider(AmbariManagementController managementController) {\rsuper(Resource.Type.Hdfs, propertyIds, keyPropertyIds, managementController);\r}\r@Override\rprotected Set\u0026lt;Resource\u0026gt; getResourcesAuthorized(Request request, Predicate predicate){\rSet\u0026lt;String\u0026gt; hdfsIds=getRequestPropertyIds(request,predicate);\rSet\u0026lt;Resource\u0026gt; resources=new HashSet\u0026lt;\u0026gt;();\r//查询数据库略\rfor(int i=0;i\u0026lt;3;i++){\rResourceImpl resource=new ResourceImpl(Resource.Type.Hdfs);\rsetResourceProperty(resource,HDFS_RESOURCE_HDFS_ID_PROPERTY_ID,i,hdfsIds);\rsetResourceProperty(resource,HDFS_RESOURCE_HDFS_PATH_PROPERTY_ID,\u0026quot;path\u0026quot;+i,hdfsIds);\rsetResourceProperty(resource,HDFS_RESOURCE_HDFS_SIZE_PROPERTY_ID,i*100,hdfsIds);\rresources.add(resource);\r}\rreturn resources;\r}\rprivate HdfsRequest getRequest(Map\u0026lt;String,Object\u0026gt; properties){\rif(properties==null){\rreturn new HdfsRequest();\r}\rHdfsRequest hdfsRequest=new HdfsRequest();\rif(properties.get(\u0026quot;HDFS_RESOURCE_HDFS_ID_PROPERTY_ID\u0026quot;)!=null){\rhdfsRequest.setId(Integer.parseInt(properties.get(\u0026quot;HDFS_RESOURCE_HDFS_ID_PROPERTY_ID\u0026quot;).toString()));\r}\rif(properties.get(\u0026quot;HDFS_RESOURCE_HDFS_SIZE_PROPERTY_ID\u0026quot;)!=null){\rhdfsRequest.setSize(Integer.parseInt(properties.get(\u0026quot;HDFS_RESOURCE_HDFS_SIZE_PROPERTY_ID\u0026quot;).toString()));\r}\rhdfsRequest.setPath(properties.get(\u0026quot;HDFS_RESOURCE_HDFS_ID_PROPERTY_ID\u0026quot;).toString());\rreturn hdfsRequest;\r}\r@Override\rpublic RequestStatus updateResources(Request request, Predicate predicate){\r//更新操作略\rreturn getRequestStatus(null);\r}\r@Override\rprotected Set\u0026lt;String\u0026gt; getPKPropertyIds() {\rreturn new HashSet\u0026lt;\u0026gt;(keyPropertyIds.values());\r}\r}\r这里面定义了各种参数字段和参数完整性校验，对应前端传值，实现CRUD逻辑，调用dao等。ResourceProvider和Request类的作用有交叉。\ngetRequest()用于从request Map里获取字符串参数组装成对象。\n同时需要在AbstractControllerResourceProvider里增加一条记录\ncase AlertTarget:\rreturn resourceProviderFactory.getAlertTargetResourceProvider();\rcase ViewInstance:\rreturn resourceProviderFactory.getViewInstanceResourceProvider();\rcase Hdfs:\rreturn new HdfsResourceProvider(managementController);\rdefault: throw new IllegalArgumentException(\u0026quot;Unknown type \u0026quot; + type);\r3.实现ResourceDefinition package org.apache.ambari.server.api.resources;\rimport org.apache.ambari.server.controller.spi.Resource;\rimport java.util.HashSet;\rimport java.util.Set;\rpublic class HdfsResourceDefinition extends BaseResourceDefinition {\r{\r}\r/**\r* Constructor.\r*\r* @param resourceType resource type\r*/\rpublic HdfsResourceDefinition() {\rsuper(Resource.Type.Hdfs);\r}\r/**\r* Obtain the plural name of the resource.\r*\r* @return the plural name of the resource\r*/\r@Override\rpublic String getPluralName() {\rreturn \u0026quot;hdfses\u0026quot;;\r}\r/**\r* Obtain the singular name of the resource.\r*\r* @return the singular name of the resource\r*/\r@Override\rpublic String getSingularName() {\rreturn \u0026quot;hdfs\u0026quot;;\r}\r@Override\rpublic Set\u0026lt;SubResourceDefinition\u0026gt; getSubResourceDefinitions() {\rfinal Set\u0026lt;SubResourceDefinition\u0026gt; subResourceDefinitions = new HashSet\u0026lt;\u0026gt;();\rsubResourceDefinitions.add(new SubResourceDefinition(Resource.Type.Hdfs));\rreturn subResourceDefinitions;\r}\r}\r这里跟权限应该就有了关系。\n修改ResourceInstanceFactoryImpl，加入自己定义的新类型\ncase RemoteCluster:\rresourceDefinition = new RemoteClusterResourceDefinition();\rbreak;\rcase Hdfs:\rresourceDefinition = new HdfsResourceDefinition();\rbreak;\rdefault:\rthrow new IllegalArgumentException(\u0026quot;Unsupported resource type: \u0026quot; + type);\r}\rspi包下Resource接口新增一个枚举\npackage org.apache.ambari.server.controller.spi;\rpublic interface Resource {\renum InternalType {\rCluster,\rService,\rSetting,\r4.数据库相关 orm包下添加对应的实体类和Dao实现，resource/META-INF下需要手动添加实体类对象全名，比如\n\u0026lt;persistence-unit name=\u0026quot;ambari-server\u0026quot; transaction-type=\u0026quot;RESOURCE_LOCAL\u0026quot;\u0026gt;\r\u0026lt;provider\u0026gt;org.eclipse.persistence.jpa.PersistenceProvider\u0026lt;/provider\u0026gt;\r\u0026lt;class\u0026gt;org.apache.ambari.server.orm.entities.AlertCurrentEntity\u0026lt;/class\u0026gt;\r\u0026lt;class\u0026gt;org.apache.ambari.server.orm.entities.AlertDefinitionEntity\u0026lt;/class\u0026gt;\r\u0026lt;/persistence-unit\u0026gt; entity举例：\npackage org.apache.ambari.server.orm.entities;\rimport javax.persistence.*;\r@Entity\r@Table(name = \u0026quot;admin_cluster_host\u0026quot;)\rpublic class AdminClusterHostEntity {\r@Id\r@GeneratedValue(strategy = GenerationType.AUTO)\r@Column(name = \u0026quot;id\u0026quot;, nullable = false, updatable = false)\rprivate Integer id;\r@Column(name = \u0026quot;host\u0026quot;, length = 255)\rprivate String host;\r@Column(name = \u0026quot;cluster\u0026quot;, length = 255)\rprivate String cluster;\rpublic Integer getId() {\rreturn id;\r}\rpublic void setId(Integer id) {\rthis.id = id;\r}\rpublic String getHost() {\rreturn host;\r}\rpublic void setHost(String host) {\rthis.host = host;\r}\rpublic String getCluster() {\rreturn cluster;\r}\rpublic void setCluster(String cluster) {\rthis.cluster = cluster;\r}\r}\rdao举例\npackage org.apache.ambari.server.orm.dao;\rimport com.google.inject.Inject;\rimport com.google.inject.Provider;\rimport com.google.inject.Singleton;\rimport org.apache.ambari.server.orm.RequiresSession;\rimport org.apache.ambari.server.orm.entities.AdminClusterHostEntity;\rimport org.apache.ambari.server.orm.entities.AlertHistoryEntity;\rimport javax.persistence.EntityManager;\rimport javax.persistence.NoResultException;\rimport javax.persistence.TypedQuery;\rimport java.util.Collections;\rimport java.util.List;\r@Singleton\rpublic class AdminClusterDAO {\r@Inject\rprivate Provider\u0026lt;EntityManager\u0026gt; m_entityManagerProvider;\r@RequiresSession\rpublic List\u0026lt;AdminClusterHostEntity\u0026gt; findAll() {\rTypedQuery\u0026lt;AdminClusterHostEntity\u0026gt; query = m_entityManagerProvider.get().createQuery(\r\u0026quot;SELECT ac FROM AdminClusterHostEntity ac\u0026quot;, AdminClusterHostEntity.class);\rtry {\rreturn query.getResultList();\r} catch (NoResultException e) {\rreturn Collections.emptyList();\r}\r}\r}\r5.注入相关 AmbariServer类里也需要相应注入类依赖的对象，一种方式是手动注入，例如：\nermissionResourceProvider.init(injector.getInstance(PermissionDAO.class));\rViewPermissionResourceProvider.init(injector.getInstance(PermissionDAO.class));\rPrivilegeResourceProvider.init(injector.getInstance(PrivilegeDAO.class), injector.getInstance(UserDAO.class),\rinjector.getInstance(GroupDAO.class), injector.getInstance(PrincipalDAO.class),\rinjector.getInstance(PermissionDAO.class), injector.getInstance(ResourceDAO.class));\r还有一种方式是注解注入，参考org.apache.ambari.server.controller.ControllerModule\nAmbari注入这块比较迷，比如dao里用到的m_entityManagerProvider对象就不需要手动注入，在它原有的类里使用新加的dao也不需要手动注入。但是有些自己写的ResourceProvider里就需要注入。\n6.postman模拟验证 请求\ncurl --location --request GET 'http://10.180.210.146:8080/api/v1/hdfs?fields=Hdfses/*' \\\r--header 'Content-Typ: application/x-www-form-urlencoded; charset=UTF-8' \\\r--header 'Cookie: AMBARISESSIONID=node0qm8s4v2muk61199wsf0jqgmg1.node0' \\\r--header 'X-Requested-By: X-Requested-By' \\\r--data-raw ''\r返回\n{\r\u0026quot;href\u0026quot; : \u0026quot;http://10.180.210.146:8080/api/v1/hdfs?fields=Hdfses/*\u0026quot;,\r\u0026quot;items\u0026quot; : [\r{\r\u0026quot;href\u0026quot; : \u0026quot;http://10.180.210.146:8080/api/v1/hdfs/0\u0026quot;,\r\u0026quot;Hdfses\u0026quot; : {\r\u0026quot;hdfs_id\u0026quot; : 0,\r\u0026quot;hdfs_path\u0026quot; : \u0026quot;path0\u0026quot;,\r\u0026quot;hdfs_size\u0026quot; : 0\r}\r},\r{\r\u0026quot;href\u0026quot; : \u0026quot;http://10.180.210.146:8080/api/v1/hdfs/1\u0026quot;,\r\u0026quot;Hdfses\u0026quot; : {\r\u0026quot;hdfs_id\u0026quot; : 1,\r\u0026quot;hdfs_path\u0026quot; : \u0026quot;path1\u0026quot;,\r\u0026quot;hdfs_size\u0026quot; : 100\r}\r},\r{\r\u0026quot;href\u0026quot; : \u0026quot;http://10.180.210.146:8080/api/v1/hdfs/2\u0026quot;,\r\u0026quot;Hdfses\u0026quot; : {\r\u0026quot;hdfs_id\u0026quot; : 2,\r\u0026quot;hdfs_path\u0026quot; : \u0026quot;path2\u0026quot;,\r\u0026quot;hdfs_size\u0026quot; : 200\r}\r}\r]\r}\r请求必须带上?fields=Hdfses/*,表示展示所有字段，否则查询结果是显示不完整的。\n7.自由风格Controller 也可以抛开ambari的规则，自由使用javax.ws风格。\n但这样就没法使用Ambari内置的权限和谓词风格URL查询了\n8.异常和参数校验 参数校验在ResourceProvider里，抛出SystemException即可返回给页面\n权限异常\nif (!AuthorizationHelper.isAuthorized(resourceType, resourceId, RoleAuthorization.SERVICE_RUN_SERVICE_CHECK)) {\rthrow new AuthorizationException(\u0026quot;The authenticated user is not authorized to execute service checks.\u0026quot;);\r}\r","date":"2020-10-13","permalink":"http://localhost:1313/post/ambari%E9%87%8C%E8%87%AA%E5%AE%9A%E4%B9%89%E8%B5%84%E6%BA%90%E6%A8%A1%E5%9D%97%E7%9A%84%E5%AE%9E%E7%8E%B0/","tags":["Java","大数据"],"title":"Ambari里自定义资源模块的实现"},{"content":"按惯例上Prosody 自己的文档: https://prosody.im/doc/\n安装 使用centos8安装\nyum install prosody\rdnf --enablerepo=PowerTools install lua-filesystem\r其它版本linux则无需单独安装lua-filesystem依赖。\n配置 主配置文件 prosody.cfg.lua 一般不需要修改。\n下面写些咱做的修改😂\n在 modules_enabled 中取消启用 version 和 uptime 模块，顺便启动些其他的模块，比如offline。 如果需要允许在客户端上注册的话，把 allow_registration 设置成 true 。 其它配置保持默认即可。\n另外一个配置文件就是具体和域名对应的配置文件了，位于/etc/prosody/conf.d目录下 我的配置是： baidecai.xyz.cfg.lua\nVirtualHost \u0026quot;baidecai.xyz\u0026quot;\rhttp_host = \u0026quot;www.baidecai.xyz\u0026quot;\r-- enabled = false -- Remove this line to enable this host\r-- Prosody will automatically search for a certificate and key\r-- in /etc/prosody/certs/ unless a path is manually specified\r-- in the config file, see https://prosody.im/doc/certificates\rssl = {\rkey = \u0026quot;/etc/prosody/cer/baidecai.xyz.key\u0026quot;;\rcertificate = \u0026quot;/etc/prosody/cer/baidecai.xyz.crt\u0026quot;;\rprotocol = \u0026quot;tlsv1_1+\u0026quot;;\r--- 为客户端到服务器（c2s）和服务器到服务器（s2s）打开认证\rverify = { \u0026quot;peer\u0026quot;, \u0026quot;peer\u0026quot; };\rciphers = \u0026quot;EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH\u0026quot;;\rdhparam = \u0026quot;/etc/prosody/certs/dh-1024.pem\u0026quot;\r}\rdisco_items = {\r{ \u0026quot;upload.baidecai.xyz\u0026quot; },\r}\rComponent \u0026quot;upload.baidecai.xyz\u0026quot; \u0026quot;http_upload\u0026quot;\rhttp_upload_file_size_limit = 1024000\rhttp_upload_expire_after = 60 * 60 * 24 * 7\rhttp_upload_path = \u0026quot;/uploaded/files\u0026quot;\rhttp_files_dir = \u0026quot;/uploaded/files\u0026quot;\r为了支持聊天中发送文件，我加入了http_upload模块。需要注意的是，这个模块来自社区，并不是prosody自带的，所以需要自己去下载放入prosody的插件目录（在这个问题上，我折腾了好几天才搞定，官方文档没有说清楚），要不然你的xmpp就没法发文件了，及时客户端支持发送操作也会报错。\nprosody的插件目录位置可以通过这个命令查看：\nprosodyctl about\r社区插件下载地址： https://hg.prosody.im/prosody-modules/file/tip 记得给http_upload_path赋予可写权限 重启即可。\n注意 现在的xmpp client基本都不再支持非SSL登陆了，所以你必须要有一个证书。也就是前文配置中的certificate和key文件，这个很好申请，推荐网址： https://freessl.cn/ 。 dhparam文件生成指令 openssl dhparam -out dh.pem 1024 如果没开启允许客户端注册的话，用 prosodyctl 注册账户 prosodyctl adduser \u0026lt;JID\u0026gt;\r到此为止，你已经拥有了一个可以加密聊天，可以发文件的xmpp server了。\n","date":"2020-08-26","permalink":"http://localhost:1313/post/prosody%E6%90%AD%E5%BB%BAxmpp%E6%9C%8D%E5%8A%A1%E5%99%A8/","tags":["Linux","闲扯淡"],"title":"Prosody搭建xmpp服务器"},{"content":"k8s rest api对rc、svc、ingress、pod、deployment等都提供的watch接口，可以实时的监听应用部署状态。\n在此之前简单先说一下http长连接\n分块传输编码（Chunked transfer encoding） 超文本传输协议（HTTP）中的一种数据传输机制，允许HTTP由应用服务器发送给客户端应用（ 通常是网页浏览器）的数据可以分成多个部分。分块传输编码只在HTTP协议1.1版本（HTTP/1.1）中提供。 通常，HTTP应答消息中发送的数据是整个发送的，Content-Length消息头字段表示数据的长度。数据的长度很重要，因为客户端需要知道哪里是应答消息的结束，以及后续应答消息的开始。然而，使用分块传输编码，数据分解成一系列数据块，并以一个或多个块发送，这样服务器可以发送数据而不需要预先知道发送内容的总大小。通常数据块的大小是一致的，但也不总是这种情况。\nTransfer-Encoding 消息首部指明了将 entity 安全传递给用户所采用的编码形式。\nTransfer-Encoding 是一个逐跳传输消息首部，即仅应用于两个节点之间的消息传递，而不是所请求的资源本身。一个多节点连接中的每一段都可以应用不同的Transfer-Encoding 值。如果你想要将压缩后的数据应用于整个连接，那么请使用端到端传输消息首部 Content-Encoding 。\n当这个消息首部出现在 HEAD 请求的响应中，而这样的响应没有消息体，那么它其实指的是应用在相应的 GET 请求的应答的值。\n指令 chunked 数据以一系列分块的形式进行发送。 Content-Length 首部在这种情况下不被发送。。在每一个分块的开头需要添加当前分块的长度，以十六进制的形式表示，后面紧跟着 \u0026lsquo;\\r\\n\u0026rsquo; ，之后是分块本身，后面也是\u0026rsquo;\\r\\n\u0026rsquo; 。终止块是一个常规的分块，不同之处在于其长度为0。终止块后面是一个挂载（trailer），由一系列（或者为空）的实体消息首部构成。\n分块编码 分块编码主要应用于如下场景，即要传输大量的数据，但是在请求在没有被处理完之前响应的长度是无法获得的。例如，当需要用从数据库中查询获得的数据生成一个大的HTML表格的时候，或者需要传输大量的图片的时候。一个分块响应形式如下：\nHTTP/1.1 200 OK Content-Type: text/plain Transfer-Encoding: chunked\r7\\r\\n\rMozilla\\r\\n 9\\r\\n\rDeveloper\\r\\n\r7\\r\\n\rNetwork\\r\\n\r0\\r\\n \\r\\n\rHTTP 1.1引入分块传输编码提供了以下几点好处：\nHTTP分块传输编码允许服务器为动态生成的内容维持HTTP持久连接。通常，持久链接需要服务器在开始发送消息体前发送Content-Length消息头字段，但是对于动态生成的内容来说，在内容创建完之前是不可知的。[动态内容，content-length无法预知] 分块传输编码允许服务器在最后发送消息头字段。对于那些头字段值在内容被生成之前无法知道的情形非常重要，例如消息的内容要使用散列进行签名，散列的结果通过HTTP消息头字段进行传输。没有分块传输编码时，服务器必须缓冲内容直到完成后计算头字段的值并在发送内容前发送这些头字段的值。[散列签名，需缓冲完成才能计算] HTTP服务器有时使用压缩 （gzip或deflate）以缩短传输花费的时间。分块传输编码可以用来分隔压缩对象的多个部分。在这种情况下，块不是分别压缩的，而是整个负载进行压缩，压缩的输出使用本文描述的方案进行分块传输。在压缩的情形中，分块编码有利于一边进行压缩一边发送数据，而不是先完成压缩过程以得知压缩后数据的大小。[gzip压缩，压缩与传输同时进行] 一般情况HTTP的Header包含Content-Length域来指明报文体的长度。有时候服务生成HTTP回应是无法确定消息大小的，比如大文件的下载，或者后台需要复杂的逻辑才能全部处理页面的请求，这时用需要实时生成消息长度，服务器一般使用chunked编码\n原理 k8s提供的watch功能是建立在对etcd的watch之上的，当etcd的key-value出现变化时，会通知kube-apiserver，这里的Key-vlaue其实就是k8s资源的持久化。\n早期的k8s架构中，kube-apiserver、kube-controller-manager、kube-scheduler、kubelet、kube-proxy，都是直接去watch etcd的，这样就造成etcd的连接数太大（节点成千上万时），对etcd压力太大，浪费资源，因此到了后面，只有kube-apiserver去watch etcd，而kube-apiserver对外提供watch api，也就是kube-controller-manager、kube-scheduler、kubelet、kube-proxy去watch kube-apiserver，这样大大减小了etcd的压力\nWatch API 通过k8s 官网 rest api的描述，可以看到，Watch API实际上一个标准的HTTP GET请求，我们以Pod的Watch API为例\nHTTP Request\rGET /api/v1/watch/namespaces/{namespace}/pods\rPath Parameters\rParameter Description\rnamespace object name and auth scope, such as for teams and projects\rQuery Parameters\rParameter Description\rfieldSelector A selector to restrict the list of returned objects by their fields. Defaults to everything.\rlabelSelector A selector to restrict the list of returned objects by their labels. Defaults to everything.\rpretty If ‘true’, then the output is pretty printed.\rresourceVersion When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it’s 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\rtimeoutSeconds Timeout for the list/watch call.\rwatch Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\rResponse\rCode Description\r200 WatchEvent OK\r从上面可以看出Watch其实就是一个GET请求，和一般请求不同的是，它有一个watch的query parameter，也就是kube-apiserver接到这个请求，当发现query parameter里面包含watch，就知道这是一个Watch API，watch参数默认为true。\n==返回值是200和WatchEvent。apiserver首先会返回一个200的状态码，建立长连接，然后不断的返回watch event==\n源码 原理都讲完了，现在到源码了，很简单。\nOkHttpClient client = makeSSLClient();\rRequest request = new Request.Builder()\r.url(\u0026quot;https://10.1.1.11:6443/api/v1/watch/namespaces/default/pods\u0026quot;)\r.addHeader(\u0026quot;Authorization\u0026quot;,\u0026quot;Bearer \u0026quot;+\u0026quot;eyJhbGciOiBnlQ\u0026quot;)\r.get()\r.build();\rclient.newCall(request).enqueue(new Callback() {\r@Override\rpublic void onFailure(Call call, IOException e) {\rlog.info(\u0026quot;Watch connection failed. reason: {}\u0026quot;, e.getMessage());\r}\r@Override\rpublic void onResponse(Call call, Response response) throws IOException {\rif (!response.isSuccessful()) {\rlog.info(\u0026quot;!response.isSuccessful() {}\u0026quot;, response.code());\r}\rtry {\rBufferedSource source = response.body().source();\rwhile (!source.exhausted()) {\rString message = source.readUtf8LineStrict();\rlog.info(message);\r}\r} catch (Exception e) {\rlog.info(\u0026quot;Watch terminated unexpectedly. reason: {}\u0026quot;, e.getMessage());\r}\r}\r});\r剩下的就待自己完善了。\n需要注意的是：\nk8s提供的restful API在此处并不是网上常说的HTTP2协议，它就是HTTP 1.1 长连接 要注意http connection的超时，这里是长连接，超时应该是-1 如果是Java k8s client，可以使用fabric8的watch机制，使用如下：\nKubernetesClient client = new DefaultKubernetesClient(config);//使用默认的就足够了\r//由于4.10.2版本有个影响events使用的回归bug，暂时回退到4.9.2版本。详情见官网issue#2328\r//4.10.3已修复\rclient.v1().events().inAnyNamespace().watch(new Watcher\u0026lt;Event\u0026gt;() {\r@Override\rpublic void eventReceived(Action action, Event resource) {\rlog.info(\u0026quot;event {} resource:{}\u0026quot; , action.name(),resource.toString());\rredisService.lSet(\u0026quot;k8sevent\u0026quot;,resource,3600*24*5);\r}\r@Override\rpublic void onClose(KubernetesClientException cause) {\rlog.info(\u0026quot;Watcher close due to {}\u0026quot; , cause);\r}\r});\r其本质也是调用的restful API。\n","date":"2020-08-11","permalink":"http://localhost:1313/post/%E5%9F%BA%E4%BA%8Erestfulapi%E5%AE%9E%E7%8E%B0k8s%E7%9A%84%E7%9B%91%E5%90%AC%E6%9C%BA%E5%88%B6/","tags":["k8s","Java"],"title":"基于restfulAPI实现k8s的监听机制"},{"content":"helm3集成minio搭建私有仓库 我们一般是从本地的目录结构中的chart去进行部署，如果要集中管理chart,就需要涉及到repository的问题可以通过minio建立一个私有的存放仓库。\nminio安装 安装过程略去，直接下载执行文件即可\n.\\minio.exe server g:/tmp/\r配置mc\nmc config host add minio http://192.168.1.51 BKIKJAA5BMMU2RHO6IBB V7f1CwQqAcwo80UEIJEjc5gVQUSSx5ohQ9GSrr12\r仓库创建 helm create helm-chart\rhelm package ./helm-chart --debug\r#构建索引\rhelm repo index ./\r接下来是复制生成的index.yaml到minio中\n.\\mc.exe policy set download minio/data\r.\\mc.exe cp G:\\data\\project\\helm\\index.yaml minio/data/\r到这一步基本就快好了，然后\nhelm repo add mi http://10.180.204.129:9000/data/\rhelm repo list\r最终可以看到如下结果，说明添加仓库成功：\nPS G:\\data\\project\\helm\u0026gt; helm repo list\rNAME URL\rstable https://kubernetes-charts.storage.googleapis.com/\rmi http://10.180.204.129:9000/data/\rPS G:\\data\\project\\helm\u0026gt;\r搜索下\nPS G:\\tmp\\data\u0026gt; helm search repo mi/helm-chart\rNAME CHART VERSION APP VERSION DESCRIPTION\rmi/helm-chart 0.2.0 1.16.4 A Helm chart for Kubernetes\r也能搜到新加的Chart，完工。\n注意 1.minio虽然是一个文件对象服务器，但是也支持直接在OS文件系统下的操作。也就是说，直接在文件夹上的操作会同步到minio的数据库中。此前一直顾虑minio这种文件系统是否适合用来做repo，其实是多虑的。\n2.官网 https://helm.sh/docs/topics/chart_repository/ 的helm仓库格式如下，典型的tgz+index.yaml格式\ncharts/\r|\r|- index.yaml\r|\r|- alpine-0.1.2.tgz\r|\r|- alpine-0.1.2.tgz.prov\r然而，helm安装是支持文件夹格式的包路径，所以有些应用商店如rancher内置了一些仓库是git+文件夹格式的组织结构，这不是标准的helm仓库，但是也是可以使用的，只是不能被helm repo add而已。这样的仓库需要下载一个文件夹到临时目录再调用helm安装。\n3.如果你发布了两个版本的chart包，也update了，但是仓库默认只能搜到高版本的。需要这么做\nPS G:\\tmp\\data\u0026gt; helm search repo mi/helm-chart --versions\rNAME CHART VERSION APP VERSION DESCRIPTION\rmi/helm-chart 0.2.0 1.16.4 A Helm chart for Kubernetes\rmi/helm-chart 0.1.0 1.16.0 A Helm chart for Kubernetes\r安装\nhelm install mi/helm-chart --version 0.1.0 ","date":"2020-07-03","permalink":"http://localhost:1313/post/helm%E9%9B%86%E6%88%90minio%E6%90%AD%E5%BB%BA%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/","tags":["k8s"],"title":"Helm集成minio搭建私有仓库"},{"content":"在后端项目中，难免遇到需要写接口文档方便第三方调用的场景，一般业界最常用的方案是使用swagger。Java项目中，一般采用springfox项目，它集成了swagger和swagger-ui，不需要单独部署项目，可让文档随着项目一起发布。\n但是开源项目往往是开源一时热，事后拂衣去，缺少维护。这个项目已经两年多没有维护了，很多人在issue反馈过bug，作者一年前表示自己比较忙，没空维护。\nspringfox最新的版本是2.9.2，不支持spring5（虽然有个快照版支持spring5，但一直没发布，整合也有点麻烦）。spring5比较大的一个改变就是增加了webflux，因此旧版springfox无法兼容spring5的。\n其实用快照版，稍作修改也能让springfox支持webflux，但是我不是很喜欢这种做法。一个是增加了打包体积和运行内存占用，另一个则是swagger的使用污染了Java源码，很是不美观，强迫症不能忍。\n@RestController\r@RequestMapping(\u0026quot;/dataspace/api/v1/hive\u0026quot;)\r@Api(value = \u0026quot;hive\u0026quot;, description = \u0026quot;hive资源管理\u0026quot;)\rpublic class HiveManagerController {\r@Autowired\rHiveManagerService hiveManagerService;\r@RequestMapping(value = \u0026quot;/list\u0026quot;, method = {RequestMethod.POST})\r@ApiOperation(value = \u0026quot;资源列表\u0026quot;, notes = \u0026quot;\u0026quot;)\rpublic PageResult\u0026lt;HiveVO\u0026gt; showPublic(@ApiParam(value = \u0026quot;hive查询对象\u0026quot;)\r@RequestBody PageReqParam\u0026lt;HiveReq\u0026gt; hiveReq) {\rPageResult\u0026lt;HiveVO\u0026gt; result = new PageResult\u0026lt;\u0026gt;();\rif (hiveReq.getReqParam() == null) {\rresult.setCode(-1);\rresult.setMsg(\u0026quot;参数不完整\u0026quot;);\rreturn result;\r}\rif (hiveReq.getPageSize() \u0026gt; 50 || hiveReq.getPageSize() \u0026lt; 0) {\rresult.setCode(-1);\rresult.setMsg(\u0026quot;页码非法\u0026quot;);\rreturn result;\r}\rresult = hiveManagerService.getList(hiveReq);\rreturn result;\r}\r源码中混入了各种ApiParam、Api、ApiOperation注解。\n再加上我现在使用的springcloud套件，需要在gateway的feign接口上加注释，这样的话，无论是springfox，还是很多第三方的api doc工具都很难胜任。\n于是，我想到了另外一种方法，就是javadoc。然而javadoc自带的注解很有限，不能满足第三方对文档的需求，比如\n/**\r* 根据节点名删除主机\r* @method DELETE\r* @path host/delHostByNodeName\r* @param nodeName 节点名\r* @param cluster 集群名\r* @return JSON\r*/\r@DeleteMapping(\u0026quot;/delHostByNodeName\u0026quot;)\rpublic String delHostByNodeName(@RequestParam(\u0026quot;nodeName\u0026quot;) String nodeName,@RequestParam(\u0026quot;cluster\u0026quot;) String cluster);\rjavadoc并不认识method和path这两个标签，生成的文档还是缺少一些必须要的信息。\n这个不难，扩展下taglet即可。\n先引入maven依赖\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;jdk.tools\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jdk.tools\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;1.8\u0026lt;/version\u0026gt;\r\u0026lt;scope\u0026gt;system\u0026lt;/scope\u0026gt;\r\u0026lt;systemPath\u0026gt;${JAVA_HOME}/lib/tools.jar\u0026lt;/systemPath\u0026gt;\r\u0026lt;/dependency\u0026gt;\r扩展taglet代码\npackage com.github.cloud.ali.common.tool;\rimport com.sun.javadoc.Tag;\rimport com.sun.tools.doclets.Taglet;\rimport java.util.Map;\rpublic class MethodTaglet implements Taglet {\rprivate String NAME = \u0026quot;HTTP请求类型\u0026quot;;\rprivate String HEADER = \u0026quot;HTTP请求类型:\u0026quot;;\r@Override\rpublic boolean inField() {\rreturn false;\r}\r@Override\rpublic boolean inConstructor() {\rreturn false;\r}\r@Override\rpublic boolean inMethod() {\rreturn true;\r}\r@Override\rpublic boolean inOverview() {\rreturn true;\r}\r@Override\rpublic boolean inPackage() {\rreturn true;\r}\r@Override\rpublic boolean inType() {\rreturn true;\r}\r@Override\rpublic boolean isInlineTag() {\rreturn false;\r}\rpublic static void register(Map tagletMap) {\rMethodTaglet tag = new MethodTaglet();\rTaglet t = (Taglet) tagletMap.get(tag.getName());\rif (t != null) {\rtagletMap.remove(tag.getName());\r}\rtagletMap.put(tag.getName(), tag);\r}\r@Override\rpublic String getName() {\rreturn NAME;\r}\r@Override\rpublic String toString(Tag tag) {\rreturn \u0026quot;\u0026lt;DT\u0026gt;\u0026lt;B\u0026gt;\u0026quot; + HEADER + \u0026quot;\u0026lt;/B\u0026gt;\u0026lt;DD\u0026gt;\u0026quot;\r+ \u0026quot;\u0026lt;table cellpadding=2 cellspacing=0\u0026gt;\u0026lt;tr\u0026gt;\u0026lt;td bgcolor=\\\u0026quot;yellow\\\u0026quot;\u0026gt;\u0026quot;\r+ tag.text()\r+ \u0026quot;\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;/table\u0026gt;\u0026lt;/DD\u0026gt;\\n\u0026quot;;\r}\r@Override\rpublic String toString(Tag[] tags) {\rif (tags.length == 0) {\rreturn null;\r}\rString result = \u0026quot;\\n\u0026lt;DT\u0026gt;\u0026lt;B\u0026gt;\u0026quot; + HEADER + \u0026quot;\u0026lt;/B\u0026gt;\u0026lt;DD\u0026gt;\u0026quot;;\rresult += \u0026quot;\u0026lt;table cellpadding=2 cellspacing=0\u0026gt;\u0026lt;tr\u0026gt;\u0026lt;td bgcolor=\\\u0026quot;yellow\\\u0026quot;\u0026gt;\u0026quot;;\rfor (int i = 0; i \u0026lt; tags.length; i++) {\rif (i \u0026gt; 0) {\rresult += \u0026quot;, \u0026quot;;\r}\rresult += tags[i].text();\r}\rreturn result + \u0026quot;\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;/table\u0026gt;\u0026lt;/DD\u0026gt;\\n\u0026quot;;\r}\r}\r同理，path注解也是类似的实现。编译命令如下：\njavadoc -protected -splitindex -use -author -version -encoding utf-8 -charset utf-8 -d /usr/jackma/doc -windowtitle \u0026quot;ali 文档\u0026quot; $(ls /usr/jackma/ali/ali-common/src/main/java/com/github/cloud/ali/common/model/*.java |tr \u0026quot;\\n\u0026quot; \u0026quot; \u0026quot;) $(ls /usr/jackma/ali/ali-gateway/src/main/java/com/github/cloud/ali/feign/*.java |tr \u0026quot;\\n\u0026quot; \u0026quot; \u0026quot;) -tag method:a:\u0026quot;HTTP请求方法:\u0026quot; -tag path:a:\u0026quot;请求路径:\u0026quot; -tagletpath /usr/jackma/ali/ali-common/src/main/java/com/github/cloud/ali/common/tool/MethodTaglet.java -tagletpath /usr/jackma/ali/ali-common/src/main/java/com/github/cloud/ali/common/tool/PathTaglet.java -taglet com.github.cloud.ali.common.tool.MethodTaglet -taglet com.github.cloud.ali.common.tool.PathTaglet\r最终效果如下：\n还可以进一步，加上数据类型的注解，这样就更完善了。\n虽然离swagger-ui还有点差距，但是还是比原版javadoc好多了。最大的优点是没有任何限制和对源码的污染。\n不得不说，Java的扩展性不是盖的。\n","date":"2020-05-12","permalink":"http://localhost:1313/post/%E4%B8%80%E7%A7%8Dswagger-ui%E7%9A%84%E6%9B%BF%E4%BB%A3%E6%96%B9%E6%A1%88%E4%B8%8D%E5%BC%95%E5%85%A5%E4%BB%BB%E4%BD%95%E6%BA%90%E7%A0%81%E6%B1%A1%E6%9F%93/","tags":["Java"],"title":"一种swagger Ui的替代方案不引入任何源码污染"},{"content":"​ 这个问题纠结我快一年了。某次manjaro升级后，我的manjaro在系统自带应用上如konsole,kate,Yakuake上都不能切换输入法（目测系统自带的软件都不能），鼠标放键盘图标上提示“无输入窗口”。但是浏览器和其他软件是可以的。这个问题不是太影响使用，就忍了很久，大不了其他地方写好了再复制到kate里，但是就好像衣服上落沾了一坨黄泥，始终感觉不爽，每隔一两个月就要尝试解决一次，始终无果。\n尝试过的解决方案有下面几种：\n修改/etc/profile 修改.xprofile 修改/etc/environment 更换其他中文输入法 用fcitx-diagnose诊断配置 配置文件肯定是正确的，按照网上说的 Linux下输入中文的配置也检查了很多，作为一个有六七年经验的 Linux老司机，怎么可能翻车呢。搜了很多文章，死马当作活马医，一直无解。\nfcitx-diagnose诊断结果如下，然而确认配置了，可为什么就是不认识一直没理解。\n\u0026quot; 而不是 \u0026quot;fcitx\u0026quot;. 请检查您是否在某个初始化文件中错误的设置了它的值.**\r**您可能会在 qt4 程序中使用 fcitx 时遇到问题.**\r**请使用您发行版提供的工具将环境变量 QT_IM_MODULE 设为 \u0026quot;fcitx\u0026quot; 或者将 `export QT_IM_MODULE=fcitx` 添加到您的 `~/.xprofile` 中. 参见 [输入法相关的环境变量: QT_IM_MODULE](http://fcitx-im.org/wiki/Input_method_related_environment_variables/zh-cn#QT_IM_MODULE).**\rgtk - `${GTK_IM_MODULE}`:\r\u0026quot; 而不是 \u0026quot;fcitx\u0026quot;. 请检查您是否在某个初始化文件中错误的设置了它的值.**\r**您可能会在 gtk 程序中使用 fcitx 时遇到问题.**\r**请使用您发行版提供的工具将环境变量 GTK_IM_MODULE 设为 \u0026quot;fcitx\u0026quot; 或者将 `export GTK_IM_MODULE=fcitx` 添加到您的 `~/.xprofile` 中. 参见 [输入法相关的环境变量: GTK_IM_MODULE](http://fcitx-im.org/wiki/Input_method_related_environment_variables/zh-cn#GTK_IM_MODULE).**\r直到今天，偶尔搜到了这篇文章，出现的问题和我遇到的一模一样。原来是我的.xprofile里环境变量 XMODIFIERS、QT_IM_MODULE、GTK_IM_MODULE 值的末尾有一个回车符。也就是说，设置这些环境变量的那个文件错误地使用了 DOS / Windows 的换行符。\n解决方案就很简单了，在 Vim 中打开并执行 :set ff=unix，然后保存并退出 :wq。\n重新注销，解决了。\n然后想起来，快一年前更新系统，结果挂了。这是唯一一次更新 manjaro滚挂了（这是manjaro软件源的一次bug 导致），修复系统后用了百度复制来的代码，竟然疏忽了。\n要是没那篇文章，真不知何年何月能解决。放狗一搜，还有许许多多受害者遇到这种情况至今没有解决，甚至在manjaro官网提问也无解。所以记录下，希望更多人能看到。\n","date":"2020-03-07","permalink":"http://localhost:1313/post/kde%E6%A1%8C%E9%9D%A2%E4%B8%8B%E9%83%A8%E5%88%86%E5%BA%94%E7%94%A8%E6%97%A0%E6%B3%95%E8%BE%93%E5%85%A5%E4%B8%AD%E6%96%87/","tags":["linux"],"title":"Kde桌面下自带应用无法输入中文"},{"content":"1.安装k8s 安装K8S的步骤略去，使用k3s安装会更快捷方便，方便测试环境。\n如果使用k3s会有个坑，k3s默认使用container而不是docker作为容器，会导致运行时出现一些问题，后面会详细分析。\n安装k3s后，需要按照如下修改 /etc/systemd/system/k3s.service\nExecStartPre=-/sbin/modprobe overlay\rExecStart=/usr/local/bin/k3s \\\rserver --docker \\\r#添加 --docker 参数\r2.springboot镜像准备 pom.xml\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt;\r\u0026lt;project xmlns=\u0026quot;http://maven.apache.org/POM/4.0.0\u0026quot; xmlns:xsi=\u0026quot;http://www.w3.org/2001/XMLSchema-instance\u0026quot;\rxsi:schemaLocation=\u0026quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026quot;\u0026gt;\r\u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt;\r\u0026lt;parent\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.2.5.RELEASE\u0026lt;/version\u0026gt;\r\u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt;\r\u0026lt;/parent\u0026gt;\r\u0026lt;groupId\u0026gt;com.github.iminto\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;bcdemo\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt;\r\u0026lt;name\u0026gt;bcdemo\u0026lt;/name\u0026gt;\r\u0026lt;description\u0026gt;Demo project for Spring Boot\u0026lt;/description\u0026gt;\r\u0026lt;properties\u0026gt;\r\u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt;\r\u0026lt;/properties\u0026gt;\r\u0026lt;dependencies\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;/dependencies\u0026gt;\r\u0026lt;build\u0026gt;\r\u0026lt;plugins\u0026gt;\r\u0026lt;plugin\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt;\r\u0026lt;/plugin\u0026gt;\r\u0026lt;/plugins\u0026gt;\r\u0026lt;/build\u0026gt;\r\u0026lt;/project\u0026gt;\rBcdemoApplication.java 启动器代码略。\nsrc\\main\\java\\com\\github\\iminto\\bcdemo\\controller\\HomeController.java\npackage com.github.iminto.bcdemo.controller;\rimport org.springframework.web.bind.annotation.RequestMapping;\rimport org.springframework.web.bind.annotation.RestController;\r@RestController\rpublic class HomeController {\r@RequestMapping(\u0026quot;/\u0026quot;)\rpublic String home() {\rreturn \u0026quot;Hello Docker World\u0026quot;;\r}\r}\rsrc\\main\\resources\\application.yaml\nserver:\rport: 9010\rmvn打包。\nDockerfile文件如下：\nFROM openjdk:8-jdk-alpine\rENV TZ=Asia/Shanghai\rRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime \u0026amp;\u0026amp; echo $TZ \u0026gt; /etc/timezone\rCOPY bcdemo.jar /opt/app.jar\rCOPY run.sh /opt/run.sh\rEXPOSE 9010\rENTRYPOINT [\u0026quot;/bin/sh\u0026quot;, \u0026quot;/opt/run.sh\u0026quot;]\rrun.sh\n#!/bin/bash\r# do other things here\rjava -jar /opt/app.jar 2\u0026gt;\u0026amp;1 需要注意，docker必须要有一个前台进程，不然运行后会马上退出，所以不能使用下面的命令\n#这么写是错的\rjava -jar /opt/app.jar 2\u0026gt;\u0026amp;1 \u0026amp; docker镜像构建\ndocker build . -t bcdemo:1.0\r测试docker镜像是否正确时，需要用ctrl+p+q终止控制台日志打印，不要用ctrl+c。\n3.k8s部署 编写yaml文件\napiVersion: v1\rkind: Deployment\rmetadata:\rname: k8s-springboot-demo\rlabels:\rapp: k8s-springboot-demo\rspec:\rreplicas: 1\rrevisionHistoryLimit: 10\rselector:\rmatchLabels:\rapp: k8s-springboot-demo\rtemplate:\rmetadata:\rlabels:\rapp: k8s-springboot-demo\rspec:\rcontainers:\r- name: k8s-springboot-demo\rimage: bcdemo:1.0\rports:\r- containerPort: 9010\rprotocol: TCP\rlivenessProbe:\rhttpGet:\rpath: /\rport: 9010\rinitialDelaySeconds: 30\rtimeoutSeconds: 30\rimagePullPolicy: IfNotPresent\rtolerations:\r- key: node-role.kubernetes.io/master\reffect: NoSchedule\r---\rapiVersion: v1\rkind: Service\rmetadata:\rname: k8s-springboot-demo\rnamespace: default\rlabels:\rapp: k8s-springboot-demo\rspec:\rports:\r- port: 9010\rtargetPort: 9010\rselector:\rapp: k8s-springboot-demo\rtype: NodePort\r部署\n#部署\rkubectl apply -f sp.yaml\r#查看运行状态\rkubectl get po,svc,deploy -o wide\r#删除Deployment\rkubectl delete -f sp.yaml\r#删除节点\rkubectl delete pod k8s-springboot-demo-fc778b44-f4p49\r#查看节点详细运行状态，可用于排错\rkubectl describe pod k8s-springboot-demo-fc778b44-f4p49\r最终部署结果如下：\n[root@chenwork2 project]# kubectl get po,svc,deploy -o wide\rNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES\rpod/k8s-springboot-demo-fc778b44-zfjnx 1/1 Running 0 16h 10.42.0.11 chenwork2 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt;\rNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR\rservice/k8s-springboot-demo NodePort 10.43.35.126 \u0026lt;none\u0026gt; 9010:31622/TCP 16h app=k8s-springboot-demo\rservice/kubernetes ClusterIP 10.43.0.1 \u0026lt;none\u0026gt; 443/TCP 51d \u0026lt;none\u0026gt;\rNAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR\rdeployment.extensions/k8s-springboot-demo 1/1 1 1 16h k8s-springboot-demo bcdemo:1.0 app=k8s-springboot-demo\r验证：\n[root@chenwork2 project]# curl -i -X GET chenwork2:31622/\rHTTP/1.1 200 Content-Type: text/plain;charset=UTF-8\rContent-Length: 18\rDate: Fri, 06 Mar 2020 01:55:40 GMT\rHello Docker World\r这样的端口，只能在集群内访问，集群外是无法访问的。\n4.k3s的问题 如果pod一直是 ContainerCreating 状态，那就是pod没有创建成功，用describe命令看一下，最后几行一般会看到如下报错\nWarning FailedCreatePodSandBox 91s (x29 over 21m) kubelet, host123 Failed create pod sandbox: rpc error: code = Unknown desc = failed to get sandbox image \u0026quot;k8s.gcr.io/pause:3.1\u0026quot;: failed to pull image \u0026quot;k8s.gcr.io/pause:3.1\u0026quot;: failed to pull and unpack image \u0026quot;k8s.gcr.io/pause:3.1\u0026quot;: failed to resolve reference \u0026quot;k8s.gcr.io/pause:3.1\u0026quot;: failed to do request: Head https://k8s.gcr.io/v2/pause/manifests/3.1: dial tcp 108.177.97.82:443: i/o timeout\r原因已经非常清楚了，failed to pull image \u0026ldquo;k8s.gcr.io/pause:3.1\u0026rdquo;，镜像拉不到。\n解决方法：\ndocker pull mirrorgooglecontainers/pause:3.1\r#其实直接把rancher/pause镜像命名成k8s.gcr.io/pause即可\rdocker tag mirrorgooglecontainers/pause:3.1 k8s.gcr.io/pause:3.1\r重启k3s，你会发现pod还是启动不起来，这就是前面说的原因：k3s默认使用container而不是docker作为容器\n你有了pause镜像，但是k3s不认docker镜像，而是认container容器，所以需要把k3s改成docker运行时。\n或者如下操作：\nctr --version\r#需要预先导出pause镜像\rctr images import pause-amd64-3.1.tar\r#看看有没有加载进来\rctr images list\r#如果加载了，但是名字不匹配，需要打标签\rctr images tag gcr.io/google_containers/pause-amd64:3.1 k8s.gcr.io/pause:3.1\r5.LoadBalancer服务暴露给外部访问 K8S Service 暴露服务类型有三种：ClusterIP、NodePort、LoadBalancer，三种类型分别有不同的应用场景。\n对内服务发现，可以使用 ClusterIP 方式对内暴露服务，因为存在 Service 重新创建 IP 会更改的情况，所以不建议直接使用分配的 ClusterIP 方式来内部访问，可以使用 K8S DNS 方式解析，DNS 命名规则为：\u0026lt;svc_name\u0026gt;.\u0026lt;namespace_name\u0026gt;.svc.cluster.local，按照该方式可以直接在集群内部访问对应服务。\n对外服务暴露，可以采用 NodePort、LoadBalancer 方式对外暴露服务，NodePort 方式使用集群固定 IP，但是端口号是指定范围内随机选择的，每次更新 Service 该 Port 就会更改，不太方便，当然也可以指定固定的 NodePort，但是需要自己维护 Port 列表，也不方便。LoadBalancer 方式使用集群固定 IP 和 NodePort，会额外申请申请一个负载均衡器来转发到对应服务，但是需要底层平台支撑。如果使用 Aliyun、GCE 等云平台商，可以使用该种方式，他们底层会提供 LoadBalancer 支持，直接使用非常方便。\n以上方式或多或少都会存在一定的局限性，所以建议如果在公有云上运行，可以使用 LoadBalancer、 Ingress 方式对外提供服务，私有云的话，可以使用 Ingress 通过域名解析来对外提供服务。\n下面使用LoadBalancer方式。\nyaml文件修改 修改k8s-springboot-demo.yaml\napiVersion: v1 kind: Service metadata: name: k8s-springboot-demo\rnamespace: default\rlabels: app: k8s-springboot-demo\rspec: ports: - port: 8080 targetPort: 8080\rselector: app: k8s-springboot-demo type: LoadBalancer\rservice的type修改为LoadBalancer，然后\nkubectl apply -f k8s-springboot-demo.yaml\r命令修改 用命令修改的方式更方便。\n[root@chenwork2 project]# kubectl delete svc k8s-springboot-demo\rservice \u0026quot;k8s-springboot-demo\u0026quot; deleted\r[root@chenwork2 project]# kubectl get po,svc,deploy\rNAME READY STATUS RESTARTS AGE\rpod/k8s-springboot-demo-fc778b44-zfjnx 1/1 Running 0 16h\rNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\rservice/kubernetes ClusterIP 10.43.0.1 \u0026lt;none\u0026gt; 443/TCP 51d\rNAME READY UP-TO-DATE AVAILABLE AGE\rdeployment.extensions/k8s-springboot-demo 1/1 1 1 16h\r[root@chenwork2 project]# kubectl expose deploy k8s-springboot-demo --type=LoadBalancer\rservice/k8s-springboot-demo exposed\r[root@chenwork2 project]# kubectl get po,svc,deploy\rNAME READY STATUS RESTARTS AGE\rpod/k8s-springboot-demo-fc778b44-zfjnx 1/1 Running 0 16h\rpod/svclb-k8s-springboot-demo-crfvw 1/1 Running 0 4s\rNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\rservice/k8s-springboot-demo LoadBalancer 10.43.112.54 10.180.249.73 9010:32219/TCP 4s\rservice/kubernetes ClusterIP 10.43.0.1 \u0026lt;none\u0026gt; 443/TCP 51d\rNAME READY UP-TO-DATE AVAILABLE AGE\rdeployment.extensions/k8s-springboot-demo 1/1 1 1 16h\r这样就能在集群外，直接用浏览器访问了。\n也可以使用 ClusterIP+kubectl proxy 方式，但不推荐。\n6.容器部署yaml中传递参数 可以向容器传递参数到脚本执行一些特殊操作，而且这里变成脚本来启动，这样后续构建镜像基本不需要改 Dockerfile 了\n#!/bin/bash\r# do other things here\rjava -jar $JAVA_OPTS /opt/project/app.jar $1 2\u0026gt;\u0026amp;1\r上边示例中，我们就注入 $JAVA_OPTS 环境变量，来优化 JVM 参数，还可以传递一个变量，这个变量大家应该就猜到了，就是服务启动加载哪个配置文件参数，例如：\u0026ndash;spring.profiles.active=prod 那么，在 Deployment 中就可以通过如下方式配置了：\nspec:\rcontainers:\r- name: project-name\rimage: registry.docker.com/project/app:v1.0.0\rargs: [\u0026quot;--spring.profiles.active=prod\u0026quot;]\renv:\r- name: JAVA_OPTS\rvalue: \u0026quot;-XX:PermSize=512M -XX:MaxPermSize=512M -Xms1024M -Xmx1024M...\u0026quot;\r7.参考 Spring Boot 项目转容器化 K8S 部署实用经验分享\nK8s 集群使用 ConfigMap 优雅加载 Spring Boot 配置文件\n[Spring Boot应用容器化及Kubernetes部署](http://fly-luck.github.io/2018/11/10/Spring Boot App on Kubernetes/)\n基于Kubernetes和Springboot构建微服务\nDocker / Kubernetes部署Java / SpringBoot项目\n在Kubernetes中部署spring boot应用\n","date":"2020-03-06","permalink":"http://localhost:1313/post/k8s%E9%83%A8%E7%BD%B2springboot/","tags":["k8s","Java"],"title":"K8s部署springboot"},{"content":"rancher 是一个为DevOps团队提供的完整的Kubernetes与容器管理解决方案。rancher最大的优点就是安装部署方便，极大地简化了K8S的安装配置。在官网上，推荐的是使用docker方式安装rancher，这种方式隐藏了大量的细节。在网上搜了下现有的资料，几乎都是照抄官方文档，更没有在windows上安装rancher的先例。\nrancher是用golang写的，跨平台问题不大，但也需要一些修改。正好最近要对rancher做二次开发，于是记录下了在windows上编译安装rancher的步骤。\n1.修改源码 rancher要在windows上编译通过并运行，需要修改以下源码\nmain.go\nfunc run(cfg app.Config) error {\rlogrus.Infof(\u0026quot;Rancher version %s is starting\u0026quot;, VERSION)\rlogrus.Infof(\u0026quot;Rancher arguments %+v\u0026quot;, cfg)\rdump.GoroutineDumpOn(syscall.SIGUSR1, syscall.SIGILL)\rctx := signals.SetupSignalHandler(context.Background())\r改为如下，此处修改基本不会有副作用\nfunc run(cfg app.Config) error {\rlogrus.Infof(\u0026quot;Rancher version %s is starting\u0026quot;, VERSION)\rlogrus.Infof(\u0026quot;Rancher arguments %+v\u0026quot;, cfg)\rdump.GoroutineDumpOn(syscall.SIGILL, syscall.SIGILL)\rctx := signals.SetupSignalHandler(context.Background())\r然后屏蔽以下几个文件中相关syscall的处理：（这几处修改可能会导致K8S相关的功能带来影响，但影响未知.建议使用条件编译方式）\npkg/controllers/user/helm/common/common.go\nfunc JailCommand(cmd *exec.Cmd, jailPath string) (*exec.Cmd, error) {\rif os.Getenv(\u0026quot;CATTLE_DEV_MODE\u0026quot;) != \u0026quot;\u0026quot; {\rreturn cmd, nil\r} else {\r//cred, err := jailer.GetUserCred()\r//if err != nil {\r// return nil, errors.WithMessage(err, \u0026quot;get user cred error\u0026quot;)\r//}\r//\r//cmd.SysProcAttr = \u0026amp;syscall.SysProcAttr{}\r//cmd.SysProcAttr.Credential = cred\r//cmd.SysProcAttr.Chroot = jailPath\r//cmd.Env = jailer.WhitelistEnvvars(cmd.Env)\rreturn cmd, nil\r}\r}\rpkg/controllers/management/node/utils.go 修改同理\nfunc buildCommand(nodeDir string, node *v3.Node, cmdArgs []string) (*exec.Cmd, error) {\r// In dev_mode, don't need jail or reference to jail in command\rif os.Getenv(\u0026quot;CATTLE_DEV_MODE\u0026quot;) != \u0026quot;\u0026quot; {\renv := initEnviron(nodeDir)\rcommand := exec.Command(nodeCmd, cmdArgs...)\rcommand.Env = env\rreturn command, nil\r}\r//cred, err := jailer.GetUserCred()\r//if err != nil {\r// return nil, errors.WithMessage(err, \u0026quot;get user cred error\u0026quot;)\r//}\rcommand := exec.Command(nodeCmd, cmdArgs...)\r//command.SysProcAttr = \u0026amp;syscall.SysProcAttr{}\r//command.SysProcAttr.Credential = cred\r//command.SysProcAttr.Chroot = path.Join(jailer.BaseJailPath, node.Namespace)\renvvars := []string{\rnodeDirEnvKey + nodeDir,\r\u0026quot;PATH=/usr/bin:/var/lib/rancher/management-state/bin\u0026quot;,\r}\rcommand.Env = jailer.WhitelistEnvvars(envvars)\rreturn command, nil\r}\r屏蔽jailer的处理\npkg/jailer/jailer.go 注释掉这个方法\n// GetUserCred looks up the user and provides it in syscall.Credential\r//func GetUserCred() (*syscall.Credential, error) {\r//\r//}\r修改一个依赖库里的文件 （比较正规的方式是在go mod中使用replace语法，而不是直接修改第三方package）\nvendor/github.com/rancher/kontainer-engine/service/service.go\n#446行开始注释这段代码\r//if os.Getenv(\u0026quot;CATTLE_DEV_MODE\u0026quot;) == \u0026quot;\u0026quot; {\r// cred, err := getUserCred()\r// if err != nil {\r// return \u0026quot;\u0026quot;, errors.WithMessage(err, \u0026quot;get user cred error\u0026quot;)\r// }\r//\r// cmd.SysProcAttr = \u0026amp;syscall.SysProcAttr{}\r// cmd.SysProcAttr.Credential = cred\r// cmd.SysProcAttr.Chroot = \u0026quot;/opt/jail/driver-jail\u0026quot;\r// cmd.Env = whitelistEnvvars([]string{\u0026quot;PATH=/usr/bin\u0026quot;})\r//}\r628行注释掉这个方法\n// getUserCred looks up the user and provides it in syscall.Credential\r//func getUserCred() (*syscall.Credential, error) {\r然后编译即可生成exe文件。\n2.运行 如果笔记本内存在8G以上，可以安装windows版本k8s或者minikube\n由于我本机配置太低，所以使用了linux服务器上的配置。\n#每次运行一定要执行这个命令，或者在环境变量里配置加下也可一劳永逸\rset CATTLE_DEV_MODE=true\rgo build -mod=vendor\r#生成可执行文件 rancher.exe 运行文件需要k8s 在服务器上安装k8s 然后将配置文件k3s.yaml下载到本地windows上，修改配置文件的ip为k8s所在服务器上的ip #修改完成后执行下面指令 其中：g:\\data\\k3s.yaml为配置文件所在本地路径\rrancher.exe --k8s-mode=external --kubeconfig g:\\data\\k3s.yaml --no-cacerts=true\rk3s.yaml是Linux服务器上的K8S配置文件。不要使用服务器上已经被rancher使用过的k8s，而是用一个崭新的K8S环境。\n服务器上安装k8s可以参考这里：https://k3s.io/\n#这一步可能需要翻墙\rcurl -sfL https://get.k3s.io | sh -\r#Check for Ready node, takes maybe 30 seconds\rk3s kubectl get node\r新增一个用户试一下，可以新增成功\n3.条件编译 条件编译不需要在原有文件内容上做修改，编译出的文件可以保证在linux上是完整的。\n以修改pkg/controllers/user/helm/common/common.go 为例，将原文件重命名未common_linux.go，然后新建一个common_windows_amd64.go，里面是windows版本的源码。\n然后编译即可。\n看起来条件编译对源文件做了重命名操作，但是保证了linux上代码的完整，不会让windows上的修改导致linux上产生隐患。\ngolang条件编译的源里可以参考此处：https://www.jianshu.com/p/4bb03e67e7ae\n4.问题 1.未测试更多高级功能，还未知。\n","date":"2020-02-28","permalink":"http://localhost:1313/post/windows%E4%B8%8A%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%E8%BF%90%E8%A1%8Crancher/","tags":["k8s"],"title":"Windows上编译安装运行rancher"},{"content":"今天群里有位360的安全大佬，发了个链接http://93.175.29.89:8008/，说爬这个网址的时候，IO会一直卡在那，一直没有返回响应。 那个网址是他构造的一个特殊请求，输出一个视频流，但是服务器端不返回Content-Length，也不输出真实数据，就是输出不到1024字节的流后就一直停在那也不close，浏览器打开的效果就是看到了视频的前几帧，然后一直卡在哪转圈。\n这么说来，感觉不是个大问题，设置下ReadTimeout不就好了么，大佬说他也设置了，但是无效，他使用的python代码实现，刚开始我觉得是他代码的问题，或者那个API库实现的问题，就用Java也实现了一把\npackage sms.bai.util;\rimport com.squareup.okhttp.Headers;\rimport com.squareup.okhttp.OkHttpClient;\rimport com.squareup.okhttp.Request;\rimport com.squareup.okhttp.Response;\rimport java.io.IOException;\rimport java.util.concurrent.*;\rpublic class Req {\rpublic static void reqUrl() throws IOException {\rOkHttpClient client = new OkHttpClient();\rclient.setConnectTimeout(5,TimeUnit.SECONDS);\rclient.setReadTimeout(5,TimeUnit.SECONDS);\rRequest request = new Request.Builder()\r.url(\u0026quot;http://93.175.29.89:8008/\u0026quot;)\r.build();\rResponse response = client.newCall(request).execute();\rif (!response.isSuccessful()) {\rthrow new IOException(\u0026quot;服务器端错误: \u0026quot; + response);\r}\rHeaders responseHeaders = response.headers();\rfor (int i = 0; i \u0026lt; responseHeaders.size(); i++) {\rSystem.out.println(responseHeaders.name(i) + \u0026quot;: \u0026quot; + responseHeaders.value(i));\r}\rSystem.out.println(response.body().string());\r}\rpublic static void main(String[] args) throws IOException {\rreqUrl();\r}\r}\r果然如其所言，无论设置ConnectTimeout还是ReadTimeout都是无效的，代码一直停留在输出那里，不输出任何body（浏览器里还能勉强看到画面），程序也不stop\nContent-Type: multipart/x-mixed-replace;boundary=---nessy2jpegboundary\rOkHttp-Sent-Millis: 1582028133591\rOkHttp-Received-Millis: 1582028133875\r这里用的是OkHttp库 ,换其它库或者用Java自带的HttpUrlConnection理论上效果也是一样的。\n用ffmpeg来看看这个请求\n[kk@kk ~]$ ffmpeg -i http://93.175.29.89:8008/ -f mp4 out.mp4\rffmpeg version n4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\rbuilt with gcc 9.2.0 (GCC)\rlibavutil 56. 31.100 / 56. 31.100\rlibavcodec 58. 54.100 / 58. 54.100\rlibavformat 58. 29.100 / 58. 29.100\rlibavdevice 58. 8.100 / 58. 8.100\rlibavfilter 7. 57.100 / 7. 57.100\rlibswscale 5. 5.100 / 5. 5.100\rlibswresample 3. 5.100 / 3. 5.100\rlibpostproc 55. 5.100 / 55. 5.100\rInput #0, mpjpeg, from 'http://93.175.29.89:8008/':\rDuration: N/A, bitrate: N/A\rStream #0:0: Video: mjpeg (Baseline), yuvj420p(pc, bt470bg/unknown/unknown), 640x480 [SAR 1:1 DAR 4:3], 25 tbr, 25 tbn, 25 tbc\rStream mapping:\rStream #0:0 -\u0026gt; #0:0 (mjpeg (native) -\u0026gt; h264 (libx264))\rPress [q] to stop, [?] for help\r[libx264 @ 0x562ad6812cc0] using SAR=1/1\r[libx264 @ 0x562ad6812cc0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\r[libx264 @ 0x562ad6812cc0] profile High, level 3.0, 4:2:0, 8-bit\r[libx264 @ 0x562ad6812cc0] 264 - core 159 r2991 1771b55 - H.264/MPEG-4 AVC codec - Copyleft 2003-2019 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\rOutput #0, mp4, to 'out.mp4':\rMetadata:\rencoder : Lavf58.29.100\rStream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuvj420p(pc), 640x480 [SAR 1:1 DAR 4:3], q=-1--1, 25 fps, 12800 tbn, 25 tbc\rMetadata:\rencoder : Lavc58.54.100 libx264\rSide data:\rcpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\rframe= 83 fps=1.1 q=-1.0 Lsize= 336kB time=00:00:03.20 bitrate= 859.8kbits/s speed=0.0436x ffmpeg 能识别出是一个视频流，但是会一直卡在frame=xx这里，一直读取帧而不停止。强行终止后能输出一个时长有几秒的视频\n看来依靠HttpUrlConnection中的SocketTimeoutException是无解了，只能在外面套一层了。main方法改成如下\npublic static void main(String[] args) throws Exception {\rfinal ExecutorService exec = Executors.newFixedThreadPool(1);\rCallable\u0026lt;String\u0026gt; call = new Callable\u0026lt;String\u0026gt;() {\rpublic String call() throws Exception {\r//开始执行耗时操作\rreqUrl();\rreturn \u0026quot;线程执行完成.\u0026quot;;\r}\r};\rFuture\u0026lt;String\u0026gt; future = null;\rtry {\rfuture = exec.submit(call);\rString obj = future.get(1000 * 10, TimeUnit.MILLISECONDS); //任务处理超时时间设为 10 秒\rSystem.out.println(\u0026quot;任务成功返回:\u0026quot; + obj);\r} catch (TimeoutException ex) {\rSystem.out.println(\u0026quot;处理超时啦....\u0026quot;);\rex.printStackTrace();\rfuture.cancel(true);\r} catch (Exception e) {\rSystem.out.println(\u0026quot;处理失败.\u0026quot;);\re.printStackTrace();\r}finally {\r// 关闭线程池\rSystem.out.println(\u0026quot;关闭线程池\u0026quot;);\rexec.shutdown();\r}\r}\r这下能得到期望的结果了\nContent-Type: multipart/x-mixed-replace;boundary=---nessy2jpegboundary\rOkHttp-Sent-Millis: 1582028854911\rOkHttp-Received-Millis: 1582028855178\r处理超时啦....\rjava.util.concurrent.TimeoutException\rat java.util.concurrent.FutureTask.get(FutureTask.java:205)\rat sms.bai.util.Req.main(Req.java:47)\r关闭线程池\rProcess finished with exit code 0\r那这个HttpUrlConnection里的超时到底是啥意思呢？为什么无效呢？看一下文档。 ConnectTimeout , java 是这样解释的：\nSets a specified timeout value, in milliseconds, to be used when opening a communications link to the resource referenced by this URLConnection. If the timeout expires before the connection can be established, a java.net.SocketTimeoutException is raised. A timeout of zero is interpreted as an infinite timeout.\nSome non-standard implmentation of this method may ignore the specified timeout. To see the connect timeout set, please call getConnectTimeout().\n意思是用来建立连接的时间。如果到了指定的时间，还没建立连接，则报异常。 这个比较好理解。\nReadTimeout , Java 是这样解释的：\nSets the read timeout to a specified timeout, in milliseconds. A non-zero value specifies the timeout when reading from Input stream when a connection is established to a resource. If the timeout expires before there is data available for read, a java.net.SocketTimeoutException is raised. A timeout of zero is interpreted as an infinite timeout.\nSome non-standard implementation of this method ignores the specified timeout. To see the read timeout set, please call getReadTimeout().\n意思是已经建立连接，并开始读取服务端资源。如果到了指定的时间，没有可能的数据被客户端读取，则报异常。\n也就是说setReadTimeout not mean read complete, it mean when wait for 10s, when there\u0026rsquo;re no more data read in, will throw a timeoutexception。\n所以针对这种特殊的服务器构造的异常流，是没法用SocketTimeoutException来解决超时的，只能在外面再设置一层，通过线程的超时来控制。\n另外提一句，python是通过设置gevent超时来解决的，原理是一样的。\ntips：360大佬认为，这种特殊URL，不失为一种给爬虫挖坑的做法。\n","date":"2020-02-18","permalink":"http://localhost:1313/post/httpurlconnection%E9%87%8Csetreadtimeout%E8%B6%85%E6%97%B6%E6%97%A0%E6%95%88/","tags":["Java"],"title":"HttpURLConnection里setReadTimeout超时无效"},{"content":"k8s每个版本看起来兼容性不是太好，很多网上的例子跑起来往往都有问题。\n目前用的版本\nroot@de001:/develop# kubectl version\rClient Version: version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;17\u0026quot;, GitVersion:\u0026quot;v1.17.2+k3s1\u0026quot;, GitCommit:\u0026quot;cdab19b09a84389ffbf57bebd33871c60b1d6b28\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2020-01-27T18:09:26Z\u0026quot;, GoVersion:\u0026quot;go1.13.6\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;}\rServer Version: version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;17\u0026quot;, GitVersion:\u0026quot;v1.17.2+k3s1\u0026quot;, GitCommit:\u0026quot;cdab19b09a84389ffbf57bebd33871c60b1d6b28\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2020-01-27T18:09:26Z\u0026quot;, GoVersion:\u0026quot;go1.13.6\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;}\r1.编写Spec文档 apiVersion: apiextensions.k8s.io/v1beta1\rkind: CustomResourceDefinition\rmetadata:\r# name must match the spec fields below, and be in the form: \u0026lt;plural\u0026gt;.\u0026lt;group\u0026gt;\rname: crontabs.chenwen.com\rspec:\r# group name to use for REST API: /apis/\u0026lt;group\u0026gt;/\u0026lt;version\u0026gt;\rgroup: chenwen.com\r# list of versions supported by this CustomResourceDefinition\rversions:\r- name: v2\r# Each version can be enabled/disabled by Served flag.\rserved: true\r# One and only one version must be marked as the storage version.\rstorage: true\r# A schema is required\r# The conversion section is introduced in Kubernetes 1.13+ with a default value of\r# None conversion (strategy sub-field set to None).\rconversion:\r# None conversion assumes the same schema for all versions and only sets the apiVersion\r# field of custom resources to the proper value\rstrategy: None\r# either Namespaced or Cluster\rscope: Namespaced\rnames:\r# plural name to be used in the URL: /apis/\u0026lt;group\u0026gt;/\u0026lt;version\u0026gt;/\u0026lt;plural\u0026gt;\rplural: crontabs\r# singular name to be used as an alias on the CLI and for display\rsingular: crontab\r# kind is normally the CamelCased singular type. Your resource manifests use this.\rkind: Crontab\rlistKind: CrontabList\r# shortNames allow shorter string to match your resource on the CLI\rshortNames:\r- ct 2.导入K8S ln -s /etc/rancher/k3s/k3s.yaml ~/.kube/config\rkubectl apply -f crontab_crd.yml\rkubectl get crd\r可以看到自己创建的crd了。\n查看这个CRD\nroot@de001:/develop# kubectl describe crontabs.chenwen.com\rName: my-test-crontab\rNamespace: default\rLabels: \u0026lt;none\u0026gt;\rAnnotations: kubectl.kubernetes.io/last-applied-configuration:\r{\u0026quot;apiVersion\u0026quot;:\u0026quot;chenwen.com/v2\u0026quot;,\u0026quot;kind\u0026quot;:\u0026quot;Crontab\u0026quot;,\u0026quot;metadata\u0026quot;:{\u0026quot;annotations\u0026quot;:{},\u0026quot;name\u0026quot;:\u0026quot;my-test-crontab\u0026quot;,\u0026quot;namespace\u0026quot;:\u0026quot;default\u0026quot;},\u0026quot;spec\u0026quot;:{\u0026quot;cron...\rAPI Version: chenwen.com/v2\rKind: Crontab\rMetadata:\rCreation Timestamp: 2020-02-05T06:09:10Z\rGeneration: 1\rResource Version: 19965\rSelf Link: /apis/chenwen.com/v2/namespaces/default/crontabs/my-test-crontab\rUID: 27beca8a-0ddb-4861-8643-90bb2f850b0d\rSpec:\rCron Spec: * * * * */10\rImage: my-test-image\rReplicas: 2\rEvents: \u0026lt;none\u0026gt;\rroot@de001:/develop# rancher启动的时候也会给K8S注册一些CRD\n不太清楚这样创建的CRD里用rancher的API是否能看到（rancher环境未搭建好测试 ）\n添加一个自定义对象\napiVersion: chenwen.com/v2\rkind: Crontab\rmetadata:\rname: my-test-crontab\rspec:\rcronSpec: \u0026quot;* * * * */10\u0026quot;\rimage: my-test-image\rreplicas: 2\r导入\nkubectl apply -f test_crd.yml\rkubectl get ct\r#删除自定义对象\rkubectl delete ct my-test-crontab\r#删除CRD\rkubectl delete crd crontabs.chenwen.com\r运行结果：\nroot@de001:/develop# kubectl get crd|grep cron\rcrontabs.chenwen.com 2020-02-05T06:08:53Z\rroot@de001:/develop# kubectl get ct\rNAME AGE\rmy-test-crontab 75s\rroot@de001:/develop# 3.代码生成 先在gopath下建立如下目录\ngo\r└── src\r└── github.com\r└── examplechen\r└── go.mod\r└── hack\r└── pkg\r└── apis\r└── chenwen.com\r└── v1\r├── doc.go\r└── types.go\r└── pkg\r└── bin\r然后安装https://github.com/kubernetes/code-generator 项目的代码到gopath下。\ndoc.go文件内容\n// FileName: doc.go\r// Distributed under terms of the GPL license.\r// +k8s:deepcopy-gen=package\r// Package v1 is the v1 version of the API.\r// +groupName=chenwen.com\rpackage v1 上述代码中的两行注释，都是代码生成工具会用到的，一个是声明为整个v1包下的类型定义生成DeepCopy方法，另一个声明了这个包对应的API的组名，和CRD中的组名一致\n“// +k8s:deepcopy-gen=package”：为这个package中的所有type生成deepcopy代码。\n“// +groupName=crd.lijiaocn.com”：设置这个package对应的api group。\ntypes.go文件内容\npackage v1\rimport (\rmetav1 \u0026quot;k8s.io/apimachinery/pkg/apis/meta/v1\u0026quot;\r)\r// +genclient\r// +genclient:noStatus\r// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object\r// CronTab is a top-level type. A client is created for it.\r// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object\rtype Crontab struct {\rmetav1.TypeMeta `json:\u0026quot;,inline\u0026quot;`\r// +optional\rmetav1.ObjectMeta `json:\u0026quot;metadata,omitempty\u0026quot;`\r// Username unique username of the consumer.\rUsername string `json:\u0026quot;username,omitempty\u0026quot;`\r// CustomID existing unique ID for the consumer - useful for mapping\r// Kong with users in your existing database\rCustomID string `json:\u0026quot;custom_id,omitempty\u0026quot;`\r// Spec is the custom resource spec\rSpec CrontabSpec `json:\u0026quot;spec\u0026quot;`\r}\r// the spec for a MyResource resource\rtype CrontabSpec struct {\rMin int `json:\u0026quot;min\u0026quot;`\r}\r// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object\rtype CrontabList struct {\rmetav1.TypeMeta `json:\u0026quot;,inline\u0026quot;`\rmetav1.ListMeta `json:\u0026quot;metadata\u0026quot;`\rItems []Crontab `json:\u0026quot;items\u0026quot;`\r}\r// Configuration contains a plugin configuration\r// +k8s:deepcopy-gen=false\rtype Configuration map[string]interface{} “// +genclient”：为该type生成client代码。\n“// +genclient:noStatus”：为该type生成的client代码，不包含UpdateStatus方法。\n“// +genclient:nonNamespaced”：如果是集群资源，设置为不带namespace。\n还支持在注释中使用以下tag：\n// +genclient:noVerbs\r// +genclient:onlyVerbs=create,delete\r// +genclient:skipVerbs=get,list,create,update,patch,delete,deleteCollection,watch\r// +genclient:method=Create,verb=create,result=k8s.io/apimachinery/pkg/apis/meta/v1.Status\r==CrontabSpec结构体的字段不需要和yaml文件里的Spec 部分一一对应==。\n同级目录编写register.go (这个文件非必须，此文件的作用是通过addKnownTypes方法使得client可以知道Crontab类型的API对象)\npackage v1\rimport (\rmetav1 \u0026quot;k8s.io/apimachinery/pkg/apis/meta/v1\u0026quot;\r\u0026quot;k8s.io/apimachinery/pkg/runtime\u0026quot;\r\u0026quot;k8s.io/apimachinery/pkg/runtime/schema\u0026quot;\rexamplecom \u0026quot;github.com/examplechen/pkg/apis/chenwen.com\u0026quot;\r)\r// SchemeGroupVersion is group version used to register these objects\rvar SchemeGroupVersion = schema.GroupVersion{Group: examplecom.GroupName, Version: \u0026quot;v1\u0026quot;}\r// Resource takes an unqualified resource and returns a Group qualified GroupResource\rfunc Resource(resource string) schema.GroupResource {\rreturn SchemeGroupVersion.WithResource(resource).GroupResource()\r}\rvar (\r// localSchemeBuilder and AddToScheme will stay in k8s.io/kubernetes.\rSchemeBuilder runtime.SchemeBuilder\rlocalSchemeBuilder = \u0026amp;SchemeBuilder\rAddToScheme = localSchemeBuilder.AddToScheme\r)\rfunc init() {\r// We only register manually written functions here. The registration of the\r// generated functions takes place in the generated files. The separation\r// makes the code compile even when the generated files are missing.\rlocalSchemeBuilder.Register(addKnownTypes)\r}\r// Adds the list of known types to api.Scheme.\rfunc addKnownTypes(scheme *runtime.Scheme) error {\rscheme.AddKnownTypes(SchemeGroupVersion,\r\u0026amp;Crontab{},\r\u0026amp;CrontabList{},\r)\rmetav1.AddToGroupVersion(scheme, SchemeGroupVersion)\rreturn nil\r}\rgo.mod文件内容\nmodule github.com/examplechen\rgo 1.13\r生成代码只需要以上三个文件和其对应的目录结构\n生成代码\n[koudai@koudai-pc v1]$ /develop/go/src/k8s.io/code-generator/generate-groups.sh all github.com/examplechen/pkg/client/crontab github.com/examplechen/pkg/apis chenwen.com:v1\rGenerating deepcopy funcs\rGenerating clientset for chenwen.com:v1 at github.com/examplechen/pkg/client/crontab/clientset\rGenerating listers for chenwen.com:v1 at github.com/examplechen/pkg/client/crontab/listers\rGenerating informers for chenwen.com:v1 at github.com/examplechen/pkg/client/crontab/informers\r尤其需要注意的是generate-groups.sh必须是==绝对路径==，不能是进入到code-generator目录下执行相对路径，不然会报找不到包的报错。\n另外，需要进入到examplechen目录执行，不然会报莫名其妙如下的错误\nGenerating deepcopy funcs\rF0210 17:31:46.418659 16605 deepcopy.go:885] Hit an unsupported type invalid type for invalid type, from github.com/examplechen/pkg/apis/chenwen.com/v1.Crontab\r生成后的目录树如下：\n[koudai@koudai-pc examplechen]$ tree\r.\r├── go.mod\r├── go.sum\r├── hack\r│ └── boilerplate.go.txt\r└── pkg\r├── apis\r│ └── chenwen.com\r│ ├── register.go\r│ └── v1\r│ ├── doc.go\r│ ├── types.go\r│ └── zz_generated.deepcopy.go\r└── client\r└── crontab\r├── clientset\r│ └── versioned\r│ ├── clientset.go\r│ ├── doc.go\r│ ├── fake\r│ │ ├── clientset_generated.go\r│ │ ├── doc.go\r│ │ └── register.go\r│ ├── scheme\r│ │ ├── doc.go\r│ │ └── register.go\r│ └── typed\r│ └── chenwen.com\r│ └── v1\r│ ├── chenwen.com_client.go\r│ ├── crontab.go\r│ ├── doc.go\r│ ├── fake\r│ │ ├── doc.go\r│ │ ├── fake_chenwen.com_client.go\r│ │ └── fake_crontab.go\r│ └── generated_expansion.go\r├── informers\r│ └── externalversions\r│ ├── chenwen.com\r│ │ ├── interface.go\r│ │ └── v1\r│ │ ├── crontab.go\r│ │ └── interface.go\r│ ├── factory.go\r│ ├── generic.go\r│ └── internalinterfaces\r│ └── factory_interfaces.go\r└── listers\r└── chenwen.com\r└── v1\r├── crontab.go\r└── expansion_generated.go\r23 directories, 29 files\r4.使用自动生成的代码 examplechen 下新建main.go用来测试\npackage main\rimport (\r\u0026quot;flag\u0026quot;\r\u0026quot;fmt\u0026quot;\r\u0026quot;github.com/golang/glog\u0026quot;\rmetav1 \u0026quot;k8s.io/apimachinery/pkg/apis/meta/v1\u0026quot;\r\u0026quot;k8s.io/client-go/tools/clientcmd\u0026quot;\r\u0026quot;k8s.io/client-go/rest\u0026quot;\rexamplecomclientset \u0026quot;github.com/examplechen/pkg/client/crontab/clientset/versioned\u0026quot;\r)\rvar (\rkuberconfig = flag.String(\u0026quot;kubeconfig\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;Path to a kubeconfig. Only required if out-of-cluster.\u0026quot;)\rmaster = flag.String(\u0026quot;master\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;The address of the Kubernetes API server. Overrides any value in kubeconfig. Only required if out-of-cluster.\u0026quot;)\r)\rfunc main() {\rflag.Parse()\rcfg, err := buildConfig(\u0026quot;https://127.0.0.1:6443\u0026quot;, \u0026quot;/root/.kube/config\u0026quot;)\rif err != nil {\rfmt.Printf(\u0026quot;%v\\n\u0026quot;, err)\rreturn\r}\rexampleClient, err := examplecomclientset.NewForConfig(cfg)\rif err != nil {\rglog.Fatalf(\u0026quot;Error building example clientset: %v\u0026quot;, err)\r}\rlist, err := exampleClient.ChenwenV1().Crontabs(\u0026quot;default\u0026quot;).List(metav1.ListOptions{})\rif err != nil {\rglog.Fatalf(\u0026quot;Error listing all databases: %v\u0026quot;, err)\r}\rfor _, db := range list.Items {\rfmt.Printf(\u0026quot;database %s with user %q\\n\u0026quot;, db.Name, db.Spec.Min)\r}\r}\rfunc buildConfig(master, kubeconfig string) (*rest.Config, error) {\rif master != \u0026quot;\u0026quot; || kubeconfig != \u0026quot;\u0026quot; {\rreturn clientcmd.BuildConfigFromFlags(master, kubeconfig)\r}\rreturn rest.InClusterConfig()\r}\r编译通过，但运行报错。\nF0210 14:19:32.477583 1845 main.go:39] Error listing all databases: the server could not find the requested resource (get crontabs.chenwen.com)\r经检查，是版本号不一致造成，将yml文件里的版本号v2换成v1，另一个yml文件同理\nspec:\r# group name to use for REST API: /apis/\u0026lt;group\u0026gt;/\u0026lt;version\u0026gt;\rgroup: chenwen.com\r# list of versions supported by this CustomResourceDefinition\rversions:\r- name: v1 # 把v2换成v1，需要和API对应\r重新编译，运行结果如下，符合预期\n#go build\r#./examplechenold -kubeconfig=$HOME/.kube/config database my-test-crontab with user '\\x00'\rdatabase my-test-crontab2 with user '\\x00'\r5.进一步了解API 再写个稍微复杂点的例子\n在 项目根目录下新建controller.go文件\npackage main\rimport (\r\u0026quot;fmt\u0026quot;\r\u0026quot;time\u0026quot;\r\u0026quot;github.com/golang/glog\u0026quot;\rcorev1 \u0026quot;k8s.io/api/core/v1\u0026quot;\r\u0026quot;k8s.io/apimachinery/pkg/api/errors\u0026quot;\r\u0026quot;k8s.io/apimachinery/pkg/util/runtime\u0026quot;\rutilruntime \u0026quot;k8s.io/apimachinery/pkg/util/runtime\u0026quot;\r\u0026quot;k8s.io/apimachinery/pkg/util/wait\u0026quot;\r\u0026quot;k8s.io/client-go/kubernetes\u0026quot;\r\u0026quot;k8s.io/client-go/kubernetes/scheme\u0026quot;\rtypedcorev1 \u0026quot;k8s.io/client-go/kubernetes/typed/core/v1\u0026quot;\r\u0026quot;k8s.io/client-go/tools/cache\u0026quot;\r\u0026quot;k8s.io/client-go/tools/record\u0026quot;\r\u0026quot;k8s.io/client-go/util/workqueue\u0026quot;\rbolingcavalryv1 \u0026quot;github.com/examplechen/pkg/apis/chenwen.com/v1\u0026quot;\rclientset \u0026quot;github.com/examplechen/pkg/client/crontab/clientset/versioned\u0026quot;\rcronscheme \u0026quot;github.com/examplechen/pkg/client/crontab/clientset/versioned/scheme\u0026quot;\rinformers \u0026quot;github.com/examplechen/pkg/client/crontab/informers/externalversions/chenwen.com/v1\u0026quot;\rlisters \u0026quot;github.com/examplechen/pkg/client/crontab/listers/chenwen.com/v1\u0026quot;\r)\rconst controllerAgentName = \u0026quot;student-controller\u0026quot;\rconst (\rSuccessSynced = \u0026quot;Synced\u0026quot;\rMessageResourceSynced = \u0026quot;Student synced successfully\u0026quot;\r)\r// Controller is the controller implementation for Student resources\rtype Controller struct {\r// kubeclientset is a standard kubernetes clientset\rkubeclientset kubernetes.Interface\r// cronclientset is a clientset for our own API group\rcronclientset clientset.Interface\rcronsLister listers.CrontabLister\rcronsSynced cache.InformerSynced\rworkqueue workqueue.RateLimitingInterface\rrecorder record.EventRecorder\r}\r// NewController returns a new student controller\rfunc NewController(\rkubeclientset kubernetes.Interface,\rcronclientset clientset.Interface,\rcronInformer informers.CrontabInformer) *Controller {\rutilruntime.Must(cronscheme.AddToScheme(scheme.Scheme))\rglog.V(4).Info(\u0026quot;Creating event broadcaster\u0026quot;)\reventBroadcaster := record.NewBroadcaster()\reventBroadcaster.StartLogging(glog.Infof)\reventBroadcaster.StartRecordingToSink(\u0026amp;typedcorev1.EventSinkImpl{Interface: kubeclientset.CoreV1().Events(\u0026quot;\u0026quot;)})\rrecorder := eventBroadcaster.NewRecorder(scheme.Scheme, corev1.EventSource{Component: controllerAgentName})\rcontroller := \u0026amp;Controller{\rkubeclientset: kubeclientset,\rcronclientset: cronclientset,\rcronsLister: cronInformer.Lister(),\rcronsSynced: cronInformer.Informer().HasSynced,\rworkqueue: workqueue.NewNamedRateLimitingQueue(workqueue.DefaultControllerRateLimiter(), \u0026quot;Students\u0026quot;),\rrecorder: recorder,\r}\rglog.Info(\u0026quot;Setting up event handlers\u0026quot;)\r// Set up an event handler for when Student resources change\rcronInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{\rAddFunc: controller.enqueueStudent,\rUpdateFunc: func(old, new interface{}) {\roldStudent := old.(*bolingcavalryv1.Crontab)\rnewStudent := new.(*bolingcavalryv1.Crontab)\rif oldStudent.ResourceVersion == newStudent.ResourceVersion {\r//版本一致，就表示没有实际更新的操作，立即返回\rreturn\r}\rcontroller.enqueueStudent(new)\r},\rDeleteFunc: controller.enqueueStudentForDelete,\r})\rreturn controller\r}\r//在此处开始controller的业务\rfunc (c *Controller) Run(threadiness int, stopCh \u0026lt;-chan struct{}) error {\rdefer runtime.HandleCrash()\rdefer c.workqueue.ShutDown()\rglog.Info(\u0026quot;开始controller业务，开始一次缓存数据同步\u0026quot;)\rif ok := cache.WaitForCacheSync(stopCh, c.cronsSynced); !ok {\rreturn fmt.Errorf(\u0026quot;failed to wait for caches to sync\u0026quot;)\r}\rglog.Info(\u0026quot;worker启动\u0026quot;)\rfor i := 0; i \u0026lt; threadiness; i++ {\rgo wait.Until(c.runWorker, time.Second, stopCh)\r}\rglog.Info(\u0026quot;worker已经启动\u0026quot;)\r\u0026lt;-stopCh\rglog.Info(\u0026quot;worker已经结束\u0026quot;)\rreturn nil\r}\rfunc (c *Controller) runWorker() {\rfor c.processNextWorkItem() {\r}\r}\r// 取数据处理\rfunc (c *Controller) processNextWorkItem() bool {\robj, shutdown := c.workqueue.Get()\rif shutdown {\rreturn false\r}\r// We wrap this block in a func so we can defer c.workqueue.Done.\rerr := func(obj interface{}) error {\rdefer c.workqueue.Done(obj)\rvar key string\rvar ok bool\rif key, ok = obj.(string); !ok {\rc.workqueue.Forget(obj)\rruntime.HandleError(fmt.Errorf(\u0026quot;expected string in workqueue but got %#v\u0026quot;, obj))\rreturn nil\r}\r// 在syncHandler中处理业务\rif err := c.syncHandler(key); err != nil {\rreturn fmt.Errorf(\u0026quot;error syncing '%s': %s\u0026quot;, key, err.Error())\r}\rc.workqueue.Forget(obj)\rglog.Infof(\u0026quot;Successfully synced '%s'\u0026quot;, key)\rreturn nil\r}(obj)\rif err != nil {\rruntime.HandleError(err)\rreturn true\r}\rreturn true\r}\r// 处理\rfunc (c *Controller) syncHandler(key string) error {\r// Convert the namespace/name string into a distinct namespace and name\rnamespace, name, err := cache.SplitMetaNamespaceKey(key)\rif err != nil {\rruntime.HandleError(fmt.Errorf(\u0026quot;invalid resource key: %s\u0026quot;, key))\rreturn nil\r}\r// 从缓存中取对象\rstudent, err := c.cronsLister.Crontabs(namespace).Get(name)\rif err != nil {\r// 如果Cron对象被删除了，就会走到这里，所以应该在这里加入执行\rif errors.IsNotFound(err) {\rglog.Infof(\u0026quot;Student对象被删除，请在这里执行实际的删除业务: %s/%s ...\u0026quot;, namespace, name)\rreturn nil\r}\rruntime.HandleError(fmt.Errorf(\u0026quot;failed to list student by: %s/%s\u0026quot;, namespace, name))\rreturn err\r}\rglog.Infof(\u0026quot;这里是cron对象的期望状态: %#v ...\u0026quot;, student)\rglog.Infof(\u0026quot;实际状态是从业务层面得到的，此处应该去的实际状态，与期望状态做对比，并根据差异做出响应(新增或者删除)\u0026quot;)\rc.recorder.Event(student, corev1.EventTypeNormal, SuccessSynced, MessageResourceSynced)\rreturn nil\r}\r// 数据先放入缓存，再入队列\rfunc (c *Controller) enqueueStudent(obj interface{}) {\rvar key string\rvar err error\r// 将对象放入缓存\rif key, err = cache.MetaNamespaceKeyFunc(obj); err != nil {\rruntime.HandleError(err)\rreturn\r}\r// 将key放入队列\rc.workqueue.AddRateLimited(key)\r}\r// 删除操作\rfunc (c *Controller) enqueueStudentForDelete(obj interface{}) {\rvar key string\rvar err error\r// 从缓存中删除指定对象\rkey, err = cache.DeletionHandlingMetaNamespaceKeyFunc(obj)\rif err != nil {\rruntime.HandleError(err)\rreturn\r}\r//再将key放入队列\rc.workqueue.AddRateLimited(key)\r}\r然后是 main.go\npackage main\rimport (\r\u0026quot;flag\u0026quot;\r\u0026quot;fmt\u0026quot;\r\u0026quot;time\u0026quot;\r\u0026quot;github.com/golang/glog\u0026quot;\r\u0026quot;k8s.io/client-go/tools/clientcmd\u0026quot;\r\u0026quot;k8s.io/client-go/kubernetes\u0026quot;\rinformers \u0026quot;github.com/examplechen/pkg/client/crontab/informers/externalversions\u0026quot;\r\u0026quot;github.com/examplechen/pkg/signals\u0026quot;\rexamplecomclientset \u0026quot;github.com/examplechen/pkg/client/crontab/clientset/versioned\u0026quot;\r)\rvar (\rkubeconfig string\rmaster string\r)\rfunc main() {\rflag.Parse()\r// 处理信号量\rstopCh := signals.SetupSignalHandler()\rcfg, err := clientcmd.BuildConfigFromFlags(master, kubeconfig)\rif err != nil {\rfmt.Printf(\u0026quot;%v\\n\u0026quot;, err)\rreturn\r}\rkubeClient, err := kubernetes.NewForConfig(cfg)\rif err != nil {\rglog.Fatalf(\u0026quot;Error building kubernetes clientset: %s\u0026quot;, err.Error())\r}\rexampleClient, err := examplecomclientset.NewForConfig(cfg)\rif err != nil {\rglog.Fatalf(\u0026quot;Error building example clientset: %v\u0026quot;, err)\r}\rstudentInformerFactory := informers.NewSharedInformerFactory(exampleClient, time.Second*30)\r//得到controller\rcontroller := NewController(kubeClient, exampleClient,\rstudentInformerFactory.Chenwen().V1().Crontabs())\r//启动informer\rgo studentInformerFactory.Start(stopCh)\r//controller开始处理消息\rif err = controller.Run(2, stopCh); err != nil {\rglog.Fatalf(\u0026quot;Error running controller: %s\u0026quot;, err.Error())\r}\r}\rfunc init() {\rflag.StringVar(\u0026amp;kubeconfig, \u0026quot;kubeconfig\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;Path to a kubeconfig. Only required if out-of-cluster.\u0026quot;)\rflag.StringVar(\u0026amp;master, \u0026quot;master\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;The address of the Kubernetes API server. Overrides any value in kubeconfig. Only required if out-of-cluster.\u0026quot;)\r}\r编译运行\nroot@de001:/develop# ./examplechen -kubeconfig=$HOME/.kube/config I0210 17:40:22.161175 18552 controller.go:72] Setting up event handlers\rI0210 17:40:22.161769 18552 controller.go:96] 开始controller业务，开始一次缓存数据同步\rI0210 17:40:22.262540 18552 controller.go:101] worker启动\rI0210 17:40:22.262616 18552 controller.go:106] worker已经启动\rI0210 17:40:22.262693 18552 controller.go:181] 这里是student对象的期望状态: \u0026amp;v1.Crontab{TypeMeta:v1.TypeMeta{Kind:\u0026quot;Crontab\u0026quot;, APIVersion:\u0026quot;chenwen.com/v1\u0026quot;}, ObjectMeta:v1.ObjectMeta{Name:\u0026quot;my-test-crontab2\u0026quot;, GenerateName:\u0026quot;\u0026quot;, Namespace:\u0026quot;default\u0026quot;, SelfLink:\u0026quot;/apis/chenwen.com/v1/namespaces/default/crontabs/my-test-crontab2\u0026quot;, UID:\u0026quot;ab5e00e6-88e4-4b7e-b587-f5797baec3eb\u0026quot;, ResourceVersion:\u0026quot;29576\u0026quot;, Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63716923534, loc:(*time.Location)(0x1e56c60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string{\u0026quot;kubectl.kubernetes.io/last-applied-configuration\u0026quot;:\u0026quot;{\\\u0026quot;apiVersion\\\u0026quot;:\\\u0026quot;chenwen.com/v1\\\u0026quot;,\\\u0026quot;kind\\\u0026quot;:\\\u0026quot;Crontab\\\u0026quot;,\\\u0026quot;metadata\\\u0026quot;:{\\\u0026quot;annotations\\\u0026quot;:{},\\\u0026quot;name\\\u0026quot;:\\\u0026quot;my-test-crontab2\\\u0026quot;,\\\u0026quot;namespace\\\u0026quot;:\\\u0026quot;default\\\u0026quot;},\\\u0026quot;spec\\\u0026quot;:{\\\u0026quot;cronSpec\\\u0026quot;:\\\u0026quot;* * * * */10\\\u0026quot;,\\\u0026quot;image\\\u0026quot;:\\\u0026quot;my-test-image\\\u0026quot;,\\\u0026quot;replicas\\\u0026quot;:2}}\\n\u0026quot;}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:\u0026quot;\u0026quot;, ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Username:\u0026quot;\u0026quot;, CustomID:\u0026quot;\u0026quot;, Spec:v1.CrontabSpec{Min:0}} ...\rI0210 17:40:22.262988 18552 controller.go:182] 实际状态是从业务层面得到的，此处应该去的实际状态，与期望状态做对比，并根据差异做出响应(新增或者删除)\rI0210 17:40:22.263039 18552 controller.go:145] Successfully synced 'default/my-test-crontab2'\rI0210 17:40:22.263063 18552 controller.go:181] 这里是student对象的期望状态: \u0026amp;v1.Crontab{TypeMeta:v1.TypeMeta{Kind:\u0026quot;Crontab\u0026quot;, APIVersion:\u0026quot;chenwen.com/v1\u0026quot;}, ObjectMeta:v1.ObjectMeta{Name:\u0026quot;my-test-crontab\u0026quot;, GenerateName:\u0026quot;\u0026quot;, Namespace:\u0026quot;default\u0026quot;, SelfLink:\u0026quot;/apis/chenwen.com/v1/namespaces/default/crontabs/my-test-crontab\u0026quot;, UID:\u0026quot;72036436-451a-4ec5-9851-bc27342faa5f\u0026quot;, ResourceVersion:\u0026quot;29532\u0026quot;, Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63716923360, loc:(*time.Location)(0x1e56c60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string{\u0026quot;kubectl.kubernetes.io/last-applied-configuration\u0026quot;:\u0026quot;{\\\u0026quot;apiVersion\\\u0026quot;:\\\u0026quot;chenwen.com/v1\\\u0026quot;,\\\u0026quot;kind\\\u0026quot;:\\\u0026quot;Crontab\\\u0026quot;,\\\u0026quot;metadata\\\u0026quot;:{\\\u0026quot;annotations\\\u0026quot;:{},\\\u0026quot;name\\\u0026quot;:\\\u0026quot;my-test-crontab\\\u0026quot;,\\\u0026quot;namespace\\\u0026quot;:\\\u0026quot;default\\\u0026quot;},\\\u0026quot;spec\\\u0026quot;:{\\\u0026quot;cronSpec\\\u0026quot;:\\\u0026quot;* * * * */10\\\u0026quot;,\\\u0026quot;image\\\u0026quot;:\\\u0026quot;my-test-image\\\u0026quot;,\\\u0026quot;replicas\\\u0026quot;:2}}\\n\u0026quot;}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:\u0026quot;\u0026quot;, ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Username:\u0026quot;\u0026quot;, CustomID:\u0026quot;\u0026quot;, Spec:v1.CrontabSpec{Min:0}} ...\rI0210 17:40:22.263157 18552 controller.go:182] 实际状态是从业务层面得到的，此处应该去的实际状态，与期望状态做对比，并根据差异做出响应(新增或者删除)\rI0210 17:40:22.263185 18552 controller.go:145] Successfully synced 'default/my-test-crontab'\rI0210 17:40:22.265730 18552 event.go:278] Event(v1.ObjectReference{Kind:\u0026quot;Crontab\u0026quot;, Namespace:\u0026quot;default\u0026quot;, Name:\u0026quot;my-test-crontab\u0026quot;, UID:\u0026quot;72036436-451a-4ec5-9851-bc27342faa5f\u0026quot;, APIVersion:\u0026quot;chenwen.com/v1\u0026quot;, ResourceVersion:\u0026quot;29532\u0026quot;, FieldPath:\u0026quot;\u0026quot;}): type: 'Normal' reason: 'Synced' Student synced successfully\rI0210 17:40:22.265885 18552 event.go:278] Event(v1.ObjectReference{Kind:\u0026quot;Crontab\u0026quot;, Namespace:\u0026quot;default\u0026quot;, Name:\u0026quot;my-test-crontab2\u0026quot;, UID:\u0026quot;ab5e00e6-88e4-4b7e-b587-f5797baec3eb\u0026quot;, APIVersion:\u0026quot;chenwen.com/v1\u0026quot;, ResourceVersion:\u0026quot;29576\u0026quot;, FieldPath:\u0026quot;\u0026quot;}): type: 'Normal' reason: 'Synced' Student synced successfully\rI0210 17:41:00.324824 18552 controller.go:181] 这里是student对象的期望状态: \u0026amp;v1.Crontab{TypeMeta:v1.TypeMeta{Kind:\u0026quot;\u0026quot;, APIVersion:\u0026quot;\u0026quot;}, ObjectMeta:v1.ObjectMeta{Name:\u0026quot;my-test-crontab2\u0026quot;, GenerateName:\u0026quot;\u0026quot;, Namespace:\u0026quot;default\u0026quot;, SelfLink:\u0026quot;/apis/chenwen.com/v1/namespaces/default/crontabs/my-test-crontab2\u0026quot;, UID:\u0026quot;ab5e00e6-88e4-4b7e-b587-f5797baec3eb\u0026quot;, ResourceVersion:\u0026quot;29811\u0026quot;, Generation:2, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63716923534, loc:(*time.Location)(0x1e56c60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string{\u0026quot;kubectl.kubernetes.io/last-applied-configuration\u0026quot;:\u0026quot;{\\\u0026quot;apiVersion\\\u0026quot;:\\\u0026quot;chenwen.com/v1\\\u0026quot;,\\\u0026quot;kind\\\u0026quot;:\\\u0026quot;Crontab\\\u0026quot;,\\\u0026quot;metadata\\\u0026quot;:{\\\u0026quot;annotations\\\u0026quot;:{},\\\u0026quot;name\\\u0026quot;:\\\u0026quot;my-test-crontab2\\\u0026quot;,\\\u0026quot;namespace\\\u0026quot;:\\\u0026quot;default\\\u0026quot;},\\\u0026quot;spec\\\u0026quot;:{\\\u0026quot;cronSpec\\\u0026quot;:\\\u0026quot;* 5 * * */10\\\u0026quot;,\\\u0026quot;image\\\u0026quot;:\\\u0026quot;my-test-image\\\u0026quot;,\\\u0026quot;replicas\\\u0026quot;:2}}\\n\u0026quot;}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:\u0026quot;\u0026quot;, ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Username:\u0026quot;\u0026quot;, CustomID:\u0026quot;\u0026quot;, Spec:v1.CrontabSpec{Min:0}} ...\r6.验证controller 新开一个窗口连接到k8s环境，新建一个名为test2_crd.yml的文件，内容如下\napiVersion: chenwen.com/v1\rkind: Crontab\rmetadata:\rname: my-test-crontab2\rspec:\rcronSpec: \u0026quot;* 5 * * */10\u0026quot;\rimage: my-test-image\rreplicas: 2\r执行命令\nkubectl apply -f test2_crd.yml 返回controller所在的控制台窗口，发现新输出了如下内容，可见新增Crontab对象的事件已经被controller监听并处理：\nI0210 17:41:00.324974 18552 controller.go:182] 实际状态是从业务层面得到的，此处应该去的实际状态，与期望状态做对比，并根据差异做出响应(新增或者删除)\rI0210 17:41:00.325006 18552 controller.go:145] Successfully synced 'default/my-test-crontab2'\rI0210 17:41:00.332401 18552 event.go:278] Event(v1.ObjectReference{Kind:\u0026quot;Crontab\u0026quot;, Namespace:\u0026quot;default\u0026quot;, Name:\u0026quot;my-test-crontab2\u0026quot;, UID:\u0026quot;ab5e00e6-88e4-4b7e-b587-f5797baec3eb\u0026quot;, APIVersion:\u0026quot;chenwen.com/v1\u0026quot;, ResourceVersion:\u0026quot;29811\u0026quot;, FieldPath:\u0026quot;\u0026quot;}): type: 'Normal' reason: 'Synced' Student synced successfully\r接下来您也可以尝试修改和删除已有的Crontab对象，观察controller控制台的输出，确定是否已经监听到所有Crontab变化的事件.\n7.总结 三步走：\n创建CRD（Custom Resource Definition），令k8s明白我们自定义的API对象； 编写代码，将CRD的情况写入对应的代码中，然后通过自动代码生成工具，将controller之外的informer，client等内容较为固定的代码通过工具生成； 编写controller，在里面判断实际情况是否达到了API对象的声明情况，如果未达到，就要进行实际业务处理，而这也是controller的通用做法； 实际要自己动手写的文件不多，就3-4个，但是理解起来比较难。\n8.refer https://blog.csdn.net/weixin_41806245/article/details/94451734\nhttps://blog.csdn.net/aixiaoyang168/article/details/81875907\nhttps://github.com/kubernetes/sample-controller/blob/master/README.md\nhttps://blog.openshift.com/kubernetes-deep-dive-code-generation-customresources/\nhttps://www.jianshu.com/p/4910da4c8285\nhttps://blog.csdn.net/boling_cavalry/article/details/88924194\n","date":"2020-02-11","permalink":"http://localhost:1313/post/k8s%E7%AE%A1%E7%90%86crd%E5%92%8Ck8sapi%E7%BC%96%E7%A8%8B/","tags":["k8s"],"title":"K8s管理crd和K8SAPI编程"},{"content":"hadoop 3.1.2 单机模式安装配置 现在搞大数据记录一下，方便查阅。\n1.安装配置jdk和下载hadoop略。 hadoop 下载地址：http://mirror.bit.edu.cn/apache/hadoop/common/ 使用了较新且保守的3.1.2版本\n2.配置修改 环境变量修改\nexport HADOOP_HOME=/soft/hadoop\rexport PATH=$PATH:$HADOOP_HOME/bin\r配置etc/hadoop/hadoop-env.sh\nexport JAVA_HOME=/soft/java\rexport HADOOP_HOME=/soft/hadoop\r配置etc/hadoop/core-site.xml\n\u0026lt;configuration\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;hadoop.tmp.dir\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;file:///develop/data/hadoop\u0026lt;/value\u0026gt;\r\u0026lt;description\u0026gt;Abase for other temporary directories.\u0026lt;/description\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;fs.defaultFS\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;hdfs://192.168.0.104:8888\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;/configuration\u0026gt;\r配置etc/hadoop/hdfs-site.xml\n\u0026lt;configuration\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.replication\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;1\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.namenode.name.dir\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;file:///develop/data/hadoop/dfs/name\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.datanode.data.dir\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;file:///develop/data/hadoop/dfs/data\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.datanode.du.reserved\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;1073741824\u0026lt;/value\u0026gt;\r\u0026lt;description\u0026gt;Reserved space in bytes per volume..\u0026lt;/description\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;/configuration\u0026gt;\r3.配置免密码SSH登录 ssh-keygen -t rsa\rcat ~/ssh/id_rsa.pub\u0026gt;\u0026gt;~/ssh/authorized_keys\r#ssh localhost 测试是否成功 4.启动测试 #格式化\rhdfs namenode -format\r#启动hdfs\r./sbin/start-dfs.sh\r#停止hdfs\r./sbin/stop-dfs.sh\r#验证是否成功\rhttp://localhost:9870/\r至此，hadoop的单机模式基本安装结束。\n简单的验证hadoop命令：\nhadoop fs -mkdir /test\r在浏览器中应该可以看到新建的目录了。\n注意： 1.网上的教程很多是2.x老版本，3.1.0版本后，hdfs的web 50070端口 -\u0026gt; 9870端口了 。\n2.如果webHDFS出错，提示\u0026quot;Failed to retrieve data from /webhdfs/v1/?op=LISTSTATUS:Server Error“，也无法透过Web界面上传文件，一般是JDK版本过高引起的，目前hadoop还只支持JDK8版本。如果是JDK9以上版本，可以编辑hadoop-env.sh\nexport HADOOP_OPTS=\u0026quot;--add-modules java.activation\u0026quot;\r3.上传文件/创建目录报错 Permission Denied，修改hdfs-site.xml，设定dfs.permissions=false。按照本文的最新配置就不会遇到这个问题。\n","date":"2019-08-25","permalink":"http://localhost:1313/post/hadoop3.1.2%E5%8D%95%E6%9C%BA%E6%A8%A1%E5%BC%8F%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","tags":["Java","大数据"],"title":"hadoop 3.1.2 单机模式安装配置"},{"content":"互联网低潮，老是会看到别人发面试经验，看到很多人谈乐观锁，谈CAS，但是都没有说清楚。忍不住叨叨几句。\n那什么是乐观锁呢，比较书面的定义是 “它假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据。在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，正在提交的事务会进行回滚。”，在多线程中则指对于数据冲突保持一种乐观态度，操作数据时不会对操作的数据进行加锁（这使得多个任务可以并行的对数据进行操作），只有到数据提交的时候才通过一种机制来验证数据是否存在冲突。在Java中，是通过CAS来实现乐观锁的。\nCAS是英文单词Compare And Swap的缩写，翻译过来就是比较并替换。CAS机制当中使用了3个基本操作数：内存地址V，旧的预期值A，要修改的新值B。\n更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B。\nCAS比较难于理解的地方就在于V、A、B这三个变量到底代表什么含义，很容易混淆，也不容易讲清楚。单纯看书上的文章会觉得晦涩，我们可以来看个例子。\n举个例子：\n1.在内存地址V当中，存储着值为10的变量\n2.此时线程1想要把变量的值增加1。对线程1来说，旧的预期值A=10，要修改的新值B=11。\n3.在线程1要提交更新之前，另一个线程2抢先一步，把内存地址V中的变量值率先更新成了11。\n4.线程1开始提交更新，首先进行A和地址V的实际值比较（Compare），发现A不等于V的实际值，提交失败。\n5.线程1重新获取内存地址V的当前值，并重新计算想要修改的新值。此时对线程1来说，A=11，B=12。这个重新尝试的过程被称为自旋。\n6.这一次比较幸运，没有其他线程改变地址V的值。线程1进行Compare，发现A和地址V的实际值是相等的，线程1进行Swap，把地址V的值替换为B，也就是12。在这一步，Compare和Swap这个过程是原子的(由操作系统和硬件保证)，比较并更新的过程是不会被其他线程打断的。\n到这里，其实基本说请了CAS的过程，但是CAS的API，还是不够清晰，很多人能够进行到这里，但如果让他实际使用CAS的API时则又没辙了，这里我们通过一个例子来演示CAS的API实际用例。\n/**\r* 使用CAS来获取单例\r*/\rpublic class CasSingleton {\rprivate static final AtomicReference\u0026lt;CasSingleton\u0026gt; INSTANCE=new AtomicReference\u0026lt;\u0026gt;();\rprivate CasSingleton(){}\rpublic static CasSingleton getInstance(){\rfor(;;){\rCasSingleton singleton=INSTANCE.get();\rif(null!=singleton){\rreturn singleton;\r}\rsingleton=new CasSingleton();\rif(INSTANCE.compareAndSet(null,singleton)){\rreturn singleton;\r}\r}\r}\rpublic static void main(String[] args) {\rCasSingleton singleton=getInstance();\rCasSingleton singleton1=getInstance();\rSystem.out.println(singleton);\rSystem.out.println(singleton1);\r}\r}\r这里使用CAS来实现单例，我们对照着compareAndSet的API来看看\n/**\r* Atomically sets the value to {@code newValue}\r* if the current value {@code == expectedValue},\r* with memory effects as specified by {@link VarHandle#compareAndSet}.\r*\r* @param expectedValue the expected value\r* @param newValue the new value\r* @return {@code true} if successful. False return indicates that\r* the actual value was not equal to the expected value.\r*/\rpublic final boolean compareAndSet(V expectedValue, V newValue) {\rreturn VALUE.compareAndSet(this, expectedValue, newValue);\r}\r上面CAS实现单例的代码中，第一个参数null就是A，第二个参数singleton就是B，调用者INSTANCE就是V。在调用compareAndSet的同时，已经完成了更新的过程，并且返回了更新与否的结果。这样就比较好理解了（虽然CAS能实现单例，但在这个场景下并不是最佳方案，为什么，大家可以思考下）。\n现在再来看看AtomicInteger的源码，能理解++i这块的实现了吗？\npublic final int incrementAndGet() {\rfor (;;) {\rint current = get();\rint next = current + 1;\rif (compareAndSet(current, next))\rreturn next;\r}\r}\r至于什么ABA问题和CPU底层实现，则不是本文重点。\n","date":"2019-07-16","permalink":"http://localhost:1313/post/%E8%AE%B2%E6%B8%85%E6%A5%9Acas%E7%9A%84%E9%82%A3%E7%82%B9%E4%BA%8B/","tags":["Java"],"title":"讲清楚CAS的那点事"},{"content":"netty实现http服务器keep-alive无效的问题排查 今天在用netty实现一个http服务器的时候，发现keep-alive并没有生效，具体表现是在request和response的header里都能看到keep-alive的标志：\nrequest:\rAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\rAccept-Encoding: gzip, deflate, br\rAccept-Language: zh-CN,zh;q=0.9,en;q=0.8\rCache-Control: max-age=0\rConnection: keep-alive\rresponse:\rHTTP/1.1 200 OK\rcontent-type: text/html;charset=UTF-8\rcontent-length: 0\rconnection: keep-alive\r可以看出，无论是请求还是响应，都是keep-alive的，但是请求两次，服务器端日志如下：\n七月 06, 2019 9:51:27 下午 io.netty.handler.logging.LoggingHandler channelRead\r信息: [id: 0xade39344, L:/0:0:0:0:0:0:0:0:8080] READ: [id: 0x26d40041, L:/0:0:0:0:0:0:0:1:8080 - R:/0:0:0:0:0:0:0:1:33130]\r七月 06, 2019 9:51:27 下午 io.netty.handler.logging.LoggingHandler channelReadComplete\r信息: [id: 0xade39344, L:/0:0:0:0:0:0:0:0:8080] READ COMPLETE\rkeepAlive=true\rchannel id=26d40041\rhttp uri: /a.txt?name=chen\u0026amp;f=123;key=456\rname=chen\rf=123\rkey=456\r七月 06, 2019 9:51:29 下午 io.netty.handler.logging.LoggingHandler channelRead\r信息: [id: 0xade39344, L:/0:0:0:0:0:0:0:0:8080] READ: [id: 0x600995e6, L:/0:0:0:0:0:0:0:1:8080 - R:/0:0:0:0:0:0:0:1:33156]\r七月 06, 2019 9:51:29 下午 io.netty.handler.logging.LoggingHandler channelReadComplete\r信息: [id: 0xade39344, L:/0:0:0:0:0:0:0:0:8080] READ COMPLETE\rkeepAlive=true\rchannel id=600995e6\rhttp uri: /a.txt?name=chen\u0026amp;f=123;key=456\rname=chen\rf=123\rkey=456\r客户端两次连接的socket端口一次是33130,第二次是33156，channel id也不一样，证明确实是两个连接，keep-alive并没有生效。\n其中，channel id来自这里\n@Override\rpublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\r//\rSystem.out.println(\u0026quot;channel id=\u0026quot;+ctx.channel().id());\r}\r为什么呢，看下代码中Server和ServerHandle也没什么问题，关键代码如下：\nserverBootstrap.channel(NioServerSocketChannel.class)\r.group(boss, work)\r.handler(new LoggingHandler(LogLevel.INFO)) // handler在初始化时就会执行，可以设置打印日志级别\r.childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() {\r@Override\rprotected void initChannel(SocketChannel ch) throws Exception {\rch.pipeline().addLast(\u0026quot;http-coder\u0026quot;,new HttpServerCodec());\rch.pipeline().addLast(\u0026quot;aggregator\u0026quot;,new HttpObjectAggregator(1024*1024)); //在处理 POST消息体时需要加上\rch.pipeline().addLast(new HttpServerHandler());\r}\r})\r.option(ChannelOption.SO_BACKLOG, 1024)\r.childOption(ChannelOption.SO_KEEPALIVE, true)\r.childOption(ChannelOption.TCP_NODELAY, true);\r//handle代码\rhttpResponse.headers().set(HttpHeaderNames.CONTENT_TYPE, \u0026quot;text/html;charset=UTF-8\u0026quot;);\rhttpResponse.headers().setInt(HttpHeaderNames.CONTENT_LENGTH, httpResponse.content().readableBytes());\rif (keepAlive) {\rhttpResponse.headers().set(HttpHeaderNames.CONNECTION, HttpHeaderValues.KEEP_ALIVE);\rctx.writeAndFlush(httpResponse);\r} else {\rctx.writeAndFlush(httpResponse).addListener(ChannelFutureListener.CLOSE);\r}\r代码很明显，如果请求是 keep-alive的，那么响应头也加上keep-alive标志，从而实现了长连接。看了半天代码没看出端倪来，突然注意到了在浏览器中，F12看到了/favicon.ico的请求一直是pending的，也就是阻塞在了这里，代码里是这么写的\n//去除浏览器\u0026quot;/favicon.ico\u0026quot;的干扰\rif (uri.equals(FAVICON_ICO)) {\rreturn ;\r}\r这段代码来自我参考的别人的代码，本意是要忽略 /favicon.ico这种无效的请求，但是由于直接return了，导致当前连接被阻塞了，如果这时刷新，就会导致新开一个连接来处理请求。要解决这个问题很简单，只需要注释掉这段代码，对于/favicon.ico请求，直接返回空的200状态码就好了。\n现在再来看下请求日志：\n信息: [id: 0xee8bc5e1, L:/0:0:0:0:0:0:0:0:8080] READ: [id: 0x734e2ebb, L:/0:0:0:0:0:0:0:1:8080 - R:/0:0:0:0:0:0:0:1:37386]\r七月 06, 2019 10:03:48 下午 io.netty.handler.logging.LoggingHandler channelReadComplete\r信息: [id: 0xee8bc5e1, L:/0:0:0:0:0:0:0:0:8080] READ COMPLETE\rkeepAlive=true\rchannel id=734e2ebb\rhttp uri: /a.txt?name=chen\u0026amp;f=123;key=456\rname=chen\rf=123\rkey=456\rkeepAlive=true\rchannel id=734e2ebb\rhttp uri: /favicon.ico\rkeepAlive=true\rchannel id=734e2ebb\rhttp uri: /a.txt?name=chen\u0026amp;f=123;key=456\rname=chen\rf=123\rkey=456\rkeepAlive=true\rchannel id=734e2ebb\rhttp uri: /favicon.ico\r无论刷新多少次，服务器端日志里也只记录了一次socket连接日志，并且每次的channel id都是一样的。\n顺便再测试下，如果把server中的ChannelOption.SO_KEEPALIVE设置为false，是不会影响http的keep-alive的。\n","date":"2019-07-06","permalink":"http://localhost:1313/post/netty%E5%AE%9E%E7%8E%B0http%E6%9C%8D%E5%8A%A1%E5%99%A8keep-alive%E6%97%A0%E6%95%88%E7%9A%84%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/","tags":["Java"],"title":"Netty实现http服务器keep Alive无效的问题排查"},{"content":"我用的filebeat7来收集日志发给Elastic search，版本是7.1.1，对应的elasticsearch版本和其相同。\n默认的，filebeat生成的索引名字是filebeat-7.1.1-2019.06.24这种，不利于区分不同的业务，需要自定义索引，看了下官方文档， 是这么写的\nindexedit\rThe index name to write events to. The default is \u0026quot;filebeat-%{[agent.version]}-%{+yyyy.MM.dd}\u0026quot; (for example, \u0026quot;filebeat-7.2.0-2019-06-26\u0026quot;). If you change this setting, you also need to configure the setup.template.name and setup.template.pattern options (see Load the Elasticsearch index template).\rIf you are using the pre-built Kibana dashboards, you also need to set the setup.dashboards.index option (see Load the Kibana dashboards).\rYou can set the index dynamically by using a format string to access any event field. For example, this configuration uses a custom field, fields.log_type, to set the index:\routput.elasticsearch:\rhosts: [\u0026quot;http://localhost:9200\u0026quot;]\rindex: \u0026quot;%{[fields.log_type]}-%{[agent.version]}-%{+yyyy.MM.dd}\u0026quot; 重点提到了还需要修改setup.template.name和setup.template.pattern，于是我配置如下：\noutput.elasticsearch:\rhosts: [\u0026quot;127.0.0.1:9200\u0026quot;]\rindex: \u0026quot;ngerr-%{[agent.version]}-%{+yyyy.MM.dd}\u0026quot;\rsetup.template.name: \u0026quot;ngerr\u0026quot;\rsetup.template.pattern: \u0026quot;ngerr-*\u0026quot;\r结果发现无论如何都不生效，找了很多文章都说配置这几个地方就行，包括google也搜不到结果。我试了不同的配置，甚至把setup.template配置调了位置，还是徒劳，控制台永远都是输出如下\n2019-06-26T13:11:20.287+0800 INFO pipeline/output.go:95 Connecting to backoff(elasticsearch(http://127.0.0.1:9200))\r2019-06-26T13:11:20.294+0800 INFO elasticsearch/client.go:734 Attempting to connect to Elasticsearch version 7.1.1\r2019-06-26T13:11:20.379+0800 INFO [index-management] idxmgmt/std.go:223 Auto ILM enable success.\r2019-06-26T13:11:20.380+0800 INFO [index-management.ilm] ilm/std.go:134 do not generate ilm policy: exists=true, overwrite=false\r2019-06-26T13:11:20.380+0800 INFO [index-management] idxmgmt/std.go:238 ILM policy successfully loaded.\r2019-06-26T13:11:20.380+0800 INFO [index-management] idxmgmt/std.go:361 Set setup.template.name to '{filebeat-7.1.1 {now/d}-000001}' as ILM is enabled.\r2019-06-26T13:11:20.380+0800 INFO [index-management] idxmgmt/std.go:366 Set setup.template.pattern to 'filebeat-7.1.1-*' as ILM is enabled.\r2019-06-26T13:11:20.380+0800 INFO [index-management] idxmgmt/std.go:400 Set settings.index.lifecycle.rollover_alias in template to {filebeat-7.1.1 {now/d}-000001} as ILM is enabled.\r2019-06-26T13:11:20.380+0800 INFO [index-management] idxmgmt/std.go:404 Set settings.index.lifecycle.name in template to {filebeat-7.1.1 map[policy:{\u0026quot;phases\u0026quot;:{\u0026quot;hot\u0026quot;:{\u0026quot;actions\u0026quot;:{\u0026quot;rollover\u0026quot;:{\u0026quot;max_age\u0026quot;:\u0026quot;30d\u0026quot;,\u0026quot;max_size\u0026quot;:\u0026quot;50gb\u0026quot;}}}}}]} as ILM is enabled.\r2019-06-26T13:11:20.383+0800 INFO template/load.go:129 Template already exists and will not be overwritten.\r2019-06-26T13:11:20.383+0800 INFO [index-management] idxmgmt/std.go:272 Loaded index template.\r2019-06-26T13:11:20.524+0800 INFO [index-management] idxmgmt/std.go:283 Write alias successfully generated.\r{filebeat-7.1.1 {now/d}-000001} 这个名字总是会覆盖我自己的配置。反复尝试，觉得是 ILM 这个东西在作梗，于是试着搜索了下“filebeat ILM is enabled”，发现了这个issue ，有不少人踩坑了。提出issue的人也指出了文档没有说清楚。\n指向了这个官方文档：https://www.elastic.co/guide/en/beats/filebeat/current/ilm.html\n原来\nStarting with version 7.0, Filebeat uses index lifecycle management by default when it connects to a cluster that supports lifecycle management. Filebeat loads the default policy automatically and applies it to any indices created by Filebeat.\n可惜的是filebeat的配置项那里一直没有说清楚。网上由于大多数人用的都是很保守的配置和较老的版本，所以很难搜索到类似的问题，我基本上是头几个踩坑的了。\n加上这个配置就好了：\nsetup.ilm.enabled: false\r希望能帮到踩坑的人，我已经在这个问题上浪费了三四个小时了。\n","date":"2019-06-26","permalink":"http://localhost:1313/post/filebeat%E4%BF%AE%E6%94%B9index%E7%9A%84%E4%B8%80%E4%B8%AA%E5%9D%91/","tags":["Java"],"title":"Filebeat7自定义index的一个坑"},{"content":"本来我一个软件工程师，是很不屑提产品的，但时不时总见到一些产品人吹牛皮，也忍不住凑个热闹。\n钉钉(DingTalk)是一款由阿里巴巴集团开发的用于商务沟通和工作协同的IM，其和企业版微信占据了中国的大部分企业IM市场。阿里并不是一个擅长做社交的公司，钉钉也是一款命途多舛的产品。2014年左右阿里在内部强行推广来往，一款承载了阿里社交梦的产品，花了巨额的研发和营销费用后，依然是折戟沉沙。后来，来往的团队保留了部分下来，做起了钉钉，针对办公社交，居然做成功了。\n在办公社交上，钉钉的崛起甚至早于以社交闻名的腾讯，在社交上扳回了一局，甚至可以说是唯一的一局。微信和QQ在钉钉后也快速推出了办公社交QQ和企业微信等功能，但是在它们推出后，钉钉在很多城市使用的频率已经很高了。\n我用的是linux操作系统，钉钉并没有官方linux版本，所以有时候我会使用手机钉钉和网页版钉钉凑合。但是某一次打开钉钉设置的时候，发现了一个问题。\n不知大家注意到没有，网页版钉钉的设置使用了流行的switch开关，但是用了红色和绿色的搭配。可能钉钉的设计和开发者觉得“红灯停，绿灯行”的概念已经深入人心，但是他们是否想到了一个事实：中国存在近亿的色盲和色弱用户，这其中又以红绿色盲色弱最多！\n红色和绿色，是两个对比度比较接近的颜色，也是最难辨识的两个颜色，别说对色盲和色弱用户来说，即使是对于普通人来说，在某些光线条件下，红绿色也是很难于辨识的。实际上在打开这个页面的时候，我也愣了一会，才辨清了这两个颜色状态。\n正因为红绿色是很难于辨识的两种颜色，现在城市的红绿灯，大部分都是掺了蓝色的，所以大家看到的绿灯，都是泛蓝的，而不是单纯的绿色。还有的城市，绿灯不仅掺了蓝色，还会使用动画或声音提示行人车辆，目的就是为了减少了特殊用户甚至是正常用户的困扰。\n阿里一直宣传产品的人文关怀，比如雇佣残疾人客服，支付宝支持语音支付等，但是可曾想到，他们另外一款最流行的企业IM软件，却忽略了上亿人！\n产品的设计开发中，有许多细节，只有真正用心的人才会注意到，并设计出用户友好的软件，减少用户的困扰。\n作者使用了钉钉很久了，最早的APP版设置页面就是使用红色和绿色来作为swith开关的，作者曾经在微博等多个渠道向阿里反馈，可惜一直没有收到阿里的回复，直到一年后的某天，钉钉悄悄地改了这个细节，也不知道是无意中修改还是真的收到了用户的反馈。遗憾的是，网页版钉钉至今没有修改这个细节。\n","date":"2019-05-06","permalink":"http://localhost:1313/post/oh-dingtalk/","tags":["闲扯淡"],"title":"从钉钉一个忽略了近亿人的产品细节谈谈产品思维"},{"content":"公司的生产服务器买了QiZhi Technologie的堡垒机，每次登录都得输入密码+空格+OTOP验证码，都得打开手机APP操作一把，烦不胜烦。\n不可忍，想了想，还是借助Java在每次调用时自动生成验证码，然后搞个ssh自动登录（别问我问啥不用公钥，哪有权限啊）得了。\n结合之前写的博客 TOTP算法Java版本，很容易就写出计算验证码的代码：\npublic long getCode(String secret, long timeMsec) throws Exception {\rBase32 codec = new Base32();\rbyte[] decodedKey = codec.decode(secret);\rlong t = (timeMsec / 1000L) / 30L;\rfor (int i = -window_size; i \u0026lt;= window_size; ++i) {\rlong hash;\rtry {\rhash = verify_code(decodedKey, t + i);\rreturn hash;\r} catch (Exception e) {\re.printStackTrace();\r}\r}\rreturn 0L;\r}\r写一个类，专门调用这个方法生成验证码，获取程序执行结果\njava -Dfile.encoding=UTF-8 -classpath /soft/tool/authcode/ GoogleAuthTest\r，接下来，要实现自动登录就简单多了，先写一个shell\n#!/bin/bash\rpasswd=$(java -Dfile.encoding=UTF-8 -classpath /soft/tool/authcode/ GoogleAuthTest)\r./prod.exp $passwd\rshell调用java生成验证码，然后传给expect脚本\n#!/bin/expect\rset timeout 10\rset fullpasswd [lindex $argv 0]\rspawn ssh -l chenwen 172.10.3.110\rexpect \u0026quot;*ssword*\u0026quot;\rsend \u0026quot;dev744988 $fullpasswd\\r\u0026quot;\rinteract\r不到100行新代码，搞定收工，全程不到半小时。最耗时的还是传递变量给expact花了不少时间。\n","date":"2018-11-16","permalink":"http://localhost:1313/post/auto-login-bastion-with-otop-by-java/","tags":["Java","Linux"],"title":"使用Java自动登录需要动态密码的堡垒机"},{"content":"在Linux里，用户层面并没有文件创建时间的概念，无论是用ls还是stat 指令，都无法获取到文件的创建时间\n[tudou@tudou-pc statx]$ stat test-statx.c\r文件：test-statx.c\r大小：6656 块：16 IO 块：4096 普通文件\r设备：805h/2053d Inode：6684737 硬链接：1\r权限：(0644/-rw-r--r--) Uid：( 1000/ tudou) Gid：( 1001/ tudou)\r最近访问：2018-10-07 13:16:29.000000000 +0800\r最近更改：2018-10-07 13:21:09.855461986 +0800\r最近改动：2018-10-07 13:21:09.855461986 +0800\r创建时间：-\r可以看到「创建时间」一行总是「-」。\n如果我们使用百度的话，会看到很多文章说，最近改动时间就是创建时间。的确，我们拿很多文件试验了下，这个最近改动时间（Change Time）确实和创建时间很相近，然而Change time并不是Create time，它实际是文件属性修改时间。 试一下即知：\n[tudou@tudou-pc 下载]$ ./statx ~/.face\rstatx(/home/tudou/.face) = 0\rresults=fff\rSize: 7589 Blocks: 16 IO Block: 4096 regular file\rDevice: 08:05 Inode: 5505043 Links: 1\rAccess: (0644/-rw-r--r--) Uid: 1000 Gid: 1001\rAccess: 2018-09-16 01:15:52.320014139+0800\rModify: 2018-09-16 01:15:52.320014139+0800\rChange: 2018-09-16 01:15:52.320014139+0800\rBirth: 2018-09-16 01:15:52.320014139+0800\rAttributes: 0000000000000000 (........ ........ ........ ........ ........ ........ ....-... .---.-..)\r[tudou@tudou-pc 下载]$ chattr +u ~/.face\r[tudou@tudou-pc 下载]$ ./statx ~/.face\rstatx(/home/tudou/.face) = 0\rresults=fff\rSize: 7589 Blocks: 16 IO Block: 4096 regular file\rDevice: 08:05 Inode: 5505043 Links: 1\rAccess: (0644/-rw-r--r--) Uid: 1000 Gid: 1001\rAccess: 2018-09-16 01:15:52.320014139+0800\rModify: 2018-09-16 01:15:52.320014139+0800\rChange: 2018-10-07 16:17:10.929769171+0800\rBirth: 2018-09-16 01:15:52.320014139+0800\rAttributes: 0000000000000000 (........ ........ ........ ........ ........ ........ ....-... .---.-..)\r不过，linux也不是完全不支持文件创建时间，文件系统如ext4其实是支持的，只是没有API可以获取到这个数据。比如Java提供的文件API，也就因此无法获取文件创建时间。\n不过，自内核 4.11 版本引入的 statx 系统调用支持获取创建时间了，字段名里用的是 btime（Birth time）。\n如果用户想要实现在代码里获取这个创建时间，那么只需要调用glibc提供的API即可。但是目前glibc还没有支持，所以只能自己用syscall函数调用。如果仅仅只是想自己实现一个小工具来获取这个时间，那么内核源码树里 samples/statx/test-statx.c 这个文件就是现成的实现。 下载源码：https://cdn.kernel.org/pub/linux/kernel/v4.x/linux-4.18.12.tar.xz，选择一个和自己操作系统版本最近的源码分支 . 你要是不想下载几十M的linux源码的话，也可以从这里获取到各个linux版本的源码 编译文件：\n[tudou@tudou-pc statx]$ gcc -O2 -o statx test-statx.c\rIn file included from /usr/include/sys/stat.h:446,\rfrom test-statx.c:28:\r/usr/include/bits/statx.h:25:8: 错误：‘struct statx_timestamp’重定义\rstruct statx_timestamp\r^~~~~~~~~~~~~~~\rIn file included from test-statx.c:26:\r/usr/include/linux/stat.h:56:8: 附注：原先在这里定义\rstruct statx_timestamp {\r^~~~~~~~~~~~~~~\rIn file included from /usr/include/sys/stat.h:446,\rfrom test-statx.c:28:\r/usr/include/bits/statx.h:36:8: 错误：‘struct statx’重定义\r注释如下两行代码：\n#define _GNU_SOURCE\r#define _ATFILE_SOURCE\r再次编译即可。\n[tudou@tudou-pc statx]$ gcc -O2 -o statx test-statx.c\r[tudou@tudou-pc statx]$ ./statx test-statx.c\rstatx(test-statx.c) = 0\rresults=fff\rSize: 6656 Blocks: 16 IO Block: 4096 regular file\rDevice: 08:05 Inode: 6684737 Links: 1\rAccess: (0644/-rw-r--r--) Uid: 1000 Gid: 1001\rAccess: 2018-10-07 13:16:29.000000000+0800\rModify: 2018-10-07 13:21:09.855461986+0800\rChange: 2018-10-07 13:21:09.855461986+0800\rBirth: 2018-10-07 13:16:47.771175840+0800\rAttributes: 0000000000000000 (........ ........ ........ ........ ........ ........ ....-... .---.-..)\r另外一个思路， 使用debugfs来搞。\n附：glibc即将支持statx调用Glibc Support For Statx Is Finally Under Review\n参考： https://blog.lilydjwg.me/2018/7/11/get-file-birth-time-in-linux.213101.html\n","date":"2018-10-07","permalink":"http://localhost:1313/post/get-createtime-in-linux/","tags":["Linux"],"title":"Linux 下获取文件创建时间"},{"content":"现在的一些Linux软件很流行使用bin这种安装包格式，只需要下载个安装包就能自动安装解压，比tar.gz省事，比.deb，.rpm的安装包兼容性强，适应范围广。但也有一个问题，bin安装包让人无法知道里面的细节，还是有所顾虑的。比如我前几天需要下载一个JRE6，但Oracle官方在JDK7之前都没有tar.gz包，只有bin包。我肯定不能直接安装bin文件啊，这会破坏我本机已有的JDK8开发环境。\n怎么从bin文件里提取出原始安装包呢？其实很简单。用vi打开一个bin文件就知道了，bin文件其实就是一个sh文件和二进制文件的合并文件，前面一段是sh命令，负责实际的安装，它会提取后半部分的二进制数据，后半部分一般是个压缩文件包或者自解压文件的二进制流。\nvi jre-for-linux.bin\r可以看到，第一行是\n#!/bin/bash\r接下来就是一堆安装和设置环境变量，提取解压部分了，最关键的部分在这几行\noutname=install.sfx.$$\rtail ${tail_args} +162 \u0026quot;$0\u0026quot;\u0026gt;$outname\rchmod +x $outname\r继续往下看，267行是exit 0，从第268行开始，就是一堆看似乱码的二进制了，到这里那就清晰多了\n# 从268行起提取二进制文件\rtail -n +268 jre-for-linux.bin \u0026gt;install.sfx\r# 因为是sfx格式，就用7z解压\r7z x install.sfx\r到此解压成功。手动安装，使用export设置临时变量，就用上了JRE6了。\n","date":"2018-06-02","permalink":"http://localhost:1313/post/linux%E4%B8%8B%E8%A7%A3%E5%8E%8Bbin%E6%96%87%E4%BB%B6/","tags":["Linux"],"title":"linux下解压bin文件"},{"content":"今天在修一个老项目，使用的是jfinal框架，这个框架算是一个比较传统的框架，只支持打包成war运行放入容器中运行，但是在开发过程中可以使用jetty快速启动和调试。个人不是很喜欢jetty，遂换成了undertow。 引入如下依赖\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;io.undertow\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;undertow-core\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.0.1.Final\u0026lt;/version\u0026gt;\r\u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;io.undertow\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;undertow-servlet\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.0.1.Final\u0026lt;/version\u0026gt;\r\u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r再写一个启动类就好了\npublic class Main {\rpublic static void main(String[] args) throws Exception {\rDeploymentInfo servletBuilder = Servlets.deployment()\r.setContextPath(\u0026quot;/\u0026quot;)\r.setClassLoader(Main.class.getClassLoader())\r.setDeploymentName(\u0026quot;zooadmin.war\u0026quot;)\r;\rFilterInfo jfinalFilter=new FilterInfo(\u0026quot;jfinal\u0026quot;,JFinalFilter.class);\rjfinalFilter.addInitParam(\u0026quot;configClass\u0026quot;,\u0026quot;com.baicai.core.Config\u0026quot;);\rservletBuilder.addFilter(jfinalFilter);\rservletBuilder.addFilterUrlMapping(\u0026quot;jfinal\u0026quot;,\u0026quot;/*\u0026quot;, DispatcherType.REQUEST);\rservletBuilder.addFilterUrlMapping(\u0026quot;jfinal\u0026quot;,\u0026quot;/*\u0026quot;, DispatcherType.FORWARD);\rservletBuilder.setResourceManager(new FileResourceManager(new File(\u0026quot;src/main/webapp\u0026quot;), 1024));\rDeploymentManager manager = Servlets.defaultContainer().addDeployment(servletBuilder);\rmanager.deploy();\rPathHandler path = Handlers.path(Handlers.redirect(\u0026quot;/\u0026quot;))\r.addPrefixPath(\u0026quot;/\u0026quot;, manager.start());\rUndertow server = Undertow.builder()\r.addHttpListener(1080, \u0026quot;localhost\u0026quot;)\r.setHandler(path)\r.build();\r// start server\rserver.start();\r}\r}\r直接在这个类上运行main方法即可。关键的地方就是把传统的web项目的web.xml翻译成Java代码而已。 本来想继续实现springboot那种fatjar的打包方式，最后发现现有的maven插件都无法满足需求，spring是自己扩展了jar的一套协议实现的，实现起来颇有难度。留待以后折腾吧\n","date":"2018-05-19","permalink":"http://localhost:1313/post/%E4%BD%BF%E7%94%A8%E5%86%85%E5%B5%8Cundertow%E5%BC%80%E5%8F%91%E8%B0%83%E8%AF%95jfinal%E9%A1%B9%E7%9B%AE/","tags":["Java"],"title":"使用内嵌undertow开发调试jfinal项目"},{"content":"之前公司的一个网站使用了OTP来做二次验证，然后我就在手机上安装了freeotp这款软件来管理OTP密码，等到换手机了，才发现没法导出原手机的配置，这就尴尬了。FreeOTP is sponsored and officially published by Red Hat，也算是大家闺秀出品的软件，居然不支持这么重要的功能。\n试了很多方法，在手机的文件管理器中到处搜索，都没有找到这个配置，基本可以确定freeotp把密钥存放在了系统目录，没有root的话，是没法查看和处理系统目录下的文件，即使用备份工具也备份不出来。\n当初网站的OTP二维码也找不到了，网站也没找到重新设置OTP的入口，本着万事不求人的想法，暂时还不想最后求助运维。看来唯一的办法就是root手机了，试了很多工具，没想到kingroot居然支持root魅蓝手机了。\nroot成功后，马上去freeotp的配置存储目录找到配置文件，找到 /data/data/org.fedorahosted.freeotp/shared_prefs/tokens.xml 文件，得到如下的配置,配置中的引号被转义了\n\u0026lt;?xml version='1.0' encoding='utf-8' standalone='yes' ?\u0026gt;\r\u0026lt;map\u0026gt;\r\u0026lt;string name=\u0026quot;bbcx@qq.com:chen\u0026quot;\u0026gt;{\u0026quot;algo\u0026quot;:\u0026quot;SHA256\u0026quot;,\u0026quot;counter\u0026quot;:0,\u0026quot;digits\u0026quot;:6,\u0026quot;issuerExt\u0026quot;:\u0026quot;bbcx@qq.com\u0026quot;,\u0026quot;label\u0026quot;:\u0026quot;chen\u0026quot;,\u0026quot;period\u0026quot;:30,\u0026quot;secret\u0026quot;:[17,-56,-42,-70,-48,-79,53],\u0026quot;type\u0026quot;:\u0026quot;TOTP\u0026quot;}\u0026lt;/string\u0026gt;\r\u0026lt;string name=\u0026quot;bbc\u0026quot;\u0026gt;{\u0026quot;algo\u0026quot;:\u0026quot;SHA1\u0026quot;,\u0026quot;counter\u0026quot;:0,\u0026quot;digits\u0026quot;:6,\u0026quot;issuerExt\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;label\u0026quot;:\u0026quot;bbc\u0026quot;,\u0026quot;period\u0026quot;:30,\u0026quot;secret\u0026quot;:[0,1,2,3],\u0026quot;type\u0026quot;:\u0026quot;TOTP\u0026quot;}\u0026lt;/string\u0026gt;\r\u0026lt;string name=\u0026quot;tokenOrder\u0026quot;\u0026gt;[\u0026quot;bbcx@qq.com:bbcx\u0026quot;,\u0026quot;bbc\u0026quot;]\u0026lt;/string\u0026gt;\r\u0026lt;/map\u0026gt;\r可以看出，这里面是就是关于otp的全部配置了，最关键的就是secret字段，这里做了加密，反复试验了半天，没找到解决方案，最终想到Google，找到了这个解决方案： https://github.com/viljoviitanen/freeotp-export/blob/master/README.md ，只需要把tokens.xml贴到这里，https://rawgit.com/viljoviitanen/freeotp-export/master/export-xml.html，就能还原出二维码来，用新手机扫描就好了。\n事情还没完，最后想去freeotp的官方那里反应下，没想到官方的态度让我大跌眼镜，https://github.com/freeotp/freeotp-android/issues/20，“出门右转买收费软件去，老子就是不增加备份功能，你能咋地”。\n\u0026quot;'''Can I create backupcodes'''?\r''No, but if you're using an Android smartphone you can replace the Google Authenticator app with Authenticator Plus.\rIt's a really nice app that can import your existing settings, sync between devices and backup/restore using your sd-card.\rIt's not a free app, but it's well worth the money.''\u0026quot;\rThis proprietary app, Authenticator Plus, does look very nice and has some nice features, but the most beneficial I think is its ability to backup and restore codes.\rThis could be a huge addition to FreeOTP and I would like to request that someone considers this feature and looks at a way of implementing it. I am not able to code myself.\r最终，在用户义愤填膺的评论下，发现这个软件 andOTP，真是兴奋，满足了我对OTP软件的所有需求，也支持备份和导入，极力推荐。\n立马卸载了拽拽的freeOTP，装上andOTP，感觉整个世界都阳光明媚。开源的傲慢真是领悟了，惹不起惹不起。\n","date":"2018-05-14","permalink":"http://localhost:1313/post/export-freeopt-config/","tags":null,"title":"导出freeOTP中的配置"},{"content":"很久没更新博客了，想到几个小坑，虽然没啥技术含量，但或许有人不知道呢。\n1.删除sublist的元素导致原对象元素被删除 看下面这段代码\nList\u0026lt;Integer\u0026gt; students=new ArrayList\u0026lt;Integer\u0026gt;();\rfor (int i = 0; i \u0026lt;5 ; i++) {\rstudents.add(i);\r}\rList\u0026lt;Integer\u0026gt; subList=new ArrayList\u0026lt;Integer\u0026gt;();\rsubList=students.subList(0,5);\rsubList.remove(0);\rsubList.remove(1);\rfor (int i = 0; i \u0026lt;5 ; i++) {\rSystem.out.println(i+\u0026quot;=\u0026quot;+students.get(i));\r}\rstudents是个list，然后我们新建立了一个subList对象，这个对象截取了students的一部分，我们删除了subList对象里的一些元素，看下运行结果。\n0=1\r1=3\r2=4\rException in thread \u0026quot;main\u0026quot; java.lang.IndexOutOfBoundsException: Index: 3, Size: 3\rat java.util.ArrayList.rangeCheck(ArrayList.java:657)\rat java.util.ArrayList.get(ArrayList.java:433)\rat bai.ListDo.main(ListDo.java:17)\r难道说，删除subList对象里的元素也会导致students里的元素被删除？我明明是新建了一个对象啊。然而，事实确实是这样的。 我们要理解一个事情，使用new新建一个对象，只是开辟了一块空间，用来存放这个对象的地址指针，但是这个新建的对象地址，指向的却是原有对象，也就是说，使用subList这个方法的时候，并没有从students里把内容拷贝了一份，仅仅是纪录了一个指针的移动，这样从某种角度来说，是提高了性能节省内存的做法。 看一下subList这个方法的JavaDoc我们就更清楚了。\nReturns a view of the portion of this list between the specified\r* \u0026lt;tt\u0026gt;fromIndex\u0026lt;/tt\u0026gt;, inclusive, and \u0026lt;tt\u0026gt;toIndex\u0026lt;/tt\u0026gt;, exclusive. (If\r* \u0026lt;tt\u0026gt;fromIndex\u0026lt;/tt\u0026gt; and \u0026lt;tt\u0026gt;toIndex\u0026lt;/tt\u0026gt; are equal, the returned list is\r* empty.) The returned list is backed by this list, so non-structural\r* changes in the returned list are reflected in this list, and vice-versa.\r* The returned list supports all of the optional list operations supported\r* by this list.\u0026lt;p\u0026gt;\r什么时候会用到subList方法呢，通常是接收到了一个大的list，需要切割成一个个小的子list再加工处理，以减少内存占用和提高性能，如果不注意的话，就很容易触发这种隐形的bug。所以，使用subList时不要轻易做增删操作，要么不使用subList方法，而是手动add.\n2.SimpleDateFormat的线程安全问题 很多博客和文章都会告诉我们，一定要注意SimpleDateFormat的线程安全问题，那究竟是怎么回事呢？ 看下面的代码\npublic class DateFormatTest extends Thread {\r@Override\rpublic void run() {\rwhile(true) {\rtry {\rthis.join(2000);\r} catch (InterruptedException e1) {\re1.printStackTrace();\r}\rtry {\rSystem.out.println(this.getName()+\u0026quot;:\u0026quot;+DateUtil.parse(\u0026quot;2018-05-05 12:12:12\u0026quot;));\r} catch (ParseException e) {\re.printStackTrace();\r}\r}\r}\rpublic static void main(String[] args) {\rfor(int i = 0; i \u0026lt; 3; i++){\rnew DateFormatTest().start();\r}\r}\r}\rclass DateUtil {\rprivate static final SimpleDateFormat sdf = new SimpleDateFormat(\u0026quot;yyyy-MM-dd HH:mm:ss\u0026quot;);\rpublic static String formatDate(Date date)throws ParseException{\rreturn sdf.format(date);\r}\rpublic static Date parse(String strDate) throws ParseException{\rreturn sdf.parse(strDate);\r}\r}\r运行这段代码后，会发现Thread-1会报出Exception in thread \u0026ldquo;Thread-0\u0026rdquo; Exception in thread \u0026ldquo;Thread-1\u0026rdquo; java.lang.NumberFormatException: multiple points 的异常，并且导致Thread-2有一些错误的日期输出。为什么呢，原因在于SimpleDataFormat不是线程安全的，因为SimpleDataFormat里面用了Calendar 这个成员变量来实现SimpleDataFormat,并且在Parse 和Format的时候对Calendar 进行了修改，calendar.clear()，calendar.setTime(date); 为了线程安全和效率的双重兼顾，建议使用ThreadLocal，代码如下：\npublic class DateUtil1 {\rprivate static final ThreadLocal\u0026lt;DateFormat\u0026gt; messageFormat = new ThreadLocal\u0026lt;DateFormat\u0026gt;();\rprivate static final String MESSAGE_FORMAT = \u0026quot;MM-dd HH:mm:ss.ms\u0026quot;;\rprivate static final DateFormat getDateFormat() {\rDateFormat format = messageFormat.get();\rif (format == null) {\rformat = new SimpleDateFormat(MESSAGE_FORMAT, Locale.getDefault());\rmessageFormat.set(format);\r}\rreturn format;\r}\r}\r如果自己没有把握的话，还是建议每次new一个SimpleDataFormat对象。 Java里面还有许多线程不安全的类，使用这些类的时候，务必注意使用同步原语，或者使用new新建一个对象省事，或者使用对应的线程安全的类。比如hashMap对应的ConcurrentHashMap.\n3.split的坑 看下面的代码，\nString[] re=\u0026quot;2|33|4\u0026quot;.split(\u0026quot;|\u0026quot;);\rfor (int i = 0; i \u0026lt;re.length ; i++) {\rSystem.out.println(re[i]);\r}\r你以为输出的结果会是2,33,4，实际上却是 2,|，3,3，|，4。为什么呢，稍微看一下split的方法注释就知道了，原来split的分隔符参数实际上是一个正则表达式，而不是普通的字符串。 所以，正确的写法应该是String.split(\u0026quot;\\|\u0026quot;) 当然，这种坑纯粹是由于对Java基本方法的使用不熟悉造成的，是完全可以避免的。\n","date":"2018-05-05","permalink":"http://localhost:1313/post/java_trap/","tags":["Java"],"title":"Java里常见的几个语法小坑"},{"content":" 这两天想给博客做个插件,利用阿里云的OSS来存储文件.但阿里的文档和代码都烂的超乎想象,要么代码老旧不堪,要么跟小脚老太一样引入一坨依赖,想必这块是外包团队做的吧,或者阿里非核心业务员的技术水平也就这样吧.\n所以想绕开阿里云官方提供的代码自己整一套OSS的API,先跑一个上传文件的demo,能在客户端跑通后再用代码去实现.最简单的方法就是用REST client来模拟.折腾了一下,还挺费劲,记录下折腾过程\n先来试试上传文件,选择PUT方法,要请求的URL为http://baicaidoc.oss-cn-shenzhen.aliyuncs.com/image/small/mm1.jpg ,添加以下header,header头需要包含哪些内容可以看这里\nAuthorization:OSS\rLTAIxkX6Qj2OuMZ6:tLZ7nYYP/hkCJbG/6gkOJ7Mi4E=\rDate:Thu, 25 Jan 2018 15:20:39 GMT\rContent-Disposition:attachment;filename=ivy.jpg\rHost:baicaidoc.oss-cn-shenzhen.aliyuncs.com\rContent-Encoding:utf-8\r然后在body里添加file body. 至于header头怎么写和Authorization字段计算的方法,文档里说的比较清晰了https://help.aliyun.com/document_detail/31951.html. 尤其需要注意的是Date必须是GMT格式,这个对Java来说也好办,不过要注意时区的问题,GMT时间比东八区慢了8个小时.还有Host需要带上bucket,这在早期是不需要的(早期带上反而会报错SignatureDoesNotMatch) 另外就是这个Authorization字段的签名需要注意,base64需要处理byte[]数组,而不是字符串.所以用网上的在线验证工具是验证不了的. Java版的签名代码如下:\nimport bai.tool.Base64;\rimport javax.crypto.Mac;\rimport javax.crypto.spec.SecretKeySpec;\rimport java.security.InvalidKeyException;\rimport java.security.NoSuchAlgorithmException;\r/**\r* Hello world!\r*\r*/\rpublic class App\r{\rpublic static byte[] hamcsha1(byte[] data, byte[] key)\r{\rtry {\rSecretKeySpec signingKey = new SecretKeySpec(key, \u0026quot;HmacSHA1\u0026quot;);\rMac mac = Mac.getInstance(\u0026quot;HmacSHA1\u0026quot;);\rmac.init(signingKey);\rreturn mac.doFinal(data);\r} catch (NoSuchAlgorithmException e) {\re.printStackTrace();\r} catch (InvalidKeyException e) {\re.printStackTrace();\r}\rreturn null;\r}\rpublic static void main( String[] args ) {\rString toSign=\u0026quot;PUT\\n\u0026quot; +\r\u0026quot;\\n\u0026quot; +\r\u0026quot;image/jpeg; charset=UTF-8\\n\u0026quot; +\r\u0026quot;Thu, 25 Jan 2018 15:20:39 GMT\\n\u0026quot; +\r\u0026quot;/baicaidoc/image/small/mm1.jpg\u0026quot;;\rString accessKey=\u0026quot;OrzrzxIsfpFjA7S7yk0Lwy8Bw21TLhquhboiip56\u0026quot;;\rbyte[] hm=hamcsha1(toSign.getBytes(),accessKey.getBytes());\rSystem.out.println(\u0026quot;OSS LTAIxkX6Qj2OuMZ6:\u0026quot;+Base64.encodeToString(hm));\r}\r}\r客户端能跑通就好办了，最后是代码，使用HttpURLConnection来实现PUT上传代码。阿里云的OSS SDK太重了，而一般常用的就上传和删除功能\nimport java.io.*;\rimport java.net.HttpURLConnection;\rimport java.net.MalformedURLException;\rimport java.net.URL;\rimport java.text.SimpleDateFormat;\rimport java.util.Date;\rimport java.util.Locale;\rimport java.util.TimeZone;\rpublic class OSSUpload {\rpublic String httpUrlConnectionPut(String fileName) {\rString result = \u0026quot;\u0026quot;;\rURL url = null;\rString httpUrl = \u0026quot;http://baicaidoc.oss-cn-shenzhen.aliyuncs.com/image/small/test.jpg\u0026quot;;\rtry {\rurl = new URL(httpUrl);\r} catch (MalformedURLException e) {\re.printStackTrace();\r}\rif (url != null) {\rHttpURLConnection urlConn;\rtry {\rurlConn = (HttpURLConnection) url.openConnection();\rFile file = new File(fileName);\rurlConn.setRequestProperty(\u0026quot;content-type\u0026quot;, \u0026quot;image/jpeg; charset=UTF-8\u0026quot;);\rurlConn.setDoOutput(true);// http正文内，因此需要设为true, 默认情况下是false;\rurlConn.setDoInput(true);// 设置是否从httpUrlConnection读入，默认情况下是true;\rurlConn.setConnectTimeout(15 * 1000);\rurlConn.setRequestProperty(\u0026quot;User-Agent\u0026quot;, \u0026quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.84 Safari/537.36\u0026quot;);\r//设置请求方式为 PUT\rurlConn.setRequestMethod(\u0026quot;PUT\u0026quot;); urlConn.setRequestProperty(\u0026quot;Connection\u0026quot;, \u0026quot;Keep-Alive\u0026quot;);\rSimpleDateFormat sdf = new SimpleDateFormat(\u0026quot;EEE, dd MMM yyyy HH:mm:ss 'GMT'\u0026quot;, Locale.US);\rsdf.setTimeZone(TimeZone.getTimeZone(\u0026quot;GMT\u0026quot;));\rurlConn.setRequestProperty(\u0026quot;Host\u0026quot;, \u0026quot;baicaidoc.oss-cn-shenzhen.aliyuncs.com\u0026quot;);\rurlConn.setRequestProperty(\u0026quot;Content-Encoding\u0026quot;, \u0026quot;UTF-8\u0026quot;);\rurlConn.setRequestProperty(\u0026quot;Date\u0026quot;, sdf.format(new Date()));\rurlConn.setRequestProperty(\u0026quot;Content-Length\u0026quot;, String.valueOf(file.length()));\rurlConn.setRequestProperty(\u0026quot;Authorization\u0026quot;, \u0026quot;OSS LTAIxk223j2OuMZ6:tLZ74YYP/hkCJbG/6gkOJ7Mi4E=\u0026quot;);\rDataOutputStream dos = new DataOutputStream(urlConn.getOutputStream());\r//写入请求参数\rtry {\rInputStream in = new FileInputStream(file);\rint bytes = 0;\rbyte[] bufferOut = new byte[4096];\rwhile ((bytes = in.read(bufferOut)) != -1) {\rdos.write(bufferOut, 0, bytes);\r}\rdos.flush();\rdos.close();\rInputStream is = urlConn.getInputStream();\rint ch;\rStringBuffer b = new StringBuffer();\rwhile ((ch = is.read()) != -1) {\rb.append((char) ch);\r}\rSystem.out.println(\u0026quot;result:\u0026quot; + b.toString());\r}catch (IOException e){\re.printStackTrace();\rInputStream is=urlConn.getErrorStream();\rint ch;\rStringBuffer b = new StringBuffer();\rwhile ((ch = is.read()) != -1) {\rb.append((char) ch);\r}\rSystem.out.println(\u0026quot;error result:\u0026quot;+b.toString());\r}\rurlConn.disconnect();\r} catch (Exception e) {\re.printStackTrace();\r}finally {\r}\r}\rreturn result;\r}\rpublic static void main(String[] args) {\rOSSUpload oss = new OSSUpload(); oss.httpUrlConnectionPut(\u0026quot;/home/chen/Desktop/tmp/sd.png\u0026quot;);\r}\r}\r","date":"2018-01-25","permalink":"http://localhost:1313/post/aliyun_oss_custom/","tags":["Java"],"title":"折腾阿里云OSS的API"},{"content":" 前不久,有人问到我一个问题，就是使用mb_check_encoding来侦测一段字符的编码，预期是GBK编码，但是PHP给出来UTF-8编码的错误判断。那么，mb_check_encoding的正确姿势是什么呢？ 我们来看一段代码，\n\u0026lt;?php\r$utf8Str = '别abc扯淡';\rvar_dump(mb_check_encoding($utf8Str, 'UTF-8')); //输出true\rvar_dump(mb_check_encoding($utf8Str, 'gbk')); //输出true\r这段代码的输出是啥呢？按理，我们的PHP文件保存为什么编码，那它输出的就应该是啥编码，然而以上输出的都是true。再换个例子，这样呢？\n\u0026lt;?php\r$utf8Str = '别abc扯淡啊';\rvar_dump(mb_check_encoding($utf8Str, 'UTF-8'));\rvar_dump(mb_check_encoding($utf8Str, 'gbk'));\r后面多加了一个汉字，这次PHP做出了正确的判断，给出了是UTF-8的判断。那么mb_check_encoding到底有没有用？是这个函数有bug还是我自己不懂姿势？\n难道是，只要汉字是3的整数倍就会判断失灵？试验后确实是的，当然这只是表面现象，但无疑说明这个函数是不可靠的。为什么呢？其实原理说起来也不难理解，计算机并不懂什么叫乱码。一段文字，解释成UTF8或GBK其实都是可以的，我们用肉眼看到有了乱码，根据我们的经验，觉得解释成这种编码是错误的，而解释成另外一种编码才算正确。可是计算机不懂啊，你觉得有个字符很奇怪，你不认识所以认定是乱码，可计算机认识啊，它不觉得奇怪。除非字节数解释成另外一种编码，会多出一个字节，并且ASCII码也不是常见范围，计算机才能大胆判定解释成这种编码不对。所以这样去检测编码是无法完全可靠地.\n那既然mb_check_encoding这个函数不可靠，那么用正则可靠么？或许吧。 但是我们更应该关注的是PHP为什么会有这么一个功能？为什么其他语言没有这个方法，或者根本不会遇到这个问题？\n问题还是出在PHP本身。因为客户端可能会有多种编码输入，PHP为了解决这个问题就引入这么一个贴心的函数给使用者。可是PHP不应该是遇到问题就去动歪脑筋解决问题啊，而且规范问题。为什么其他语言不需要在SDK里引入这个方法呢？或者说是PHP程序员的使用姿势不正确?\n最后，其实PHP给出这个函数也不算错，但是一定要参照其他语言里的惯行做法，在文档里说清楚，这个函数的判断的是一种“可信度”，而不是给出一个非此即彼的“权威”结果。但是遗憾的是，这个函数的文档里没说很好的说清楚，而是这么写的，\n“Checks if the specified byte stream is valid for the specified encoding. It is useful to prevent so-called \u0026ldquo;Invalid Encoding Attack Returns TRUE on success or FALSE on failure.”\n其实加上这样一句话“This function only give the confidence level of the result”就好了，也就不会平白引起那么多的疑虑。\n比如，Python的做法就比较专业，chardet模块给出的是一个置信检测，而不是非true即false的判断。java里面的第三方工具包cpdetector也指出了其规则，按照“谁最先返回非空的探测结果，就以该结果为准”的原则返回探测到的字符集编码。其是基于统计学原理的，不保证完全正确。\n","date":"2018-01-12","permalink":"http://localhost:1313/post/php%E7%9A%84mb_check_encoding%E5%87%BD%E6%95%B0%E7%9A%84%E5%AD%98%E5%9C%A8%E6%98%AF%E9%B8%A1%E8%82%8B%E5%90%97/","tags":["PHP"],"title":"PHP的mb_check_encoding函数的存在是鸡肋吗"},{"content":" 针对最新火狐浏览器50+以上版本的firebug协议，类似FirePHP，但是FirePHP已经很久不更新，并且对最新的浏览器也已失效。\n这个在Firebug之上运行的扩展，结合一个服务器端的库，就可以让你的PHP代码向浏览器发送调试信息，该信息以HTTP响应头（HTTP headers）的方式编码。经过设置，你可以像在Firebug控制台调试JavaScript代码一样得到PHP脚本的警告和错误提示。下面我们来看看具体步骤。\n直接上代码\nimport com.alibaba.fastjson.JSON;\rimport java.util.ArrayList;\rimport java.util.HashMap;\rimport java.util.Map;\rimport java.util.Objects;\r/**\r* @version V1.0\r* @Description:直接输出服务器端调试日志到控制台，简易版本。\r* @date 2017/6/13 16:51\r*/\rpublic class DebugTool {\rpublic final String VERSION = \u0026quot;2.0.j1\u0026quot;;\rpublic final String HEADER_NAME = \u0026quot;X-ChromeLogger-Data\u0026quot;;\rprotected Map\u0026lt;String, Object\u0026gt; console = new HashMap\u0026lt;\u0026gt;();\rprivate String response=\u0026quot;\u0026quot;;\rpublic DebugTool() {\rconsole.put(\u0026quot;version\u0026quot;, VERSION);\rconsole.put(\u0026quot;columns\u0026quot;, new String[]{\u0026quot;log\u0026quot;, \u0026quot;backtrace\u0026quot;, \u0026quot;type\u0026quot;});\rconsole.put(\u0026quot;rows\u0026quot;, new ArrayList\u0026lt;Objects\u0026gt;());\rconsole.put(\u0026quot;request_uri\u0026quot;, this.getClass().getName());\r}\rpublic DebugTool(Class cls) {\rthis();\rconsole.put(\u0026quot;request_uri\u0026quot;, cls.getName());\r}\rpublic void log(Object o) {\rlog(o,\u0026quot;\u0026quot;);\r}\rpublic void info(Object o) {\rlog(o,\u0026quot;info\u0026quot;);\r}\rpublic void warn(Object o) {\rlog(o,\u0026quot;warn\u0026quot;);\r}\rpublic void error(Object o) {\rlog(o,\u0026quot;error\u0026quot;);\r}\rpublic void log(Object o,String type) {\rObject[] info;\rif(o instanceof Map){\rinfo = new Object[]{o};\r}else {\rinfo = new Object[]{o.toString()};\r}\rObject[] obj = new Object[]{info, console.get(\u0026quot;request_uri\u0026quot;), type};\rArrayList\u0026lt;Object\u0026gt; rows = (ArrayList\u0026lt;Object\u0026gt;) console.get(\u0026quot;rows\u0026quot;);\rrows.add(obj);\rconsole.put(\u0026quot;rows\u0026quot;, rows);\r}\rpublic String getResponse(){\rString json = JSON.toJSONString(console);\rjson = Base64.encodeToString(json);\rreturn json;\r}\r}\r使用方法：\nDebugTool debug=new DebugTool(this.getClass());\rtool.log(\u0026quot;hello 八阿哥\u0026quot;);\rMap hash=new HashMap();\rhash.put(\u0026quot;25\u0026quot;,\u0026quot;张三\u0026quot;);\rhash.put(\u0026quot;19\u0026quot;,\u0026quot;李四\u0026quot;);\rtool.warn(hash);\rresponse.add(DebugTool.HEADER_NAME,tool.response);\r仅对最新版Firefox有效。新版chrome有自己的debug协议（使用websocket）。有趣的是，这本来是一个chrome浏览器支持的协议，后来chrome放弃了，而Firefox拿过来了。 参考：https://craig.is/writing/chrome-logger\n","date":"2018-01-10","permalink":"http://localhost:1313/post/firejava%E8%BE%93%E5%87%BAjava%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E8%B0%83%E8%AF%95%E6%97%A5%E5%BF%97%E5%88%B0%E6%8E%A7%E5%88%B6%E5%8F%B0/","tags":["Java"],"title":"FireJava输出Java服务器端调试日志到控制台"},{"content":"TOTP 概念 TOTP - Time-based One-time Password Algorithm is an extension of the HMAC-based One Time Password algorithm HOTP to support a time based moving factor.\nTOTP（基于时间的一次性密码算法）是支持时间作为动态因素基于HMAC一次性密码算法的扩展。它是OTP算法的一种\n算法如下: TOTP = Truncate(HMAC-SHA-1(K, (T - T0) / X))\nK 共享密钥 T 时间 T0 开始计数的时间步长 X 时间步长\n代码实现 最简实现需要如下两个类 1.Base32.java\npublic class Base32 {\rprivate static final char[] ALPHABET = { 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O',\r'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '2', '3', '4', '5', '6', '7' };\rprivate static final byte[] DECODE_TABLE;\rstatic {\rDECODE_TABLE = new byte[128];\rfor (int i = 0; i \u0026lt; DECODE_TABLE.length; i++) {\rDECODE_TABLE[i] = (byte) 0xFF;\r}\rfor (int i = 0; i \u0026lt; ALPHABET.length; i++) {\rDECODE_TABLE[(int) ALPHABET[i]] = (byte) i;\rif (i \u0026lt; 24) {\rDECODE_TABLE[(int) Character.toLowerCase(ALPHABET[i])] = (byte) i;\r}\r}\r}\rpublic static String encode(byte[] data) {\rchar[] chars = new char[((data.length * 8) / 5) + ((data.length % 5) != 0 ? 1 : 0)];\rfor (int i = 0, j = 0, index = 0; i \u0026lt; chars.length; i++) {\rif (index \u0026gt; 3) {\rint b = data[j] \u0026amp; (0xFF \u0026gt;\u0026gt; index);\rindex = (index + 5) % 8;\rb \u0026lt;\u0026lt;= index;\rif (j \u0026lt; data.length - 1) {\rb |= (data[j + 1] \u0026amp; 0xFF) \u0026gt;\u0026gt; (8 - index);\r}\rchars[i] = ALPHABET[b];\rj++;\r} else {\rchars[i] = ALPHABET[((data[j] \u0026gt;\u0026gt; (8 - (index + 5))) \u0026amp; 0x1F)];\rindex = (index + 5) % 8;\rif (index == 0) {\rj++;\r}\r}\r}\rreturn new String(chars);\r}\rpublic static byte[] decode(String s) throws Exception {\rchar[] stringData = s.toCharArray();\rbyte[] data = new byte[(stringData.length * 5) / 8];\rfor (int i = 0, j = 0, index = 0; i \u0026lt; stringData.length; i++) {\rint val;\rtry {\rval = DECODE_TABLE[stringData[i]];\r} catch (ArrayIndexOutOfBoundsException e) {\rthrow new Exception(\u0026quot;Illegal character\u0026quot;);\r}\rif (val == 0xFF) {\rthrow new Exception(\u0026quot;Illegal character\u0026quot;);\r}\rif (index \u0026lt;= 3) {\rindex = (index + 5) % 8;\rif (index == 0) {\rdata[j++] |= val;\r} else {\rdata[j] |= val \u0026lt;\u0026lt; (8 - index);\r}\r} else {\rindex = (index + 5) % 8;\rdata[j++] |= (val \u0026gt;\u0026gt; index);\rif (j \u0026lt; data.length) {\rdata[j] |= val \u0026lt;\u0026lt; (8 - index);\r}\r}\r}\rreturn data;\r}\r}\r2.GoogleAuthenticator.java\nimport javax.crypto.spec.SecretKeySpec;\rimport java.security.InvalidKeyException;\rimport java.security.NoSuchAlgorithmException;\rimport java.security.SecureRandom;\rimport java.util.Base64;\rimport javax.crypto.Mac;\rpublic class GoogleAuthenticator {\r// taken from Google pam docs - we probably don't need to mess with these\rpublic static final int SECRET_SIZE = 10;\rpublic static final String SEED = \u0026quot;g8GjEvTbW5oVSV7avLBdwIHqGlUYNzKFI7izOF8GwLDVKs2m0QN7vxRs2im5MDaNCWGmcD2rvcZx\u0026quot;;\rpublic static final String RANDOM_NUMBER_ALGORITHM = \u0026quot;SHA1PRNG\u0026quot;;\rint window_size = 3; // default 3 - max 17 (from google docs)最多可偏移的时间\r/**\r* set the windows size. This is an integer value representing the number of 30 second windows\r* we allow\r* The bigger the window, the more tolerant of clock skew we are.\r* @param s window size - must be \u0026gt;=1 and \u0026lt;=17. Other values are ignored\r*/\rpublic void setWindowSize(int s) {\rif (s \u0026gt;= 1 \u0026amp;\u0026amp; s \u0026lt;= 17)\rwindow_size = s;\r}\r/**\r* Generate a random secret key. This must be saved by the server and associated with the\r* users account to verify the code displayed by Google Authenticator.\r* The user must register this secret on their device.\r* @return secret key\r*/\rpublic static String generateSecretKey() {\rSecureRandom sr = null;\rtry {\rsr = SecureRandom.getInstance(RANDOM_NUMBER_ALGORITHM);\rsr.setSeed(Base64.getDecoder().decode(SEED));\rbyte[] buffer = sr.generateSeed(SECRET_SIZE);\rBase32 codec = new Base32();\rbyte[] bEncodedKey = codec.encode(buffer).getBytes();\rString encodedKey = new String(bEncodedKey);\rreturn encodedKey;\r}catch (NoSuchAlgorithmException e) {\r// should never occur... configuration error\r}\rreturn null;\r}\r/**\r* Return a URL that generates and displays a QR barcode. The user scans this bar code with the\r* Google Authenticator application on their smartphone to register the auth code. They can also\r* manually enter the\r* secret if desired\r* @param user user id (e.g. fflinstone)\r* @param host host or system that the code is for (e.g. myapp.com)\r* @param secret the secret that was previously generated for this user\r* @return the URL for the QR code to scan\r*/\rpublic static String getQRBarcodeURL(String user, String host, String secret) {\rString format = \u0026quot;https://www.google.com/chart?chs=200x200\u0026amp;chld=M%%7C0\u0026amp;cht=qr\u0026amp;chl=otpauth://totp/%s@%s%%3Fsecret%%3D%s\u0026quot;;\rreturn String.format(format, user, host, secret);\r}\r/**\r* Check the code entered by the user to see if it is valid\r* @param secret The users secret.\r* @param code The code displayed on the users device\r* @param t The time in msec (System.currentTimeMillis() for example)\r* @return\r* @throws Exception\r*/\rpublic boolean check_code(String secret, long code, long timeMsec) throws Exception {\rBase32 codec = new Base32();\rbyte[] decodedKey = codec.decode(secret);\r// convert unix msec time into a 30 second \u0026quot;window\u0026quot;\r// this is per the TOTP spec (see the RFC for details)\rlong t = (timeMsec / 1000L) / 30L;\r// Window is used to check codes generated in the near past.\r// You can use this value to tune how far you're willing to go.\rfor (int i = -window_size; i \u0026lt;= window_size; ++i) {\rlong hash;\rtry {\rhash = verify_code(decodedKey, t + i);\r}catch (Exception e) {\r// Yes, this is bad form - but\r// the exceptions thrown would be rare and a static configuration problem\re.printStackTrace();\rthrow new RuntimeException(e.getMessage());\r//return false;\r}\rif (hash == code) {\rreturn true;\r}\r}\r// The validation code is invalid.\rreturn false;\r}\rprivate static int verify_code(byte[] key, long t) throws NoSuchAlgorithmException, InvalidKeyException {\rbyte[] data = new byte[8];\rlong value = t;\rfor (int i = 8; i-- \u0026gt; 0; value \u0026gt;\u0026gt;\u0026gt;= 8) {\rdata[i] = (byte) value;\r}\rSecretKeySpec signKey = new SecretKeySpec(key, \u0026quot;HmacSHA1\u0026quot;);\rMac mac = Mac.getInstance(\u0026quot;HmacSHA1\u0026quot;);\rmac.init(signKey);\rbyte[] hash = mac.doFinal(data);\rint offset = hash[20 - 1] \u0026amp; 0xF;\r// We're using a long because Java hasn't got unsigned int.\rlong truncatedHash = 0;\rfor (int i = 0; i \u0026lt; 4; ++i) {\rtruncatedHash \u0026lt;\u0026lt;= 8;\r// We are dealing with signed bytes:\r// we just keep the first byte.\rtruncatedHash |= (hash[offset + i] \u0026amp; 0xFF);\r}\rtruncatedHash \u0026amp;= 0x7FFFFFFF;\rtruncatedHash %= 1000000;\rreturn (int) truncatedHash;\r}\r}\r测试类如下:\nimport org.junit.Test;\rpublic class GoogleAuthTest {\r@Test\rpublic void genSecretTest() {\rString secret = GoogleAuthenticator.generateSecretKey();\rSystem.out.println(\u0026quot;secret=\u0026quot;+secret);\rString url = GoogleAuthenticator.getQRBarcodeURL(\u0026quot;testuser\u0026quot;, \u0026quot;testhost\u0026quot;, secret);\rSystem.out.println(\u0026quot;Please register \u0026quot; + url);\rSystem.out.println(\u0026quot;Secret key is \u0026quot; + secret);\r}\r// Change this to the saved secret from the running the above test.\rstatic String savedSecret = \u0026quot;VGH25A7M54QPME5F\u0026quot;;\r@Test\rpublic void authTest() throws Exception {\r// enter the code shown on device. Edit this and run it fast before the code expires!\rlong code = 146841;\rlong t = System.currentTimeMillis();\rGoogleAuthenticator ga = new GoogleAuthenticator();\rga.setWindowSize(5); //should give 5 * 30 seconds of grace...\rboolean r = ga.check_code(savedSecret, code, t);\rSystem.out.println(\u0026quot;Check code = \u0026quot; + r);\r}\r}\rOTP Auth协议 在实际使用中,通常把secret嵌入一段URL中并以二维码的形式发布,这个URL一般称为otpauth协议.其URL如下所示: otpauth://totp/testuser@testhost?secret=VGH25A7M54QPME5F\u0026amp;algorithm=SHA1\u0026amp;digits=6\u0026amp;period=30\n","date":"2018-01-08","permalink":"http://localhost:1313/post/totp%E7%AE%97%E6%B3%95java%E7%89%88%E6%9C%AC/","tags":["Java"],"title":"TOTP算法Java版本"},{"content":" 前段时间用vala开发了一个很小的程序,体验了一把vala的使用,网上关于vala的文章比较少,所以写一篇博客,如果你有相同的使用经验可以交流下.\n根据百度百科的解释，vala是一种新的、为GNOME开发者提供的具有现代化编程语言功能的一种编程语言。Vala是一种和C#极度类似的语言。\n众所周知,C是一门古老而落后的语言,虽然由于历史原因,大量的操作系统底层仍然在使用C(毕竟最早写底层的那批人早就退休甚至不在人世了,谁又愿意没事找事去重构呢.不过,还别说,Google就在干这种事,开发全新的操作系统),但并不适用于大型项目和协作开发.尽管Linux的作者Linus极度憎恨C++这样的面向对象的语言,并拒绝C++在Linux内核的使用.但是,Linux的其它开发者也心知肚明,C并不是一切,并且在Linux的各个方面大量使用C++和面向对象的开发模式.知名的KDE桌面就是基于QT来构建的,而QT是对C++的一个扩展,Linux上的大部分可用的应用都是基于QT来构建的,而另一个桌面环境Gnome则使用了GTK绑定,同时也大量使用了面向对象的特性和组件,比如Gobject,Vala.Vala的一个重要使用场景就是Gnome环境的GUI开发.\nVala语言的主要特点：支持lambda表达式；支持对象反射与内省；使用引用计数进行内存管理，计数嵌入在对象内；使用Glib和Gobject的主循环、事件回调系统。\n安装 在Ubuntu/Debian下安装很简单，使用命令sudo apt-get install valac，测试valac编译器的版本号，可以输入valac \u0026ndash;version命令。 我现在使用的是0.36版本,最新版本应该是0.40 Beta.\nHelloWorld程序 class Demo.HelloWorld : GLib.Object {\rpublic static int main(string[] args)\r{\rstdout.printf(\u0026quot;Hello, World\\n\u0026quot;);\rreturn 0;\r}\r}\r其实在Vala里,类并不是必须的.类名和文件名并不需要一致,并且一个类里允许多个类.\n编译运行 编译这个程序使用命令valac hello.vala，编译成功之后生成hello这个可执行程序，运行这个程序，输入结果为： Hello, World\nVala一个比较有趣的地方就是可以直接从Vala源码编译成C源码,比如上面的代码可以使用如下的命令编译成C源码\nvalac -C ./hello.vala\r生成的C源码如下:\n/* hello.c generated by valac 0.36.5, the Vala compiler\r* generated from hello.vala, do not modify */\r#include \u0026lt;glib.h\u0026gt;\r#include \u0026lt;glib-object.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\r#include \u0026lt;string.h\u0026gt;\r#include \u0026lt;stdio.h\u0026gt;\r#define DEMO_TYPE_HELLO_WORLD (demo_hello_world_get_type ())\r#define DEMO_HELLO_WORLD(obj) (G_TYPE_CHECK_INSTANCE_CAST ((obj), DEMO_TYPE_HELLO_WORLD, DemoHelloWorld))\r#define DEMO_HELLO_WORLD_CLASS(klass) (G_TYPE_CHECK_CLASS_CAST ((klass), DEMO_TYPE_HELLO_WORLD, DemoHelloWorldClass))\r#define DEMO_IS_HELLO_WORLD(obj) (G_TYPE_CHECK_INSTANCE_TYPE ((obj), DEMO_TYPE_HELLO_WORLD))\r#define DEMO_IS_HELLO_WORLD_CLASS(klass) (G_TYPE_CHECK_CLASS_TYPE ((klass), DEMO_TYPE_HELLO_WORLD))\r#define DEMO_HELLO_WORLD_GET_CLASS(obj) (G_TYPE_INSTANCE_GET_CLASS ((obj), DEMO_TYPE_HELLO_WORLD, DemoHelloWorldClass))\rtypedef struct _DemoHelloWorld DemoHelloWorld;\rtypedef struct _DemoHelloWorldClass DemoHelloWorldClass;\rtypedef struct _DemoHelloWorldPrivate DemoHelloWorldPrivate;\rstruct _DemoHelloWorld {\rGObject parent_instance;\rDemoHelloWorldPrivate * priv;\r};\rstruct _DemoHelloWorldClass {\rGObjectClass parent_class;\r};\rstatic gpointer demo_hello_world_parent_class = NULL;\rGType demo_hello_world_get_type (void) G_GNUC_CONST;\renum {\rDEMO_HELLO_WORLD_DUMMY_PROPERTY\r};\rgint demo_hello_world_main (gchar** args, int args_length1);\rDemoHelloWorld* demo_hello_world_new (void);\rDemoHelloWorld* demo_hello_world_construct (GType object_type);\rgint demo_hello_world_main (gchar** args, int args_length1) {\rgint result = 0;\rFILE* _tmp0_;\r_tmp0_ = stdout;\rfprintf (_tmp0_, \u0026quot;Hello, World\\n\u0026quot;);\rresult = 0;\rreturn result;\r}\rint main (int argc, char ** argv) {\r#if !GLIB_CHECK_VERSION (2,35,0)\rg_type_init ();\r#endif\rreturn demo_hello_world_main (argv, argc);\r}\rDemoHelloWorld* demo_hello_world_construct (GType object_type) {\rDemoHelloWorld * self = NULL;\rself = (DemoHelloWorld*) g_object_new (object_type, NULL);\rreturn self;\r}\rDemoHelloWorld* demo_hello_world_new (void) {\rreturn demo_hello_world_construct (DEMO_TYPE_HELLO_WORLD);\r}\rstatic void demo_hello_world_class_init (DemoHelloWorldClass * klass) {\rdemo_hello_world_parent_class = g_type_class_peek_parent (klass);\r}\rstatic void demo_hello_world_instance_init (DemoHelloWorld * self) {\r}\rGType demo_hello_world_get_type (void) {\rstatic volatile gsize demo_hello_world_type_id__volatile = 0;\rif (g_once_init_enter (\u0026amp;demo_hello_world_type_id__volatile)) {\rstatic const GTypeInfo g_define_type_info = { sizeof (DemoHelloWorldClass), (GBaseInitFunc) NULL, (GBaseFinalizeFunc) NULL, (GClassInitFunc) demo_hello_world_class_init, (GClassFinalizeFunc) NULL, NULL, sizeof (DemoHelloWorld), 0, (GInstanceInitFunc) demo_hello_world_instance_init, NULL };\rGType demo_hello_world_type_id;\rdemo_hello_world_type_id = g_type_register_static (G_TYPE_OBJECT, \u0026quot;DemoHelloWorld\u0026quot;, \u0026amp;g_define_type_info, 0);\rg_once_init_leave (\u0026amp;demo_hello_world_type_id__volatile, demo_hello_world_type_id);\r}\rreturn demo_hello_world_type_id__volatile;\r}\r可以看出 vala实际是把vala源码编译成GObject的语法,并且加入了很多语法糖.由于vala的这个特性,从而也决定了vala是一种性能比较高的语言.既能获得面向对象的便利,又能获得接近于C语言的性能.\nvala可以大量使用glib的库,具有比较强的表现力和较高的开发效率.然而由于其定位的问题,不能在服务端市场分得一杯羹,导致发展极为有限,可惜了这门在我看来,在Linux上开发体验仅次于C++和Java的语言.如果你接触过C++ 17 以上标准的C++,你就会感觉到C++的表现能力和开发效率,已经是一门比较现代化的语言了,并不会比脚本语言低多少.\n","date":"2018-01-08","permalink":"http://localhost:1313/post/vala%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C/","tags":["Vala"],"title":"Vala使用体验"}]